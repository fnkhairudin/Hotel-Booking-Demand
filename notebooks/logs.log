2023-07-27 20:54:34,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-27 20:54:34,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-27 20:54:34,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-27 20:54:34,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-27 20:54:38,623:INFO:PyCaret ClusteringExperiment
2023-07-27 20:54:38,624:INFO:Logging name: cluster-default-name
2023-07-27 20:54:38,624:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-27 20:54:38,625:INFO:version 3.0.4
2023-07-27 20:54:38,625:INFO:Initializing setup()
2023-07-27 20:54:38,625:INFO:self.USI: 0ace
2023-07-27 20:54:38,625:INFO:self._variable_keys: {'idx', 'memory', '_available_plots', 'pipeline', 'html_param', 'exp_id', 'gpu_param', 'log_plots_param', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'logging_param', '_ml_usecase', 'data', 'X', 'exp_name_log', 'USI'}
2023-07-27 20:54:38,625:INFO:Checking environment
2023-07-27 20:54:38,625:INFO:python_version: 3.9.13
2023-07-27 20:54:38,625:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-27 20:54:38,625:INFO:machine: AMD64
2023-07-27 20:54:38,625:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-27 20:54:38,628:INFO:Memory: svmem(total=17055166464, available=8718888960, percent=48.9, used=8336277504, free=8718888960)
2023-07-27 20:54:38,628:INFO:Physical Core: 4
2023-07-27 20:54:38,628:INFO:Logical Core: 8
2023-07-27 20:54:38,629:INFO:Checking libraries
2023-07-27 20:54:38,629:INFO:System:
2023-07-27 20:54:38,629:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-27 20:54:38,629:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-27 20:54:38,629:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-27 20:54:38,629:INFO:PyCaret required dependencies:
2023-07-27 20:54:38,631:INFO:                 pip: 22.0.4
2023-07-27 20:54:38,631:INFO:          setuptools: 58.1.0
2023-07-27 20:54:38,631:INFO:             pycaret: 3.0.4
2023-07-27 20:54:38,631:INFO:             IPython: 8.13.1
2023-07-27 20:54:38,632:INFO:          ipywidgets: 8.0.7
2023-07-27 20:54:38,632:INFO:                tqdm: 4.65.0
2023-07-27 20:54:38,632:INFO:               numpy: 1.23.0
2023-07-27 20:54:38,632:INFO:              pandas: 1.5.3
2023-07-27 20:54:38,632:INFO:              jinja2: 3.1.2
2023-07-27 20:54:38,632:INFO:               scipy: 1.10.1
2023-07-27 20:54:38,632:INFO:              joblib: 1.2.0
2023-07-27 20:54:38,632:INFO:             sklearn: 1.2.2
2023-07-27 20:54:38,632:INFO:                pyod: 1.1.0
2023-07-27 20:54:38,632:INFO:            imblearn: 0.11.0
2023-07-27 20:54:38,632:INFO:   category_encoders: 2.6.1
2023-07-27 20:54:38,632:INFO:            lightgbm: 3.3.5
2023-07-27 20:54:38,632:INFO:               numba: 0.57.1
2023-07-27 20:54:38,632:INFO:            requests: 2.31.0
2023-07-27 20:54:38,632:INFO:          matplotlib: 3.7.1
2023-07-27 20:54:38,632:INFO:          scikitplot: 0.3.7
2023-07-27 20:54:38,632:INFO:         yellowbrick: 1.5
2023-07-27 20:54:38,632:INFO:              plotly: 5.15.0
2023-07-27 20:54:38,632:INFO:    plotly-resampler: Not installed
2023-07-27 20:54:38,633:INFO:             kaleido: 0.2.1
2023-07-27 20:54:38,633:INFO:           schemdraw: 0.15
2023-07-27 20:54:38,633:INFO:         statsmodels: 0.14.0
2023-07-27 20:54:38,633:INFO:              sktime: 0.20.0
2023-07-27 20:54:38,633:INFO:               tbats: 1.1.3
2023-07-27 20:54:38,633:INFO:            pmdarima: 2.0.3
2023-07-27 20:54:38,633:INFO:              psutil: 5.9.5
2023-07-27 20:54:38,633:INFO:          markupsafe: 2.1.3
2023-07-27 20:54:38,633:INFO:             pickle5: Not installed
2023-07-27 20:54:38,633:INFO:         cloudpickle: 2.2.1
2023-07-27 20:54:38,633:INFO:         deprecation: 2.1.0
2023-07-27 20:54:38,633:INFO:              xxhash: 3.2.0
2023-07-27 20:54:38,633:INFO:           wurlitzer: Not installed
2023-07-27 20:54:38,633:INFO:PyCaret optional dependencies:
2023-07-27 20:54:38,651:INFO:                shap: Not installed
2023-07-27 20:54:38,651:INFO:           interpret: Not installed
2023-07-27 20:54:38,651:INFO:                umap: Not installed
2023-07-27 20:54:38,651:INFO:    pandas_profiling: 4.3.1
2023-07-27 20:54:38,651:INFO:  explainerdashboard: Not installed
2023-07-27 20:54:38,651:INFO:             autoviz: Not installed
2023-07-27 20:54:38,651:INFO:           fairlearn: Not installed
2023-07-27 20:54:38,651:INFO:          deepchecks: Not installed
2023-07-27 20:54:38,651:INFO:             xgboost: Not installed
2023-07-27 20:54:38,651:INFO:            catboost: Not installed
2023-07-27 20:54:38,651:INFO:              kmodes: Not installed
2023-07-27 20:54:38,651:INFO:             mlxtend: 0.22.0
2023-07-27 20:54:38,651:INFO:       statsforecast: Not installed
2023-07-27 20:54:38,651:INFO:        tune_sklearn: Not installed
2023-07-27 20:54:38,651:INFO:                 ray: Not installed
2023-07-27 20:54:38,652:INFO:            hyperopt: Not installed
2023-07-27 20:54:38,652:INFO:              optuna: Not installed
2023-07-27 20:54:38,652:INFO:               skopt: Not installed
2023-07-27 20:54:38,652:INFO:              mlflow: Not installed
2023-07-27 20:54:38,652:INFO:              gradio: Not installed
2023-07-27 20:54:38,652:INFO:             fastapi: Not installed
2023-07-27 20:54:38,652:INFO:             uvicorn: Not installed
2023-07-27 20:54:38,652:INFO:              m2cgen: Not installed
2023-07-27 20:54:38,652:INFO:           evidently: Not installed
2023-07-27 20:54:38,652:INFO:               fugue: Not installed
2023-07-27 20:54:38,652:INFO:           streamlit: Not installed
2023-07-27 20:54:38,652:INFO:             prophet: Not installed
2023-07-27 20:54:38,652:INFO:None
2023-07-27 20:54:38,652:INFO:Set up data.
2023-07-27 20:54:38,662:INFO:Set up index.
2023-07-27 20:54:38,662:INFO:Assigning column types.
2023-07-27 20:54:38,665:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-27 20:54:38,665:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-27 20:54:38,666:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:38,666:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-27 20:54:38,666:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:38,666:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-27 20:54:38,666:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:38,666:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:38,668:INFO:Preparing preprocessing pipeline...
2023-07-27 20:54:38,668:INFO:Set up simple imputation.
2023-07-27 20:54:38,671:INFO:Set up encoding of categorical features.
2023-07-27 20:54:38,853:INFO:Finished creating preprocessing pipeline.
2023-07-27 20:54:38,884:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['market_se...
                                             'customer_type',
                                             'reserved_room_type'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['market_segment', 'deposit_type',
                                             'customer_type',
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-07-27 20:54:38,884:INFO:Creating final display dataframe.
2023-07-27 20:54:39,001:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  4659
1        Original data shape            (10202, 9)
2     Transformed data shape           (10202, 30)
3           Numeric features                     5
4       Categorical features                     4
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9   Maximum one-hot encoding                    -1
10           Encoding method                  None
11                  CPU Jobs                    -1
12                   Use GPU                 False
13            Log Experiment                 False
14           Experiment Name  cluster-default-name
15                       USI                  0ace
2023-07-27 20:54:39,010:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:39,010:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:54:39,011:INFO:setup() successfully completed in 1.26s...............
2023-07-27 20:55:50,773:INFO:Initializing create_model()
2023-07-27 20:55:50,773:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-27 20:55:50,774:INFO:Checking exceptions
2023-07-27 20:55:51,114:INFO:Importing untrained model
2023-07-27 20:55:51,120:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:55:51,129:INFO:Fitting Model
2023-07-27 20:55:54,612:INFO:DBSCAN(n_jobs=-1)
2023-07-27 20:55:54,612:INFO:create_models() successfully completed......................................
2023-07-27 20:55:54,620:INFO:Uploading results into container
2023-07-27 20:55:54,626:INFO:Uploading model into container now
2023-07-27 20:55:54,638:INFO:_master_model_container: 1
2023-07-27 20:55:54,638:INFO:_display_container: 2
2023-07-27 20:55:54,638:INFO:DBSCAN(n_jobs=-1)
2023-07-27 20:55:54,638:INFO:create_model() successfully completed......................................
2023-07-27 20:56:33,262:INFO:Initializing create_model()
2023-07-27 20:56:33,262:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:56:33,262:INFO:Checking exceptions
2023-07-27 20:56:33,320:INFO:Importing untrained model
2023-07-27 20:56:33,327:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:56:33,337:INFO:Fitting Model
2023-07-27 20:56:36,426:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:56:36,427:INFO:create_models() successfully completed......................................
2023-07-27 20:56:36,434:INFO:Uploading results into container
2023-07-27 20:56:36,438:INFO:Uploading model into container now
2023-07-27 20:56:36,449:INFO:_master_model_container: 2
2023-07-27 20:56:36,449:INFO:_display_container: 3
2023-07-27 20:56:36,450:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:56:36,450:INFO:create_model() successfully completed......................................
2023-07-27 20:56:43,247:INFO:Initializing create_model()
2023-07-27 20:56:43,247:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.5})
2023-07-27 20:56:43,248:INFO:Checking exceptions
2023-07-27 20:56:43,330:INFO:Importing untrained model
2023-07-27 20:56:43,339:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:56:43,360:INFO:Fitting Model
2023-07-27 20:56:46,045:INFO:DBSCAN(n_jobs=-1)
2023-07-27 20:56:46,045:INFO:create_models() successfully completed......................................
2023-07-27 20:56:46,052:INFO:Uploading results into container
2023-07-27 20:56:46,057:INFO:Uploading model into container now
2023-07-27 20:56:46,066:INFO:_master_model_container: 3
2023-07-27 20:56:46,067:INFO:_display_container: 4
2023-07-27 20:56:46,067:INFO:DBSCAN(n_jobs=-1)
2023-07-27 20:56:46,068:INFO:create_model() successfully completed......................................
2023-07-27 20:56:49,553:INFO:Initializing create_model()
2023-07-27 20:56:49,553:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.8})
2023-07-27 20:56:49,554:INFO:Checking exceptions
2023-07-27 20:56:49,633:INFO:Importing untrained model
2023-07-27 20:56:49,643:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:56:49,654:INFO:Fitting Model
2023-07-27 20:56:52,838:INFO:DBSCAN(eps=0.8, n_jobs=-1)
2023-07-27 20:56:52,838:INFO:create_models() successfully completed......................................
2023-07-27 20:56:52,846:INFO:Uploading results into container
2023-07-27 20:56:52,850:INFO:Uploading model into container now
2023-07-27 20:56:52,858:INFO:_master_model_container: 4
2023-07-27 20:56:52,858:INFO:_display_container: 5
2023-07-27 20:56:52,858:INFO:DBSCAN(eps=0.8, n_jobs=-1)
2023-07-27 20:56:52,859:INFO:create_model() successfully completed......................................
2023-07-27 20:56:55,092:INFO:Initializing create_model()
2023-07-27 20:56:55,092:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.2})
2023-07-27 20:56:55,092:INFO:Checking exceptions
2023-07-27 20:56:55,153:INFO:Importing untrained model
2023-07-27 20:56:55,161:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:56:55,171:INFO:Fitting Model
2023-07-27 20:56:58,158:INFO:DBSCAN(eps=0.2, n_jobs=-1)
2023-07-27 20:56:58,158:INFO:create_models() successfully completed......................................
2023-07-27 20:56:58,170:INFO:Uploading results into container
2023-07-27 20:56:58,174:INFO:Uploading model into container now
2023-07-27 20:56:58,190:INFO:_master_model_container: 5
2023-07-27 20:56:58,190:INFO:_display_container: 6
2023-07-27 20:56:58,191:INFO:DBSCAN(eps=0.2, n_jobs=-1)
2023-07-27 20:56:58,192:INFO:create_model() successfully completed......................................
2023-07-27 20:57:16,822:INFO:Initializing create_model()
2023-07-27 20:57:16,822:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=62, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:57:16,822:INFO:Checking exceptions
2023-07-27 20:57:16,883:INFO:Importing untrained model
2023-07-27 20:57:16,891:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:57:16,903:INFO:Fitting Model
2023-07-27 20:57:19,901:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:19,902:INFO:create_models() successfully completed......................................
2023-07-27 20:57:19,910:INFO:Uploading results into container
2023-07-27 20:57:19,917:INFO:Uploading model into container now
2023-07-27 20:57:19,926:INFO:_master_model_container: 6
2023-07-27 20:57:19,926:INFO:_display_container: 7
2023-07-27 20:57:19,927:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:19,927:INFO:create_model() successfully completed......................................
2023-07-27 20:57:26,428:INFO:Initializing create_model()
2023-07-27 20:57:26,429:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=70, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:57:26,429:INFO:Checking exceptions
2023-07-27 20:57:26,520:INFO:Importing untrained model
2023-07-27 20:57:26,527:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:57:26,539:INFO:Fitting Model
2023-07-27 20:57:29,322:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:29,322:INFO:create_models() successfully completed......................................
2023-07-27 20:57:29,328:INFO:Uploading results into container
2023-07-27 20:57:29,333:INFO:Uploading model into container now
2023-07-27 20:57:29,343:INFO:_master_model_container: 7
2023-07-27 20:57:29,344:INFO:_display_container: 8
2023-07-27 20:57:29,344:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:29,345:INFO:create_model() successfully completed......................................
2023-07-27 20:57:32,982:INFO:Initializing create_model()
2023-07-27 20:57:32,982:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=80, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:57:32,982:INFO:Checking exceptions
2023-07-27 20:57:33,094:INFO:Importing untrained model
2023-07-27 20:57:33,106:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:57:33,120:INFO:Fitting Model
2023-07-27 20:57:36,010:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:36,010:INFO:create_models() successfully completed......................................
2023-07-27 20:57:36,018:INFO:Uploading results into container
2023-07-27 20:57:36,022:INFO:Uploading model into container now
2023-07-27 20:57:36,031:INFO:_master_model_container: 8
2023-07-27 20:57:36,031:INFO:_display_container: 9
2023-07-27 20:57:36,032:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:36,032:INFO:create_model() successfully completed......................................
2023-07-27 20:57:39,419:INFO:Initializing create_model()
2023-07-27 20:57:39,419:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=30, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:57:39,420:INFO:Checking exceptions
2023-07-27 20:57:39,500:INFO:Importing untrained model
2023-07-27 20:57:39,513:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:57:39,526:INFO:Fitting Model
2023-07-27 20:57:42,633:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:42,633:INFO:create_models() successfully completed......................................
2023-07-27 20:57:42,640:INFO:Uploading results into container
2023-07-27 20:57:42,645:INFO:Uploading model into container now
2023-07-27 20:57:42,662:INFO:_master_model_container: 9
2023-07-27 20:57:42,663:INFO:_display_container: 10
2023-07-27 20:57:42,666:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:42,666:INFO:create_model() successfully completed......................................
2023-07-27 20:57:54,321:INFO:Initializing create_model()
2023-07-27 20:57:54,321:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=dbscan, num_clusters=30, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:57:54,322:INFO:Checking exceptions
2023-07-27 20:57:54,400:INFO:Importing untrained model
2023-07-27 20:57:54,408:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:57:54,418:INFO:Fitting Model
2023-07-27 20:57:57,602:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:57,602:INFO:create_models() successfully completed......................................
2023-07-27 20:57:57,609:INFO:Uploading results into container
2023-07-27 20:57:57,615:INFO:Uploading model into container now
2023-07-27 20:57:57,636:INFO:_master_model_container: 10
2023-07-27 20:57:57,636:INFO:_display_container: 11
2023-07-27 20:57:57,637:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:57:57,637:INFO:create_model() successfully completed......................................
2023-07-27 20:57:59,900:INFO:Initializing evaluate_model()
2023-07-27 20:57:59,900:INFO:evaluate_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, estimator=DBSCAN(eps=0.3, n_jobs=-1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-07-27 20:58:00,016:INFO:Initializing plot_model()
2023-07-27 20:58:00,016:INFO:plot_model(plot=pipeline, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:58:00,016:INFO:Checking exceptions
2023-07-27 20:58:00,019:INFO:Preloading libraries
2023-07-27 20:58:00,020:INFO:Copying training dataset
2023-07-27 20:58:00,020:INFO:Plot type: pipeline
2023-07-27 20:58:00,711:INFO:Visual Rendered Successfully
2023-07-27 20:58:00,856:INFO:plot_model() successfully completed......................................
2023-07-27 20:58:04,634:INFO:Initializing plot_model()
2023-07-27 20:58:04,635:INFO:plot_model(plot=cluster, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:58:04,635:INFO:Checking exceptions
2023-07-27 20:58:04,637:INFO:Preloading libraries
2023-07-27 20:58:04,637:INFO:Copying training dataset
2023-07-27 20:58:04,638:INFO:Plot type: cluster
2023-07-27 20:58:04,638:INFO:SubProcess assign_model() called ==================================
2023-07-27 20:58:04,639:INFO:Initializing assign_model()
2023-07-27 20:58:04,639:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=True, score=True, verbose=False)
2023-07-27 20:58:04,639:INFO:Checking exceptions
2023-07-27 20:58:04,639:INFO:Determining Trained Model
2023-07-27 20:58:04,639:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 20:58:04,639:INFO:Copying data
2023-07-27 20:58:04,657:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-27 20:58:04,661:INFO:(10202, 31)
2023-07-27 20:58:04,661:INFO:assign_model() successfully completed......................................
2023-07-27 20:58:04,662:INFO:SubProcess assign_model() end ==================================
2023-07-27 20:58:04,666:INFO:Fitting PCA()
2023-07-27 20:58:04,890:INFO:Sorting dataframe
2023-07-27 20:58:04,897:INFO:Rendering Visual
2023-07-27 20:58:24,154:INFO:Visual Rendered Successfully
2023-07-27 20:58:24,357:INFO:plot_model() successfully completed......................................
2023-07-27 20:58:44,917:INFO:PyCaret ClusteringExperiment
2023-07-27 20:58:44,918:INFO:Logging name: cluster-default-name
2023-07-27 20:58:44,918:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-27 20:58:44,918:INFO:version 3.0.4
2023-07-27 20:58:44,918:INFO:Initializing setup()
2023-07-27 20:58:44,918:INFO:self.USI: f6fa
2023-07-27 20:58:44,918:INFO:self._variable_keys: {'idx', 'memory', '_available_plots', 'pipeline', 'html_param', 'exp_id', 'gpu_param', 'log_plots_param', 'seed', 'n_jobs_param', 'gpu_n_jobs_param', 'logging_param', '_ml_usecase', 'data', 'X', 'exp_name_log', 'USI'}
2023-07-27 20:58:44,919:INFO:Checking environment
2023-07-27 20:58:44,919:INFO:python_version: 3.9.13
2023-07-27 20:58:44,919:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-27 20:58:44,919:INFO:machine: AMD64
2023-07-27 20:58:44,919:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-27 20:58:44,924:INFO:Memory: svmem(total=17055166464, available=8646545408, percent=49.3, used=8408621056, free=8646545408)
2023-07-27 20:58:44,924:INFO:Physical Core: 4
2023-07-27 20:58:44,924:INFO:Logical Core: 8
2023-07-27 20:58:44,924:INFO:Checking libraries
2023-07-27 20:58:44,925:INFO:System:
2023-07-27 20:58:44,925:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-27 20:58:44,925:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-27 20:58:44,925:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-27 20:58:44,925:INFO:PyCaret required dependencies:
2023-07-27 20:58:44,925:INFO:                 pip: 22.0.4
2023-07-27 20:58:44,925:INFO:          setuptools: 58.1.0
2023-07-27 20:58:44,925:INFO:             pycaret: 3.0.4
2023-07-27 20:58:44,925:INFO:             IPython: 8.13.1
2023-07-27 20:58:44,925:INFO:          ipywidgets: 8.0.7
2023-07-27 20:58:44,925:INFO:                tqdm: 4.65.0
2023-07-27 20:58:44,925:INFO:               numpy: 1.23.0
2023-07-27 20:58:44,926:INFO:              pandas: 1.5.3
2023-07-27 20:58:44,926:INFO:              jinja2: 3.1.2
2023-07-27 20:58:44,926:INFO:               scipy: 1.10.1
2023-07-27 20:58:44,926:INFO:              joblib: 1.2.0
2023-07-27 20:58:44,926:INFO:             sklearn: 1.2.2
2023-07-27 20:58:44,926:INFO:                pyod: 1.1.0
2023-07-27 20:58:44,926:INFO:            imblearn: 0.11.0
2023-07-27 20:58:44,926:INFO:   category_encoders: 2.6.1
2023-07-27 20:58:44,926:INFO:            lightgbm: 3.3.5
2023-07-27 20:58:44,926:INFO:               numba: 0.57.1
2023-07-27 20:58:44,927:INFO:            requests: 2.31.0
2023-07-27 20:58:44,927:INFO:          matplotlib: 3.7.1
2023-07-27 20:58:44,927:INFO:          scikitplot: 0.3.7
2023-07-27 20:58:44,927:INFO:         yellowbrick: 1.5
2023-07-27 20:58:44,927:INFO:              plotly: 5.15.0
2023-07-27 20:58:44,927:INFO:    plotly-resampler: Not installed
2023-07-27 20:58:44,927:INFO:             kaleido: 0.2.1
2023-07-27 20:58:44,927:INFO:           schemdraw: 0.15
2023-07-27 20:58:44,927:INFO:         statsmodels: 0.14.0
2023-07-27 20:58:44,927:INFO:              sktime: 0.20.0
2023-07-27 20:58:44,927:INFO:               tbats: 1.1.3
2023-07-27 20:58:44,927:INFO:            pmdarima: 2.0.3
2023-07-27 20:58:44,927:INFO:              psutil: 5.9.5
2023-07-27 20:58:44,928:INFO:          markupsafe: 2.1.3
2023-07-27 20:58:44,928:INFO:             pickle5: Not installed
2023-07-27 20:58:44,928:INFO:         cloudpickle: 2.2.1
2023-07-27 20:58:44,928:INFO:         deprecation: 2.1.0
2023-07-27 20:58:44,928:INFO:              xxhash: 3.2.0
2023-07-27 20:58:44,928:INFO:           wurlitzer: Not installed
2023-07-27 20:58:44,928:INFO:PyCaret optional dependencies:
2023-07-27 20:58:44,928:INFO:                shap: Not installed
2023-07-27 20:58:44,928:INFO:           interpret: Not installed
2023-07-27 20:58:44,928:INFO:                umap: Not installed
2023-07-27 20:58:44,928:INFO:    pandas_profiling: 4.3.1
2023-07-27 20:58:44,928:INFO:  explainerdashboard: Not installed
2023-07-27 20:58:44,928:INFO:             autoviz: Not installed
2023-07-27 20:58:44,929:INFO:           fairlearn: Not installed
2023-07-27 20:58:44,929:INFO:          deepchecks: Not installed
2023-07-27 20:58:44,929:INFO:             xgboost: Not installed
2023-07-27 20:58:44,929:INFO:            catboost: Not installed
2023-07-27 20:58:44,929:INFO:              kmodes: Not installed
2023-07-27 20:58:44,929:INFO:             mlxtend: 0.22.0
2023-07-27 20:58:44,929:INFO:       statsforecast: Not installed
2023-07-27 20:58:44,929:INFO:        tune_sklearn: Not installed
2023-07-27 20:58:44,929:INFO:                 ray: Not installed
2023-07-27 20:58:44,930:INFO:            hyperopt: Not installed
2023-07-27 20:58:44,930:INFO:              optuna: Not installed
2023-07-27 20:58:44,930:INFO:               skopt: Not installed
2023-07-27 20:58:44,930:INFO:              mlflow: Not installed
2023-07-27 20:58:44,930:INFO:              gradio: Not installed
2023-07-27 20:58:44,930:INFO:             fastapi: Not installed
2023-07-27 20:58:44,930:INFO:             uvicorn: Not installed
2023-07-27 20:58:44,930:INFO:              m2cgen: Not installed
2023-07-27 20:58:44,930:INFO:           evidently: Not installed
2023-07-27 20:58:44,931:INFO:               fugue: Not installed
2023-07-27 20:58:44,931:INFO:           streamlit: Not installed
2023-07-27 20:58:44,931:INFO:             prophet: Not installed
2023-07-27 20:58:44,931:INFO:None
2023-07-27 20:58:44,931:INFO:Set up data.
2023-07-27 20:58:44,953:INFO:Set up index.
2023-07-27 20:58:44,954:INFO:Assigning column types.
2023-07-27 20:58:44,958:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-27 20:58:44,959:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-27 20:58:44,959:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:44,959:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-27 20:58:44,959:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:44,959:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-27 20:58:44,960:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:44,960:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:44,962:INFO:Preparing preprocessing pipeline...
2023-07-27 20:58:44,962:INFO:Set up simple imputation.
2023-07-27 20:58:44,965:INFO:Set up encoding of categorical features.
2023-07-27 20:58:44,966:INFO:Set up feature normalization.
2023-07-27 20:58:45,048:INFO:Finished creating preprocessing pipeline.
2023-07-27 20:58:45,056:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['market_se...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['market_segment', 'deposit_type',
                                             'customer_type',
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-07-27 20:58:45,056:INFO:Creating final display dataframe.
2023-07-27 20:58:45,124:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  1156
1        Original data shape            (10202, 9)
2     Transformed data shape           (10202, 30)
3           Numeric features                     5
4       Categorical features                     4
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9   Maximum one-hot encoding                    -1
10           Encoding method                  None
11                 Normalize                  True
12          Normalize method                zscore
13                  CPU Jobs                    -1
14                   Use GPU                 False
15            Log Experiment                 False
16           Experiment Name  cluster-default-name
17                       USI                  f6fa
2023-07-27 20:58:45,133:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:45,134:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-27 20:58:45,136:INFO:setup() successfully completed in 1.0s...............
2023-07-27 20:58:59,940:INFO:Initializing create_model()
2023-07-27 20:58:59,941:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=30, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:58:59,941:INFO:Checking exceptions
2023-07-27 20:59:00,239:INFO:Importing untrained model
2023-07-27 20:59:00,247:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:59:00,258:INFO:Fitting Model
2023-07-27 20:59:03,342:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:59:03,342:INFO:create_models() successfully completed......................................
2023-07-27 20:59:03,348:INFO:Uploading results into container
2023-07-27 20:59:03,352:INFO:Uploading model into container now
2023-07-27 20:59:03,362:INFO:_master_model_container: 1
2023-07-27 20:59:03,363:INFO:_display_container: 2
2023-07-27 20:59:03,363:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:59:03,363:INFO:create_model() successfully completed......................................
2023-07-27 20:59:10,114:INFO:Initializing create_model()
2023-07-27 20:59:10,114:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=62, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 20:59:10,114:INFO:Checking exceptions
2023-07-27 20:59:10,191:INFO:Importing untrained model
2023-07-27 20:59:10,200:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 20:59:10,214:INFO:Fitting Model
2023-07-27 20:59:13,258:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:59:13,258:INFO:create_models() successfully completed......................................
2023-07-27 20:59:13,266:INFO:Uploading results into container
2023-07-27 20:59:13,272:INFO:Uploading model into container now
2023-07-27 20:59:13,285:INFO:_master_model_container: 2
2023-07-27 20:59:13,286:INFO:_display_container: 3
2023-07-27 20:59:13,286:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 20:59:13,286:INFO:create_model() successfully completed......................................
2023-07-27 20:59:14,586:INFO:Initializing plot_model()
2023-07-27 20:59:14,587:INFO:plot_model(plot=elbow, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:14,587:INFO:Checking exceptions
2023-07-27 20:59:14,589:INFO:Preloading libraries
2023-07-27 20:59:14,590:INFO:Copying training dataset
2023-07-27 20:59:14,590:INFO:Plot type: elbow
2023-07-27 20:59:14,833:INFO:Fitting Model
2023-07-27 20:59:14,834:ERROR:Elbow plot failed. Exception:
2023-07-27 20:59:14,882:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1053, in elbow
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\elbow.py", line 338, in fit
    self.estimator.set_params(n_clusters=k)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py", line 205, in set_params
    raise ValueError(
ValueError: Invalid parameter 'n_clusters' for estimator DBSCAN(eps=0.3, n_jobs=-1). Valid parameters are: ['algorithm', 'eps', 'leaf_size', 'metric', 'metric_params', 'min_samples', 'n_jobs', 'p'].

2023-07-27 20:59:18,290:INFO:Initializing plot_model()
2023-07-27 20:59:18,291:INFO:plot_model(plot=silhouette, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:18,291:INFO:Checking exceptions
2023-07-27 20:59:18,293:INFO:Preloading libraries
2023-07-27 20:59:18,294:INFO:Copying training dataset
2023-07-27 20:59:18,294:INFO:Plot type: silhouette
2023-07-27 20:59:18,310:INFO:Fitting Model
2023-07-27 20:59:18,310:ERROR:Silhouette plot failed. Exception:
2023-07-27 20:59:18,344:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1079, in silhouette
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\silhouette.py", line 142, in fit
    self.n_clusters_ = self.estimator.n_clusters
AttributeError: 'DBSCAN' object has no attribute 'n_clusters'

2023-07-27 20:59:20,365:INFO:Initializing plot_model()
2023-07-27 20:59:20,366:INFO:plot_model(plot=distance, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:20,366:INFO:Checking exceptions
2023-07-27 20:59:20,367:INFO:Preloading libraries
2023-07-27 20:59:20,368:INFO:Copying training dataset
2023-07-27 20:59:20,368:INFO:Plot type: distance
2023-07-27 20:59:20,412:INFO:Fitting Model
2023-07-27 20:59:20,412:ERROR:Distance plot failed. Exception:
2023-07-27 20:59:20,455:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\utils\wrapper.py", line 48, in __getattr__
    return getattr(self._wrapped, attr)
AttributeError: 'DBSCAN' object has no attribute 'cluster_centers_'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1102, in distance
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\icdm.py", line 291, in fit
    C = self.cluster_centers_
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\utils\wrapper.py", line 50, in __getattr__
    raise YellowbrickAttributeError(f"neither visualizer '{self.__class__.__name__}' nor wrapped estimator '{type(self._wrapped).__name__}' have attribute '{attr}'") from e
yellowbrick.exceptions.YellowbrickAttributeError: neither visualizer 'InterclusterDistance' nor wrapped estimator 'DBSCAN' have attribute 'cluster_centers_'

2023-07-27 20:59:21,960:INFO:Initializing plot_model()
2023-07-27 20:59:21,960:INFO:plot_model(plot=distribution, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:21,961:INFO:Checking exceptions
2023-07-27 20:59:21,963:INFO:Preloading libraries
2023-07-27 20:59:21,964:INFO:Copying training dataset
2023-07-27 20:59:21,965:INFO:Plot type: distribution
2023-07-27 20:59:21,965:INFO:SubProcess assign_model() called ==================================
2023-07-27 20:59:21,966:INFO:Initializing assign_model()
2023-07-27 20:59:21,966:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=False)
2023-07-27 20:59:21,966:INFO:Checking exceptions
2023-07-27 20:59:21,966:INFO:Determining Trained Model
2023-07-27 20:59:21,966:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 20:59:21,966:INFO:Copying data
2023-07-27 20:59:21,972:INFO:(10202, 10)
2023-07-27 20:59:21,972:INFO:assign_model() successfully completed......................................
2023-07-27 20:59:21,973:INFO:SubProcess assign_model() end ==================================
2023-07-27 20:59:21,973:INFO:Sorting dataframe
2023-07-27 20:59:22,000:INFO:Rendering Visual
2023-07-27 20:59:27,695:INFO:Visual Rendered Successfully
2023-07-27 20:59:27,842:INFO:plot_model() successfully completed......................................
2023-07-27 20:59:36,116:INFO:Initializing plot_model()
2023-07-27 20:59:36,116:INFO:plot_model(plot=elbow, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:36,117:INFO:Checking exceptions
2023-07-27 20:59:36,118:INFO:Preloading libraries
2023-07-27 20:59:36,119:INFO:Copying training dataset
2023-07-27 20:59:36,120:INFO:Plot type: elbow
2023-07-27 20:59:36,149:INFO:Fitting Model
2023-07-27 20:59:36,149:ERROR:Elbow plot failed. Exception:
2023-07-27 20:59:36,150:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1053, in elbow
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\elbow.py", line 338, in fit
    self.estimator.set_params(n_clusters=k)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py", line 205, in set_params
    raise ValueError(
ValueError: Invalid parameter 'n_clusters' for estimator DBSCAN(eps=0.3, n_jobs=-1). Valid parameters are: ['algorithm', 'eps', 'leaf_size', 'metric', 'metric_params', 'min_samples', 'n_jobs', 'p'].

2023-07-27 20:59:38,184:INFO:Initializing plot_model()
2023-07-27 20:59:38,185:INFO:plot_model(plot=silhouette, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:38,185:INFO:Checking exceptions
2023-07-27 20:59:38,187:INFO:Preloading libraries
2023-07-27 20:59:38,189:INFO:Copying training dataset
2023-07-27 20:59:38,189:INFO:Plot type: silhouette
2023-07-27 20:59:38,220:INFO:Fitting Model
2023-07-27 20:59:38,220:ERROR:Silhouette plot failed. Exception:
2023-07-27 20:59:38,221:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1079, in silhouette
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\silhouette.py", line 142, in fit
    self.n_clusters_ = self.estimator.n_clusters
AttributeError: 'DBSCAN' object has no attribute 'n_clusters'

2023-07-27 20:59:39,542:INFO:Initializing plot_model()
2023-07-27 20:59:39,542:INFO:plot_model(plot=tsne, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 20:59:39,542:INFO:Checking exceptions
2023-07-27 20:59:39,543:INFO:Preloading libraries
2023-07-27 20:59:39,544:INFO:Copying training dataset
2023-07-27 20:59:39,544:INFO:Plot type: tsne
2023-07-27 20:59:39,544:INFO:SubProcess assign_model() called ==================================
2023-07-27 20:59:39,545:INFO:Initializing assign_model()
2023-07-27 20:59:39,545:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=True, score=False, verbose=False)
2023-07-27 20:59:39,545:INFO:Checking exceptions
2023-07-27 20:59:39,545:INFO:Determining Trained Model
2023-07-27 20:59:39,545:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 20:59:39,545:INFO:Copying data
2023-07-27 20:59:39,565:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-27 20:59:39,571:INFO:(10202, 31)
2023-07-27 20:59:39,571:INFO:assign_model() successfully completed......................................
2023-07-27 20:59:39,573:INFO:SubProcess assign_model() end ==================================
2023-07-27 20:59:39,575:INFO:Fitting TSNE()
2023-07-27 21:01:21,385:INFO:Initializing create_model()
2023-07-27 21:01:21,385:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 21:01:21,386:INFO:Checking exceptions
2023-07-27 21:01:21,479:INFO:Importing untrained model
2023-07-27 21:01:21,488:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:01:21,500:INFO:Fitting Model
2023-07-27 21:01:24,885:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:24,885:INFO:create_models() successfully completed......................................
2023-07-27 21:01:24,893:INFO:Uploading results into container
2023-07-27 21:01:24,898:INFO:Uploading model into container now
2023-07-27 21:01:24,912:INFO:_master_model_container: 3
2023-07-27 21:01:24,913:INFO:_display_container: 4
2023-07-27 21:01:24,913:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:24,913:INFO:create_model() successfully completed......................................
2023-07-27 21:01:26,057:INFO:Initializing plot_model()
2023-07-27 21:01:26,057:INFO:plot_model(plot=pipeline, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 21:01:26,057:INFO:Checking exceptions
2023-07-27 21:01:26,059:INFO:Preloading libraries
2023-07-27 21:01:26,060:INFO:Copying training dataset
2023-07-27 21:01:26,060:INFO:Plot type: pipeline
2023-07-27 21:01:26,193:INFO:Visual Rendered Successfully
2023-07-27 21:01:26,403:INFO:plot_model() successfully completed......................................
2023-07-27 21:01:30,501:INFO:Initializing plot_model()
2023-07-27 21:01:30,501:INFO:plot_model(plot=cluster, fold=None, verbose=False, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, system=True)
2023-07-27 21:01:30,502:INFO:Checking exceptions
2023-07-27 21:01:30,503:INFO:Preloading libraries
2023-07-27 21:01:30,504:INFO:Copying training dataset
2023-07-27 21:01:30,505:INFO:Plot type: cluster
2023-07-27 21:01:30,505:INFO:SubProcess assign_model() called ==================================
2023-07-27 21:01:30,506:INFO:Initializing assign_model()
2023-07-27 21:01:30,506:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418B962FA0>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=True, score=True, verbose=False)
2023-07-27 21:01:30,506:INFO:Checking exceptions
2023-07-27 21:01:30,506:INFO:Determining Trained Model
2023-07-27 21:01:30,507:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:01:30,507:INFO:Copying data
2023-07-27 21:01:30,529:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-27 21:01:30,534:INFO:(10202, 31)
2023-07-27 21:01:30,534:INFO:assign_model() successfully completed......................................
2023-07-27 21:01:30,535:INFO:SubProcess assign_model() end ==================================
2023-07-27 21:01:30,540:INFO:Fitting PCA()
2023-07-27 21:01:30,588:INFO:Sorting dataframe
2023-07-27 21:01:30,600:INFO:Rendering Visual
2023-07-27 21:01:33,401:INFO:Visual Rendered Successfully
2023-07-27 21:01:33,535:INFO:plot_model() successfully completed......................................
2023-07-27 21:01:48,587:INFO:Initializing create_model()
2023-07-27 21:01:48,587:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 21:01:48,587:INFO:Checking exceptions
2023-07-27 21:01:48,646:INFO:Importing untrained model
2023-07-27 21:01:48,654:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:01:48,664:INFO:Fitting Model
2023-07-27 21:01:51,508:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:51,508:INFO:create_models() successfully completed......................................
2023-07-27 21:01:51,517:INFO:Uploading results into container
2023-07-27 21:01:51,522:INFO:Uploading model into container now
2023-07-27 21:01:51,534:INFO:_master_model_container: 4
2023-07-27 21:01:51,535:INFO:_display_container: 5
2023-07-27 21:01:51,536:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:51,536:INFO:create_model() successfully completed......................................
2023-07-27 21:01:55,550:INFO:Initializing create_model()
2023-07-27 21:01:55,550:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=5, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 21:01:55,550:INFO:Checking exceptions
2023-07-27 21:01:55,641:INFO:Importing untrained model
2023-07-27 21:01:55,653:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:01:55,667:INFO:Fitting Model
2023-07-27 21:01:58,790:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:58,790:INFO:create_models() successfully completed......................................
2023-07-27 21:01:58,798:INFO:Uploading results into container
2023-07-27 21:01:58,802:INFO:Uploading model into container now
2023-07-27 21:01:58,812:INFO:_master_model_container: 5
2023-07-27 21:01:58,813:INFO:_display_container: 6
2023-07-27 21:01:58,814:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:01:58,814:INFO:create_model() successfully completed......................................
2023-07-27 21:02:02,943:INFO:Initializing create_model()
2023-07-27 21:02:02,943:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=10, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 21:02:02,944:INFO:Checking exceptions
2023-07-27 21:02:03,068:INFO:Importing untrained model
2023-07-27 21:02:03,081:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:02:03,099:INFO:Fitting Model
2023-07-27 21:02:06,366:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:02:06,366:INFO:create_models() successfully completed......................................
2023-07-27 21:02:06,376:INFO:Uploading results into container
2023-07-27 21:02:06,382:INFO:Uploading model into container now
2023-07-27 21:02:06,395:INFO:_master_model_container: 6
2023-07-27 21:02:06,395:INFO:_display_container: 7
2023-07-27 21:02:06,396:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:02:06,396:INFO:create_model() successfully completed......................................
2023-07-27 21:02:26,761:INFO:Initializing create_model()
2023-07-27 21:02:26,762:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=10, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-27 21:02:26,762:INFO:Checking exceptions
2023-07-27 21:02:26,856:INFO:Importing untrained model
2023-07-27 21:02:26,868:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:02:26,880:INFO:Fitting Model
2023-07-27 21:02:30,272:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-27 21:02:30,272:INFO:create_models() successfully completed......................................
2023-07-27 21:02:30,282:INFO:Uploading results into container
2023-07-27 21:02:30,287:INFO:Uploading model into container now
2023-07-27 21:02:30,300:INFO:_master_model_container: 7
2023-07-27 21:02:30,300:INFO:_display_container: 8
2023-07-27 21:02:30,301:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-27 21:02:30,301:INFO:create_model() successfully completed......................................
2023-07-27 21:02:36,184:INFO:Initializing create_model()
2023-07-27 21:02:36,184:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, estimator=dbscan, num_clusters=10, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-27 21:02:36,184:INFO:Checking exceptions
2023-07-27 21:02:36,254:INFO:Importing untrained model
2023-07-27 21:02:36,263:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-27 21:02:36,275:INFO:Fitting Model
2023-07-27 21:02:39,144:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:02:39,145:INFO:create_models() successfully completed......................................
2023-07-27 21:02:39,155:INFO:Uploading results into container
2023-07-27 21:02:39,163:INFO:Uploading model into container now
2023-07-27 21:02:39,180:INFO:_master_model_container: 8
2023-07-27 21:02:39,180:INFO:_display_container: 9
2023-07-27 21:02:39,181:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-27 21:02:39,181:INFO:create_model() successfully completed......................................
2023-07-27 21:03:55,058:INFO:Initializing plot_model()
2023-07-27 21:03:55,058:INFO:plot_model(plot=tsne, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, system=True)
2023-07-27 21:03:55,058:INFO:Checking exceptions
2023-07-27 21:03:55,065:INFO:Preloading libraries
2023-07-27 21:03:55,066:INFO:Copying training dataset
2023-07-27 21:03:55,067:INFO:Plot type: tsne
2023-07-27 21:03:55,067:INFO:SubProcess assign_model() called ==================================
2023-07-27 21:03:55,068:INFO:Initializing assign_model()
2023-07-27 21:03:55,068:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=True, score=False, verbose=False)
2023-07-27 21:03:55,068:INFO:Checking exceptions
2023-07-27 21:03:55,068:INFO:Determining Trained Model
2023-07-27 21:03:55,069:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:03:55,069:INFO:Copying data
2023-07-27 21:03:55,108:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-27 21:03:55,116:INFO:(10202, 31)
2023-07-27 21:03:55,116:INFO:assign_model() successfully completed......................................
2023-07-27 21:03:55,118:INFO:SubProcess assign_model() end ==================================
2023-07-27 21:03:55,121:INFO:Fitting TSNE()
2023-07-27 21:04:15,433:INFO:Initializing plot_model()
2023-07-27 21:04:15,434:INFO:plot_model(plot=elbow, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, system=True)
2023-07-27 21:04:15,434:INFO:Checking exceptions
2023-07-27 21:04:15,440:INFO:Preloading libraries
2023-07-27 21:04:15,442:INFO:Copying training dataset
2023-07-27 21:04:15,442:INFO:Plot type: elbow
2023-07-27 21:04:15,485:INFO:Fitting Model
2023-07-27 21:04:15,486:ERROR:Elbow plot failed. Exception:
2023-07-27 21:04:15,487:ERROR:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1053, in elbow
    return show_yellowbrick_plot(
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\yellowbrick\cluster\elbow.py", line 338, in fit
    self.estimator.set_params(n_clusters=k)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py", line 205, in set_params
    raise ValueError(
ValueError: Invalid parameter 'n_clusters' for estimator DBSCAN(eps=0.3, n_jobs=-1). Valid parameters are: ['algorithm', 'eps', 'leaf_size', 'metric', 'metric_params', 'min_samples', 'n_jobs', 'p'].

2023-07-27 21:04:29,374:INFO:Initializing plot_model()
2023-07-27 21:04:29,374:INFO:plot_model(plot=cluster, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.3, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, system=True)
2023-07-27 21:04:29,374:INFO:Checking exceptions
2023-07-27 21:04:29,382:INFO:Preloading libraries
2023-07-27 21:04:29,384:INFO:Copying training dataset
2023-07-27 21:04:29,385:INFO:Plot type: cluster
2023-07-27 21:04:29,385:INFO:SubProcess assign_model() called ==================================
2023-07-27 21:04:29,385:INFO:Initializing assign_model()
2023-07-27 21:04:29,385:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=True, score=True, verbose=False)
2023-07-27 21:04:29,386:INFO:Checking exceptions
2023-07-27 21:04:29,386:INFO:Determining Trained Model
2023-07-27 21:04:29,386:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:04:29,386:INFO:Copying data
2023-07-27 21:04:29,422:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-27 21:04:29,435:INFO:(10202, 31)
2023-07-27 21:04:29,435:INFO:assign_model() successfully completed......................................
2023-07-27 21:04:29,437:INFO:SubProcess assign_model() end ==================================
2023-07-27 21:04:29,445:INFO:Fitting PCA()
2023-07-27 21:04:29,513:INFO:Sorting dataframe
2023-07-27 21:04:29,528:INFO:Rendering Visual
2023-07-27 21:04:32,408:INFO:Visual Rendered Successfully
2023-07-27 21:04:32,585:INFO:plot_model() successfully completed......................................
2023-07-27 21:05:35,947:INFO:Initializing get_config()
2023-07-27 21:05:35,948:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, variable=None)
2023-07-27 21:05:50,603:INFO:Initializing get_config()
2023-07-27 21:05:50,603:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, variable=train_transformed)
2023-07-27 21:05:50,662:INFO:Variable: train returned as        market_segment_Offline TA/TO  market_segment_Online TA  \
0                          2.425684                 -0.969871   
1                         -0.412255                  1.031065   
2                         -0.412255                  1.031065   
3                         -0.412255                  1.031065   
4                         -0.412255                  1.031065   
...                             ...                       ...   
83515                     -0.412255                 -0.969871   
83543                     -0.412255                  1.031065   
83554                     -0.412255                 -0.969871   
83562                     -0.412255                  1.031065   
83565                      2.425684                 -0.969871   

       market_segment_Direct  market_segment_Groups  market_segment_Corporate  \
0                  -0.514602              -0.301092                 -0.233622   
1                  -0.514602              -0.301092                 -0.233622   
2                  -0.514602              -0.301092                 -0.233622   
3                  -0.514602              -0.301092                 -0.233622   
4                  -0.514602              -0.301092                 -0.233622   
...                      ...                    ...                       ...   
83515               1.943249              -0.301092                 -0.233622   
83543              -0.514602              -0.301092                 -0.233622   
83554              -0.514602               3.321244                 -0.233622   
83562              -0.514602              -0.301092                 -0.233622   
83565              -0.514602              -0.301092                 -0.233622   

       market_segment_Complementary  market_segment_Aviation  \
0                         -0.134395                 -0.08946   
1                         -0.134395                 -0.08946   
2                         -0.134395                 -0.08946   
3                         -0.134395                 -0.08946   
4                         -0.134395                 -0.08946   
...                             ...                      ...   
83515                     -0.134395                 -0.08946   
83543                     -0.134395                 -0.08946   
83554                     -0.134395                 -0.08946   
83562                     -0.134395                 -0.08946   
83565                     -0.134395                 -0.08946   

       market_segment_Undefined  previous_cancellations  booking_changes  ...  \
0                     -0.009901               -0.107789        -0.614804  ...   
1                     -0.009901               -0.107789        -0.614804  ...   
2                     -0.009901               -0.107789         0.158495  ...   
3                     -0.009901               -0.107789        -0.614804  ...   
4                     -0.009901               -0.107789         0.931795  ...   
...                         ...                     ...              ...  ...   
83515                 -0.009901               -0.107789         0.931795  ...   
83543                 -0.009901               -0.107789        -0.614804  ...   
83554                 -0.009901               -0.107789        -0.614804  ...   
83562                 -0.009901               -0.107789        -0.614804  ...   
83565                 -0.009901               -0.107789        -0.614804  ...   

       reserved_room_type_D  reserved_room_type_F  reserved_room_type_B  \
0                 -0.500245              -0.27556             -0.215809   
1                 -0.500245              -0.27556             -0.215809   
2                 -0.500245              -0.27556             -0.215809   
3                 -0.500245              -0.27556             -0.215809   
4                 -0.500245              -0.27556             -0.215809   
...                     ...                   ...                   ...   
83515             -0.500245              -0.27556             -0.215809   
83543             -0.500245              -0.27556             -0.215809   
83554             -0.500245              -0.27556             -0.215809   
83562             -0.500245              -0.27556              4.633720   
83565             -0.500245              -0.27556             -0.215809   

       reserved_room_type_G  reserved_room_type_C  reserved_room_type_H  \
0                 -0.239398             -0.185677             -0.138495   
1                 -0.239398             -0.185677             -0.138495   
2                 -0.239398             -0.185677             -0.138495   
3                 -0.239398             -0.185677             -0.138495   
4                 -0.239398             -0.185677             -0.138495   
...                     ...                   ...                   ...   
83515             -0.239398             -0.185677             -0.138495   
83543             -0.239398              5.385711             -0.138495   
83554             -0.239398             -0.185677             -0.138495   
83562             -0.239398             -0.185677             -0.138495   
83565             -0.239398             -0.185677             -0.138495   

       reserved_room_type_L  reserved_room_type_P  \
0                 -0.014003             -0.019805   
1                 -0.014003             -0.019805   
2                 -0.014003             -0.019805   
3                 -0.014003             -0.019805   
4                 -0.014003             -0.019805   
...                     ...                   ...   
83515             -0.014003             -0.019805   
83543             -0.014003             -0.019805   
83554             -0.014003             -0.019805   
83562             -0.014003             -0.019805   
83565             -0.014003             -0.019805   

       required_car_parking_spaces  total_of_special_requests  
0                        -0.424396                  -0.906789  
1                        -0.424396                   1.020114  
2                        -0.424396                   1.020114  
3                        -0.424396                   0.056662  
4                        -0.424396                   1.020114  
...                            ...                        ...  
83515                     2.115010                   0.056662  
83543                    -0.424396                   1.020114  
83554                    -0.424396                   0.056662  
83562                    -0.424396                  -0.906789  
83565                    -0.424396                   1.020114  

[10202 rows x 30 columns]
2023-07-27 21:05:50,662:INFO:get_config() successfully completed......................................
2023-07-27 21:06:08,212:INFO:Initializing get_config()
2023-07-27 21:06:08,212:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, variable=None)
2023-07-27 21:06:53,271:INFO:Initializing assign_model()
2023-07-27 21:06:53,272:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-27 21:06:53,273:INFO:Checking exceptions
2023-07-27 21:06:53,274:INFO:Determining Trained Model
2023-07-27 21:06:53,274:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:06:53,274:INFO:Copying data
2023-07-27 21:06:53,288:INFO:(10202, 10)
2023-07-27 21:06:53,288:INFO:assign_model() successfully completed......................................
2023-07-27 21:07:24,872:INFO:Initializing assign_model()
2023-07-27 21:07:24,872:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-27 21:07:24,873:INFO:Checking exceptions
2023-07-27 21:07:24,874:INFO:Determining Trained Model
2023-07-27 21:07:24,875:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:07:24,875:INFO:Copying data
2023-07-27 21:07:24,888:INFO:(10202, 10)
2023-07-27 21:07:24,889:INFO:assign_model() successfully completed......................................
2023-07-27 21:07:36,968:INFO:Initializing assign_model()
2023-07-27 21:07:36,969:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-27 21:07:36,969:INFO:Checking exceptions
2023-07-27 21:07:36,969:INFO:Determining Trained Model
2023-07-27 21:07:36,970:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:07:36,970:INFO:Copying data
2023-07-27 21:07:36,985:INFO:(10202, 10)
2023-07-27 21:07:36,985:INFO:assign_model() successfully completed......................................
2023-07-27 21:08:09,904:INFO:Initializing assign_model()
2023-07-27 21:08:09,904:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-27 21:08:09,904:INFO:Checking exceptions
2023-07-27 21:08:09,904:INFO:Determining Trained Model
2023-07-27 21:08:09,905:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:08:09,905:INFO:Copying data
2023-07-27 21:08:09,912:INFO:(10202, 10)
2023-07-27 21:08:09,913:INFO:assign_model() successfully completed......................................
2023-07-27 21:08:21,773:INFO:Initializing assign_model()
2023-07-27 21:08:21,774:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000002418D2D9700>, model=DBSCAN(eps=0.3, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-27 21:08:21,774:INFO:Checking exceptions
2023-07-27 21:08:21,774:INFO:Determining Trained Model
2023-07-27 21:08:21,775:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-27 21:08:21,775:INFO:Copying data
2023-07-27 21:08:21,785:INFO:(10202, 10)
2023-07-27 21:08:21,785:INFO:assign_model() successfully completed......................................
2023-07-28 21:31:39,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-28 21:31:39,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-28 21:31:39,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-28 21:31:39,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-28 21:31:40,630:INFO:PyCaret ClusteringExperiment
2023-07-28 21:31:40,630:INFO:Logging name: cluster-default-name
2023-07-28 21:31:40,630:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-28 21:31:40,630:INFO:version 3.0.4
2023-07-28 21:31:40,630:INFO:Initializing setup()
2023-07-28 21:31:40,630:INFO:self.USI: 862d
2023-07-28 21:31:40,630:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'data', 'exp_name_log', 'idx', 'seed', 'USI', 'n_jobs_param', 'gpu_param', 'X', 'pipeline', '_available_plots', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'memory', 'logging_param'}
2023-07-28 21:31:40,630:INFO:Checking environment
2023-07-28 21:31:40,630:INFO:python_version: 3.9.13
2023-07-28 21:31:40,630:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-28 21:31:40,630:INFO:machine: AMD64
2023-07-28 21:31:40,630:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-28 21:31:40,638:INFO:Memory: svmem(total=33737928704, available=22099271680, percent=34.5, used=11638657024, free=22099271680)
2023-07-28 21:31:40,638:INFO:Physical Core: 8
2023-07-28 21:31:40,638:INFO:Logical Core: 16
2023-07-28 21:31:40,638:INFO:Checking libraries
2023-07-28 21:31:40,638:INFO:System:
2023-07-28 21:31:40,638:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-28 21:31:40,638:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-28 21:31:40,638:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-28 21:31:40,638:INFO:PyCaret required dependencies:
2023-07-28 21:31:40,728:INFO:                 pip: 22.0.4
2023-07-28 21:31:40,728:INFO:          setuptools: 58.1.0
2023-07-28 21:31:40,728:INFO:             pycaret: 3.0.4
2023-07-28 21:31:40,728:INFO:             IPython: 8.13.1
2023-07-28 21:31:40,728:INFO:          ipywidgets: 8.0.7
2023-07-28 21:31:40,728:INFO:                tqdm: 4.65.0
2023-07-28 21:31:40,728:INFO:               numpy: 1.23.0
2023-07-28 21:31:40,728:INFO:              pandas: 1.5.3
2023-07-28 21:31:40,728:INFO:              jinja2: 3.1.2
2023-07-28 21:31:40,728:INFO:               scipy: 1.10.1
2023-07-28 21:31:40,728:INFO:              joblib: 1.3.1
2023-07-28 21:31:40,728:INFO:             sklearn: 1.2.2
2023-07-28 21:31:40,728:INFO:                pyod: 1.1.0
2023-07-28 21:31:40,728:INFO:            imblearn: 0.11.0
2023-07-28 21:31:40,728:INFO:   category_encoders: 2.6.1
2023-07-28 21:31:40,728:INFO:            lightgbm: 4.0.0
2023-07-28 21:31:40,728:INFO:               numba: 0.57.1
2023-07-28 21:31:40,728:INFO:            requests: 2.31.0
2023-07-28 21:31:40,728:INFO:          matplotlib: 3.7.1
2023-07-28 21:31:40,728:INFO:          scikitplot: 0.3.7
2023-07-28 21:31:40,728:INFO:         yellowbrick: 1.5
2023-07-28 21:31:40,728:INFO:              plotly: 5.15.0
2023-07-28 21:31:40,728:INFO:    plotly-resampler: Not installed
2023-07-28 21:31:40,728:INFO:             kaleido: 0.2.1
2023-07-28 21:31:40,728:INFO:           schemdraw: 0.15
2023-07-28 21:31:40,728:INFO:         statsmodels: 0.14.0
2023-07-28 21:31:40,728:INFO:              sktime: 0.20.1
2023-07-28 21:31:40,728:INFO:               tbats: 1.1.3
2023-07-28 21:31:40,728:INFO:            pmdarima: 2.0.3
2023-07-28 21:31:40,728:INFO:              psutil: 5.9.5
2023-07-28 21:31:40,728:INFO:          markupsafe: 2.1.3
2023-07-28 21:31:40,728:INFO:             pickle5: Not installed
2023-07-28 21:31:40,728:INFO:         cloudpickle: 2.2.1
2023-07-28 21:31:40,728:INFO:         deprecation: 2.1.0
2023-07-28 21:31:40,728:INFO:              xxhash: 3.2.0
2023-07-28 21:31:40,728:INFO:           wurlitzer: Not installed
2023-07-28 21:31:40,728:INFO:PyCaret optional dependencies:
2023-07-28 21:31:40,737:INFO:                shap: 0.42.1
2023-07-28 21:31:40,737:INFO:           interpret: Not installed
2023-07-28 21:31:40,737:INFO:                umap: 0.5.3
2023-07-28 21:31:40,737:INFO:    pandas_profiling: Not installed
2023-07-28 21:31:40,737:INFO:  explainerdashboard: 0.4.2.2
2023-07-28 21:31:40,737:INFO:             autoviz: 0.1.730
2023-07-28 21:31:40,737:INFO:           fairlearn: Not installed
2023-07-28 21:31:40,737:INFO:          deepchecks: Not installed
2023-07-28 21:31:40,737:INFO:             xgboost: 1.7.6
2023-07-28 21:31:40,737:INFO:            catboost: Not installed
2023-07-28 21:31:40,737:INFO:              kmodes: Not installed
2023-07-28 21:31:40,737:INFO:             mlxtend: Not installed
2023-07-28 21:31:40,737:INFO:       statsforecast: Not installed
2023-07-28 21:31:40,737:INFO:        tune_sklearn: Not installed
2023-07-28 21:31:40,737:INFO:                 ray: Not installed
2023-07-28 21:31:40,737:INFO:            hyperopt: Not installed
2023-07-28 21:31:40,737:INFO:              optuna: Not installed
2023-07-28 21:31:40,737:INFO:               skopt: Not installed
2023-07-28 21:31:40,737:INFO:              mlflow: Not installed
2023-07-28 21:31:40,737:INFO:              gradio: Not installed
2023-07-28 21:31:40,737:INFO:             fastapi: Not installed
2023-07-28 21:31:40,737:INFO:             uvicorn: Not installed
2023-07-28 21:31:40,737:INFO:              m2cgen: Not installed
2023-07-28 21:31:40,737:INFO:           evidently: Not installed
2023-07-28 21:31:40,737:INFO:               fugue: Not installed
2023-07-28 21:31:40,737:INFO:           streamlit: Not installed
2023-07-28 21:31:40,737:INFO:             prophet: Not installed
2023-07-28 21:31:40,737:INFO:None
2023-07-28 21:31:40,737:INFO:Set up data.
2023-07-28 21:31:40,744:INFO:Set up index.
2023-07-28 21:31:40,744:INFO:Assigning column types.
2023-07-28 21:31:40,744:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-28 21:31:40,744:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:31:40,744:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,744:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:31:40,744:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,744:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-28 21:31:40,744:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,744:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,753:INFO:Preparing preprocessing pipeline...
2023-07-28 21:31:40,753:INFO:Set up simple imputation.
2023-07-28 21:31:40,753:INFO:Set up encoding of categorical features.
2023-07-28 21:31:40,753:INFO:Set up feature normalization.
2023-07-28 21:31:40,883:INFO:Finished creating preprocessing pipeline.
2023-07-28 21:31:40,891:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'is_canceled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(includ...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['market_segment', 'deposit_type',
                                             'customer_type',
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-07-28 21:31:40,891:INFO:Creating final display dataframe.
2023-07-28 21:31:40,957:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  2373
1        Original data shape           (10202, 10)
2     Transformed data shape           (10202, 31)
3           Numeric features                     6
4       Categorical features                     4
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9   Maximum one-hot encoding                    -1
10           Encoding method                  None
11                 Normalize                  True
12          Normalize method                zscore
13                  CPU Jobs                    -1
14                   Use GPU                 False
15            Log Experiment                 False
16           Experiment Name  cluster-default-name
17                       USI                  862d
2023-07-28 21:31:40,966:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,966:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:31:40,966:INFO:setup() successfully completed in 0.79s...............
2023-07-28 21:32:05,565:INFO:Initializing create_model()
2023-07-28 21:32:05,565:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8CA6C7430>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.3})
2023-07-28 21:32:05,565:INFO:Checking exceptions
2023-07-28 21:32:05,671:INFO:Importing untrained model
2023-07-28 21:32:05,671:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:32:05,679:INFO:Fitting Model
2023-07-28 21:32:07,676:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-28 21:32:07,676:INFO:create_models() successfully completed......................................
2023-07-28 21:32:07,676:INFO:Uploading results into container
2023-07-28 21:32:07,684:INFO:Uploading model into container now
2023-07-28 21:32:07,684:INFO:_master_model_container: 1
2023-07-28 21:32:07,692:INFO:_display_container: 2
2023-07-28 21:32:07,692:INFO:DBSCAN(eps=0.3, n_jobs=-1)
2023-07-28 21:32:07,692:INFO:create_model() successfully completed......................................
2023-07-28 21:32:16,655:INFO:Initializing create_model()
2023-07-28 21:32:16,655:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8CA6C7430>, estimator=dbscan, num_clusters=7, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.1})
2023-07-28 21:32:16,655:INFO:Checking exceptions
2023-07-28 21:32:16,759:INFO:Importing untrained model
2023-07-28 21:32:16,767:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:32:16,767:INFO:Fitting Model
2023-07-28 21:32:18,717:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:32:18,717:INFO:create_models() successfully completed......................................
2023-07-28 21:32:18,717:INFO:Uploading results into container
2023-07-28 21:32:18,717:INFO:Uploading model into container now
2023-07-28 21:32:18,726:INFO:_master_model_container: 2
2023-07-28 21:32:18,726:INFO:_display_container: 3
2023-07-28 21:32:18,726:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:32:18,726:INFO:create_model() successfully completed......................................
2023-07-28 21:32:35,898:INFO:Initializing get_config()
2023-07-28 21:32:35,898:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8CA6C7430>, variable=None)
2023-07-28 21:32:42,346:INFO:Initializing get_config()
2023-07-28 21:32:42,346:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8CA6C7430>, variable=X_train_transformed)
2023-07-28 21:32:42,419:INFO:Variable: X_train returned as        market_segment_Online TA  market_segment_Direct  market_segment_Groups  \
0                      1.031065              -0.514602              -0.301092   
1                     -0.969871               1.943249              -0.301092   
2                      1.031065              -0.514602              -0.301092   
3                      1.031065              -0.514602              -0.301092   
4                      1.031065              -0.514602              -0.301092   
...                         ...                    ...                    ...   
10197                  1.031065              -0.514602              -0.301092   
10198                  1.031065              -0.514602              -0.301092   
10199                  1.031065              -0.514602              -0.301092   
10200                 -0.969871              -0.514602              -0.301092   
10201                 -0.969871              -0.514602               3.321244   

       market_segment_Offline TA/TO  market_segment_Complementary  \
0                         -0.412255                     -0.134395   
1                         -0.412255                     -0.134395   
2                         -0.412255                     -0.134395   
3                         -0.412255                     -0.134395   
4                         -0.412255                     -0.134395   
...                             ...                           ...   
10197                     -0.412255                     -0.134395   
10198                     -0.412255                     -0.134395   
10199                     -0.412255                     -0.134395   
10200                      2.425684                     -0.134395   
10201                     -0.412255                     -0.134395   

       market_segment_Aviation  market_segment_Corporate  \
0                     -0.08946                 -0.233622   
1                     -0.08946                 -0.233622   
2                     -0.08946                 -0.233622   
3                     -0.08946                 -0.233622   
4                     -0.08946                 -0.233622   
...                        ...                       ...   
10197                 -0.08946                 -0.233622   
10198                 -0.08946                 -0.233622   
10199                 -0.08946                 -0.233622   
10200                 -0.08946                 -0.233622   
10201                 -0.08946                 -0.233622   

       market_segment_Undefined  previous_cancellations  booking_changes  ...  \
0                     -0.009901               -0.107789        -0.614804  ...   
1                     -0.009901               -0.107789        -0.614804  ...   
2                     -0.009901               -0.107789        -0.614804  ...   
3                     -0.009901               -0.107789         3.251693  ...   
4                     -0.009901               -0.107789        -0.614804  ...   
...                         ...                     ...              ...  ...   
10197                 -0.009901               -0.107789        -0.614804  ...   
10198                 -0.009901               -0.107789        -0.614804  ...   
10199                 -0.009901               -0.107789         0.158495  ...   
10200                 -0.009901               -0.107789        -0.614804  ...   
10201                 -0.009901               -0.107789        -0.614804  ...   

       reserved_room_type_A  reserved_room_type_F  reserved_room_type_C  \
0                 -0.911019              -0.27556             -0.185677   
1                 -0.911019              -0.27556             -0.185677   
2                 -0.911019              -0.27556             -0.185677   
3                 -0.911019              -0.27556             -0.185677   
4                 -0.911019              -0.27556             -0.185677   
...                     ...                   ...                   ...   
10197              1.097672              -0.27556             -0.185677   
10198             -0.911019              -0.27556             -0.185677   
10199             -0.911019              -0.27556             -0.185677   
10200              1.097672              -0.27556             -0.185677   
10201              1.097672              -0.27556             -0.185677   

       reserved_room_type_H  reserved_room_type_B  reserved_room_type_P  \
0                 -0.138495             -0.215809             -0.019805   
1                 -0.138495             -0.215809             -0.019805   
2                 -0.138495             -0.215809             -0.019805   
3                 -0.138495             -0.215809             -0.019805   
4                 -0.138495             -0.215809             -0.019805   
...                     ...                   ...                   ...   
10197             -0.138495             -0.215809             -0.019805   
10198             -0.138495             -0.215809             -0.019805   
10199             -0.138495             -0.215809             -0.019805   
10200             -0.138495             -0.215809             -0.019805   
10201             -0.138495             -0.215809             -0.019805   

       reserved_room_type_L  required_car_parking_spaces  \
0                 -0.014003                    -0.424396   
1                 -0.014003                     2.115010   
2                 -0.014003                    -0.424396   
3                 -0.014003                    -0.424396   
4                 -0.014003                     2.115010   
...                     ...                          ...   
10197             -0.014003                    -0.424396   
10198             -0.014003                    -0.424396   
10199             -0.014003                    -0.424396   
10200             -0.014003                    -0.424396   
10201             -0.014003                    -0.424396   

       total_of_special_requests  is_canceled  
0                       0.056662     1.796157  
1                      -0.906789    -0.556744  
2                       0.056662    -0.556744  
3                       0.056662    -0.556744  
4                       1.983565    -0.556744  
...                          ...          ...  
10197                   1.983565     1.796157  
10198                   1.020114    -0.556744  
10199                   1.983565    -0.556744  
10200                  -0.906789    -0.556744  
10201                  -0.906789     1.796157  

[10202 rows x 31 columns]
2023-07-28 21:32:42,419:INFO:get_config() successfully completed......................................
2023-07-28 21:34:07,443:INFO:PyCaret ClusteringExperiment
2023-07-28 21:34:07,443:INFO:Logging name: cluster-default-name
2023-07-28 21:34:07,443:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-28 21:34:07,443:INFO:version 3.0.4
2023-07-28 21:34:07,443:INFO:Initializing setup()
2023-07-28 21:34:07,443:INFO:self.USI: 8d2c
2023-07-28 21:34:07,443:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'data', 'exp_name_log', 'idx', 'seed', 'USI', 'n_jobs_param', 'gpu_param', 'X', 'pipeline', '_available_plots', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'memory', 'logging_param'}
2023-07-28 21:34:07,443:INFO:Checking environment
2023-07-28 21:34:07,443:INFO:python_version: 3.9.13
2023-07-28 21:34:07,443:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-28 21:34:07,443:INFO:machine: AMD64
2023-07-28 21:34:07,443:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-28 21:34:07,451:INFO:Memory: svmem(total=33737928704, available=22949658624, percent=32.0, used=10788270080, free=22949658624)
2023-07-28 21:34:07,451:INFO:Physical Core: 8
2023-07-28 21:34:07,451:INFO:Logical Core: 16
2023-07-28 21:34:07,451:INFO:Checking libraries
2023-07-28 21:34:07,451:INFO:System:
2023-07-28 21:34:07,451:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-28 21:34:07,451:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-28 21:34:07,451:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-28 21:34:07,451:INFO:PyCaret required dependencies:
2023-07-28 21:34:07,451:INFO:                 pip: 22.0.4
2023-07-28 21:34:07,451:INFO:          setuptools: 58.1.0
2023-07-28 21:34:07,451:INFO:             pycaret: 3.0.4
2023-07-28 21:34:07,451:INFO:             IPython: 8.13.1
2023-07-28 21:34:07,451:INFO:          ipywidgets: 8.0.7
2023-07-28 21:34:07,451:INFO:                tqdm: 4.65.0
2023-07-28 21:34:07,451:INFO:               numpy: 1.23.0
2023-07-28 21:34:07,451:INFO:              pandas: 1.5.3
2023-07-28 21:34:07,451:INFO:              jinja2: 3.1.2
2023-07-28 21:34:07,451:INFO:               scipy: 1.10.1
2023-07-28 21:34:07,451:INFO:              joblib: 1.3.1
2023-07-28 21:34:07,451:INFO:             sklearn: 1.2.2
2023-07-28 21:34:07,451:INFO:                pyod: 1.1.0
2023-07-28 21:34:07,451:INFO:            imblearn: 0.11.0
2023-07-28 21:34:07,451:INFO:   category_encoders: 2.6.1
2023-07-28 21:34:07,451:INFO:            lightgbm: 4.0.0
2023-07-28 21:34:07,451:INFO:               numba: 0.57.1
2023-07-28 21:34:07,451:INFO:            requests: 2.31.0
2023-07-28 21:34:07,451:INFO:          matplotlib: 3.7.1
2023-07-28 21:34:07,451:INFO:          scikitplot: 0.3.7
2023-07-28 21:34:07,451:INFO:         yellowbrick: 1.5
2023-07-28 21:34:07,451:INFO:              plotly: 5.15.0
2023-07-28 21:34:07,451:INFO:    plotly-resampler: Not installed
2023-07-28 21:34:07,451:INFO:             kaleido: 0.2.1
2023-07-28 21:34:07,451:INFO:           schemdraw: 0.15
2023-07-28 21:34:07,451:INFO:         statsmodels: 0.14.0
2023-07-28 21:34:07,451:INFO:              sktime: 0.20.1
2023-07-28 21:34:07,451:INFO:               tbats: 1.1.3
2023-07-28 21:34:07,451:INFO:            pmdarima: 2.0.3
2023-07-28 21:34:07,451:INFO:              psutil: 5.9.5
2023-07-28 21:34:07,451:INFO:          markupsafe: 2.1.3
2023-07-28 21:34:07,451:INFO:             pickle5: Not installed
2023-07-28 21:34:07,451:INFO:         cloudpickle: 2.2.1
2023-07-28 21:34:07,451:INFO:         deprecation: 2.1.0
2023-07-28 21:34:07,451:INFO:              xxhash: 3.2.0
2023-07-28 21:34:07,451:INFO:           wurlitzer: Not installed
2023-07-28 21:34:07,451:INFO:PyCaret optional dependencies:
2023-07-28 21:34:07,451:INFO:                shap: 0.42.1
2023-07-28 21:34:07,451:INFO:           interpret: Not installed
2023-07-28 21:34:07,451:INFO:                umap: 0.5.3
2023-07-28 21:34:07,451:INFO:    pandas_profiling: Not installed
2023-07-28 21:34:07,451:INFO:  explainerdashboard: 0.4.2.2
2023-07-28 21:34:07,451:INFO:             autoviz: 0.1.730
2023-07-28 21:34:07,451:INFO:           fairlearn: Not installed
2023-07-28 21:34:07,451:INFO:          deepchecks: Not installed
2023-07-28 21:34:07,451:INFO:             xgboost: 1.7.6
2023-07-28 21:34:07,451:INFO:            catboost: Not installed
2023-07-28 21:34:07,451:INFO:              kmodes: Not installed
2023-07-28 21:34:07,451:INFO:             mlxtend: Not installed
2023-07-28 21:34:07,451:INFO:       statsforecast: Not installed
2023-07-28 21:34:07,451:INFO:        tune_sklearn: Not installed
2023-07-28 21:34:07,451:INFO:                 ray: Not installed
2023-07-28 21:34:07,451:INFO:            hyperopt: Not installed
2023-07-28 21:34:07,451:INFO:              optuna: Not installed
2023-07-28 21:34:07,451:INFO:               skopt: Not installed
2023-07-28 21:34:07,451:INFO:              mlflow: Not installed
2023-07-28 21:34:07,451:INFO:              gradio: Not installed
2023-07-28 21:34:07,451:INFO:             fastapi: Not installed
2023-07-28 21:34:07,451:INFO:             uvicorn: Not installed
2023-07-28 21:34:07,451:INFO:              m2cgen: Not installed
2023-07-28 21:34:07,451:INFO:           evidently: Not installed
2023-07-28 21:34:07,451:INFO:               fugue: Not installed
2023-07-28 21:34:07,451:INFO:           streamlit: Not installed
2023-07-28 21:34:07,451:INFO:             prophet: Not installed
2023-07-28 21:34:07,451:INFO:None
2023-07-28 21:34:07,451:INFO:Set up data.
2023-07-28 21:34:07,459:INFO:Set up index.
2023-07-28 21:34:07,459:INFO:Assigning column types.
2023-07-28 21:34:07,459:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-28 21:34:07,459:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:34:07,459:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,459:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:34:07,459:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,459:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-28 21:34:07,459:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,459:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,459:INFO:Preparing preprocessing pipeline...
2023-07-28 21:34:07,459:INFO:Set up simple imputation.
2023-07-28 21:34:07,459:INFO:Set up feature normalization.
2023-07-28 21:34:07,475:INFO:Finished creating preprocessing pipeline.
2023-07-28 21:34:07,483:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['encoder__market_segment_0',
                                             'encoder__market_segment_1',
                                             'encoder__market_segment_2',
                                             'encoder__market_segment_3',
                                             'encoder__deposit_type_0',
                                             'encoder__deposit_type_1',
                                             'encoder__customer_type_0',
                                             'encoder__customer_type_1'...
                                             'scaller__booking_changes',
                                             'scaller__days_in_waiting_list',
                                             'scaller__required_car_parking_spaces',
                                             'scaller__total_of_special_requests',
                                             'scaller__is_canceled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-07-28 21:34:07,483:INFO:Creating final display dataframe.
2023-07-28 21:34:07,499:INFO:Setup _display_container:                Description                 Value
0               Session id                  8924
1      Original data shape           (10202, 19)
2   Transformed data shape           (10202, 19)
3         Numeric features                    19
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                Normalize                  True
9         Normalize method                zscore
10                CPU Jobs                    -1
11                 Use GPU                 False
12          Log Experiment                 False
13         Experiment Name  cluster-default-name
14                     USI                  8d2c
2023-07-28 21:34:07,507:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,507:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:34:07,507:INFO:setup() successfully completed in 0.34s...............
2023-07-28 21:34:18,006:INFO:Initializing create_model()
2023-07-28 21:34:18,006:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8D4FA1280>, estimator=dbscan, num_clusters=7, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.1})
2023-07-28 21:34:18,006:INFO:Checking exceptions
2023-07-28 21:34:18,046:INFO:Importing untrained model
2023-07-28 21:34:18,046:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:34:18,054:INFO:Fitting Model
2023-07-28 21:34:19,832:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:34:19,832:INFO:create_models() successfully completed......................................
2023-07-28 21:34:19,832:INFO:Uploading results into container
2023-07-28 21:34:19,832:INFO:Uploading model into container now
2023-07-28 21:34:19,840:INFO:_master_model_container: 1
2023-07-28 21:34:19,840:INFO:_display_container: 2
2023-07-28 21:34:19,840:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:34:19,840:INFO:create_model() successfully completed......................................
2023-07-28 21:34:22,770:INFO:Initializing get_config()
2023-07-28 21:34:22,770:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8D4FA1280>, variable=X_train_transformed)
2023-07-28 21:34:22,794:INFO:Variable: X_train returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                      -0.009901                  -0.535263   
1                      -0.009901                  -0.535263   
2                      -0.009901                  -0.535263   
3                      -0.009901                  -0.535263   
4                      -0.009901                  -0.535263   
...                          ...                        ...   
10197                  -0.009901                  -0.535263   
10198                  -0.009901                  -0.535263   
10199                  -0.009901                  -0.535263   
10200                  -0.009901                   1.868239   
10201                  -0.009901                  -0.535263   

       encoder__market_segment_2  encoder__market_segment_3  \
0                      -0.737328                   0.754358   
1                       1.356248                  -1.325631   
2                      -0.737328                   0.754358   
3                      -0.737328                   0.754358   
4                      -0.737328                   0.754358   
...                          ...                        ...   
10197                  -0.737328                   0.754358   
10198                  -0.737328                   0.754358   
10199                  -0.737328                   0.754358   
10200                  -0.737328                  -1.325631   
10201                   1.356248                   0.754358   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                    -0.155876                 0.068031   
1                    -0.155876                 0.068031   
2                    -0.155876                 0.068031   
3                    -0.155876                 0.068031   
4                    -0.155876                 0.068031   
...                        ...                      ...   
10197                -0.155876                 0.068031   
10198                -0.155876                 0.068031   
10199                -0.155876                 0.068031   
10200                -0.155876                 0.068031   
10201                 6.415374                 0.068031   

       encoder__customer_type_0  encoder__customer_type_1  \
0                     -0.222442                 -0.616556   
1                     -0.222442                 -0.616556   
2                     -0.222442                 -0.616556   
3                     -0.222442                 -0.616556   
4                     -0.222442                 -0.616556   
...                         ...                       ...   
10197                  4.495551                 -0.616556   
10198                 -0.222442                 -0.616556   
10199                 -0.222442                 -0.616556   
10200                 -0.222442                  1.621914   
10201                 -0.222442                 -0.616556   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                      0.652576                      -0.217298   
1                      0.652576                      -0.217298   
2                      0.652576                      -0.217298   
3                      0.652576                      -0.217298   
4                      0.652576                      -0.217298   
...                         ...                            ...   
10197                 -1.532387                      -0.217298   
10198                  0.652576                      -0.217298   
10199                  0.652576                      -0.217298   
10200                 -1.532387                      -0.217298   
10201                  0.652576                      -0.217298   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                          -1.166163                      -0.665121   
1                          -1.166163                       1.503485   
2                          -1.166163                      -0.665121   
3                          -1.166163                       1.503485   
4                          -1.166163                       1.503485   
...                              ...                            ...   
10197                       0.857513                      -0.665121   
10198                      -1.166163                       1.503485   
10199                      -1.166163                       1.503485   
10200                       0.857513                      -0.665121   
10201                       0.857513                      -0.665121   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                           1.651496                        -0.107789   
1                          -0.605512                        -0.107789   
2                           1.651496                        -0.107789   
3                          -0.605512                        -0.107789   
4                           1.651496                        -0.107789   
...                              ...                              ...   
10197                      -0.605512                        -0.107789   
10198                      -0.605512                        -0.107789   
10199                      -0.605512                        -0.107789   
10200                      -0.605512                        -0.107789   
10201                      -0.605512                        -0.107789   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                     -0.614804                      -0.160405   
1                     -0.614804                      -0.160405   
2                     -0.614804                      -0.160405   
3                      3.251693                      -0.160405   
4                     -0.614804                      -0.160405   
...                         ...                            ...   
10197                 -0.614804                      -0.160405   
10198                 -0.614804                      -0.160405   
10199                  0.158495                      -0.160405   
10200                 -0.614804                      -0.160405   
10201                 -0.614804                      -0.160405   

       scaller__required_car_parking_spaces  \
0                                 -0.424396   
1                                  2.115010   
2                                 -0.424396   
3                                 -0.424396   
4                                  2.115010   
...                                     ...   
10197                             -0.424396   
10198                             -0.424396   
10199                             -0.424396   
10200                             -0.424396   
10201                             -0.424396   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                0.056662              1.796157  
1                               -0.906789             -0.556744  
2                                0.056662             -0.556744  
3                                0.056662             -0.556744  
4                                1.983565             -0.556744  
...                                   ...                   ...  
10197                            1.983565              1.796157  
10198                            1.020114             -0.556744  
10199                            1.983565             -0.556744  
10200                           -0.906789             -0.556744  
10201                           -0.906789              1.796157  

[10202 rows x 19 columns]
2023-07-28 21:34:22,794:INFO:get_config() successfully completed......................................
2023-07-28 21:34:32,410:INFO:Initializing get_config()
2023-07-28 21:34:32,410:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C8D4FA1280>, variable=X_train)
2023-07-28 21:34:32,410:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-07-28 21:34:32,418:INFO:Variable:  returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                            0.0                        0.0   
1                            0.0                        0.0   
2                            0.0                        0.0   
3                            0.0                        0.0   
4                            0.0                        0.0   
...                          ...                        ...   
10197                        0.0                        0.0   
10198                        0.0                        0.0   
10199                        0.0                        0.0   
10200                        0.0                        1.0   
10201                        0.0                        0.0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                            0.0                        1.0   
1                            1.0                        0.0   
2                            0.0                        1.0   
3                            0.0                        1.0   
4                            0.0                        1.0   
...                          ...                        ...   
10197                        0.0                        1.0   
10198                        0.0                        1.0   
10199                        0.0                        1.0   
10200                        0.0                        0.0   
10201                        1.0                        1.0   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                          0.0                      1.0   
1                          0.0                      1.0   
2                          0.0                      1.0   
3                          0.0                      1.0   
4                          0.0                      1.0   
...                        ...                      ...   
10197                      0.0                      1.0   
10198                      0.0                      1.0   
10199                      0.0                      1.0   
10200                      0.0                      1.0   
10201                      1.0                      1.0   

       encoder__customer_type_0  encoder__customer_type_1  \
0                           0.0                       0.0   
1                           0.0                       0.0   
2                           0.0                       0.0   
3                           0.0                       0.0   
4                           0.0                       0.0   
...                         ...                       ...   
10197                       1.0                       0.0   
10198                       0.0                       0.0   
10199                       0.0                       0.0   
10200                       0.0                       1.0   
10201                       0.0                       0.0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                           1.0                            0.0   
1                           1.0                            0.0   
2                           1.0                            0.0   
3                           1.0                            0.0   
4                           1.0                            0.0   
...                         ...                            ...   
10197                       0.0                            0.0   
10198                       1.0                            0.0   
10199                       1.0                            0.0   
10200                       0.0                            0.0   
10201                       1.0                            0.0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                0.0                            0.0   
1                                0.0                            1.0   
2                                0.0                            0.0   
3                                0.0                            1.0   
4                                0.0                            1.0   
...                              ...                            ...   
10197                            1.0                            0.0   
10198                            0.0                            1.0   
10199                            0.0                            1.0   
10200                            1.0                            0.0   
10201                            1.0                            0.0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                1.0                        -0.107789   
1                                0.0                        -0.107789   
2                                1.0                        -0.107789   
3                                0.0                        -0.107789   
4                                1.0                        -0.107789   
...                              ...                              ...   
10197                            0.0                        -0.107789   
10198                            0.0                        -0.107789   
10199                            0.0                        -0.107789   
10200                            0.0                        -0.107789   
10201                            0.0                        -0.107789   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                     -0.614804                      -0.160405   
1                     -0.614804                      -0.160405   
2                     -0.614804                      -0.160405   
3                      3.251693                      -0.160405   
4                     -0.614804                      -0.160405   
...                         ...                            ...   
10197                 -0.614804                      -0.160405   
10198                 -0.614804                      -0.160405   
10199                  0.158495                      -0.160405   
10200                 -0.614804                      -0.160405   
10201                 -0.614804                      -0.160405   

       scaller__required_car_parking_spaces  \
0                                 -0.424396   
1                                  2.115010   
2                                 -0.424396   
3                                 -0.424396   
4                                  2.115010   
...                                     ...   
10197                             -0.424396   
10198                             -0.424396   
10199                             -0.424396   
10200                             -0.424396   
10201                             -0.424396   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                0.056662              1.796157  
1                               -0.906789             -0.556744  
2                                0.056662             -0.556744  
3                                0.056662             -0.556744  
4                                1.983565             -0.556744  
...                                   ...                   ...  
10197                            1.983565              1.796157  
10198                            1.020114             -0.556744  
10199                            1.983565             -0.556744  
10200                           -0.906789             -0.556744  
10201                           -0.906789              1.796157  

[10202 rows x 19 columns]
2023-07-28 21:34:32,418:INFO:get_config() successfully completed......................................
2023-07-28 21:39:03,222:INFO:PyCaret ClusteringExperiment
2023-07-28 21:39:03,222:INFO:Logging name: cluster-default-name
2023-07-28 21:39:03,222:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-28 21:39:03,222:INFO:version 3.0.4
2023-07-28 21:39:03,222:INFO:Initializing setup()
2023-07-28 21:39:03,222:INFO:self.USI: e188
2023-07-28 21:39:03,222:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'data', 'exp_name_log', 'idx', 'seed', 'USI', 'n_jobs_param', 'gpu_param', 'X', 'pipeline', '_available_plots', 'gpu_n_jobs_param', '_ml_usecase', 'html_param', 'memory', 'logging_param'}
2023-07-28 21:39:03,222:INFO:Checking environment
2023-07-28 21:39:03,222:INFO:python_version: 3.9.13
2023-07-28 21:39:03,222:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-28 21:39:03,222:INFO:machine: AMD64
2023-07-28 21:39:03,222:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-28 21:39:03,230:INFO:Memory: svmem(total=33737928704, available=22726717440, percent=32.6, used=11011211264, free=22726717440)
2023-07-28 21:39:03,230:INFO:Physical Core: 8
2023-07-28 21:39:03,230:INFO:Logical Core: 16
2023-07-28 21:39:03,230:INFO:Checking libraries
2023-07-28 21:39:03,230:INFO:System:
2023-07-28 21:39:03,230:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-28 21:39:03,230:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-28 21:39:03,230:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-28 21:39:03,230:INFO:PyCaret required dependencies:
2023-07-28 21:39:03,230:INFO:                 pip: 22.0.4
2023-07-28 21:39:03,230:INFO:          setuptools: 58.1.0
2023-07-28 21:39:03,230:INFO:             pycaret: 3.0.4
2023-07-28 21:39:03,230:INFO:             IPython: 8.13.1
2023-07-28 21:39:03,230:INFO:          ipywidgets: 8.0.7
2023-07-28 21:39:03,230:INFO:                tqdm: 4.65.0
2023-07-28 21:39:03,230:INFO:               numpy: 1.23.0
2023-07-28 21:39:03,230:INFO:              pandas: 1.5.3
2023-07-28 21:39:03,230:INFO:              jinja2: 3.1.2
2023-07-28 21:39:03,230:INFO:               scipy: 1.10.1
2023-07-28 21:39:03,230:INFO:              joblib: 1.3.1
2023-07-28 21:39:03,230:INFO:             sklearn: 1.2.2
2023-07-28 21:39:03,230:INFO:                pyod: 1.1.0
2023-07-28 21:39:03,230:INFO:            imblearn: 0.11.0
2023-07-28 21:39:03,230:INFO:   category_encoders: 2.6.1
2023-07-28 21:39:03,230:INFO:            lightgbm: 4.0.0
2023-07-28 21:39:03,230:INFO:               numba: 0.57.1
2023-07-28 21:39:03,230:INFO:            requests: 2.31.0
2023-07-28 21:39:03,230:INFO:          matplotlib: 3.7.1
2023-07-28 21:39:03,230:INFO:          scikitplot: 0.3.7
2023-07-28 21:39:03,230:INFO:         yellowbrick: 1.5
2023-07-28 21:39:03,230:INFO:              plotly: 5.15.0
2023-07-28 21:39:03,230:INFO:    plotly-resampler: Not installed
2023-07-28 21:39:03,230:INFO:             kaleido: 0.2.1
2023-07-28 21:39:03,230:INFO:           schemdraw: 0.15
2023-07-28 21:39:03,230:INFO:         statsmodels: 0.14.0
2023-07-28 21:39:03,230:INFO:              sktime: 0.20.1
2023-07-28 21:39:03,230:INFO:               tbats: 1.1.3
2023-07-28 21:39:03,230:INFO:            pmdarima: 2.0.3
2023-07-28 21:39:03,230:INFO:              psutil: 5.9.5
2023-07-28 21:39:03,230:INFO:          markupsafe: 2.1.3
2023-07-28 21:39:03,230:INFO:             pickle5: Not installed
2023-07-28 21:39:03,230:INFO:         cloudpickle: 2.2.1
2023-07-28 21:39:03,230:INFO:         deprecation: 2.1.0
2023-07-28 21:39:03,230:INFO:              xxhash: 3.2.0
2023-07-28 21:39:03,230:INFO:           wurlitzer: Not installed
2023-07-28 21:39:03,230:INFO:PyCaret optional dependencies:
2023-07-28 21:39:03,230:INFO:                shap: 0.42.1
2023-07-28 21:39:03,230:INFO:           interpret: Not installed
2023-07-28 21:39:03,230:INFO:                umap: 0.5.3
2023-07-28 21:39:03,230:INFO:    pandas_profiling: Not installed
2023-07-28 21:39:03,230:INFO:  explainerdashboard: 0.4.2.2
2023-07-28 21:39:03,230:INFO:             autoviz: 0.1.730
2023-07-28 21:39:03,230:INFO:           fairlearn: Not installed
2023-07-28 21:39:03,230:INFO:          deepchecks: Not installed
2023-07-28 21:39:03,230:INFO:             xgboost: 1.7.6
2023-07-28 21:39:03,230:INFO:            catboost: Not installed
2023-07-28 21:39:03,230:INFO:              kmodes: Not installed
2023-07-28 21:39:03,230:INFO:             mlxtend: Not installed
2023-07-28 21:39:03,230:INFO:       statsforecast: Not installed
2023-07-28 21:39:03,230:INFO:        tune_sklearn: Not installed
2023-07-28 21:39:03,230:INFO:                 ray: Not installed
2023-07-28 21:39:03,230:INFO:            hyperopt: Not installed
2023-07-28 21:39:03,230:INFO:              optuna: Not installed
2023-07-28 21:39:03,230:INFO:               skopt: Not installed
2023-07-28 21:39:03,230:INFO:              mlflow: Not installed
2023-07-28 21:39:03,230:INFO:              gradio: Not installed
2023-07-28 21:39:03,230:INFO:             fastapi: Not installed
2023-07-28 21:39:03,230:INFO:             uvicorn: Not installed
2023-07-28 21:39:03,230:INFO:              m2cgen: Not installed
2023-07-28 21:39:03,230:INFO:           evidently: Not installed
2023-07-28 21:39:03,230:INFO:               fugue: Not installed
2023-07-28 21:39:03,230:INFO:           streamlit: Not installed
2023-07-28 21:39:03,230:INFO:             prophet: Not installed
2023-07-28 21:39:03,230:INFO:None
2023-07-28 21:39:03,230:INFO:Set up data.
2023-07-28 21:39:03,238:INFO:Set up index.
2023-07-28 21:39:03,238:INFO:Assigning column types.
2023-07-28 21:39:03,246:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-28 21:39:03,246:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:39:03,246:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,246:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-28 21:39:03,246:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,246:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-28 21:39:03,246:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,246:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,246:INFO:Preparing preprocessing pipeline...
2023-07-28 21:39:03,246:INFO:Set up simple imputation.
2023-07-28 21:39:03,246:INFO:Set up encoding of categorical features.
2023-07-28 21:39:03,246:INFO:Set up feature normalization.
2023-07-28 21:39:03,334:INFO:Finished creating preprocessing pipeline.
2023-07-28 21:39:03,464:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'is_canceled'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(includ...
                                                                        'mapping':     customer_type_0  customer_type_1  customer_type_2
 1                0                0                1
 2                0                1                0
 3                0                1                1
 4                1                0                0
-1                0                0                0
-2                0                0                0},
                                                                       {'col': 'reserved_room_type',
                                                                        'mapping':      reserved_room_type_0  reserved_room_type_1  reserved_room_type_2  \
 1                      0                     0                     0   
 2                      0                     0                     1   
 3                      0                     0                     1   
 4                      0                     1                     0   
 5                      0                     1                     0   
 6                      0                     1                     1   
 7                      0                     1                     1   
 8                      1                     0                     0   
 9                      1                     0                     0   
 10                     1                     0                     1   
-1                      0                     0                     0   
-2                      0                     0                     0   

     reserved_room_type_3  
 1                      1  
 2                      0  
 3                      1  
 4                      0  
 5                      1  
 6                      0  
 7                      1  
 8                      0  
 9                      1  
 10                     0  
-1                      0  
-2                      0  }]))),
                ('normalize',
                 TransformerWrapper(transformer=StandardScaler()))])
2023-07-28 21:39:03,464:INFO:Creating final display dataframe.
2023-07-28 21:39:03,528:INFO:Setup _display_container:                  Description                 Value
0                 Session id                  2666
1        Original data shape           (10202, 10)
2     Transformed data shape           (10202, 19)
3           Numeric features                     6
4       Categorical features                     4
5                 Preprocess                  True
6            Imputation type                simple
7         Numeric imputation                  mean
8     Categorical imputation                  mode
9   Maximum one-hot encoding                     0
10           Encoding method       BinaryEncoder()
11                 Normalize                  True
12          Normalize method                zscore
13                  CPU Jobs                    -1
14                   Use GPU                 False
15            Log Experiment                 False
16           Experiment Name  cluster-default-name
17                       USI                  e188
2023-07-28 21:39:03,536:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,536:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:39:03,536:INFO:setup() successfully completed in 0.6s...............
2023-07-28 21:39:22,278:INFO:Initializing get_config()
2023-07-28 21:39:22,278:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, variable=None)
2023-07-28 21:39:26,687:INFO:Initializing get_config()
2023-07-28 21:39:26,687:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, variable=X_train_transformed)
2023-07-28 21:39:26,762:INFO:Variable: X_train returned as        market_segment_0  market_segment_1  market_segment_2  market_segment_3  \
0             -0.009901         -0.535263         -0.737328          0.754358   
1             -0.009901         -0.535263          1.356248         -1.325631   
2             -0.009901         -0.535263         -0.737328          0.754358   
3             -0.009901         -0.535263         -0.737328          0.754358   
4             -0.009901         -0.535263         -0.737328          0.754358   
...                 ...               ...               ...               ...   
10197         -0.009901         -0.535263         -0.737328          0.754358   
10198         -0.009901         -0.535263         -0.737328          0.754358   
10199         -0.009901         -0.535263         -0.737328          0.754358   
10200         -0.009901          1.868239         -0.737328         -1.325631   
10201         -0.009901         -0.535263          1.356248          0.754358   

       previous_cancellations  booking_changes  deposit_type_0  \
0                   -0.107789        -0.614804       -0.155876   
1                   -0.107789        -0.614804       -0.155876   
2                   -0.107789        -0.614804       -0.155876   
3                   -0.107789         3.251693       -0.155876   
4                   -0.107789        -0.614804       -0.155876   
...                       ...              ...             ...   
10197               -0.107789        -0.614804       -0.155876   
10198               -0.107789        -0.614804       -0.155876   
10199               -0.107789         0.158495       -0.155876   
10200               -0.107789        -0.614804       -0.155876   
10201               -0.107789        -0.614804        6.415374   

       deposit_type_1  days_in_waiting_list  customer_type_0  customer_type_1  \
0            0.068031             -0.160405        -0.222442        -0.616556   
1            0.068031             -0.160405        -0.222442        -0.616556   
2            0.068031             -0.160405        -0.222442        -0.616556   
3            0.068031             -0.160405        -0.222442        -0.616556   
4            0.068031             -0.160405        -0.222442        -0.616556   
...               ...                   ...              ...              ...   
10197        0.068031             -0.160405         4.495551        -0.616556   
10198        0.068031             -0.160405        -0.222442        -0.616556   
10199        0.068031             -0.160405        -0.222442        -0.616556   
10200        0.068031             -0.160405        -0.222442         1.621914   
10201        0.068031             -0.160405        -0.222442        -0.616556   

       customer_type_2  reserved_room_type_0  reserved_room_type_1  \
0             0.652576             -0.217298             -1.166163   
1             0.652576             -0.217298             -1.166163   
2             0.652576             -0.217298             -1.166163   
3             0.652576             -0.217298             -1.166163   
4             0.652576             -0.217298             -1.166163   
...                ...                   ...                   ...   
10197        -1.532387             -0.217298              0.857513   
10198         0.652576             -0.217298             -1.166163   
10199         0.652576             -0.217298             -1.166163   
10200        -1.532387             -0.217298              0.857513   
10201         0.652576             -0.217298              0.857513   

       reserved_room_type_2  reserved_room_type_3  \
0                 -0.665121              1.651496   
1                  1.503485             -0.605512   
2                 -0.665121              1.651496   
3                  1.503485             -0.605512   
4                  1.503485              1.651496   
...                     ...                   ...   
10197             -0.665121             -0.605512   
10198              1.503485             -0.605512   
10199              1.503485             -0.605512   
10200             -0.665121             -0.605512   
10201             -0.665121             -0.605512   

       required_car_parking_spaces  total_of_special_requests  is_canceled  
0                        -0.424396                   0.056662     1.796157  
1                         2.115010                  -0.906789    -0.556744  
2                        -0.424396                   0.056662    -0.556744  
3                        -0.424396                   0.056662    -0.556744  
4                         2.115010                   1.983565    -0.556744  
...                            ...                        ...          ...  
10197                    -0.424396                   1.983565     1.796157  
10198                    -0.424396                   1.020114    -0.556744  
10199                    -0.424396                   1.983565    -0.556744  
10200                    -0.424396                  -0.906789    -0.556744  
10201                    -0.424396                  -0.906789     1.796157  

[10202 rows x 19 columns]
2023-07-28 21:39:26,762:INFO:get_config() successfully completed......................................
2023-07-28 21:39:43,776:INFO:Initializing get_config()
2023-07-28 21:39:43,776:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, variable=X_train_transformed)
2023-07-28 21:39:43,841:INFO:Variable: X_train returned as        market_segment_0  market_segment_1  market_segment_2  market_segment_3  \
0             -0.009901         -0.535263         -0.737328          0.754358   
1             -0.009901         -0.535263          1.356248         -1.325631   
2             -0.009901         -0.535263         -0.737328          0.754358   
3             -0.009901         -0.535263         -0.737328          0.754358   
4             -0.009901         -0.535263         -0.737328          0.754358   
...                 ...               ...               ...               ...   
10197         -0.009901         -0.535263         -0.737328          0.754358   
10198         -0.009901         -0.535263         -0.737328          0.754358   
10199         -0.009901         -0.535263         -0.737328          0.754358   
10200         -0.009901          1.868239         -0.737328         -1.325631   
10201         -0.009901         -0.535263          1.356248          0.754358   

       previous_cancellations  booking_changes  deposit_type_0  \
0                   -0.107789        -0.614804       -0.155876   
1                   -0.107789        -0.614804       -0.155876   
2                   -0.107789        -0.614804       -0.155876   
3                   -0.107789         3.251693       -0.155876   
4                   -0.107789        -0.614804       -0.155876   
...                       ...              ...             ...   
10197               -0.107789        -0.614804       -0.155876   
10198               -0.107789        -0.614804       -0.155876   
10199               -0.107789         0.158495       -0.155876   
10200               -0.107789        -0.614804       -0.155876   
10201               -0.107789        -0.614804        6.415374   

       deposit_type_1  days_in_waiting_list  customer_type_0  customer_type_1  \
0            0.068031             -0.160405        -0.222442        -0.616556   
1            0.068031             -0.160405        -0.222442        -0.616556   
2            0.068031             -0.160405        -0.222442        -0.616556   
3            0.068031             -0.160405        -0.222442        -0.616556   
4            0.068031             -0.160405        -0.222442        -0.616556   
...               ...                   ...              ...              ...   
10197        0.068031             -0.160405         4.495551        -0.616556   
10198        0.068031             -0.160405        -0.222442        -0.616556   
10199        0.068031             -0.160405        -0.222442        -0.616556   
10200        0.068031             -0.160405        -0.222442         1.621914   
10201        0.068031             -0.160405        -0.222442        -0.616556   

       customer_type_2  reserved_room_type_0  reserved_room_type_1  \
0             0.652576             -0.217298             -1.166163   
1             0.652576             -0.217298             -1.166163   
2             0.652576             -0.217298             -1.166163   
3             0.652576             -0.217298             -1.166163   
4             0.652576             -0.217298             -1.166163   
...                ...                   ...                   ...   
10197        -1.532387             -0.217298              0.857513   
10198         0.652576             -0.217298             -1.166163   
10199         0.652576             -0.217298             -1.166163   
10200        -1.532387             -0.217298              0.857513   
10201         0.652576             -0.217298              0.857513   

       reserved_room_type_2  reserved_room_type_3  \
0                 -0.665121              1.651496   
1                  1.503485             -0.605512   
2                 -0.665121              1.651496   
3                  1.503485             -0.605512   
4                  1.503485              1.651496   
...                     ...                   ...   
10197             -0.665121             -0.605512   
10198              1.503485             -0.605512   
10199              1.503485             -0.605512   
10200             -0.665121             -0.605512   
10201             -0.665121             -0.605512   

       required_car_parking_spaces  total_of_special_requests  is_canceled  
0                        -0.424396                   0.056662     1.796157  
1                         2.115010                  -0.906789    -0.556744  
2                        -0.424396                   0.056662    -0.556744  
3                        -0.424396                   0.056662    -0.556744  
4                         2.115010                   1.983565    -0.556744  
...                            ...                        ...          ...  
10197                    -0.424396                   1.983565     1.796157  
10198                    -0.424396                   1.020114    -0.556744  
10199                    -0.424396                   1.983565    -0.556744  
10200                    -0.424396                  -0.906789    -0.556744  
10201                    -0.424396                  -0.906789     1.796157  

[10202 rows x 19 columns]
2023-07-28 21:39:43,841:INFO:get_config() successfully completed......................................
2023-07-28 21:39:49,273:INFO:Initializing create_model()
2023-07-28 21:39:49,273:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=7, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.1})
2023-07-28 21:39:49,273:INFO:Checking exceptions
2023-07-28 21:39:49,362:INFO:Importing untrained model
2023-07-28 21:39:49,370:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:39:49,378:INFO:Fitting Model
2023-07-28 21:39:51,240:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:39:51,240:INFO:create_models() successfully completed......................................
2023-07-28 21:39:51,248:INFO:Uploading results into container
2023-07-28 21:39:51,248:INFO:Uploading model into container now
2023-07-28 21:39:51,248:INFO:_master_model_container: 1
2023-07-28 21:39:51,248:INFO:_display_container: 2
2023-07-28 21:39:51,248:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:39:51,248:INFO:create_model() successfully completed......................................
2023-07-28 21:39:58,090:INFO:Initializing create_model()
2023-07-28 21:39:58,090:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=20, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.1})
2023-07-28 21:39:58,090:INFO:Checking exceptions
2023-07-28 21:39:58,195:INFO:Importing untrained model
2023-07-28 21:39:58,204:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:39:58,204:INFO:Fitting Model
2023-07-28 21:40:00,050:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:40:00,050:INFO:create_models() successfully completed......................................
2023-07-28 21:40:00,050:INFO:Uploading results into container
2023-07-28 21:40:00,050:INFO:Uploading model into container now
2023-07-28 21:40:00,058:INFO:_master_model_container: 2
2023-07-28 21:40:00,058:INFO:_display_container: 3
2023-07-28 21:40:00,058:INFO:DBSCAN(eps=0.1, n_jobs=-1)
2023-07-28 21:40:00,058:INFO:create_model() successfully completed......................................
2023-07-28 21:40:02,456:INFO:Initializing create_model()
2023-07-28 21:40:02,456:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=20, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-28 21:40:02,456:INFO:Checking exceptions
2023-07-28 21:40:02,545:INFO:Importing untrained model
2023-07-28 21:40:02,545:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:02,553:INFO:Fitting Model
2023-07-28 21:40:04,397:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:04,397:INFO:create_models() successfully completed......................................
2023-07-28 21:40:04,397:INFO:Uploading results into container
2023-07-28 21:40:04,397:INFO:Uploading model into container now
2023-07-28 21:40:04,405:INFO:_master_model_container: 3
2023-07-28 21:40:04,405:INFO:_display_container: 4
2023-07-28 21:40:04,405:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:04,405:INFO:create_model() successfully completed......................................
2023-07-28 21:40:06,758:INFO:Initializing create_model()
2023-07-28 21:40:06,758:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=20, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.9})
2023-07-28 21:40:06,758:INFO:Checking exceptions
2023-07-28 21:40:06,855:INFO:Importing untrained model
2023-07-28 21:40:06,863:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:06,863:INFO:Fitting Model
2023-07-28 21:40:08,708:INFO:DBSCAN(eps=0.9, n_jobs=-1)
2023-07-28 21:40:08,708:INFO:create_models() successfully completed......................................
2023-07-28 21:40:08,716:INFO:Uploading results into container
2023-07-28 21:40:08,716:INFO:Uploading model into container now
2023-07-28 21:40:08,724:INFO:_master_model_container: 4
2023-07-28 21:40:08,724:INFO:_display_container: 5
2023-07-28 21:40:08,724:INFO:DBSCAN(eps=0.9, n_jobs=-1)
2023-07-28 21:40:08,724:INFO:create_model() successfully completed......................................
2023-07-28 21:40:15,128:INFO:Initializing create_model()
2023-07-28 21:40:15,128:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=20, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-28 21:40:15,128:INFO:Checking exceptions
2023-07-28 21:40:15,216:INFO:Importing untrained model
2023-07-28 21:40:15,216:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:15,224:INFO:Fitting Model
2023-07-28 21:40:17,090:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:17,090:INFO:create_models() successfully completed......................................
2023-07-28 21:40:17,090:INFO:Uploading results into container
2023-07-28 21:40:17,098:INFO:Uploading model into container now
2023-07-28 21:40:17,098:INFO:_master_model_container: 5
2023-07-28 21:40:17,106:INFO:_display_container: 6
2023-07-28 21:40:17,106:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:17,106:INFO:create_model() successfully completed......................................
2023-07-28 21:40:20,079:INFO:Initializing create_model()
2023-07-28 21:40:20,079:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=100, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-28 21:40:20,079:INFO:Checking exceptions
2023-07-28 21:40:20,176:INFO:Importing untrained model
2023-07-28 21:40:20,184:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:20,184:INFO:Fitting Model
2023-07-28 21:40:21,927:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:21,927:INFO:create_models() successfully completed......................................
2023-07-28 21:40:21,927:INFO:Uploading results into container
2023-07-28 21:40:21,927:INFO:Uploading model into container now
2023-07-28 21:40:21,935:INFO:_master_model_container: 6
2023-07-28 21:40:21,935:INFO:_display_container: 7
2023-07-28 21:40:21,935:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:21,935:INFO:create_model() successfully completed......................................
2023-07-28 21:40:25,364:INFO:Initializing create_model()
2023-07-28 21:40:25,364:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=60, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-28 21:40:25,364:INFO:Checking exceptions
2023-07-28 21:40:25,454:INFO:Importing untrained model
2023-07-28 21:40:25,454:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:25,462:INFO:Fitting Model
2023-07-28 21:40:27,234:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:27,234:INFO:create_models() successfully completed......................................
2023-07-28 21:40:27,243:INFO:Uploading results into container
2023-07-28 21:40:27,243:INFO:Uploading model into container now
2023-07-28 21:40:27,259:INFO:_master_model_container: 7
2023-07-28 21:40:27,259:INFO:_display_container: 8
2023-07-28 21:40:27,259:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:27,259:INFO:create_model() successfully completed......................................
2023-07-28 21:40:31,322:INFO:Initializing create_model()
2023-07-28 21:40:31,322:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001C881BB3F40>, estimator=dbscan, num_clusters=80, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'eps': 0.6})
2023-07-28 21:40:31,322:INFO:Checking exceptions
2023-07-28 21:40:31,410:INFO:Importing untrained model
2023-07-28 21:40:31,418:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-28 21:40:31,418:INFO:Fitting Model
2023-07-28 21:40:33,155:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:33,155:INFO:create_models() successfully completed......................................
2023-07-28 21:40:33,155:INFO:Uploading results into container
2023-07-28 21:40:33,164:INFO:Uploading model into container now
2023-07-28 21:40:33,171:INFO:_master_model_container: 8
2023-07-28 21:40:33,171:INFO:_display_container: 9
2023-07-28 21:40:33,171:INFO:DBSCAN(eps=0.6, n_jobs=-1)
2023-07-28 21:40:33,171:INFO:create_model() successfully completed......................................
2023-07-28 21:41:42,448:INFO:gpu_param set to False
2023-07-28 21:41:42,448:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-28 21:41:42,455:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:22,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:31:22,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:31:22,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:31:22,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:31:23,937:INFO:PyCaret ClusteringExperiment
2023-07-29 20:31:23,937:INFO:Logging name: cluster-default-name
2023-07-29 20:31:23,937:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:31:23,937:INFO:version 3.0.4
2023-07-29 20:31:23,937:INFO:Initializing setup()
2023-07-29 20:31:23,937:INFO:self.USI: 0dfa
2023-07-29 20:31:23,937:INFO:self._variable_keys: {'seed', 'idx', 'data', 'n_jobs_param', 'exp_name_log', 'pipeline', 'gpu_param', 'log_plots_param', 'html_param', 'logging_param', 'X', 'USI', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'memory', 'exp_id'}
2023-07-29 20:31:23,937:INFO:Checking environment
2023-07-29 20:31:23,937:INFO:python_version: 3.9.13
2023-07-29 20:31:23,937:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:31:23,937:INFO:machine: AMD64
2023-07-29 20:31:23,937:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:31:23,942:INFO:Memory: svmem(total=33737928704, available=25838202880, percent=23.4, used=7899725824, free=25838202880)
2023-07-29 20:31:23,942:INFO:Physical Core: 8
2023-07-29 20:31:23,942:INFO:Logical Core: 16
2023-07-29 20:31:23,942:INFO:Checking libraries
2023-07-29 20:31:23,942:INFO:System:
2023-07-29 20:31:23,942:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:31:23,942:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:31:23,942:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:31:23,942:INFO:PyCaret required dependencies:
2023-07-29 20:31:24,004:INFO:                 pip: 22.0.4
2023-07-29 20:31:24,004:INFO:          setuptools: 58.1.0
2023-07-29 20:31:24,004:INFO:             pycaret: 3.0.4
2023-07-29 20:31:24,004:INFO:             IPython: 8.13.1
2023-07-29 20:31:24,004:INFO:          ipywidgets: 8.0.7
2023-07-29 20:31:24,004:INFO:                tqdm: 4.65.0
2023-07-29 20:31:24,004:INFO:               numpy: 1.23.0
2023-07-29 20:31:24,004:INFO:              pandas: 1.5.3
2023-07-29 20:31:24,004:INFO:              jinja2: 3.1.2
2023-07-29 20:31:24,005:INFO:               scipy: 1.10.1
2023-07-29 20:31:24,005:INFO:              joblib: 1.3.1
2023-07-29 20:31:24,005:INFO:             sklearn: 1.2.2
2023-07-29 20:31:24,005:INFO:                pyod: 1.1.0
2023-07-29 20:31:24,005:INFO:            imblearn: 0.11.0
2023-07-29 20:31:24,005:INFO:   category_encoders: 2.6.1
2023-07-29 20:31:24,005:INFO:            lightgbm: 4.0.0
2023-07-29 20:31:24,005:INFO:               numba: 0.57.1
2023-07-29 20:31:24,005:INFO:            requests: 2.31.0
2023-07-29 20:31:24,005:INFO:          matplotlib: 3.7.1
2023-07-29 20:31:24,005:INFO:          scikitplot: 0.3.7
2023-07-29 20:31:24,005:INFO:         yellowbrick: 1.5
2023-07-29 20:31:24,005:INFO:              plotly: 5.15.0
2023-07-29 20:31:24,005:INFO:    plotly-resampler: Not installed
2023-07-29 20:31:24,005:INFO:             kaleido: 0.2.1
2023-07-29 20:31:24,005:INFO:           schemdraw: 0.15
2023-07-29 20:31:24,005:INFO:         statsmodels: 0.14.0
2023-07-29 20:31:24,005:INFO:              sktime: 0.20.1
2023-07-29 20:31:24,005:INFO:               tbats: 1.1.3
2023-07-29 20:31:24,005:INFO:            pmdarima: 2.0.3
2023-07-29 20:31:24,005:INFO:              psutil: 5.9.5
2023-07-29 20:31:24,005:INFO:          markupsafe: 2.1.3
2023-07-29 20:31:24,005:INFO:             pickle5: Not installed
2023-07-29 20:31:24,005:INFO:         cloudpickle: 2.2.1
2023-07-29 20:31:24,005:INFO:         deprecation: 2.1.0
2023-07-29 20:31:24,005:INFO:              xxhash: 3.2.0
2023-07-29 20:31:24,005:INFO:           wurlitzer: Not installed
2023-07-29 20:31:24,005:INFO:PyCaret optional dependencies:
2023-07-29 20:31:24,014:INFO:                shap: 0.42.1
2023-07-29 20:31:24,014:INFO:           interpret: Not installed
2023-07-29 20:31:24,014:INFO:                umap: 0.5.3
2023-07-29 20:31:24,014:INFO:    pandas_profiling: Not installed
2023-07-29 20:31:24,014:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:31:24,014:INFO:             autoviz: 0.1.730
2023-07-29 20:31:24,014:INFO:           fairlearn: Not installed
2023-07-29 20:31:24,014:INFO:          deepchecks: Not installed
2023-07-29 20:31:24,014:INFO:             xgboost: 1.7.6
2023-07-29 20:31:24,014:INFO:            catboost: Not installed
2023-07-29 20:31:24,014:INFO:              kmodes: Not installed
2023-07-29 20:31:24,014:INFO:             mlxtend: Not installed
2023-07-29 20:31:24,014:INFO:       statsforecast: Not installed
2023-07-29 20:31:24,014:INFO:        tune_sklearn: Not installed
2023-07-29 20:31:24,014:INFO:                 ray: Not installed
2023-07-29 20:31:24,014:INFO:            hyperopt: Not installed
2023-07-29 20:31:24,014:INFO:              optuna: Not installed
2023-07-29 20:31:24,014:INFO:               skopt: Not installed
2023-07-29 20:31:24,014:INFO:              mlflow: Not installed
2023-07-29 20:31:24,014:INFO:              gradio: Not installed
2023-07-29 20:31:24,014:INFO:             fastapi: Not installed
2023-07-29 20:31:24,014:INFO:             uvicorn: Not installed
2023-07-29 20:31:24,014:INFO:              m2cgen: Not installed
2023-07-29 20:31:24,014:INFO:           evidently: Not installed
2023-07-29 20:31:24,015:INFO:               fugue: Not installed
2023-07-29 20:31:24,015:INFO:           streamlit: Not installed
2023-07-29 20:31:24,015:INFO:             prophet: Not installed
2023-07-29 20:31:24,015:INFO:None
2023-07-29 20:31:24,015:INFO:Set up data.
2023-07-29 20:31:24,019:INFO:Set up index.
2023-07-29 20:31:24,019:INFO:Assigning column types.
2023-07-29 20:31:24,022:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:31:24,022:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:31:24,022:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,022:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:31:24,023:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,023:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:31:24,023:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,023:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,024:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:31:24,026:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2023-07-29 20:31:24,026:INFO:Creating final display dataframe.
2023-07-29 20:31:24,037:INFO:Setup _display_container:               Description        Value
0              Session id           22
1     Original data shape  (10202, 10)
2  Transformed data shape  (10202, 10)
3        Numeric features            6
4    Categorical features            4
2023-07-29 20:31:24,042:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,042:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:31:24,043:INFO:setup() successfully completed in 0.51s...............
2023-07-29 20:33:43,305:INFO:Initializing create_model()
2023-07-29 20:33:43,305:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216E7C12580>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:33:43,305:INFO:Checking exceptions
2023-07-29 20:33:43,322:INFO:Importing untrained model
2023-07-29 20:33:43,326:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:33:43,327:INFO:Fitting Model
2023-07-29 20:34:09,291:INFO:Initializing create_model()
2023-07-29 20:34:09,291:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216E7C12580>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:34:09,291:INFO:Checking exceptions
2023-07-29 20:34:09,309:INFO:Importing untrained model
2023-07-29 20:34:09,312:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:34:09,314:INFO:Fitting Model
2023-07-29 20:34:50,017:INFO:PyCaret ClusteringExperiment
2023-07-29 20:34:50,017:INFO:Logging name: cluster-default-name
2023-07-29 20:34:50,017:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:34:50,017:INFO:version 3.0.4
2023-07-29 20:34:50,017:INFO:Initializing setup()
2023-07-29 20:34:50,017:INFO:self.USI: 34d4
2023-07-29 20:34:50,017:INFO:self._variable_keys: {'seed', 'idx', 'data', 'n_jobs_param', 'exp_name_log', 'pipeline', 'gpu_param', 'log_plots_param', 'html_param', 'logging_param', 'X', 'USI', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'memory', 'exp_id'}
2023-07-29 20:34:50,017:INFO:Checking environment
2023-07-29 20:34:50,017:INFO:python_version: 3.9.13
2023-07-29 20:34:50,017:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:34:50,017:INFO:machine: AMD64
2023-07-29 20:34:50,018:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:34:50,021:INFO:Memory: svmem(total=33737928704, available=25902698496, percent=23.2, used=7835230208, free=25902698496)
2023-07-29 20:34:50,021:INFO:Physical Core: 8
2023-07-29 20:34:50,021:INFO:Logical Core: 16
2023-07-29 20:34:50,021:INFO:Checking libraries
2023-07-29 20:34:50,021:INFO:System:
2023-07-29 20:34:50,022:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:34:50,022:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:34:50,022:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:34:50,022:INFO:PyCaret required dependencies:
2023-07-29 20:34:50,022:INFO:                 pip: 22.0.4
2023-07-29 20:34:50,022:INFO:          setuptools: 58.1.0
2023-07-29 20:34:50,022:INFO:             pycaret: 3.0.4
2023-07-29 20:34:50,022:INFO:             IPython: 8.13.1
2023-07-29 20:34:50,022:INFO:          ipywidgets: 8.0.7
2023-07-29 20:34:50,022:INFO:                tqdm: 4.65.0
2023-07-29 20:34:50,022:INFO:               numpy: 1.23.0
2023-07-29 20:34:50,022:INFO:              pandas: 1.5.3
2023-07-29 20:34:50,022:INFO:              jinja2: 3.1.2
2023-07-29 20:34:50,022:INFO:               scipy: 1.10.1
2023-07-29 20:34:50,022:INFO:              joblib: 1.3.1
2023-07-29 20:34:50,022:INFO:             sklearn: 1.2.2
2023-07-29 20:34:50,022:INFO:                pyod: 1.1.0
2023-07-29 20:34:50,022:INFO:            imblearn: 0.11.0
2023-07-29 20:34:50,022:INFO:   category_encoders: 2.6.1
2023-07-29 20:34:50,022:INFO:            lightgbm: 4.0.0
2023-07-29 20:34:50,022:INFO:               numba: 0.57.1
2023-07-29 20:34:50,022:INFO:            requests: 2.31.0
2023-07-29 20:34:50,022:INFO:          matplotlib: 3.7.1
2023-07-29 20:34:50,022:INFO:          scikitplot: 0.3.7
2023-07-29 20:34:50,022:INFO:         yellowbrick: 1.5
2023-07-29 20:34:50,022:INFO:              plotly: 5.15.0
2023-07-29 20:34:50,022:INFO:    plotly-resampler: Not installed
2023-07-29 20:34:50,022:INFO:             kaleido: 0.2.1
2023-07-29 20:34:50,022:INFO:           schemdraw: 0.15
2023-07-29 20:34:50,022:INFO:         statsmodels: 0.14.0
2023-07-29 20:34:50,022:INFO:              sktime: 0.20.1
2023-07-29 20:34:50,022:INFO:               tbats: 1.1.3
2023-07-29 20:34:50,022:INFO:            pmdarima: 2.0.3
2023-07-29 20:34:50,022:INFO:              psutil: 5.9.5
2023-07-29 20:34:50,023:INFO:          markupsafe: 2.1.3
2023-07-29 20:34:50,023:INFO:             pickle5: Not installed
2023-07-29 20:34:50,023:INFO:         cloudpickle: 2.2.1
2023-07-29 20:34:50,023:INFO:         deprecation: 2.1.0
2023-07-29 20:34:50,023:INFO:              xxhash: 3.2.0
2023-07-29 20:34:50,023:INFO:           wurlitzer: Not installed
2023-07-29 20:34:50,023:INFO:PyCaret optional dependencies:
2023-07-29 20:34:50,023:INFO:                shap: 0.42.1
2023-07-29 20:34:50,023:INFO:           interpret: Not installed
2023-07-29 20:34:50,023:INFO:                umap: 0.5.3
2023-07-29 20:34:50,023:INFO:    pandas_profiling: Not installed
2023-07-29 20:34:50,023:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:34:50,023:INFO:             autoviz: 0.1.730
2023-07-29 20:34:50,023:INFO:           fairlearn: Not installed
2023-07-29 20:34:50,023:INFO:          deepchecks: Not installed
2023-07-29 20:34:50,023:INFO:             xgboost: 1.7.6
2023-07-29 20:34:50,023:INFO:            catboost: Not installed
2023-07-29 20:34:50,023:INFO:              kmodes: Not installed
2023-07-29 20:34:50,023:INFO:             mlxtend: Not installed
2023-07-29 20:34:50,023:INFO:       statsforecast: Not installed
2023-07-29 20:34:50,023:INFO:        tune_sklearn: Not installed
2023-07-29 20:34:50,023:INFO:                 ray: Not installed
2023-07-29 20:34:50,023:INFO:            hyperopt: Not installed
2023-07-29 20:34:50,023:INFO:              optuna: Not installed
2023-07-29 20:34:50,023:INFO:               skopt: Not installed
2023-07-29 20:34:50,023:INFO:              mlflow: Not installed
2023-07-29 20:34:50,023:INFO:              gradio: Not installed
2023-07-29 20:34:50,023:INFO:             fastapi: Not installed
2023-07-29 20:34:50,023:INFO:             uvicorn: Not installed
2023-07-29 20:34:50,023:INFO:              m2cgen: Not installed
2023-07-29 20:34:50,023:INFO:           evidently: Not installed
2023-07-29 20:34:50,023:INFO:               fugue: Not installed
2023-07-29 20:34:50,023:INFO:           streamlit: Not installed
2023-07-29 20:34:50,023:INFO:             prophet: Not installed
2023-07-29 20:34:50,023:INFO:None
2023-07-29 20:34:50,023:INFO:Set up data.
2023-07-29 20:34:50,030:INFO:Set up index.
2023-07-29 20:34:50,030:INFO:Assigning column types.
2023-07-29 20:34:50,032:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:34:50,032:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:34:50,033:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,033:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:34:50,033:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,033:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:34:50,033:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,033:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,034:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:34:50,035:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2023-07-29 20:34:50,035:INFO:Creating final display dataframe.
2023-07-29 20:34:50,040:INFO:Setup _display_container:               Description        Value
0              Session id           22
1     Original data shape  (10202, 19)
2  Transformed data shape  (10202, 19)
3        Numeric features           19
2023-07-29 20:34:50,044:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,044:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:34:50,044:INFO:setup() successfully completed in 0.23s...............
2023-07-29 20:34:51,387:INFO:Initializing create_model()
2023-07-29 20:34:51,387:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:34:51,387:INFO:Checking exceptions
2023-07-29 20:34:51,402:INFO:Importing untrained model
2023-07-29 20:34:51,404:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:34:51,407:INFO:Fitting Model
2023-07-29 20:34:53,955:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:34:53,955:INFO:create_models() successfully completed......................................
2023-07-29 20:34:53,958:INFO:Uploading results into container
2023-07-29 20:34:53,960:INFO:Uploading model into container now
2023-07-29 20:34:53,966:INFO:_master_model_container: 1
2023-07-29 20:34:53,966:INFO:_display_container: 2
2023-07-29 20:34:53,966:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:34:53,966:INFO:create_model() successfully completed......................................
2023-07-29 20:35:07,988:INFO:Initializing create_model()
2023-07-29 20:35:07,988:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:35:07,988:INFO:Checking exceptions
2023-07-29 20:35:08,004:INFO:Importing untrained model
2023-07-29 20:35:08,006:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:08,008:INFO:Fitting Model
2023-07-29 20:35:10,330:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:10,330:INFO:create_models() successfully completed......................................
2023-07-29 20:35:10,333:INFO:Uploading results into container
2023-07-29 20:35:10,335:INFO:Uploading model into container now
2023-07-29 20:35:10,339:INFO:_master_model_container: 2
2023-07-29 20:35:10,339:INFO:_display_container: 3
2023-07-29 20:35:10,339:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:10,339:INFO:create_model() successfully completed......................................
2023-07-29 20:35:15,217:INFO:Initializing create_model()
2023-07-29 20:35:15,217:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:35:15,217:INFO:Checking exceptions
2023-07-29 20:35:15,232:INFO:Importing untrained model
2023-07-29 20:35:15,235:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:15,237:INFO:Fitting Model
2023-07-29 20:35:16,334:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:16,334:INFO:create_models() successfully completed......................................
2023-07-29 20:35:16,337:INFO:Uploading results into container
2023-07-29 20:35:16,339:INFO:Uploading model into container now
2023-07-29 20:35:16,343:INFO:_master_model_container: 3
2023-07-29 20:35:16,343:INFO:_display_container: 4
2023-07-29 20:35:16,344:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:16,344:INFO:create_model() successfully completed......................................
2023-07-29 20:35:18,706:INFO:Initializing create_model()
2023-07-29 20:35:18,706:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=3, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:35:18,707:INFO:Checking exceptions
2023-07-29 20:35:18,722:INFO:Importing untrained model
2023-07-29 20:35:18,725:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:18,727:INFO:Fitting Model
2023-07-29 20:35:19,793:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:19,793:INFO:create_models() successfully completed......................................
2023-07-29 20:35:19,796:INFO:Uploading results into container
2023-07-29 20:35:19,798:INFO:Uploading model into container now
2023-07-29 20:35:19,801:INFO:_master_model_container: 4
2023-07-29 20:35:19,801:INFO:_display_container: 5
2023-07-29 20:35:19,802:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:19,802:INFO:create_model() successfully completed......................................
2023-07-29 20:35:21,215:INFO:Initializing create_model()
2023-07-29 20:35:21,215:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=2, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:35:21,215:INFO:Checking exceptions
2023-07-29 20:35:21,232:INFO:Importing untrained model
2023-07-29 20:35:21,234:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:21,238:INFO:Fitting Model
2023-07-29 20:35:22,311:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:22,312:INFO:create_models() successfully completed......................................
2023-07-29 20:35:22,314:INFO:Uploading results into container
2023-07-29 20:35:22,316:INFO:Uploading model into container now
2023-07-29 20:35:22,320:INFO:_master_model_container: 5
2023-07-29 20:35:22,320:INFO:_display_container: 6
2023-07-29 20:35:22,321:INFO:DBSCAN(n_jobs=-1)
2023-07-29 20:35:22,321:INFO:create_model() successfully completed......................................
2023-07-29 20:35:26,277:INFO:Initializing create_model()
2023-07-29 20:35:26,277:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:35:26,277:INFO:Checking exceptions
2023-07-29 20:35:26,294:INFO:Importing untrained model
2023-07-29 20:35:26,296:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:26,299:INFO:Fitting Model
2023-07-29 20:35:27,551:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:35:27,551:INFO:create_models() successfully completed......................................
2023-07-29 20:35:27,554:INFO:Uploading results into container
2023-07-29 20:35:27,556:INFO:Uploading model into container now
2023-07-29 20:35:27,560:INFO:_master_model_container: 6
2023-07-29 20:35:27,560:INFO:_display_container: 7
2023-07-29 20:35:27,561:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:35:27,561:INFO:create_model() successfully completed......................................
2023-07-29 20:35:43,863:INFO:Initializing create_model()
2023-07-29 20:35:43,863:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:35:43,863:INFO:Checking exceptions
2023-07-29 20:35:43,879:INFO:Importing untrained model
2023-07-29 20:35:43,895:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:35:43,895:INFO:Fitting Model
2023-07-29 20:35:45,189:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:35:45,189:INFO:create_models() successfully completed......................................
2023-07-29 20:35:45,192:INFO:Uploading results into container
2023-07-29 20:35:45,193:INFO:Uploading model into container now
2023-07-29 20:35:45,197:INFO:_master_model_container: 7
2023-07-29 20:35:45,198:INFO:_display_container: 8
2023-07-29 20:35:45,198:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:35:45,198:INFO:create_model() successfully completed......................................
2023-07-29 20:36:14,825:INFO:Initializing plot_model()
2023-07-29 20:36:14,825:INFO:plot_model(plot=elbow, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:36:14,825:INFO:Checking exceptions
2023-07-29 20:36:14,825:INFO:Preloading libraries
2023-07-29 20:36:14,841:INFO:Copying training dataset
2023-07-29 20:36:14,841:INFO:Plot type: elbow
2023-07-29 20:36:14,857:INFO:Fitting Model
2023-07-29 20:36:14,857:ERROR:Elbow plot failed. Exception:
2023-07-29 20:36:14,873:ERROR:Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1053, in elbow
    return show_yellowbrick_plot(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\yellowbrick\cluster\elbow.py", line 338, in fit
    self.estimator.set_params(n_clusters=k)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\base.py", line 205, in set_params
    raise ValueError(
ValueError: Invalid parameter 'n_clusters' for estimator DBSCAN(eps=0.1, min_samples=1, n_jobs=-1). Valid parameters are: ['algorithm', 'eps', 'leaf_size', 'metric', 'metric_params', 'min_samples', 'n_jobs', 'p'].

2023-07-29 20:36:23,341:INFO:Initializing plot_model()
2023-07-29 20:36:23,341:INFO:plot_model(plot=silhouette, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:36:23,341:INFO:Checking exceptions
2023-07-29 20:36:23,341:INFO:Preloading libraries
2023-07-29 20:36:23,341:INFO:Copying training dataset
2023-07-29 20:36:23,341:INFO:Plot type: silhouette
2023-07-29 20:36:23,341:INFO:Fitting Model
2023-07-29 20:36:23,341:ERROR:Silhouette plot failed. Exception:
2023-07-29 20:36:23,341:ERROR:Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py", line 1079, in silhouette
    return show_yellowbrick_plot(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\plots\yellowbrick.py", line 87, in show_yellowbrick_plot
    visualizer.fit(X_train, y_train, **fit_kwargs_and_kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\yellowbrick\cluster\silhouette.py", line 142, in fit
    self.n_clusters_ = self.estimator.n_clusters
AttributeError: 'DBSCAN' object has no attribute 'n_clusters'

2023-07-29 20:36:34,958:INFO:Initializing create_model()
2023-07-29 20:36:34,958:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:36:34,958:INFO:Checking exceptions
2023-07-29 20:36:34,974:INFO:Importing untrained model
2023-07-29 20:36:34,977:INFO:K-Means Clustering Imported successfully
2023-07-29 20:36:34,980:INFO:Fitting Model
2023-07-29 20:36:36,293:INFO:KMeans(n_clusters=4, random_state=22)
2023-07-29 20:36:36,293:INFO:create_models() successfully completed......................................
2023-07-29 20:36:36,296:INFO:Uploading results into container
2023-07-29 20:36:36,298:INFO:Uploading model into container now
2023-07-29 20:36:36,302:INFO:_master_model_container: 8
2023-07-29 20:36:36,303:INFO:_display_container: 9
2023-07-29 20:36:36,303:INFO:KMeans(n_clusters=4, random_state=22)
2023-07-29 20:36:36,303:INFO:create_model() successfully completed......................................
2023-07-29 20:36:39,764:INFO:Initializing plot_model()
2023-07-29 20:36:39,764:INFO:plot_model(plot=silhouette, fold=None, verbose=True, display=None, display_format=None, estimator=KMeans(n_clusters=4, random_state=22), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:36:39,764:INFO:Checking exceptions
2023-07-29 20:36:39,766:INFO:Preloading libraries
2023-07-29 20:36:39,766:INFO:Copying training dataset
2023-07-29 20:36:39,766:INFO:Plot type: silhouette
2023-07-29 20:36:39,769:INFO:Fitting Model
2023-07-29 20:36:42,267:INFO:Visual Rendered Successfully
2023-07-29 20:36:42,359:INFO:plot_model() successfully completed......................................
2023-07-29 20:36:50,252:INFO:Initializing plot_model()
2023-07-29 20:36:50,252:INFO:plot_model(plot=elbow, fold=None, verbose=True, display=None, display_format=None, estimator=KMeans(n_clusters=4, random_state=22), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:36:50,252:INFO:Checking exceptions
2023-07-29 20:36:50,255:INFO:Preloading libraries
2023-07-29 20:36:50,255:INFO:Copying training dataset
2023-07-29 20:36:50,255:INFO:Plot type: elbow
2023-07-29 20:36:50,258:INFO:Fitting Model
2023-07-29 20:36:50,964:INFO:Visual Rendered Successfully
2023-07-29 20:36:51,056:INFO:plot_model() successfully completed......................................
2023-07-29 20:37:02,747:INFO:Initializing create_model()
2023-07-29 20:37:02,747:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=kmeans, num_clusters=5, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:37:02,747:INFO:Checking exceptions
2023-07-29 20:37:02,764:INFO:Importing untrained model
2023-07-29 20:37:02,767:INFO:K-Means Clustering Imported successfully
2023-07-29 20:37:02,770:INFO:Fitting Model
2023-07-29 20:37:03,942:INFO:KMeans(n_clusters=5, random_state=22)
2023-07-29 20:37:03,942:INFO:create_models() successfully completed......................................
2023-07-29 20:37:03,945:INFO:Uploading results into container
2023-07-29 20:37:03,948:INFO:Uploading model into container now
2023-07-29 20:37:03,952:INFO:_master_model_container: 9
2023-07-29 20:37:03,952:INFO:_display_container: 10
2023-07-29 20:37:03,953:INFO:KMeans(n_clusters=5, random_state=22)
2023-07-29 20:37:03,953:INFO:create_model() successfully completed......................................
2023-07-29 20:37:20,408:INFO:Initializing create_model()
2023-07-29 20:37:20,408:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:37:20,408:INFO:Checking exceptions
2023-07-29 20:37:20,426:INFO:Importing untrained model
2023-07-29 20:37:20,428:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:37:20,431:INFO:Fitting Model
2023-07-29 20:37:21,700:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:37:21,700:INFO:create_models() successfully completed......................................
2023-07-29 20:37:21,703:INFO:Uploading results into container
2023-07-29 20:37:21,705:INFO:Uploading model into container now
2023-07-29 20:37:21,710:INFO:_master_model_container: 10
2023-07-29 20:37:21,711:INFO:_display_container: 11
2023-07-29 20:37:21,711:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:37:21,711:INFO:create_model() successfully completed......................................
2023-07-29 20:37:29,034:INFO:Initializing plot_model()
2023-07-29 20:37:29,034:INFO:plot_model(plot=cluster, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:37:29,034:INFO:Checking exceptions
2023-07-29 20:37:29,036:INFO:Preloading libraries
2023-07-29 20:37:29,036:INFO:Copying training dataset
2023-07-29 20:37:29,036:INFO:Plot type: cluster
2023-07-29 20:37:29,037:INFO:SubProcess assign_model() called ==================================
2023-07-29 20:37:29,037:INFO:Initializing assign_model()
2023-07-29 20:37:29,037:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=True, score=True, verbose=False)
2023-07-29 20:37:29,037:INFO:Checking exceptions
2023-07-29 20:37:29,037:INFO:Determining Trained Model
2023-07-29 20:37:29,037:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:37:29,037:INFO:Copying data
2023-07-29 20:37:29,040:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-29 20:37:29,043:INFO:(10202, 20)
2023-07-29 20:37:29,043:INFO:assign_model() successfully completed......................................
2023-07-29 20:37:29,043:INFO:SubProcess assign_model() end ==================================
2023-07-29 20:37:29,044:INFO:Fitting PCA()
2023-07-29 20:37:29,061:INFO:Sorting dataframe
2023-07-29 20:37:29,067:INFO:Rendering Visual
2023-07-29 20:37:33,024:INFO:Visual Rendered Successfully
2023-07-29 20:37:33,139:INFO:plot_model() successfully completed......................................
2023-07-29 20:38:28,890:INFO:Initializing plot_model()
2023-07-29 20:38:28,890:INFO:plot_model(plot=tsne, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, system=True)
2023-07-29 20:38:28,890:INFO:Checking exceptions
2023-07-29 20:38:28,895:INFO:Preloading libraries
2023-07-29 20:38:28,895:INFO:Copying training dataset
2023-07-29 20:38:28,896:INFO:Plot type: tsne
2023-07-29 20:38:28,896:INFO:SubProcess assign_model() called ==================================
2023-07-29 20:38:28,896:INFO:Initializing assign_model()
2023-07-29 20:38:28,896:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000216EC42A7C0>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=True, score=False, verbose=False)
2023-07-29 20:38:28,896:INFO:Checking exceptions
2023-07-29 20:38:28,896:INFO:Determining Trained Model
2023-07-29 20:38:28,896:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:38:28,896:INFO:Copying data
2023-07-29 20:38:28,901:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-29 20:38:28,906:INFO:(10202, 20)
2023-07-29 20:38:28,906:INFO:assign_model() successfully completed......................................
2023-07-29 20:38:28,906:INFO:SubProcess assign_model() end ==================================
2023-07-29 20:38:28,906:INFO:Fitting TSNE()
2023-07-29 20:39:02,657:INFO:Sorting dataframe
2023-07-29 20:39:02,676:INFO:Rendering Visual
2023-07-29 20:39:05,657:INFO:Visual Rendered Successfully
2023-07-29 20:39:05,782:INFO:plot_model() successfully completed......................................
2023-07-29 20:41:18,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:41:18,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:41:18,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:41:18,280:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-29 20:41:18,646:INFO:PyCaret ClusteringExperiment
2023-07-29 20:41:18,646:INFO:Logging name: cluster-default-name
2023-07-29 20:41:18,646:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:41:18,646:INFO:version 3.0.4
2023-07-29 20:41:18,646:INFO:Initializing setup()
2023-07-29 20:41:18,646:INFO:self.USI: 2c53
2023-07-29 20:41:18,646:INFO:self._variable_keys: {'data', 'seed', 'USI', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'memory', 'exp_name_log', 'exp_id', 'gpu_param', 'log_plots_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'html_param', 'idx'}
2023-07-29 20:41:18,646:INFO:Checking environment
2023-07-29 20:41:18,646:INFO:python_version: 3.9.13
2023-07-29 20:41:18,646:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:41:18,646:INFO:machine: AMD64
2023-07-29 20:41:18,646:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:41:18,650:INFO:Memory: svmem(total=33737928704, available=26174595072, percent=22.4, used=7563333632, free=26174595072)
2023-07-29 20:41:18,650:INFO:Physical Core: 8
2023-07-29 20:41:18,650:INFO:Logical Core: 16
2023-07-29 20:41:18,650:INFO:Checking libraries
2023-07-29 20:41:18,650:INFO:System:
2023-07-29 20:41:18,650:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:41:18,650:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:41:18,650:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:41:18,650:INFO:PyCaret required dependencies:
2023-07-29 20:41:18,679:INFO:                 pip: 22.0.4
2023-07-29 20:41:18,679:INFO:          setuptools: 58.1.0
2023-07-29 20:41:18,679:INFO:             pycaret: 3.0.4
2023-07-29 20:41:18,679:INFO:             IPython: 8.13.1
2023-07-29 20:41:18,679:INFO:          ipywidgets: 8.0.7
2023-07-29 20:41:18,679:INFO:                tqdm: 4.65.0
2023-07-29 20:41:18,679:INFO:               numpy: 1.23.0
2023-07-29 20:41:18,679:INFO:              pandas: 1.5.3
2023-07-29 20:41:18,679:INFO:              jinja2: 3.1.2
2023-07-29 20:41:18,679:INFO:               scipy: 1.10.1
2023-07-29 20:41:18,679:INFO:              joblib: 1.3.1
2023-07-29 20:41:18,679:INFO:             sklearn: 1.2.2
2023-07-29 20:41:18,679:INFO:                pyod: 1.1.0
2023-07-29 20:41:18,679:INFO:            imblearn: 0.11.0
2023-07-29 20:41:18,679:INFO:   category_encoders: 2.6.1
2023-07-29 20:41:18,679:INFO:            lightgbm: 4.0.0
2023-07-29 20:41:18,679:INFO:               numba: 0.57.1
2023-07-29 20:41:18,679:INFO:            requests: 2.31.0
2023-07-29 20:41:18,679:INFO:          matplotlib: 3.7.1
2023-07-29 20:41:18,679:INFO:          scikitplot: 0.3.7
2023-07-29 20:41:18,679:INFO:         yellowbrick: 1.5
2023-07-29 20:41:18,679:INFO:              plotly: 5.15.0
2023-07-29 20:41:18,679:INFO:    plotly-resampler: Not installed
2023-07-29 20:41:18,679:INFO:             kaleido: 0.2.1
2023-07-29 20:41:18,679:INFO:           schemdraw: 0.15
2023-07-29 20:41:18,680:INFO:         statsmodels: 0.14.0
2023-07-29 20:41:18,680:INFO:              sktime: 0.20.1
2023-07-29 20:41:18,680:INFO:               tbats: 1.1.3
2023-07-29 20:41:18,680:INFO:            pmdarima: 2.0.3
2023-07-29 20:41:18,680:INFO:              psutil: 5.9.5
2023-07-29 20:41:18,680:INFO:          markupsafe: 2.1.3
2023-07-29 20:41:18,680:INFO:             pickle5: Not installed
2023-07-29 20:41:18,680:INFO:         cloudpickle: 2.2.1
2023-07-29 20:41:18,680:INFO:         deprecation: 2.1.0
2023-07-29 20:41:18,680:INFO:              xxhash: 3.2.0
2023-07-29 20:41:18,680:INFO:           wurlitzer: Not installed
2023-07-29 20:41:18,680:INFO:PyCaret optional dependencies:
2023-07-29 20:41:18,689:INFO:                shap: 0.42.1
2023-07-29 20:41:18,689:INFO:           interpret: Not installed
2023-07-29 20:41:18,689:INFO:                umap: 0.5.3
2023-07-29 20:41:18,689:INFO:    pandas_profiling: Not installed
2023-07-29 20:41:18,689:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:41:18,689:INFO:             autoviz: 0.1.730
2023-07-29 20:41:18,689:INFO:           fairlearn: Not installed
2023-07-29 20:41:18,689:INFO:          deepchecks: Not installed
2023-07-29 20:41:18,689:INFO:             xgboost: 1.7.6
2023-07-29 20:41:18,689:INFO:            catboost: Not installed
2023-07-29 20:41:18,689:INFO:              kmodes: Not installed
2023-07-29 20:41:18,689:INFO:             mlxtend: Not installed
2023-07-29 20:41:18,689:INFO:       statsforecast: Not installed
2023-07-29 20:41:18,689:INFO:        tune_sklearn: Not installed
2023-07-29 20:41:18,689:INFO:                 ray: Not installed
2023-07-29 20:41:18,689:INFO:            hyperopt: Not installed
2023-07-29 20:41:18,689:INFO:              optuna: Not installed
2023-07-29 20:41:18,689:INFO:               skopt: Not installed
2023-07-29 20:41:18,689:INFO:              mlflow: Not installed
2023-07-29 20:41:18,689:INFO:              gradio: Not installed
2023-07-29 20:41:18,689:INFO:             fastapi: Not installed
2023-07-29 20:41:18,689:INFO:             uvicorn: Not installed
2023-07-29 20:41:18,689:INFO:              m2cgen: Not installed
2023-07-29 20:41:18,689:INFO:           evidently: Not installed
2023-07-29 20:41:18,689:INFO:               fugue: Not installed
2023-07-29 20:41:18,689:INFO:           streamlit: Not installed
2023-07-29 20:41:18,690:INFO:             prophet: Not installed
2023-07-29 20:41:18,690:INFO:None
2023-07-29 20:41:18,690:INFO:Set up data.
2023-07-29 20:41:18,694:INFO:Set up index.
2023-07-29 20:41:18,694:INFO:Assigning column types.
2023-07-29 20:41:18,695:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:41:18,696:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:41:18,696:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,696:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:41:18,696:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,696:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:41:18,696:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,696:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,698:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:41:18,699:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2023-07-29 20:41:18,699:INFO:Creating final display dataframe.
2023-07-29 20:41:18,705:INFO:Setup _display_container:               Description        Value
0              Session id           22
1     Original data shape  (10202, 19)
2  Transformed data shape  (10202, 19)
3        Numeric features           19
2023-07-29 20:41:18,709:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,709:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:41:18,709:INFO:setup() successfully completed in 0.26s...............
2023-07-29 20:41:21,866:INFO:Initializing create_model()
2023-07-29 20:41:21,866:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4A146610>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:41:21,867:INFO:Checking exceptions
2023-07-29 20:41:21,954:INFO:Importing untrained model
2023-07-29 20:41:21,957:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:41:21,960:INFO:Fitting Model
2023-07-29 20:41:23,215:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:41:23,215:INFO:create_models() successfully completed......................................
2023-07-29 20:41:23,218:INFO:Uploading results into container
2023-07-29 20:41:23,220:INFO:Uploading model into container now
2023-07-29 20:41:23,224:INFO:_master_model_container: 1
2023-07-29 20:41:23,224:INFO:_display_container: 2
2023-07-29 20:41:23,224:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:41:23,225:INFO:create_model() successfully completed......................................
2023-07-29 20:42:03,373:INFO:Initializing predict_model()
2023-07-29 20:42:03,373:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4A146610>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:42:12,835:INFO:Initializing create_model()
2023-07-29 20:42:12,835:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4A146610>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:42:12,835:INFO:Checking exceptions
2023-07-29 20:42:12,850:INFO:Importing untrained model
2023-07-29 20:42:12,853:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:42:12,855:INFO:Fitting Model
2023-07-29 20:42:14,079:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:42:14,079:INFO:create_models() successfully completed......................................
2023-07-29 20:42:14,083:INFO:Uploading results into container
2023-07-29 20:42:14,085:INFO:Uploading model into container now
2023-07-29 20:42:14,089:INFO:_master_model_container: 2
2023-07-29 20:42:14,089:INFO:_display_container: 3
2023-07-29 20:42:14,089:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:42:14,089:INFO:create_model() successfully completed......................................
2023-07-29 20:42:16,587:INFO:Initializing predict_model()
2023-07-29 20:42:16,587:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4A146610>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:43:00,383:INFO:Initializing predict_model()
2023-07-29 20:43:00,383:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D4A146610>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:43:34,145:INFO:PyCaret ClusteringExperiment
2023-07-29 20:43:34,145:INFO:Logging name: cluster-default-name
2023-07-29 20:43:34,145:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:43:34,145:INFO:version 3.0.4
2023-07-29 20:43:34,145:INFO:Initializing setup()
2023-07-29 20:43:34,145:INFO:self.USI: 0893
2023-07-29 20:43:34,145:INFO:self._variable_keys: {'data', 'seed', 'USI', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'memory', 'exp_name_log', 'exp_id', 'gpu_param', 'log_plots_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'html_param', 'idx'}
2023-07-29 20:43:34,145:INFO:Checking environment
2023-07-29 20:43:34,145:INFO:python_version: 3.9.13
2023-07-29 20:43:34,145:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:43:34,145:INFO:machine: AMD64
2023-07-29 20:43:34,145:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:43:34,148:INFO:Memory: svmem(total=33737928704, available=26112860160, percent=22.6, used=7625068544, free=26112860160)
2023-07-29 20:43:34,148:INFO:Physical Core: 8
2023-07-29 20:43:34,148:INFO:Logical Core: 16
2023-07-29 20:43:34,148:INFO:Checking libraries
2023-07-29 20:43:34,148:INFO:System:
2023-07-29 20:43:34,148:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:43:34,148:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:43:34,148:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:43:34,148:INFO:PyCaret required dependencies:
2023-07-29 20:43:34,148:INFO:                 pip: 22.0.4
2023-07-29 20:43:34,148:INFO:          setuptools: 58.1.0
2023-07-29 20:43:34,148:INFO:             pycaret: 3.0.4
2023-07-29 20:43:34,148:INFO:             IPython: 8.13.1
2023-07-29 20:43:34,148:INFO:          ipywidgets: 8.0.7
2023-07-29 20:43:34,148:INFO:                tqdm: 4.65.0
2023-07-29 20:43:34,149:INFO:               numpy: 1.23.0
2023-07-29 20:43:34,149:INFO:              pandas: 1.5.3
2023-07-29 20:43:34,149:INFO:              jinja2: 3.1.2
2023-07-29 20:43:34,149:INFO:               scipy: 1.10.1
2023-07-29 20:43:34,149:INFO:              joblib: 1.3.1
2023-07-29 20:43:34,149:INFO:             sklearn: 1.2.2
2023-07-29 20:43:34,149:INFO:                pyod: 1.1.0
2023-07-29 20:43:34,149:INFO:            imblearn: 0.11.0
2023-07-29 20:43:34,149:INFO:   category_encoders: 2.6.1
2023-07-29 20:43:34,149:INFO:            lightgbm: 4.0.0
2023-07-29 20:43:34,149:INFO:               numba: 0.57.1
2023-07-29 20:43:34,149:INFO:            requests: 2.31.0
2023-07-29 20:43:34,149:INFO:          matplotlib: 3.7.1
2023-07-29 20:43:34,149:INFO:          scikitplot: 0.3.7
2023-07-29 20:43:34,149:INFO:         yellowbrick: 1.5
2023-07-29 20:43:34,149:INFO:              plotly: 5.15.0
2023-07-29 20:43:34,149:INFO:    plotly-resampler: Not installed
2023-07-29 20:43:34,149:INFO:             kaleido: 0.2.1
2023-07-29 20:43:34,149:INFO:           schemdraw: 0.15
2023-07-29 20:43:34,149:INFO:         statsmodels: 0.14.0
2023-07-29 20:43:34,149:INFO:              sktime: 0.20.1
2023-07-29 20:43:34,149:INFO:               tbats: 1.1.3
2023-07-29 20:43:34,149:INFO:            pmdarima: 2.0.3
2023-07-29 20:43:34,149:INFO:              psutil: 5.9.5
2023-07-29 20:43:34,149:INFO:          markupsafe: 2.1.3
2023-07-29 20:43:34,149:INFO:             pickle5: Not installed
2023-07-29 20:43:34,149:INFO:         cloudpickle: 2.2.1
2023-07-29 20:43:34,149:INFO:         deprecation: 2.1.0
2023-07-29 20:43:34,149:INFO:              xxhash: 3.2.0
2023-07-29 20:43:34,149:INFO:           wurlitzer: Not installed
2023-07-29 20:43:34,149:INFO:PyCaret optional dependencies:
2023-07-29 20:43:34,149:INFO:                shap: 0.42.1
2023-07-29 20:43:34,149:INFO:           interpret: Not installed
2023-07-29 20:43:34,149:INFO:                umap: 0.5.3
2023-07-29 20:43:34,149:INFO:    pandas_profiling: Not installed
2023-07-29 20:43:34,149:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:43:34,149:INFO:             autoviz: 0.1.730
2023-07-29 20:43:34,149:INFO:           fairlearn: Not installed
2023-07-29 20:43:34,150:INFO:          deepchecks: Not installed
2023-07-29 20:43:34,150:INFO:             xgboost: 1.7.6
2023-07-29 20:43:34,150:INFO:            catboost: Not installed
2023-07-29 20:43:34,150:INFO:              kmodes: Not installed
2023-07-29 20:43:34,150:INFO:             mlxtend: Not installed
2023-07-29 20:43:34,150:INFO:       statsforecast: Not installed
2023-07-29 20:43:34,150:INFO:        tune_sklearn: Not installed
2023-07-29 20:43:34,150:INFO:                 ray: Not installed
2023-07-29 20:43:34,150:INFO:            hyperopt: Not installed
2023-07-29 20:43:34,150:INFO:              optuna: Not installed
2023-07-29 20:43:34,150:INFO:               skopt: Not installed
2023-07-29 20:43:34,150:INFO:              mlflow: Not installed
2023-07-29 20:43:34,151:INFO:              gradio: Not installed
2023-07-29 20:43:34,151:INFO:             fastapi: Not installed
2023-07-29 20:43:34,151:INFO:             uvicorn: Not installed
2023-07-29 20:43:34,151:INFO:              m2cgen: Not installed
2023-07-29 20:43:34,151:INFO:           evidently: Not installed
2023-07-29 20:43:34,151:INFO:               fugue: Not installed
2023-07-29 20:43:34,151:INFO:           streamlit: Not installed
2023-07-29 20:43:34,151:INFO:             prophet: Not installed
2023-07-29 20:43:34,151:INFO:None
2023-07-29 20:43:34,151:INFO:Set up data.
2023-07-29 20:43:34,155:INFO:Set up index.
2023-07-29 20:43:34,155:INFO:Assigning column types.
2023-07-29 20:43:34,156:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:43:34,156:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:43:34,156:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,157:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:43:34,157:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,157:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:43:34,157:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,157:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,158:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:43:34,158:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2023-07-29 20:43:34,158:INFO:Creating final display dataframe.
2023-07-29 20:43:34,164:INFO:Setup _display_container:               Description        Value
0              Session id           22
1     Original data shape  (10202, 19)
2  Transformed data shape  (10202, 19)
3        Numeric features           19
2023-07-29 20:43:34,167:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,167:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:43:34,168:INFO:setup() successfully completed in 0.22s...............
2023-07-29 20:43:35,444:INFO:Initializing create_model()
2023-07-29 20:43:35,444:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:43:35,444:INFO:Checking exceptions
2023-07-29 20:43:35,460:INFO:Importing untrained model
2023-07-29 20:43:35,462:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:43:35,466:INFO:Fitting Model
2023-07-29 20:43:36,723:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:43:36,723:INFO:create_models() successfully completed......................................
2023-07-29 20:43:36,726:INFO:Uploading results into container
2023-07-29 20:43:36,728:INFO:Uploading model into container now
2023-07-29 20:43:36,733:INFO:_master_model_container: 1
2023-07-29 20:43:36,733:INFO:_display_container: 2
2023-07-29 20:43:36,733:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:43:36,733:INFO:create_model() successfully completed......................................
2023-07-29 20:43:39,431:INFO:Initializing predict_model()
2023-07-29 20:43:39,431:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:43:40,653:INFO:Initializing predict_model()
2023-07-29 20:43:40,654:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:44:09,926:INFO:Initializing get_config()
2023-07-29 20:44:09,926:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=None)
2023-07-29 20:44:23,987:INFO:Initializing get_config()
2023-07-29 20:44:23,987:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=dataset_transformed)
2023-07-29 20:44:23,993:INFO:Variable: dataset returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                              0                          0   
1                              0                          0   
2                              0                          0   
3                              0                          0   
4                              0                          0   
...                          ...                        ...   
10197                          0                          0   
10198                          0                          0   
10199                          0                          0   
10200                          0                          1   
10201                          0                          0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                              0                          1   
1                              1                          0   
2                              0                          1   
3                              0                          1   
4                              0                          1   
...                          ...                        ...   
10197                          0                          1   
10198                          0                          1   
10199                          0                          1   
10200                          0                          0   
10201                          1                          1   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                            0                        1   
1                            0                        1   
2                            0                        1   
3                            0                        1   
4                            0                        1   
...                        ...                      ...   
10197                        0                        1   
10198                        0                        1   
10199                        0                        1   
10200                        0                        1   
10201                        1                        1   

       encoder__customer_type_0  encoder__customer_type_1  \
0                             0                         0   
1                             0                         0   
2                             0                         0   
3                             0                         0   
4                             0                         0   
...                         ...                       ...   
10197                         1                         0   
10198                         0                         0   
10199                         0                         0   
10200                         0                         1   
10201                         0                         0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                             1                              0   
1                             1                              0   
2                             1                              0   
3                             1                              0   
4                             1                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         1                              0   
10199                         1                              0   
10200                         0                              0   
10201                         1                              0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                  0                              0   
1                                  0                              1   
2                                  0                              0   
3                                  0                              1   
4                                  0                              1   
...                              ...                            ...   
10197                              1                              0   
10198                              0                              1   
10199                              0                              1   
10200                              1                              0   
10201                              1                              0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                  1                                0   
1                                  0                                0   
2                                  1                                0   
3                                  0                                0   
4                                  1                                0   
...                              ...                              ...   
10197                              0                                0   
10198                              0                                0   
10199                              0                                0   
10200                              0                                0   
10201                              0                                0   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                             0                              0   
1                             0                              0   
2                             0                              0   
3                             3                              0   
4                             0                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         0                              0   
10199                         0                              0   
10200                         0                              0   
10201                         0                              0   

       scaller__required_car_parking_spaces  \
0                                         0   
1                                         2   
2                                         0   
3                                         0   
4                                         2   
...                                     ...   
10197                                     0   
10198                                     0   
10199                                     0   
10200                                     0   
10201                                     0   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                       0                     1  
1                                       0                     0  
2                                       0                     0  
3                                       0                     0  
4                                       1                     0  
...                                   ...                   ...  
10197                                   1                     1  
10198                                   1                     0  
10199                                   1                     0  
10200                                   0                     0  
10201                                   0                     1  

[10202 rows x 19 columns]
2023-07-29 20:44:23,993:INFO:get_config() successfully completed......................................
2023-07-29 20:44:32,023:INFO:Initializing get_config()
2023-07-29 20:44:32,023:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=None)
2023-07-29 20:44:36,261:INFO:Initializing get_config()
2023-07-29 20:44:36,262:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=X_train_transformed)
2023-07-29 20:44:36,267:INFO:Variable: X_train returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                              0                          0   
1                              0                          0   
2                              0                          0   
3                              0                          0   
4                              0                          0   
...                          ...                        ...   
10197                          0                          0   
10198                          0                          0   
10199                          0                          0   
10200                          0                          1   
10201                          0                          0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                              0                          1   
1                              1                          0   
2                              0                          1   
3                              0                          1   
4                              0                          1   
...                          ...                        ...   
10197                          0                          1   
10198                          0                          1   
10199                          0                          1   
10200                          0                          0   
10201                          1                          1   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                            0                        1   
1                            0                        1   
2                            0                        1   
3                            0                        1   
4                            0                        1   
...                        ...                      ...   
10197                        0                        1   
10198                        0                        1   
10199                        0                        1   
10200                        0                        1   
10201                        1                        1   

       encoder__customer_type_0  encoder__customer_type_1  \
0                             0                         0   
1                             0                         0   
2                             0                         0   
3                             0                         0   
4                             0                         0   
...                         ...                       ...   
10197                         1                         0   
10198                         0                         0   
10199                         0                         0   
10200                         0                         1   
10201                         0                         0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                             1                              0   
1                             1                              0   
2                             1                              0   
3                             1                              0   
4                             1                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         1                              0   
10199                         1                              0   
10200                         0                              0   
10201                         1                              0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                  0                              0   
1                                  0                              1   
2                                  0                              0   
3                                  0                              1   
4                                  0                              1   
...                              ...                            ...   
10197                              1                              0   
10198                              0                              1   
10199                              0                              1   
10200                              1                              0   
10201                              1                              0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                  1                                0   
1                                  0                                0   
2                                  1                                0   
3                                  0                                0   
4                                  1                                0   
...                              ...                              ...   
10197                              0                                0   
10198                              0                                0   
10199                              0                                0   
10200                              0                                0   
10201                              0                                0   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                             0                              0   
1                             0                              0   
2                             0                              0   
3                             3                              0   
4                             0                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         0                              0   
10199                         0                              0   
10200                         0                              0   
10201                         0                              0   

       scaller__required_car_parking_spaces  \
0                                         0   
1                                         2   
2                                         0   
3                                         0   
4                                         2   
...                                     ...   
10197                                     0   
10198                                     0   
10199                                     0   
10200                                     0   
10201                                     0   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                       0                     1  
1                                       0                     0  
2                                       0                     0  
3                                       0                     0  
4                                       1                     0  
...                                   ...                   ...  
10197                                   1                     1  
10198                                   1                     0  
10199                                   1                     0  
10200                                   0                     0  
10201                                   0                     1  

[10202 rows x 19 columns]
2023-07-29 20:44:36,267:INFO:get_config() successfully completed......................................
2023-07-29 20:44:44,571:INFO:Initializing get_config()
2023-07-29 20:44:44,571:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=None)
2023-07-29 20:44:55,478:INFO:Initializing get_config()
2023-07-29 20:44:55,478:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=train_transformed)
2023-07-29 20:44:55,484:INFO:Variable: train returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                              0                          0   
1                              0                          0   
2                              0                          0   
3                              0                          0   
4                              0                          0   
...                          ...                        ...   
10197                          0                          0   
10198                          0                          0   
10199                          0                          0   
10200                          0                          1   
10201                          0                          0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                              0                          1   
1                              1                          0   
2                              0                          1   
3                              0                          1   
4                              0                          1   
...                          ...                        ...   
10197                          0                          1   
10198                          0                          1   
10199                          0                          1   
10200                          0                          0   
10201                          1                          1   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                            0                        1   
1                            0                        1   
2                            0                        1   
3                            0                        1   
4                            0                        1   
...                        ...                      ...   
10197                        0                        1   
10198                        0                        1   
10199                        0                        1   
10200                        0                        1   
10201                        1                        1   

       encoder__customer_type_0  encoder__customer_type_1  \
0                             0                         0   
1                             0                         0   
2                             0                         0   
3                             0                         0   
4                             0                         0   
...                         ...                       ...   
10197                         1                         0   
10198                         0                         0   
10199                         0                         0   
10200                         0                         1   
10201                         0                         0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                             1                              0   
1                             1                              0   
2                             1                              0   
3                             1                              0   
4                             1                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         1                              0   
10199                         1                              0   
10200                         0                              0   
10201                         1                              0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                  0                              0   
1                                  0                              1   
2                                  0                              0   
3                                  0                              1   
4                                  0                              1   
...                              ...                            ...   
10197                              1                              0   
10198                              0                              1   
10199                              0                              1   
10200                              1                              0   
10201                              1                              0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                  1                                0   
1                                  0                                0   
2                                  1                                0   
3                                  0                                0   
4                                  1                                0   
...                              ...                              ...   
10197                              0                                0   
10198                              0                                0   
10199                              0                                0   
10200                              0                                0   
10201                              0                                0   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                             0                              0   
1                             0                              0   
2                             0                              0   
3                             3                              0   
4                             0                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         0                              0   
10199                         0                              0   
10200                         0                              0   
10201                         0                              0   

       scaller__required_car_parking_spaces  \
0                                         0   
1                                         2   
2                                         0   
3                                         0   
4                                         2   
...                                     ...   
10197                                     0   
10198                                     0   
10199                                     0   
10200                                     0   
10201                                     0   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                       0                     1  
1                                       0                     0  
2                                       0                     0  
3                                       0                     0  
4                                       1                     0  
...                                   ...                   ...  
10197                                   1                     1  
10198                                   1                     0  
10199                                   1                     0  
10200                                   0                     0  
10201                                   0                     1  

[10202 rows x 19 columns]
2023-07-29 20:44:55,484:INFO:get_config() successfully completed......................................
2023-07-29 20:44:59,808:INFO:Initializing get_config()
2023-07-29 20:44:59,808:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=None)
2023-07-29 20:45:05,349:INFO:Initializing get_config()
2023-07-29 20:45:05,349:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, variable=X)
2023-07-29 20:45:05,352:INFO:Variable:  returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                              0                          0   
1                              0                          0   
2                              0                          0   
3                              0                          0   
4                              0                          0   
...                          ...                        ...   
10197                          0                          0   
10198                          0                          0   
10199                          0                          0   
10200                          0                          1   
10201                          0                          0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                              0                          1   
1                              1                          0   
2                              0                          1   
3                              0                          1   
4                              0                          1   
...                          ...                        ...   
10197                          0                          1   
10198                          0                          1   
10199                          0                          1   
10200                          0                          0   
10201                          1                          1   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                            0                        1   
1                            0                        1   
2                            0                        1   
3                            0                        1   
4                            0                        1   
...                        ...                      ...   
10197                        0                        1   
10198                        0                        1   
10199                        0                        1   
10200                        0                        1   
10201                        1                        1   

       encoder__customer_type_0  encoder__customer_type_1  \
0                             0                         0   
1                             0                         0   
2                             0                         0   
3                             0                         0   
4                             0                         0   
...                         ...                       ...   
10197                         1                         0   
10198                         0                         0   
10199                         0                         0   
10200                         0                         1   
10201                         0                         0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                             1                              0   
1                             1                              0   
2                             1                              0   
3                             1                              0   
4                             1                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         1                              0   
10199                         1                              0   
10200                         0                              0   
10201                         1                              0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                  0                              0   
1                                  0                              1   
2                                  0                              0   
3                                  0                              1   
4                                  0                              1   
...                              ...                            ...   
10197                              1                              0   
10198                              0                              1   
10199                              0                              1   
10200                              1                              0   
10201                              1                              0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                  1                                0   
1                                  0                                0   
2                                  1                                0   
3                                  0                                0   
4                                  1                                0   
...                              ...                              ...   
10197                              0                                0   
10198                              0                                0   
10199                              0                                0   
10200                              0                                0   
10201                              0                                0   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                             0                              0   
1                             0                              0   
2                             0                              0   
3                             3                              0   
4                             0                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         0                              0   
10199                         0                              0   
10200                         0                              0   
10201                         0                              0   

       scaller__required_car_parking_spaces  \
0                                         0   
1                                         2   
2                                         0   
3                                         0   
4                                         2   
...                                     ...   
10197                                     0   
10198                                     0   
10199                                     0   
10200                                     0   
10201                                     0   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                       0                     1  
1                                       0                     0  
2                                       0                     0  
3                                       0                     0  
4                                       1                     0  
...                                   ...                   ...  
10197                                   1                     1  
10198                                   1                     0  
10199                                   1                     0  
10200                                   0                     0  
10201                                   0                     1  

[10202 rows x 19 columns]
2023-07-29 20:45:05,353:INFO:get_config() successfully completed......................................
2023-07-29 20:45:30,497:INFO:Initializing predict_model()
2023-07-29 20:45:30,497:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DC14850>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:45:47,673:INFO:PyCaret ClusteringExperiment
2023-07-29 20:45:47,673:INFO:Logging name: cluster-default-name
2023-07-29 20:45:47,673:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:45:47,673:INFO:version 3.0.4
2023-07-29 20:45:47,673:INFO:Initializing setup()
2023-07-29 20:45:47,673:INFO:self.USI: a2ae
2023-07-29 20:45:47,673:INFO:self._variable_keys: {'data', 'seed', 'USI', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'memory', 'exp_name_log', 'exp_id', 'gpu_param', 'log_plots_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'html_param', 'idx'}
2023-07-29 20:45:47,673:INFO:Checking environment
2023-07-29 20:45:47,673:INFO:python_version: 3.9.13
2023-07-29 20:45:47,673:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:45:47,673:INFO:machine: AMD64
2023-07-29 20:45:47,673:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:45:47,677:INFO:Memory: svmem(total=33737928704, available=26060132352, percent=22.8, used=7677796352, free=26060132352)
2023-07-29 20:45:47,677:INFO:Physical Core: 8
2023-07-29 20:45:47,677:INFO:Logical Core: 16
2023-07-29 20:45:47,677:INFO:Checking libraries
2023-07-29 20:45:47,677:INFO:System:
2023-07-29 20:45:47,677:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:45:47,677:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:45:47,677:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:45:47,677:INFO:PyCaret required dependencies:
2023-07-29 20:45:47,677:INFO:                 pip: 22.0.4
2023-07-29 20:45:47,677:INFO:          setuptools: 58.1.0
2023-07-29 20:45:47,677:INFO:             pycaret: 3.0.4
2023-07-29 20:45:47,677:INFO:             IPython: 8.13.1
2023-07-29 20:45:47,677:INFO:          ipywidgets: 8.0.7
2023-07-29 20:45:47,677:INFO:                tqdm: 4.65.0
2023-07-29 20:45:47,677:INFO:               numpy: 1.23.0
2023-07-29 20:45:47,677:INFO:              pandas: 1.5.3
2023-07-29 20:45:47,677:INFO:              jinja2: 3.1.2
2023-07-29 20:45:47,677:INFO:               scipy: 1.10.1
2023-07-29 20:45:47,677:INFO:              joblib: 1.3.1
2023-07-29 20:45:47,677:INFO:             sklearn: 1.2.2
2023-07-29 20:45:47,677:INFO:                pyod: 1.1.0
2023-07-29 20:45:47,677:INFO:            imblearn: 0.11.0
2023-07-29 20:45:47,677:INFO:   category_encoders: 2.6.1
2023-07-29 20:45:47,677:INFO:            lightgbm: 4.0.0
2023-07-29 20:45:47,677:INFO:               numba: 0.57.1
2023-07-29 20:45:47,677:INFO:            requests: 2.31.0
2023-07-29 20:45:47,677:INFO:          matplotlib: 3.7.1
2023-07-29 20:45:47,677:INFO:          scikitplot: 0.3.7
2023-07-29 20:45:47,677:INFO:         yellowbrick: 1.5
2023-07-29 20:45:47,677:INFO:              plotly: 5.15.0
2023-07-29 20:45:47,677:INFO:    plotly-resampler: Not installed
2023-07-29 20:45:47,678:INFO:             kaleido: 0.2.1
2023-07-29 20:45:47,678:INFO:           schemdraw: 0.15
2023-07-29 20:45:47,678:INFO:         statsmodels: 0.14.0
2023-07-29 20:45:47,678:INFO:              sktime: 0.20.1
2023-07-29 20:45:47,678:INFO:               tbats: 1.1.3
2023-07-29 20:45:47,678:INFO:            pmdarima: 2.0.3
2023-07-29 20:45:47,678:INFO:              psutil: 5.9.5
2023-07-29 20:45:47,678:INFO:          markupsafe: 2.1.3
2023-07-29 20:45:47,678:INFO:             pickle5: Not installed
2023-07-29 20:45:47,678:INFO:         cloudpickle: 2.2.1
2023-07-29 20:45:47,678:INFO:         deprecation: 2.1.0
2023-07-29 20:45:47,678:INFO:              xxhash: 3.2.0
2023-07-29 20:45:47,678:INFO:           wurlitzer: Not installed
2023-07-29 20:45:47,678:INFO:PyCaret optional dependencies:
2023-07-29 20:45:47,678:INFO:                shap: 0.42.1
2023-07-29 20:45:47,678:INFO:           interpret: Not installed
2023-07-29 20:45:47,678:INFO:                umap: 0.5.3
2023-07-29 20:45:47,678:INFO:    pandas_profiling: Not installed
2023-07-29 20:45:47,678:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:45:47,678:INFO:             autoviz: 0.1.730
2023-07-29 20:45:47,678:INFO:           fairlearn: Not installed
2023-07-29 20:45:47,678:INFO:          deepchecks: Not installed
2023-07-29 20:45:47,678:INFO:             xgboost: 1.7.6
2023-07-29 20:45:47,678:INFO:            catboost: Not installed
2023-07-29 20:45:47,678:INFO:              kmodes: Not installed
2023-07-29 20:45:47,678:INFO:             mlxtend: Not installed
2023-07-29 20:45:47,678:INFO:       statsforecast: Not installed
2023-07-29 20:45:47,678:INFO:        tune_sklearn: Not installed
2023-07-29 20:45:47,678:INFO:                 ray: Not installed
2023-07-29 20:45:47,678:INFO:            hyperopt: Not installed
2023-07-29 20:45:47,678:INFO:              optuna: Not installed
2023-07-29 20:45:47,678:INFO:               skopt: Not installed
2023-07-29 20:45:47,678:INFO:              mlflow: Not installed
2023-07-29 20:45:47,678:INFO:              gradio: Not installed
2023-07-29 20:45:47,678:INFO:             fastapi: Not installed
2023-07-29 20:45:47,678:INFO:             uvicorn: Not installed
2023-07-29 20:45:47,678:INFO:              m2cgen: Not installed
2023-07-29 20:45:47,678:INFO:           evidently: Not installed
2023-07-29 20:45:47,678:INFO:               fugue: Not installed
2023-07-29 20:45:47,679:INFO:           streamlit: Not installed
2023-07-29 20:45:47,679:INFO:             prophet: Not installed
2023-07-29 20:45:47,679:INFO:None
2023-07-29 20:45:47,679:INFO:Set up data.
2023-07-29 20:45:47,680:INFO:Set up index.
2023-07-29 20:45:47,681:INFO:Assigning column types.
2023-07-29 20:45:47,682:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:45:47,682:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:45:47,682:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,682:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:45:47,682:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,682:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:45:47,682:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,683:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,683:INFO:Preparing preprocessing pipeline...
2023-07-29 20:45:47,683:INFO:Set up simple imputation.
2023-07-29 20:45:47,698:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:45:47,700:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'Income', 'SpendingScore',
                                             'Savings'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-07-29 20:45:47,700:INFO:Creating final display dataframe.
2023-07-29 20:45:47,709:INFO:Setup _display_container:                Description                 Value
0               Session id                  7080
1      Original data shape              (505, 4)
2   Transformed data shape              (505, 4)
3         Numeric features                     4
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  a2ae
2023-07-29 20:45:47,713:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,713:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:47,713:INFO:setup() successfully completed in 0.24s...............
2023-07-29 20:45:47,713:INFO:Initializing create_model()
2023-07-29 20:45:47,713:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E6753D0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:45:47,713:INFO:Checking exceptions
2023-07-29 20:45:47,733:INFO:Importing untrained model
2023-07-29 20:45:47,737:INFO:K-Means Clustering Imported successfully
2023-07-29 20:45:47,740:INFO:Fitting Model
2023-07-29 20:45:47,874:INFO:KMeans(n_clusters=4, random_state=7080)
2023-07-29 20:45:47,874:INFO:create_models() successfully completed......................................
2023-07-29 20:45:47,877:INFO:Uploading results into container
2023-07-29 20:45:47,879:INFO:Uploading model into container now
2023-07-29 20:45:47,886:INFO:_master_model_container: 1
2023-07-29 20:45:47,886:INFO:_display_container: 2
2023-07-29 20:45:47,887:INFO:KMeans(n_clusters=4, random_state=7080)
2023-07-29 20:45:47,888:INFO:create_model() successfully completed......................................
2023-07-29 20:45:56,251:INFO:PyCaret ClusteringExperiment
2023-07-29 20:45:56,251:INFO:Logging name: cluster-default-name
2023-07-29 20:45:56,251:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:45:56,251:INFO:version 3.0.4
2023-07-29 20:45:56,252:INFO:Initializing setup()
2023-07-29 20:45:56,252:INFO:self.USI: 62fd
2023-07-29 20:45:56,252:INFO:self._variable_keys: {'data', 'seed', 'USI', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'memory', 'exp_name_log', 'exp_id', 'gpu_param', 'log_plots_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'html_param', 'idx'}
2023-07-29 20:45:56,252:INFO:Checking environment
2023-07-29 20:45:56,252:INFO:python_version: 3.9.13
2023-07-29 20:45:56,252:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:45:56,252:INFO:machine: AMD64
2023-07-29 20:45:56,252:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:45:56,255:INFO:Memory: svmem(total=33737928704, available=26032418816, percent=22.8, used=7705509888, free=26032418816)
2023-07-29 20:45:56,256:INFO:Physical Core: 8
2023-07-29 20:45:56,256:INFO:Logical Core: 16
2023-07-29 20:45:56,256:INFO:Checking libraries
2023-07-29 20:45:56,256:INFO:System:
2023-07-29 20:45:56,256:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:45:56,256:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:45:56,256:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:45:56,256:INFO:PyCaret required dependencies:
2023-07-29 20:45:56,256:INFO:                 pip: 22.0.4
2023-07-29 20:45:56,256:INFO:          setuptools: 58.1.0
2023-07-29 20:45:56,256:INFO:             pycaret: 3.0.4
2023-07-29 20:45:56,256:INFO:             IPython: 8.13.1
2023-07-29 20:45:56,256:INFO:          ipywidgets: 8.0.7
2023-07-29 20:45:56,256:INFO:                tqdm: 4.65.0
2023-07-29 20:45:56,256:INFO:               numpy: 1.23.0
2023-07-29 20:45:56,256:INFO:              pandas: 1.5.3
2023-07-29 20:45:56,256:INFO:              jinja2: 3.1.2
2023-07-29 20:45:56,256:INFO:               scipy: 1.10.1
2023-07-29 20:45:56,256:INFO:              joblib: 1.3.1
2023-07-29 20:45:56,256:INFO:             sklearn: 1.2.2
2023-07-29 20:45:56,256:INFO:                pyod: 1.1.0
2023-07-29 20:45:56,256:INFO:            imblearn: 0.11.0
2023-07-29 20:45:56,256:INFO:   category_encoders: 2.6.1
2023-07-29 20:45:56,256:INFO:            lightgbm: 4.0.0
2023-07-29 20:45:56,256:INFO:               numba: 0.57.1
2023-07-29 20:45:56,256:INFO:            requests: 2.31.0
2023-07-29 20:45:56,256:INFO:          matplotlib: 3.7.1
2023-07-29 20:45:56,256:INFO:          scikitplot: 0.3.7
2023-07-29 20:45:56,256:INFO:         yellowbrick: 1.5
2023-07-29 20:45:56,256:INFO:              plotly: 5.15.0
2023-07-29 20:45:56,256:INFO:    plotly-resampler: Not installed
2023-07-29 20:45:56,256:INFO:             kaleido: 0.2.1
2023-07-29 20:45:56,257:INFO:           schemdraw: 0.15
2023-07-29 20:45:56,257:INFO:         statsmodels: 0.14.0
2023-07-29 20:45:56,257:INFO:              sktime: 0.20.1
2023-07-29 20:45:56,257:INFO:               tbats: 1.1.3
2023-07-29 20:45:56,257:INFO:            pmdarima: 2.0.3
2023-07-29 20:45:56,257:INFO:              psutil: 5.9.5
2023-07-29 20:45:56,257:INFO:          markupsafe: 2.1.3
2023-07-29 20:45:56,257:INFO:             pickle5: Not installed
2023-07-29 20:45:56,257:INFO:         cloudpickle: 2.2.1
2023-07-29 20:45:56,257:INFO:         deprecation: 2.1.0
2023-07-29 20:45:56,257:INFO:              xxhash: 3.2.0
2023-07-29 20:45:56,257:INFO:           wurlitzer: Not installed
2023-07-29 20:45:56,257:INFO:PyCaret optional dependencies:
2023-07-29 20:45:56,257:INFO:                shap: 0.42.1
2023-07-29 20:45:56,257:INFO:           interpret: Not installed
2023-07-29 20:45:56,257:INFO:                umap: 0.5.3
2023-07-29 20:45:56,257:INFO:    pandas_profiling: Not installed
2023-07-29 20:45:56,257:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:45:56,257:INFO:             autoviz: 0.1.730
2023-07-29 20:45:56,257:INFO:           fairlearn: Not installed
2023-07-29 20:45:56,257:INFO:          deepchecks: Not installed
2023-07-29 20:45:56,257:INFO:             xgboost: 1.7.6
2023-07-29 20:45:56,257:INFO:            catboost: Not installed
2023-07-29 20:45:56,257:INFO:              kmodes: Not installed
2023-07-29 20:45:56,257:INFO:             mlxtend: Not installed
2023-07-29 20:45:56,257:INFO:       statsforecast: Not installed
2023-07-29 20:45:56,257:INFO:        tune_sklearn: Not installed
2023-07-29 20:45:56,257:INFO:                 ray: Not installed
2023-07-29 20:45:56,257:INFO:            hyperopt: Not installed
2023-07-29 20:45:56,257:INFO:              optuna: Not installed
2023-07-29 20:45:56,257:INFO:               skopt: Not installed
2023-07-29 20:45:56,257:INFO:              mlflow: Not installed
2023-07-29 20:45:56,257:INFO:              gradio: Not installed
2023-07-29 20:45:56,257:INFO:             fastapi: Not installed
2023-07-29 20:45:56,257:INFO:             uvicorn: Not installed
2023-07-29 20:45:56,257:INFO:              m2cgen: Not installed
2023-07-29 20:45:56,257:INFO:           evidently: Not installed
2023-07-29 20:45:56,257:INFO:               fugue: Not installed
2023-07-29 20:45:56,257:INFO:           streamlit: Not installed
2023-07-29 20:45:56,257:INFO:             prophet: Not installed
2023-07-29 20:45:56,257:INFO:None
2023-07-29 20:45:56,257:INFO:Set up data.
2023-07-29 20:45:56,259:INFO:Set up index.
2023-07-29 20:45:56,259:INFO:Assigning column types.
2023-07-29 20:45:56,260:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:45:56,260:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:45:56,260:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,260:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:45:56,261:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,261:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:45:56,261:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,261:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,261:INFO:Preparing preprocessing pipeline...
2023-07-29 20:45:56,261:INFO:Set up simple imputation.
2023-07-29 20:45:56,270:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:45:56,272:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Age', 'Income', 'SpendingScore',
                                             'Savings'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-07-29 20:45:56,272:INFO:Creating final display dataframe.
2023-07-29 20:45:56,280:INFO:Setup _display_container:                Description                 Value
0               Session id                  2929
1      Original data shape              (505, 4)
2   Transformed data shape              (505, 4)
3         Numeric features                     4
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  62fd
2023-07-29 20:45:56,284:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,284:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:45:56,285:INFO:setup() successfully completed in 0.24s...............
2023-07-29 20:45:56,484:INFO:Initializing create_model()
2023-07-29 20:45:56,484:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DF32910>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2023-07-29 20:45:56,484:INFO:Checking exceptions
2023-07-29 20:45:56,503:INFO:Importing untrained model
2023-07-29 20:45:56,506:INFO:K-Means Clustering Imported successfully
2023-07-29 20:45:56,509:INFO:Fitting Model
2023-07-29 20:45:56,571:INFO:KMeans(n_clusters=4, random_state=2929)
2023-07-29 20:45:56,571:INFO:create_models() successfully completed......................................
2023-07-29 20:45:56,574:INFO:Uploading results into container
2023-07-29 20:45:56,576:INFO:Uploading model into container now
2023-07-29 20:45:56,581:INFO:_master_model_container: 1
2023-07-29 20:45:56,582:INFO:_display_container: 2
2023-07-29 20:45:56,582:INFO:KMeans(n_clusters=4, random_state=2929)
2023-07-29 20:45:56,582:INFO:create_model() successfully completed......................................
2023-07-29 20:45:56,873:INFO:Initializing predict_model()
2023-07-29 20:45:56,874:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DF32910>, estimator=KMeans(n_clusters=4, random_state=2929), ml_usecase=None)
2023-07-29 20:46:36,651:INFO:Initializing predict_model()
2023-07-29 20:46:36,653:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0DF32910>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:46:45,097:INFO:PyCaret ClusteringExperiment
2023-07-29 20:46:45,098:INFO:Logging name: cluster-default-name
2023-07-29 20:46:45,098:INFO:ML Usecase: MLUsecase.CLUSTERING
2023-07-29 20:46:45,098:INFO:version 3.0.4
2023-07-29 20:46:45,098:INFO:Initializing setup()
2023-07-29 20:46:45,098:INFO:self.USI: d157
2023-07-29 20:46:45,098:INFO:self._variable_keys: {'data', 'seed', 'USI', 'gpu_n_jobs_param', 'pipeline', 'logging_param', 'memory', 'exp_name_log', 'exp_id', 'gpu_param', 'log_plots_param', '_ml_usecase', 'n_jobs_param', '_available_plots', 'X', 'html_param', 'idx'}
2023-07-29 20:46:45,098:INFO:Checking environment
2023-07-29 20:46:45,098:INFO:python_version: 3.9.13
2023-07-29 20:46:45,098:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-29 20:46:45,098:INFO:machine: AMD64
2023-07-29 20:46:45,098:INFO:platform: Windows-10-10.0.22621-SP0
2023-07-29 20:46:45,101:INFO:Memory: svmem(total=33737928704, available=26026573824, percent=22.9, used=7711354880, free=26026573824)
2023-07-29 20:46:45,101:INFO:Physical Core: 8
2023-07-29 20:46:45,101:INFO:Logical Core: 16
2023-07-29 20:46:45,101:INFO:Checking libraries
2023-07-29 20:46:45,101:INFO:System:
2023-07-29 20:46:45,102:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-29 20:46:45,102:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-29 20:46:45,102:INFO:   machine: Windows-10-10.0.22621-SP0
2023-07-29 20:46:45,102:INFO:PyCaret required dependencies:
2023-07-29 20:46:45,102:INFO:                 pip: 22.0.4
2023-07-29 20:46:45,102:INFO:          setuptools: 58.1.0
2023-07-29 20:46:45,102:INFO:             pycaret: 3.0.4
2023-07-29 20:46:45,102:INFO:             IPython: 8.13.1
2023-07-29 20:46:45,102:INFO:          ipywidgets: 8.0.7
2023-07-29 20:46:45,102:INFO:                tqdm: 4.65.0
2023-07-29 20:46:45,102:INFO:               numpy: 1.23.0
2023-07-29 20:46:45,102:INFO:              pandas: 1.5.3
2023-07-29 20:46:45,102:INFO:              jinja2: 3.1.2
2023-07-29 20:46:45,102:INFO:               scipy: 1.10.1
2023-07-29 20:46:45,102:INFO:              joblib: 1.3.1
2023-07-29 20:46:45,102:INFO:             sklearn: 1.2.2
2023-07-29 20:46:45,102:INFO:                pyod: 1.1.0
2023-07-29 20:46:45,102:INFO:            imblearn: 0.11.0
2023-07-29 20:46:45,102:INFO:   category_encoders: 2.6.1
2023-07-29 20:46:45,102:INFO:            lightgbm: 4.0.0
2023-07-29 20:46:45,102:INFO:               numba: 0.57.1
2023-07-29 20:46:45,102:INFO:            requests: 2.31.0
2023-07-29 20:46:45,102:INFO:          matplotlib: 3.7.1
2023-07-29 20:46:45,102:INFO:          scikitplot: 0.3.7
2023-07-29 20:46:45,102:INFO:         yellowbrick: 1.5
2023-07-29 20:46:45,102:INFO:              plotly: 5.15.0
2023-07-29 20:46:45,102:INFO:    plotly-resampler: Not installed
2023-07-29 20:46:45,102:INFO:             kaleido: 0.2.1
2023-07-29 20:46:45,102:INFO:           schemdraw: 0.15
2023-07-29 20:46:45,102:INFO:         statsmodels: 0.14.0
2023-07-29 20:46:45,102:INFO:              sktime: 0.20.1
2023-07-29 20:46:45,102:INFO:               tbats: 1.1.3
2023-07-29 20:46:45,102:INFO:            pmdarima: 2.0.3
2023-07-29 20:46:45,102:INFO:              psutil: 5.9.5
2023-07-29 20:46:45,102:INFO:          markupsafe: 2.1.3
2023-07-29 20:46:45,102:INFO:             pickle5: Not installed
2023-07-29 20:46:45,102:INFO:         cloudpickle: 2.2.1
2023-07-29 20:46:45,102:INFO:         deprecation: 2.1.0
2023-07-29 20:46:45,103:INFO:              xxhash: 3.2.0
2023-07-29 20:46:45,103:INFO:           wurlitzer: Not installed
2023-07-29 20:46:45,103:INFO:PyCaret optional dependencies:
2023-07-29 20:46:45,103:INFO:                shap: 0.42.1
2023-07-29 20:46:45,103:INFO:           interpret: Not installed
2023-07-29 20:46:45,103:INFO:                umap: 0.5.3
2023-07-29 20:46:45,103:INFO:    pandas_profiling: Not installed
2023-07-29 20:46:45,103:INFO:  explainerdashboard: 0.4.2.2
2023-07-29 20:46:45,103:INFO:             autoviz: 0.1.730
2023-07-29 20:46:45,103:INFO:           fairlearn: Not installed
2023-07-29 20:46:45,103:INFO:          deepchecks: Not installed
2023-07-29 20:46:45,103:INFO:             xgboost: 1.7.6
2023-07-29 20:46:45,103:INFO:            catboost: Not installed
2023-07-29 20:46:45,103:INFO:              kmodes: Not installed
2023-07-29 20:46:45,103:INFO:             mlxtend: Not installed
2023-07-29 20:46:45,103:INFO:       statsforecast: Not installed
2023-07-29 20:46:45,103:INFO:        tune_sklearn: Not installed
2023-07-29 20:46:45,103:INFO:                 ray: Not installed
2023-07-29 20:46:45,103:INFO:            hyperopt: Not installed
2023-07-29 20:46:45,103:INFO:              optuna: Not installed
2023-07-29 20:46:45,103:INFO:               skopt: Not installed
2023-07-29 20:46:45,103:INFO:              mlflow: Not installed
2023-07-29 20:46:45,103:INFO:              gradio: Not installed
2023-07-29 20:46:45,103:INFO:             fastapi: Not installed
2023-07-29 20:46:45,103:INFO:             uvicorn: Not installed
2023-07-29 20:46:45,103:INFO:              m2cgen: Not installed
2023-07-29 20:46:45,103:INFO:           evidently: Not installed
2023-07-29 20:46:45,103:INFO:               fugue: Not installed
2023-07-29 20:46:45,103:INFO:           streamlit: Not installed
2023-07-29 20:46:45,103:INFO:             prophet: Not installed
2023-07-29 20:46:45,103:INFO:None
2023-07-29 20:46:45,103:INFO:Set up data.
2023-07-29 20:46:45,109:INFO:Set up index.
2023-07-29 20:46:45,109:INFO:Assigning column types.
2023-07-29 20:46:45,110:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2023-07-29 20:46:45,111:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:46:45,111:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,111:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2023-07-29 20:46:45,111:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,111:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2023-07-29 20:46:45,111:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,111:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,112:INFO:Finished creating preprocessing pipeline.
2023-07-29 20:46:45,112:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('placeholder', None)])
2023-07-29 20:46:45,112:INFO:Creating final display dataframe.
2023-07-29 20:46:45,118:INFO:Setup _display_container:               Description        Value
0              Session id           22
1     Original data shape  (10202, 19)
2  Transformed data shape  (10202, 19)
3        Numeric features           19
2023-07-29 20:46:45,122:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,122:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-29 20:46:45,122:INFO:setup() successfully completed in 0.22s...............
2023-07-29 20:46:46,370:INFO:Initializing create_model()
2023-07-29 20:46:46,370:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, estimator=dbscan, num_clusters=6, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={'min_samples': 1, 'eps': 0.1})
2023-07-29 20:46:46,370:INFO:Checking exceptions
2023-07-29 20:46:46,390:INFO:Importing untrained model
2023-07-29 20:46:46,393:INFO:Density-Based Spatial Clustering Imported successfully
2023-07-29 20:46:46,396:INFO:Fitting Model
2023-07-29 20:46:47,658:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:46:47,658:INFO:create_models() successfully completed......................................
2023-07-29 20:46:47,661:INFO:Uploading results into container
2023-07-29 20:46:47,662:INFO:Uploading model into container now
2023-07-29 20:46:47,667:INFO:_master_model_container: 1
2023-07-29 20:46:47,667:INFO:_display_container: 2
2023-07-29 20:46:47,667:INFO:DBSCAN(eps=0.1, min_samples=1, n_jobs=-1)
2023-07-29 20:46:47,667:INFO:create_model() successfully completed......................................
2023-07-29 20:46:50,796:INFO:Initializing get_config()
2023-07-29 20:46:50,797:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, variable=None)
2023-07-29 20:46:55,404:INFO:Initializing predict_model()
2023-07-29 20:46:55,404:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:47:18,017:INFO:Initializing get_config()
2023-07-29 20:47:18,018:INFO:get_config(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, variable=X)
2023-07-29 20:47:18,021:INFO:Variable:  returned as        encoder__market_segment_0  encoder__market_segment_1  \
0                              0                          0   
1                              0                          0   
2                              0                          0   
3                              0                          0   
4                              0                          0   
...                          ...                        ...   
10197                          0                          0   
10198                          0                          0   
10199                          0                          0   
10200                          0                          1   
10201                          0                          0   

       encoder__market_segment_2  encoder__market_segment_3  \
0                              0                          1   
1                              1                          0   
2                              0                          1   
3                              0                          1   
4                              0                          1   
...                          ...                        ...   
10197                          0                          1   
10198                          0                          1   
10199                          0                          1   
10200                          0                          0   
10201                          1                          1   

       encoder__deposit_type_0  encoder__deposit_type_1  \
0                            0                        1   
1                            0                        1   
2                            0                        1   
3                            0                        1   
4                            0                        1   
...                        ...                      ...   
10197                        0                        1   
10198                        0                        1   
10199                        0                        1   
10200                        0                        1   
10201                        1                        1   

       encoder__customer_type_0  encoder__customer_type_1  \
0                             0                         0   
1                             0                         0   
2                             0                         0   
3                             0                         0   
4                             0                         0   
...                         ...                       ...   
10197                         1                         0   
10198                         0                         0   
10199                         0                         0   
10200                         0                         1   
10201                         0                         0   

       encoder__customer_type_2  encoder__reserved_room_type_0  \
0                             1                              0   
1                             1                              0   
2                             1                              0   
3                             1                              0   
4                             1                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         1                              0   
10199                         1                              0   
10200                         0                              0   
10201                         1                              0   

       encoder__reserved_room_type_1  encoder__reserved_room_type_2  \
0                                  0                              0   
1                                  0                              1   
2                                  0                              0   
3                                  0                              1   
4                                  0                              1   
...                              ...                            ...   
10197                              1                              0   
10198                              0                              1   
10199                              0                              1   
10200                              1                              0   
10201                              1                              0   

       encoder__reserved_room_type_3  scaller__previous_cancellations  \
0                                  1                                0   
1                                  0                                0   
2                                  1                                0   
3                                  0                                0   
4                                  1                                0   
...                              ...                              ...   
10197                              0                                0   
10198                              0                                0   
10199                              0                                0   
10200                              0                                0   
10201                              0                                0   

       scaller__booking_changes  scaller__days_in_waiting_list  \
0                             0                              0   
1                             0                              0   
2                             0                              0   
3                             3                              0   
4                             0                              0   
...                         ...                            ...   
10197                         0                              0   
10198                         0                              0   
10199                         0                              0   
10200                         0                              0   
10201                         0                              0   

       scaller__required_car_parking_spaces  \
0                                         0   
1                                         2   
2                                         0   
3                                         0   
4                                         2   
...                                     ...   
10197                                     0   
10198                                     0   
10199                                     0   
10200                                     0   
10201                                     0   

       scaller__total_of_special_requests  scaller__is_canceled  
0                                       0                     1  
1                                       0                     0  
2                                       0                     0  
3                                       0                     0  
4                                       1                     0  
...                                   ...                   ...  
10197                                   1                     1  
10198                                   1                     0  
10199                                   1                     0  
10200                                   0                     0  
10201                                   0                     1  

[10202 rows x 19 columns]
2023-07-29 20:47:18,021:INFO:get_config() successfully completed......................................
2023-07-29 20:47:18,021:INFO:Initializing predict_model()
2023-07-29 20:47:18,021:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), ml_usecase=None)
2023-07-29 20:48:54,907:INFO:Initializing assign_model()
2023-07-29 20:48:54,907:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:48:54,907:INFO:Checking exceptions
2023-07-29 20:48:54,907:INFO:Determining Trained Model
2023-07-29 20:48:54,907:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:48:54,907:INFO:Copying data
2023-07-29 20:48:54,922:INFO:(10202, 20)
2023-07-29 20:48:54,922:INFO:assign_model() successfully completed......................................
2023-07-29 20:49:17,616:INFO:Initializing assign_model()
2023-07-29 20:49:17,616:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:49:17,617:INFO:Checking exceptions
2023-07-29 20:49:17,617:INFO:Determining Trained Model
2023-07-29 20:49:17,617:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:49:17,617:INFO:Copying data
2023-07-29 20:49:17,620:INFO:(10202, 20)
2023-07-29 20:49:17,621:INFO:assign_model() successfully completed......................................
2023-07-29 20:49:20,788:INFO:Initializing assign_model()
2023-07-29 20:49:20,788:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:49:20,788:INFO:Checking exceptions
2023-07-29 20:49:20,788:INFO:Determining Trained Model
2023-07-29 20:49:20,788:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:49:20,788:INFO:Copying data
2023-07-29 20:49:20,793:INFO:(10202, 20)
2023-07-29 20:49:20,793:INFO:assign_model() successfully completed......................................
2023-07-29 20:49:34,406:INFO:Initializing assign_model()
2023-07-29 20:49:34,406:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:49:34,407:INFO:Checking exceptions
2023-07-29 20:49:34,407:INFO:Determining Trained Model
2023-07-29 20:49:34,407:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:49:34,407:INFO:Copying data
2023-07-29 20:49:34,410:INFO:(10202, 20)
2023-07-29 20:49:34,411:INFO:assign_model() successfully completed......................................
2023-07-29 20:49:49,234:INFO:Initializing assign_model()
2023-07-29 20:49:49,234:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:49:49,234:INFO:Checking exceptions
2023-07-29 20:49:49,234:INFO:Determining Trained Model
2023-07-29 20:49:49,234:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:49:49,234:INFO:Copying data
2023-07-29 20:49:49,239:INFO:(10202, 20)
2023-07-29 20:49:49,239:INFO:assign_model() successfully completed......................................
2023-07-29 20:50:14,974:INFO:Initializing assign_model()
2023-07-29 20:50:14,974:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=True, score=True, verbose=True)
2023-07-29 20:50:14,974:INFO:Checking exceptions
2023-07-29 20:50:14,974:INFO:Determining Trained Model
2023-07-29 20:50:14,974:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:50:14,974:INFO:Copying data
2023-07-29 20:50:14,979:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-29 20:50:14,982:INFO:(10202, 20)
2023-07-29 20:50:14,982:INFO:assign_model() successfully completed......................................
2023-07-29 20:50:25,618:INFO:Initializing assign_model()
2023-07-29 20:50:25,618:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:50:25,619:INFO:Checking exceptions
2023-07-29 20:50:25,619:INFO:Determining Trained Model
2023-07-29 20:50:25,619:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:50:25,619:INFO:Copying data
2023-07-29 20:50:25,622:INFO:(10202, 20)
2023-07-29 20:50:25,622:INFO:assign_model() successfully completed......................................
2023-07-29 20:50:52,111:INFO:Initializing assign_model()
2023-07-29 20:50:52,111:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:50:52,111:INFO:Checking exceptions
2023-07-29 20:50:52,114:INFO:Determining Trained Model
2023-07-29 20:50:52,114:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:50:52,114:INFO:Copying data
2023-07-29 20:50:52,120:INFO:(10202, 20)
2023-07-29 20:50:52,120:INFO:assign_model() successfully completed......................................
2023-07-29 20:51:05,881:INFO:Initializing assign_model()
2023-07-29 20:51:05,881:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:51:05,881:INFO:Checking exceptions
2023-07-29 20:51:05,881:INFO:Determining Trained Model
2023-07-29 20:51:05,881:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:51:05,881:INFO:Copying data
2023-07-29 20:51:05,887:INFO:(10202, 20)
2023-07-29 20:51:05,888:INFO:assign_model() successfully completed......................................
2023-07-29 20:51:46,248:INFO:Initializing assign_model()
2023-07-29 20:51:46,248:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=False, score=True, verbose=True)
2023-07-29 20:51:46,248:INFO:Checking exceptions
2023-07-29 20:51:46,248:INFO:Determining Trained Model
2023-07-29 20:51:46,248:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:51:46,248:INFO:Copying data
2023-07-29 20:51:46,254:INFO:(10202, 20)
2023-07-29 20:51:46,254:INFO:assign_model() successfully completed......................................
2023-07-29 20:51:53,821:INFO:Initializing plot_model()
2023-07-29 20:51:53,821:INFO:plot_model(plot=cluster, fold=None, verbose=True, display=None, display_format=None, estimator=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, system=True)
2023-07-29 20:51:53,821:INFO:Checking exceptions
2023-07-29 20:51:53,824:INFO:Preloading libraries
2023-07-29 20:51:53,825:INFO:Copying training dataset
2023-07-29 20:51:53,825:INFO:Plot type: cluster
2023-07-29 20:51:53,825:INFO:SubProcess assign_model() called ==================================
2023-07-29 20:51:53,825:INFO:Initializing assign_model()
2023-07-29 20:51:53,825:INFO:assign_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000024D0E4A3100>, model=DBSCAN(eps=0.1, min_samples=1, n_jobs=-1), transformation=True, score=True, verbose=False)
2023-07-29 20:51:53,825:INFO:Checking exceptions
2023-07-29 20:51:53,825:INFO:Determining Trained Model
2023-07-29 20:51:53,825:INFO:Trained Model : Density-Based Spatial Clustering
2023-07-29 20:51:53,825:INFO:Copying data
2023-07-29 20:51:53,828:INFO:Transformation parameter set to True. Assigned clusters are attached on transformed dataset.
2023-07-29 20:51:53,831:INFO:(10202, 20)
2023-07-29 20:51:53,831:INFO:assign_model() successfully completed......................................
2023-07-29 20:51:53,831:INFO:SubProcess assign_model() end ==================================
2023-07-29 20:51:53,833:INFO:Fitting PCA()
2023-07-29 20:51:53,843:INFO:Sorting dataframe
2023-07-29 20:51:53,850:INFO:Rendering Visual
2023-07-29 20:51:57,302:INFO:Visual Rendered Successfully
2023-07-29 20:51:57,432:INFO:plot_model() successfully completed......................................
2023-07-31 14:59:31,052:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 14:59:31,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 14:59:31,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 14:59:31,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 14:59:35,542:INFO:PyCaret ClassificationExperiment
2023-07-31 14:59:35,542:INFO:Logging name: clf-default-name
2023-07-31 14:59:35,543:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 14:59:35,543:INFO:version 3.0.4
2023-07-31 14:59:35,543:INFO:Initializing setup()
2023-07-31 14:59:35,543:INFO:self.USI: 9a0f
2023-07-31 14:59:35,543:INFO:self._variable_keys: {'exp_id', 'y', 'y_train', 'idx', 'gpu_param', 'logging_param', 'n_jobs_param', 'fix_imbalance', 'exp_name_log', 'X_train', 'fold_groups_param', '_ml_usecase', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'memory', '_available_plots', 'fold_generator', 'pipeline', 'data', 'X_test', 'html_param', 'y_test', 'is_multiclass', 'X', 'target_param', 'USI', 'fold_shuffle_param'}
2023-07-31 14:59:35,543:INFO:Checking environment
2023-07-31 14:59:35,543:INFO:python_version: 3.9.13
2023-07-31 14:59:35,543:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-31 14:59:35,543:INFO:machine: AMD64
2023-07-31 14:59:35,543:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-31 14:59:35,546:INFO:Memory: svmem(total=17055166464, available=8720781312, percent=48.9, used=8334385152, free=8720781312)
2023-07-31 14:59:35,547:INFO:Physical Core: 4
2023-07-31 14:59:35,547:INFO:Logical Core: 8
2023-07-31 14:59:35,547:INFO:Checking libraries
2023-07-31 14:59:35,547:INFO:System:
2023-07-31 14:59:35,547:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-31 14:59:35,547:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-31 14:59:35,547:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-31 14:59:35,547:INFO:PyCaret required dependencies:
2023-07-31 14:59:35,549:INFO:                 pip: 22.0.4
2023-07-31 14:59:35,549:INFO:          setuptools: 58.1.0
2023-07-31 14:59:35,549:INFO:             pycaret: 3.0.4
2023-07-31 14:59:35,549:INFO:             IPython: 8.13.1
2023-07-31 14:59:35,549:INFO:          ipywidgets: 8.0.7
2023-07-31 14:59:35,549:INFO:                tqdm: 4.65.0
2023-07-31 14:59:35,549:INFO:               numpy: 1.23.0
2023-07-31 14:59:35,550:INFO:              pandas: 1.5.3
2023-07-31 14:59:35,550:INFO:              jinja2: 3.1.2
2023-07-31 14:59:35,550:INFO:               scipy: 1.10.1
2023-07-31 14:59:35,550:INFO:              joblib: 1.2.0
2023-07-31 14:59:35,550:INFO:             sklearn: 1.2.2
2023-07-31 14:59:35,550:INFO:                pyod: 1.1.0
2023-07-31 14:59:35,550:INFO:            imblearn: 0.11.0
2023-07-31 14:59:35,550:INFO:   category_encoders: 2.6.1
2023-07-31 14:59:35,550:INFO:            lightgbm: 3.3.5
2023-07-31 14:59:35,550:INFO:               numba: 0.57.1
2023-07-31 14:59:35,550:INFO:            requests: 2.31.0
2023-07-31 14:59:35,550:INFO:          matplotlib: 3.7.1
2023-07-31 14:59:35,550:INFO:          scikitplot: 0.3.7
2023-07-31 14:59:35,550:INFO:         yellowbrick: 1.5
2023-07-31 14:59:35,550:INFO:              plotly: 5.15.0
2023-07-31 14:59:35,550:INFO:    plotly-resampler: Not installed
2023-07-31 14:59:35,550:INFO:             kaleido: 0.2.1
2023-07-31 14:59:35,550:INFO:           schemdraw: 0.15
2023-07-31 14:59:35,550:INFO:         statsmodels: 0.14.0
2023-07-31 14:59:35,550:INFO:              sktime: 0.20.0
2023-07-31 14:59:35,550:INFO:               tbats: 1.1.3
2023-07-31 14:59:35,550:INFO:            pmdarima: 2.0.3
2023-07-31 14:59:35,551:INFO:              psutil: 5.9.5
2023-07-31 14:59:35,551:INFO:          markupsafe: 2.1.3
2023-07-31 14:59:35,551:INFO:             pickle5: Not installed
2023-07-31 14:59:35,551:INFO:         cloudpickle: 2.2.1
2023-07-31 14:59:35,551:INFO:         deprecation: 2.1.0
2023-07-31 14:59:35,551:INFO:              xxhash: 3.2.0
2023-07-31 14:59:35,551:INFO:           wurlitzer: Not installed
2023-07-31 14:59:35,551:INFO:PyCaret optional dependencies:
2023-07-31 14:59:35,568:INFO:                shap: Not installed
2023-07-31 14:59:35,568:INFO:           interpret: Not installed
2023-07-31 14:59:35,568:INFO:                umap: Not installed
2023-07-31 14:59:35,568:INFO:    pandas_profiling: 4.3.1
2023-07-31 14:59:35,569:INFO:  explainerdashboard: Not installed
2023-07-31 14:59:35,569:INFO:             autoviz: Not installed
2023-07-31 14:59:35,569:INFO:           fairlearn: Not installed
2023-07-31 14:59:35,569:INFO:          deepchecks: Not installed
2023-07-31 14:59:35,569:INFO:             xgboost: Not installed
2023-07-31 14:59:35,569:INFO:            catboost: Not installed
2023-07-31 14:59:35,569:INFO:              kmodes: Not installed
2023-07-31 14:59:35,569:INFO:             mlxtend: 0.22.0
2023-07-31 14:59:35,569:INFO:       statsforecast: Not installed
2023-07-31 14:59:35,569:INFO:        tune_sklearn: Not installed
2023-07-31 14:59:35,569:INFO:                 ray: Not installed
2023-07-31 14:59:35,569:INFO:            hyperopt: Not installed
2023-07-31 14:59:35,569:INFO:              optuna: Not installed
2023-07-31 14:59:35,569:INFO:               skopt: Not installed
2023-07-31 14:59:35,570:INFO:              mlflow: Not installed
2023-07-31 14:59:35,570:INFO:              gradio: Not installed
2023-07-31 14:59:35,570:INFO:             fastapi: Not installed
2023-07-31 14:59:35,570:INFO:             uvicorn: Not installed
2023-07-31 14:59:35,570:INFO:              m2cgen: Not installed
2023-07-31 14:59:35,570:INFO:           evidently: Not installed
2023-07-31 14:59:35,570:INFO:               fugue: Not installed
2023-07-31 14:59:35,570:INFO:           streamlit: Not installed
2023-07-31 14:59:35,570:INFO:             prophet: Not installed
2023-07-31 14:59:35,570:INFO:None
2023-07-31 14:59:35,570:INFO:Set up data.
2023-07-31 14:59:35,581:INFO:Set up train/test split.
2023-07-31 14:59:35,589:INFO:Set up index.
2023-07-31 14:59:35,590:INFO:Set up folding strategy.
2023-07-31 14:59:35,590:INFO:Assigning column types.
2023-07-31 14:59:35,593:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 14:59:35,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:59:35,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:59:35,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:35,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:35,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 14:59:35,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:59:35,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:35,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:35,981:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 14:59:36,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:59:36,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 14:59:36,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,144:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 14:59:36,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:36,316:INFO:Preparing preprocessing pipeline...
2023-07-31 14:59:36,317:INFO:Set up simple imputation.
2023-07-31 14:59:36,322:INFO:Set up encoding of categorical features.
2023-07-31 14:59:36,322:INFO:Set up removing multicollinearity.
2023-07-31 14:59:36,322:INFO:Set up feature normalization.
2023-07-31 14:59:36,546:INFO:Finished creating preprocessing pipeline.
2023-07-31 14:59:36,606:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-07-31 14:59:36,606:INFO:Creating final display dataframe.
2023-07-31 14:59:36,955:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (7387, 11)
4        Transformed data shape        (7387, 31)
5   Transformed train set shape        (5909, 31)
6    Transformed test set shape        (1478, 31)
7              Numeric features                 6
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            robust
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              9a0f
2023-07-31 14:59:37,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:37,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:37,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:37,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 14:59:37,149:INFO:setup() successfully completed in 1.95s...............
2023-07-31 15:00:04,061:INFO:Initializing get_config()
2023-07-31 15:00:04,061:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, variable=pipeline)
2023-07-31 15:00:04,076:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-07-31 15:00:04,077:INFO:get_config() successfully completed......................................
2023-07-31 15:01:26,263:INFO:Initializing compare_models()
2023-07-31 15:01:26,263:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 15:01:26,263:INFO:Checking exceptions
2023-07-31 15:01:26,271:INFO:Preparing display monitor
2023-07-31 15:01:26,314:INFO:Initializing Logistic Regression
2023-07-31 15:01:26,314:INFO:Total runtime is 0.0 minutes
2023-07-31 15:01:26,319:INFO:SubProcess create_model() called ==================================
2023-07-31 15:01:26,320:INFO:Initializing create_model()
2023-07-31 15:01:26,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:01:26,320:INFO:Checking exceptions
2023-07-31 15:01:26,320:INFO:Importing libraries
2023-07-31 15:01:26,320:INFO:Copying training dataset
2023-07-31 15:01:26,328:INFO:Defining folds
2023-07-31 15:01:26,328:INFO:Declaring metric variables
2023-07-31 15:01:26,332:INFO:Importing untrained model
2023-07-31 15:01:26,338:INFO:Logistic Regression Imported successfully
2023-07-31 15:01:26,352:INFO:Starting cross validation
2023-07-31 15:01:26,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:01:39,157:INFO:Calculating mean and std
2023-07-31 15:01:39,159:INFO:Creating metrics dataframe
2023-07-31 15:01:39,563:INFO:Uploading results into container
2023-07-31 15:01:39,564:INFO:Uploading model into container now
2023-07-31 15:01:39,564:INFO:_master_model_container: 1
2023-07-31 15:01:39,564:INFO:_display_container: 2
2023-07-31 15:01:39,565:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:01:39,565:INFO:create_model() successfully completed......................................
2023-07-31 15:01:39,656:INFO:SubProcess create_model() end ==================================
2023-07-31 15:01:39,656:INFO:Creating metrics dataframe
2023-07-31 15:01:39,668:INFO:Initializing K Neighbors Classifier
2023-07-31 15:01:39,669:INFO:Total runtime is 0.22257598638534545 minutes
2023-07-31 15:01:39,674:INFO:SubProcess create_model() called ==================================
2023-07-31 15:01:39,675:INFO:Initializing create_model()
2023-07-31 15:01:39,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:01:39,676:INFO:Checking exceptions
2023-07-31 15:01:39,676:INFO:Importing libraries
2023-07-31 15:01:39,676:INFO:Copying training dataset
2023-07-31 15:01:39,684:INFO:Defining folds
2023-07-31 15:01:39,685:INFO:Declaring metric variables
2023-07-31 15:01:39,690:INFO:Importing untrained model
2023-07-31 15:01:39,698:INFO:K Neighbors Classifier Imported successfully
2023-07-31 15:01:39,711:INFO:Starting cross validation
2023-07-31 15:01:39,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:01:44,036:INFO:Calculating mean and std
2023-07-31 15:01:44,037:INFO:Creating metrics dataframe
2023-07-31 15:01:44,438:INFO:Uploading results into container
2023-07-31 15:01:44,438:INFO:Uploading model into container now
2023-07-31 15:01:44,439:INFO:_master_model_container: 2
2023-07-31 15:01:44,439:INFO:_display_container: 2
2023-07-31 15:01:44,439:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 15:01:44,440:INFO:create_model() successfully completed......................................
2023-07-31 15:01:44,519:INFO:SubProcess create_model() end ==================================
2023-07-31 15:01:44,520:INFO:Creating metrics dataframe
2023-07-31 15:01:44,533:INFO:Initializing Naive Bayes
2023-07-31 15:01:44,533:INFO:Total runtime is 0.30364259481430056 minutes
2023-07-31 15:01:44,538:INFO:SubProcess create_model() called ==================================
2023-07-31 15:01:44,538:INFO:Initializing create_model()
2023-07-31 15:01:44,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:01:44,539:INFO:Checking exceptions
2023-07-31 15:01:44,539:INFO:Importing libraries
2023-07-31 15:01:44,539:INFO:Copying training dataset
2023-07-31 15:01:44,547:INFO:Defining folds
2023-07-31 15:01:44,547:INFO:Declaring metric variables
2023-07-31 15:01:44,554:INFO:Importing untrained model
2023-07-31 15:01:44,561:INFO:Naive Bayes Imported successfully
2023-07-31 15:01:44,574:INFO:Starting cross validation
2023-07-31 15:01:44,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:01:48,861:INFO:Calculating mean and std
2023-07-31 15:01:48,863:INFO:Creating metrics dataframe
2023-07-31 15:01:49,316:INFO:Uploading results into container
2023-07-31 15:01:49,317:INFO:Uploading model into container now
2023-07-31 15:01:49,317:INFO:_master_model_container: 3
2023-07-31 15:01:49,318:INFO:_display_container: 2
2023-07-31 15:01:49,318:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 15:01:49,318:INFO:create_model() successfully completed......................................
2023-07-31 15:01:49,400:INFO:SubProcess create_model() end ==================================
2023-07-31 15:01:49,400:INFO:Creating metrics dataframe
2023-07-31 15:01:49,415:INFO:Initializing Decision Tree Classifier
2023-07-31 15:01:49,415:INFO:Total runtime is 0.3850090662638347 minutes
2023-07-31 15:01:49,419:INFO:SubProcess create_model() called ==================================
2023-07-31 15:01:49,419:INFO:Initializing create_model()
2023-07-31 15:01:49,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:01:49,420:INFO:Checking exceptions
2023-07-31 15:01:49,420:INFO:Importing libraries
2023-07-31 15:01:49,420:INFO:Copying training dataset
2023-07-31 15:01:49,428:INFO:Defining folds
2023-07-31 15:01:49,429:INFO:Declaring metric variables
2023-07-31 15:01:49,435:INFO:Importing untrained model
2023-07-31 15:01:49,440:INFO:Decision Tree Classifier Imported successfully
2023-07-31 15:01:49,452:INFO:Starting cross validation
2023-07-31 15:01:49,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:01:53,966:INFO:Calculating mean and std
2023-07-31 15:01:53,967:INFO:Creating metrics dataframe
2023-07-31 15:01:54,478:INFO:Uploading results into container
2023-07-31 15:01:54,480:INFO:Uploading model into container now
2023-07-31 15:01:54,481:INFO:_master_model_container: 4
2023-07-31 15:01:54,481:INFO:_display_container: 2
2023-07-31 15:01:54,482:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-07-31 15:01:54,482:INFO:create_model() successfully completed......................................
2023-07-31 15:01:54,617:INFO:SubProcess create_model() end ==================================
2023-07-31 15:01:54,617:INFO:Creating metrics dataframe
2023-07-31 15:01:54,642:INFO:Initializing SVM - Linear Kernel
2023-07-31 15:01:54,643:INFO:Total runtime is 0.47214275598526007 minutes
2023-07-31 15:01:54,651:INFO:SubProcess create_model() called ==================================
2023-07-31 15:01:54,652:INFO:Initializing create_model()
2023-07-31 15:01:54,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:01:54,652:INFO:Checking exceptions
2023-07-31 15:01:54,653:INFO:Importing libraries
2023-07-31 15:01:54,653:INFO:Copying training dataset
2023-07-31 15:01:54,667:INFO:Defining folds
2023-07-31 15:01:54,668:INFO:Declaring metric variables
2023-07-31 15:01:54,679:INFO:Importing untrained model
2023-07-31 15:01:54,688:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 15:01:54,711:INFO:Starting cross validation
2023-07-31 15:01:54,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:01:56,017:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,030:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,096:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,105:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,267:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,272:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,350:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:56,603:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:58,061:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:01:58,137:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:02:00,501:INFO:Calculating mean and std
2023-07-31 15:02:00,503:INFO:Creating metrics dataframe
2023-07-31 15:02:01,146:INFO:Uploading results into container
2023-07-31 15:02:01,147:INFO:Uploading model into container now
2023-07-31 15:02:01,148:INFO:_master_model_container: 5
2023-07-31 15:02:01,149:INFO:_display_container: 2
2023-07-31 15:02:01,150:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 15:02:01,150:INFO:create_model() successfully completed......................................
2023-07-31 15:02:01,272:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:01,272:INFO:Creating metrics dataframe
2023-07-31 15:02:01,301:INFO:Initializing Ridge Classifier
2023-07-31 15:02:01,301:INFO:Total runtime is 0.5831090927124024 minutes
2023-07-31 15:02:01,310:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:01,311:INFO:Initializing create_model()
2023-07-31 15:02:01,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:01,311:INFO:Checking exceptions
2023-07-31 15:02:01,312:INFO:Importing libraries
2023-07-31 15:02:01,312:INFO:Copying training dataset
2023-07-31 15:02:01,326:INFO:Defining folds
2023-07-31 15:02:01,327:INFO:Declaring metric variables
2023-07-31 15:02:01,337:INFO:Importing untrained model
2023-07-31 15:02:01,349:INFO:Ridge Classifier Imported successfully
2023-07-31 15:02:01,371:INFO:Starting cross validation
2023-07-31 15:02:01,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:02,673:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:02,693:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:02,814:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:02,945:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:02,955:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:03,019:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:03,152:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:03,169:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:04,162:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:04,180:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:02:06,478:INFO:Calculating mean and std
2023-07-31 15:02:06,480:INFO:Creating metrics dataframe
2023-07-31 15:02:07,005:INFO:Uploading results into container
2023-07-31 15:02:07,006:INFO:Uploading model into container now
2023-07-31 15:02:07,007:INFO:_master_model_container: 6
2023-07-31 15:02:07,007:INFO:_display_container: 2
2023-07-31 15:02:07,008:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-07-31 15:02:07,009:INFO:create_model() successfully completed......................................
2023-07-31 15:02:07,097:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:07,097:INFO:Creating metrics dataframe
2023-07-31 15:02:07,113:INFO:Initializing Random Forest Classifier
2023-07-31 15:02:07,113:INFO:Total runtime is 0.6799846371014914 minutes
2023-07-31 15:02:07,119:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:07,120:INFO:Initializing create_model()
2023-07-31 15:02:07,120:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:07,121:INFO:Checking exceptions
2023-07-31 15:02:07,121:INFO:Importing libraries
2023-07-31 15:02:07,121:INFO:Copying training dataset
2023-07-31 15:02:07,130:INFO:Defining folds
2023-07-31 15:02:07,131:INFO:Declaring metric variables
2023-07-31 15:02:07,137:INFO:Importing untrained model
2023-07-31 15:02:07,145:INFO:Random Forest Classifier Imported successfully
2023-07-31 15:02:07,159:INFO:Starting cross validation
2023-07-31 15:02:07,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:09,578:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:02:09,592:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:02:09,640:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:02:09,653:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:02:09,669:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:02:15,340:INFO:Calculating mean and std
2023-07-31 15:02:15,343:INFO:Creating metrics dataframe
2023-07-31 15:02:15,823:INFO:Uploading results into container
2023-07-31 15:02:15,824:INFO:Uploading model into container now
2023-07-31 15:02:15,825:INFO:_master_model_container: 7
2023-07-31 15:02:15,826:INFO:_display_container: 2
2023-07-31 15:02:15,827:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-07-31 15:02:15,827:INFO:create_model() successfully completed......................................
2023-07-31 15:02:15,910:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:15,911:INFO:Creating metrics dataframe
2023-07-31 15:02:15,926:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 15:02:15,926:INFO:Total runtime is 0.8268682916959127 minutes
2023-07-31 15:02:15,932:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:15,933:INFO:Initializing create_model()
2023-07-31 15:02:15,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:15,933:INFO:Checking exceptions
2023-07-31 15:02:15,933:INFO:Importing libraries
2023-07-31 15:02:15,933:INFO:Copying training dataset
2023-07-31 15:02:15,941:INFO:Defining folds
2023-07-31 15:02:15,942:INFO:Declaring metric variables
2023-07-31 15:02:15,949:INFO:Importing untrained model
2023-07-31 15:02:15,956:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 15:02:15,968:INFO:Starting cross validation
2023-07-31 15:02:15,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:16,413:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,413:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,416:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,417:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,421:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,437:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,461:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:16,479:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:18,275:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:18,285:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:02:20,598:INFO:Calculating mean and std
2023-07-31 15:02:20,599:INFO:Creating metrics dataframe
2023-07-31 15:02:21,120:INFO:Uploading results into container
2023-07-31 15:02:21,121:INFO:Uploading model into container now
2023-07-31 15:02:21,121:INFO:_master_model_container: 8
2023-07-31 15:02:21,122:INFO:_display_container: 2
2023-07-31 15:02:21,123:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 15:02:21,123:INFO:create_model() successfully completed......................................
2023-07-31 15:02:21,204:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:21,204:INFO:Creating metrics dataframe
2023-07-31 15:02:21,218:INFO:Initializing Ada Boost Classifier
2023-07-31 15:02:21,218:INFO:Total runtime is 0.9150679071744283 minutes
2023-07-31 15:02:21,222:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:21,223:INFO:Initializing create_model()
2023-07-31 15:02:21,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:21,223:INFO:Checking exceptions
2023-07-31 15:02:21,223:INFO:Importing libraries
2023-07-31 15:02:21,223:INFO:Copying training dataset
2023-07-31 15:02:21,232:INFO:Defining folds
2023-07-31 15:02:21,233:INFO:Declaring metric variables
2023-07-31 15:02:21,238:INFO:Importing untrained model
2023-07-31 15:02:21,244:INFO:Ada Boost Classifier Imported successfully
2023-07-31 15:02:21,256:INFO:Starting cross validation
2023-07-31 15:02:21,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:27,784:INFO:Calculating mean and std
2023-07-31 15:02:27,785:INFO:Creating metrics dataframe
2023-07-31 15:02:28,316:INFO:Uploading results into container
2023-07-31 15:02:28,317:INFO:Uploading model into container now
2023-07-31 15:02:28,317:INFO:_master_model_container: 9
2023-07-31 15:02:28,318:INFO:_display_container: 2
2023-07-31 15:02:28,318:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-07-31 15:02:28,319:INFO:create_model() successfully completed......................................
2023-07-31 15:02:28,403:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:28,403:INFO:Creating metrics dataframe
2023-07-31 15:02:28,420:INFO:Initializing Gradient Boosting Classifier
2023-07-31 15:02:28,420:INFO:Total runtime is 1.035101310412089 minutes
2023-07-31 15:02:28,425:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:28,426:INFO:Initializing create_model()
2023-07-31 15:02:28,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:28,428:INFO:Checking exceptions
2023-07-31 15:02:28,428:INFO:Importing libraries
2023-07-31 15:02:28,428:INFO:Copying training dataset
2023-07-31 15:02:28,435:INFO:Defining folds
2023-07-31 15:02:28,435:INFO:Declaring metric variables
2023-07-31 15:02:28,443:INFO:Importing untrained model
2023-07-31 15:02:28,449:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 15:02:28,465:INFO:Starting cross validation
2023-07-31 15:02:28,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:36,019:INFO:Calculating mean and std
2023-07-31 15:02:36,020:INFO:Creating metrics dataframe
2023-07-31 15:02:36,583:INFO:Uploading results into container
2023-07-31 15:02:36,584:INFO:Uploading model into container now
2023-07-31 15:02:36,584:INFO:_master_model_container: 10
2023-07-31 15:02:36,585:INFO:_display_container: 2
2023-07-31 15:02:36,585:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:02:36,586:INFO:create_model() successfully completed......................................
2023-07-31 15:02:36,670:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:36,670:INFO:Creating metrics dataframe
2023-07-31 15:02:36,684:INFO:Initializing Linear Discriminant Analysis
2023-07-31 15:02:36,684:INFO:Total runtime is 1.1728346467018127 minutes
2023-07-31 15:02:36,689:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:36,689:INFO:Initializing create_model()
2023-07-31 15:02:36,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:36,689:INFO:Checking exceptions
2023-07-31 15:02:36,689:INFO:Importing libraries
2023-07-31 15:02:36,690:INFO:Copying training dataset
2023-07-31 15:02:36,698:INFO:Defining folds
2023-07-31 15:02:36,698:INFO:Declaring metric variables
2023-07-31 15:02:36,702:INFO:Importing untrained model
2023-07-31 15:02:36,707:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 15:02:36,718:INFO:Starting cross validation
2023-07-31 15:02:36,721:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:41,633:INFO:Calculating mean and std
2023-07-31 15:02:41,634:INFO:Creating metrics dataframe
2023-07-31 15:02:42,194:INFO:Uploading results into container
2023-07-31 15:02:42,195:INFO:Uploading model into container now
2023-07-31 15:02:42,196:INFO:_master_model_container: 11
2023-07-31 15:02:42,196:INFO:_display_container: 2
2023-07-31 15:02:42,196:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 15:02:42,196:INFO:create_model() successfully completed......................................
2023-07-31 15:02:42,280:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:42,280:INFO:Creating metrics dataframe
2023-07-31 15:02:42,299:INFO:Initializing Extra Trees Classifier
2023-07-31 15:02:42,299:INFO:Total runtime is 1.2664179841677348 minutes
2023-07-31 15:02:42,304:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:42,304:INFO:Initializing create_model()
2023-07-31 15:02:42,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:42,305:INFO:Checking exceptions
2023-07-31 15:02:42,305:INFO:Importing libraries
2023-07-31 15:02:42,305:INFO:Copying training dataset
2023-07-31 15:02:42,314:INFO:Defining folds
2023-07-31 15:02:42,314:INFO:Declaring metric variables
2023-07-31 15:02:42,319:INFO:Importing untrained model
2023-07-31 15:02:42,325:INFO:Extra Trees Classifier Imported successfully
2023-07-31 15:02:42,338:INFO:Starting cross validation
2023-07-31 15:02:42,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:51,105:INFO:Calculating mean and std
2023-07-31 15:02:51,107:INFO:Creating metrics dataframe
2023-07-31 15:02:51,668:INFO:Uploading results into container
2023-07-31 15:02:51,669:INFO:Uploading model into container now
2023-07-31 15:02:51,670:INFO:_master_model_container: 12
2023-07-31 15:02:51,670:INFO:_display_container: 2
2023-07-31 15:02:51,671:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-07-31 15:02:51,671:INFO:create_model() successfully completed......................................
2023-07-31 15:02:51,759:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:51,759:INFO:Creating metrics dataframe
2023-07-31 15:02:51,774:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 15:02:51,774:INFO:Total runtime is 1.4243266940116883 minutes
2023-07-31 15:02:51,779:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:51,780:INFO:Initializing create_model()
2023-07-31 15:02:51,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:51,780:INFO:Checking exceptions
2023-07-31 15:02:51,780:INFO:Importing libraries
2023-07-31 15:02:51,780:INFO:Copying training dataset
2023-07-31 15:02:51,787:INFO:Defining folds
2023-07-31 15:02:51,787:INFO:Declaring metric variables
2023-07-31 15:02:51,794:INFO:Importing untrained model
2023-07-31 15:02:51,799:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 15:02:51,812:INFO:Starting cross validation
2023-07-31 15:02:51,816:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:57,888:INFO:Calculating mean and std
2023-07-31 15:02:57,889:INFO:Creating metrics dataframe
2023-07-31 15:02:58,479:INFO:Uploading results into container
2023-07-31 15:02:58,480:INFO:Uploading model into container now
2023-07-31 15:02:58,481:INFO:_master_model_container: 13
2023-07-31 15:02:58,481:INFO:_display_container: 2
2023-07-31 15:02:58,482:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 15:02:58,483:INFO:create_model() successfully completed......................................
2023-07-31 15:02:58,564:INFO:SubProcess create_model() end ==================================
2023-07-31 15:02:58,564:INFO:Creating metrics dataframe
2023-07-31 15:02:58,580:INFO:Initializing Dummy Classifier
2023-07-31 15:02:58,580:INFO:Total runtime is 1.537759530544281 minutes
2023-07-31 15:02:58,584:INFO:SubProcess create_model() called ==================================
2023-07-31 15:02:58,585:INFO:Initializing create_model()
2023-07-31 15:02:58,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF2D1A610>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:02:58,585:INFO:Checking exceptions
2023-07-31 15:02:58,585:INFO:Importing libraries
2023-07-31 15:02:58,585:INFO:Copying training dataset
2023-07-31 15:02:58,593:INFO:Defining folds
2023-07-31 15:02:58,593:INFO:Declaring metric variables
2023-07-31 15:02:58,600:INFO:Importing untrained model
2023-07-31 15:02:58,605:INFO:Dummy Classifier Imported successfully
2023-07-31 15:02:58,627:INFO:Starting cross validation
2023-07-31 15:02:58,647:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:02:59,517:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,517:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,518:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,525:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,532:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,582:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,623:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:02:59,642:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:03:01,541:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:03:01,883:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:03:04,278:INFO:Calculating mean and std
2023-07-31 15:03:04,279:INFO:Creating metrics dataframe
2023-07-31 15:03:04,867:INFO:Uploading results into container
2023-07-31 15:03:04,868:INFO:Uploading model into container now
2023-07-31 15:03:04,869:INFO:_master_model_container: 14
2023-07-31 15:03:04,869:INFO:_display_container: 2
2023-07-31 15:03:04,869:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-07-31 15:03:04,869:INFO:create_model() successfully completed......................................
2023-07-31 15:03:04,952:INFO:SubProcess create_model() end ==================================
2023-07-31 15:03:04,952:INFO:Creating metrics dataframe
2023-07-31 15:03:04,986:INFO:Initializing create_model()
2023-07-31 15:03:04,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEF603C8B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:03:04,987:INFO:Checking exceptions
2023-07-31 15:03:04,990:INFO:Importing libraries
2023-07-31 15:03:04,990:INFO:Copying training dataset
2023-07-31 15:03:04,997:INFO:Defining folds
2023-07-31 15:03:04,998:INFO:Declaring metric variables
2023-07-31 15:03:04,998:INFO:Importing untrained model
2023-07-31 15:03:04,998:INFO:Declaring custom model
2023-07-31 15:03:04,999:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 15:03:05,000:INFO:Cross validation set to False
2023-07-31 15:03:05,000:INFO:Fitting Model
2023-07-31 15:03:06,358:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:03:06,358:INFO:create_model() successfully completed......................................
2023-07-31 15:03:06,508:INFO:_master_model_container: 14
2023-07-31 15:03:06,509:INFO:_display_container: 2
2023-07-31 15:03:06,510:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:03:06,511:INFO:compare_models() successfully completed......................................
2023-07-31 15:05:53,036:INFO:PyCaret ClassificationExperiment
2023-07-31 15:05:53,037:INFO:Logging name: clf-default-name
2023-07-31 15:05:53,037:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 15:05:53,037:INFO:version 3.0.4
2023-07-31 15:05:53,037:INFO:Initializing setup()
2023-07-31 15:05:53,037:INFO:self.USI: 3c53
2023-07-31 15:05:53,037:INFO:self._variable_keys: {'exp_id', 'y', 'y_train', 'idx', 'gpu_param', 'logging_param', 'n_jobs_param', 'fix_imbalance', 'exp_name_log', 'X_train', 'fold_groups_param', '_ml_usecase', 'gpu_n_jobs_param', 'seed', 'log_plots_param', 'memory', '_available_plots', 'fold_generator', 'pipeline', 'data', 'X_test', 'html_param', 'y_test', 'is_multiclass', 'X', 'target_param', 'USI', 'fold_shuffle_param'}
2023-07-31 15:05:53,037:INFO:Checking environment
2023-07-31 15:05:53,037:INFO:python_version: 3.9.13
2023-07-31 15:05:53,037:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-31 15:05:53,037:INFO:machine: AMD64
2023-07-31 15:05:53,037:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-31 15:05:53,041:INFO:Memory: svmem(total=17055166464, available=7525089280, percent=55.9, used=9530077184, free=7525089280)
2023-07-31 15:05:53,042:INFO:Physical Core: 4
2023-07-31 15:05:53,042:INFO:Logical Core: 8
2023-07-31 15:05:53,042:INFO:Checking libraries
2023-07-31 15:05:53,042:INFO:System:
2023-07-31 15:05:53,042:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-31 15:05:53,042:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-31 15:05:53,042:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-31 15:05:53,042:INFO:PyCaret required dependencies:
2023-07-31 15:05:53,042:INFO:                 pip: 22.0.4
2023-07-31 15:05:53,042:INFO:          setuptools: 58.1.0
2023-07-31 15:05:53,042:INFO:             pycaret: 3.0.4
2023-07-31 15:05:53,042:INFO:             IPython: 8.13.1
2023-07-31 15:05:53,042:INFO:          ipywidgets: 8.0.7
2023-07-31 15:05:53,042:INFO:                tqdm: 4.65.0
2023-07-31 15:05:53,042:INFO:               numpy: 1.23.0
2023-07-31 15:05:53,042:INFO:              pandas: 1.5.3
2023-07-31 15:05:53,042:INFO:              jinja2: 3.1.2
2023-07-31 15:05:53,043:INFO:               scipy: 1.10.1
2023-07-31 15:05:53,043:INFO:              joblib: 1.2.0
2023-07-31 15:05:53,043:INFO:             sklearn: 1.2.2
2023-07-31 15:05:53,043:INFO:                pyod: 1.1.0
2023-07-31 15:05:53,043:INFO:            imblearn: 0.11.0
2023-07-31 15:05:53,043:INFO:   category_encoders: 2.6.1
2023-07-31 15:05:53,043:INFO:            lightgbm: 3.3.5
2023-07-31 15:05:53,043:INFO:               numba: 0.57.1
2023-07-31 15:05:53,043:INFO:            requests: 2.31.0
2023-07-31 15:05:53,043:INFO:          matplotlib: 3.7.1
2023-07-31 15:05:53,043:INFO:          scikitplot: 0.3.7
2023-07-31 15:05:53,043:INFO:         yellowbrick: 1.5
2023-07-31 15:05:53,043:INFO:              plotly: 5.15.0
2023-07-31 15:05:53,043:INFO:    plotly-resampler: Not installed
2023-07-31 15:05:53,043:INFO:             kaleido: 0.2.1
2023-07-31 15:05:53,043:INFO:           schemdraw: 0.15
2023-07-31 15:05:53,044:INFO:         statsmodels: 0.14.0
2023-07-31 15:05:53,044:INFO:              sktime: 0.20.0
2023-07-31 15:05:53,044:INFO:               tbats: 1.1.3
2023-07-31 15:05:53,044:INFO:            pmdarima: 2.0.3
2023-07-31 15:05:53,044:INFO:              psutil: 5.9.5
2023-07-31 15:05:53,044:INFO:          markupsafe: 2.1.3
2023-07-31 15:05:53,044:INFO:             pickle5: Not installed
2023-07-31 15:05:53,044:INFO:         cloudpickle: 2.2.1
2023-07-31 15:05:53,044:INFO:         deprecation: 2.1.0
2023-07-31 15:05:53,044:INFO:              xxhash: 3.2.0
2023-07-31 15:05:53,044:INFO:           wurlitzer: Not installed
2023-07-31 15:05:53,044:INFO:PyCaret optional dependencies:
2023-07-31 15:05:53,044:INFO:                shap: Not installed
2023-07-31 15:05:53,044:INFO:           interpret: Not installed
2023-07-31 15:05:53,044:INFO:                umap: Not installed
2023-07-31 15:05:53,045:INFO:    pandas_profiling: 4.3.1
2023-07-31 15:05:53,045:INFO:  explainerdashboard: Not installed
2023-07-31 15:05:53,045:INFO:             autoviz: Not installed
2023-07-31 15:05:53,045:INFO:           fairlearn: Not installed
2023-07-31 15:05:53,045:INFO:          deepchecks: Not installed
2023-07-31 15:05:53,045:INFO:             xgboost: Not installed
2023-07-31 15:05:53,045:INFO:            catboost: Not installed
2023-07-31 15:05:53,045:INFO:              kmodes: Not installed
2023-07-31 15:05:53,045:INFO:             mlxtend: 0.22.0
2023-07-31 15:05:53,045:INFO:       statsforecast: Not installed
2023-07-31 15:05:53,045:INFO:        tune_sklearn: Not installed
2023-07-31 15:05:53,045:INFO:                 ray: Not installed
2023-07-31 15:05:53,045:INFO:            hyperopt: Not installed
2023-07-31 15:05:53,045:INFO:              optuna: Not installed
2023-07-31 15:05:53,045:INFO:               skopt: Not installed
2023-07-31 15:05:53,045:INFO:              mlflow: Not installed
2023-07-31 15:05:53,045:INFO:              gradio: Not installed
2023-07-31 15:05:53,045:INFO:             fastapi: Not installed
2023-07-31 15:05:53,045:INFO:             uvicorn: Not installed
2023-07-31 15:05:53,045:INFO:              m2cgen: Not installed
2023-07-31 15:05:53,046:INFO:           evidently: Not installed
2023-07-31 15:05:53,046:INFO:               fugue: Not installed
2023-07-31 15:05:53,046:INFO:           streamlit: Not installed
2023-07-31 15:05:53,046:INFO:             prophet: Not installed
2023-07-31 15:05:53,046:INFO:None
2023-07-31 15:05:53,046:INFO:Set up data.
2023-07-31 15:05:53,058:INFO:Set up train/test split.
2023-07-31 15:05:53,065:INFO:Set up index.
2023-07-31 15:05:53,065:INFO:Set up folding strategy.
2023-07-31 15:05:53,065:INFO:Assigning column types.
2023-07-31 15:05:53,071:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 15:05:53,140:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,141:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,264:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 15:05:53,329:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 15:05:53,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,474:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,474:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 15:05:53,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:53,671:INFO:Preparing preprocessing pipeline...
2023-07-31 15:05:53,672:INFO:Set up simple imputation.
2023-07-31 15:05:53,676:INFO:Set up encoding of categorical features.
2023-07-31 15:05:53,676:INFO:Set up removing multicollinearity.
2023-07-31 15:05:53,676:INFO:Set up feature normalization.
2023-07-31 15:05:53,953:INFO:Finished creating preprocessing pipeline.
2023-07-31 15:05:53,964:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-07-31 15:05:53,965:INFO:Creating final display dataframe.
2023-07-31 15:05:54,458:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (7387, 10)  
4                                          (7387, 30)  
5                                          (5909, 30)  
6                                          (1478, 30)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                 25  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             robust  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               3c53  
2023-07-31 15:05:54,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:54,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:54,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:54,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 15:05:54,665:INFO:setup() successfully completed in 2.03s...............
2023-07-31 15:06:04,262:INFO:Initializing get_config()
2023-07-31 15:06:04,262:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, variable=pipeline)
2023-07-31 15:06:04,280:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-07-31 15:06:04,280:INFO:get_config() successfully completed......................................
2023-07-31 15:06:34,036:INFO:Initializing compare_models()
2023-07-31 15:06:34,037:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 15:06:34,038:INFO:Checking exceptions
2023-07-31 15:06:34,046:INFO:Preparing display monitor
2023-07-31 15:06:34,090:INFO:Initializing Logistic Regression
2023-07-31 15:06:34,091:INFO:Total runtime is 0.0 minutes
2023-07-31 15:06:34,097:INFO:SubProcess create_model() called ==================================
2023-07-31 15:06:34,098:INFO:Initializing create_model()
2023-07-31 15:06:34,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:06:34,098:INFO:Checking exceptions
2023-07-31 15:06:34,098:INFO:Importing libraries
2023-07-31 15:06:34,098:INFO:Copying training dataset
2023-07-31 15:06:34,106:INFO:Defining folds
2023-07-31 15:06:34,107:INFO:Declaring metric variables
2023-07-31 15:06:34,112:INFO:Importing untrained model
2023-07-31 15:06:34,119:INFO:Logistic Regression Imported successfully
2023-07-31 15:06:34,133:INFO:Starting cross validation
2023-07-31 15:06:34,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:06:40,642:INFO:Calculating mean and std
2023-07-31 15:06:40,644:INFO:Creating metrics dataframe
2023-07-31 15:06:41,224:INFO:Uploading results into container
2023-07-31 15:06:41,225:INFO:Uploading model into container now
2023-07-31 15:06:41,226:INFO:_master_model_container: 1
2023-07-31 15:06:41,226:INFO:_display_container: 2
2023-07-31 15:06:41,227:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 15:06:41,227:INFO:create_model() successfully completed......................................
2023-07-31 15:06:41,353:INFO:SubProcess create_model() end ==================================
2023-07-31 15:06:41,354:INFO:Creating metrics dataframe
2023-07-31 15:06:41,378:INFO:Initializing K Neighbors Classifier
2023-07-31 15:06:41,378:INFO:Total runtime is 0.12146666049957275 minutes
2023-07-31 15:06:41,388:INFO:SubProcess create_model() called ==================================
2023-07-31 15:06:41,389:INFO:Initializing create_model()
2023-07-31 15:06:41,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:06:41,390:INFO:Checking exceptions
2023-07-31 15:06:41,390:INFO:Importing libraries
2023-07-31 15:06:41,391:INFO:Copying training dataset
2023-07-31 15:06:41,406:INFO:Defining folds
2023-07-31 15:06:41,406:INFO:Declaring metric variables
2023-07-31 15:06:41,416:INFO:Importing untrained model
2023-07-31 15:06:41,427:INFO:K Neighbors Classifier Imported successfully
2023-07-31 15:06:41,442:INFO:Starting cross validation
2023-07-31 15:06:41,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:06:46,994:INFO:Calculating mean and std
2023-07-31 15:06:46,996:INFO:Creating metrics dataframe
2023-07-31 15:06:47,630:INFO:Uploading results into container
2023-07-31 15:06:47,632:INFO:Uploading model into container now
2023-07-31 15:06:47,633:INFO:_master_model_container: 2
2023-07-31 15:06:47,633:INFO:_display_container: 2
2023-07-31 15:06:47,633:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 15:06:47,634:INFO:create_model() successfully completed......................................
2023-07-31 15:06:47,742:INFO:SubProcess create_model() end ==================================
2023-07-31 15:06:47,742:INFO:Creating metrics dataframe
2023-07-31 15:06:47,763:INFO:Initializing Naive Bayes
2023-07-31 15:06:47,763:INFO:Total runtime is 0.22788354555765789 minutes
2023-07-31 15:06:47,769:INFO:SubProcess create_model() called ==================================
2023-07-31 15:06:47,770:INFO:Initializing create_model()
2023-07-31 15:06:47,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:06:47,770:INFO:Checking exceptions
2023-07-31 15:06:47,771:INFO:Importing libraries
2023-07-31 15:06:47,771:INFO:Copying training dataset
2023-07-31 15:06:47,784:INFO:Defining folds
2023-07-31 15:06:47,784:INFO:Declaring metric variables
2023-07-31 15:06:47,790:INFO:Importing untrained model
2023-07-31 15:06:47,799:INFO:Naive Bayes Imported successfully
2023-07-31 15:06:47,814:INFO:Starting cross validation
2023-07-31 15:06:47,817:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:06:53,283:INFO:Calculating mean and std
2023-07-31 15:06:53,284:INFO:Creating metrics dataframe
2023-07-31 15:06:53,896:INFO:Uploading results into container
2023-07-31 15:06:53,897:INFO:Uploading model into container now
2023-07-31 15:06:53,898:INFO:_master_model_container: 3
2023-07-31 15:06:53,898:INFO:_display_container: 2
2023-07-31 15:06:53,898:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 15:06:53,899:INFO:create_model() successfully completed......................................
2023-07-31 15:06:53,990:INFO:SubProcess create_model() end ==================================
2023-07-31 15:06:53,991:INFO:Creating metrics dataframe
2023-07-31 15:06:54,005:INFO:Initializing Decision Tree Classifier
2023-07-31 15:06:54,005:INFO:Total runtime is 0.33191719055175783 minutes
2023-07-31 15:06:54,011:INFO:SubProcess create_model() called ==================================
2023-07-31 15:06:54,011:INFO:Initializing create_model()
2023-07-31 15:06:54,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:06:54,012:INFO:Checking exceptions
2023-07-31 15:06:54,012:INFO:Importing libraries
2023-07-31 15:06:54,013:INFO:Copying training dataset
2023-07-31 15:06:54,022:INFO:Defining folds
2023-07-31 15:06:54,022:INFO:Declaring metric variables
2023-07-31 15:06:54,029:INFO:Importing untrained model
2023-07-31 15:06:54,037:INFO:Decision Tree Classifier Imported successfully
2023-07-31 15:06:54,050:INFO:Starting cross validation
2023-07-31 15:06:54,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:06:59,842:INFO:Calculating mean and std
2023-07-31 15:06:59,843:INFO:Creating metrics dataframe
2023-07-31 15:07:00,519:INFO:Uploading results into container
2023-07-31 15:07:00,520:INFO:Uploading model into container now
2023-07-31 15:07:00,521:INFO:_master_model_container: 4
2023-07-31 15:07:00,521:INFO:_display_container: 2
2023-07-31 15:07:00,522:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-07-31 15:07:00,522:INFO:create_model() successfully completed......................................
2023-07-31 15:07:00,603:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:00,603:INFO:Creating metrics dataframe
2023-07-31 15:07:00,616:INFO:Initializing SVM - Linear Kernel
2023-07-31 15:07:00,616:INFO:Total runtime is 0.44209998051325483 minutes
2023-07-31 15:07:00,622:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:00,622:INFO:Initializing create_model()
2023-07-31 15:07:00,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:00,623:INFO:Checking exceptions
2023-07-31 15:07:00,623:INFO:Importing libraries
2023-07-31 15:07:00,624:INFO:Copying training dataset
2023-07-31 15:07:00,632:INFO:Defining folds
2023-07-31 15:07:00,632:INFO:Declaring metric variables
2023-07-31 15:07:00,638:INFO:Importing untrained model
2023-07-31 15:07:00,646:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 15:07:00,660:INFO:Starting cross validation
2023-07-31 15:07:00,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:01,521:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,533:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,534:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,540:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,542:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,580:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,584:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:01,664:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:03,258:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:03,293:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 15:07:06,014:INFO:Calculating mean and std
2023-07-31 15:07:06,016:INFO:Creating metrics dataframe
2023-07-31 15:07:06,634:INFO:Uploading results into container
2023-07-31 15:07:06,635:INFO:Uploading model into container now
2023-07-31 15:07:06,636:INFO:_master_model_container: 5
2023-07-31 15:07:06,636:INFO:_display_container: 2
2023-07-31 15:07:06,637:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 15:07:06,637:INFO:create_model() successfully completed......................................
2023-07-31 15:07:06,717:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:06,717:INFO:Creating metrics dataframe
2023-07-31 15:07:06,734:INFO:Initializing Ridge Classifier
2023-07-31 15:07:06,734:INFO:Total runtime is 0.5440590500831605 minutes
2023-07-31 15:07:06,740:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:06,740:INFO:Initializing create_model()
2023-07-31 15:07:06,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:06,740:INFO:Checking exceptions
2023-07-31 15:07:06,740:INFO:Importing libraries
2023-07-31 15:07:06,740:INFO:Copying training dataset
2023-07-31 15:07:06,749:INFO:Defining folds
2023-07-31 15:07:06,749:INFO:Declaring metric variables
2023-07-31 15:07:06,754:INFO:Importing untrained model
2023-07-31 15:07:06,761:INFO:Ridge Classifier Imported successfully
2023-07-31 15:07:06,774:INFO:Starting cross validation
2023-07-31 15:07:06,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:07,560:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,566:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,598:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,618:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,628:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,679:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,696:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:07,749:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:09,325:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:09,402:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 15:07:12,100:INFO:Calculating mean and std
2023-07-31 15:07:12,101:INFO:Creating metrics dataframe
2023-07-31 15:07:12,719:INFO:Uploading results into container
2023-07-31 15:07:12,720:INFO:Uploading model into container now
2023-07-31 15:07:12,721:INFO:_master_model_container: 6
2023-07-31 15:07:12,721:INFO:_display_container: 2
2023-07-31 15:07:12,721:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-07-31 15:07:12,722:INFO:create_model() successfully completed......................................
2023-07-31 15:07:12,801:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:12,801:INFO:Creating metrics dataframe
2023-07-31 15:07:12,819:INFO:Initializing Random Forest Classifier
2023-07-31 15:07:12,819:INFO:Total runtime is 0.6454757571220399 minutes
2023-07-31 15:07:12,824:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:12,825:INFO:Initializing create_model()
2023-07-31 15:07:12,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:12,826:INFO:Checking exceptions
2023-07-31 15:07:12,826:INFO:Importing libraries
2023-07-31 15:07:12,826:INFO:Copying training dataset
2023-07-31 15:07:12,836:INFO:Defining folds
2023-07-31 15:07:12,836:INFO:Declaring metric variables
2023-07-31 15:07:12,844:INFO:Importing untrained model
2023-07-31 15:07:12,851:INFO:Random Forest Classifier Imported successfully
2023-07-31 15:07:12,866:INFO:Starting cross validation
2023-07-31 15:07:12,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:15,335:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:15,337:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:15,368:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:15,499:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:22,065:INFO:Calculating mean and std
2023-07-31 15:07:22,067:INFO:Creating metrics dataframe
2023-07-31 15:07:22,751:INFO:Uploading results into container
2023-07-31 15:07:22,752:INFO:Uploading model into container now
2023-07-31 15:07:22,752:INFO:_master_model_container: 7
2023-07-31 15:07:22,752:INFO:_display_container: 2
2023-07-31 15:07:22,753:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-07-31 15:07:22,753:INFO:create_model() successfully completed......................................
2023-07-31 15:07:22,837:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:22,837:INFO:Creating metrics dataframe
2023-07-31 15:07:22,852:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 15:07:22,852:INFO:Total runtime is 0.812692399819692 minutes
2023-07-31 15:07:22,859:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:22,859:INFO:Initializing create_model()
2023-07-31 15:07:22,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:22,859:INFO:Checking exceptions
2023-07-31 15:07:22,860:INFO:Importing libraries
2023-07-31 15:07:22,860:INFO:Copying training dataset
2023-07-31 15:07:22,868:INFO:Defining folds
2023-07-31 15:07:22,868:INFO:Declaring metric variables
2023-07-31 15:07:22,875:INFO:Importing untrained model
2023-07-31 15:07:22,881:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 15:07:22,894:INFO:Starting cross validation
2023-07-31 15:07:22,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:23,364:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,368:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,393:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,404:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,405:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,418:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,426:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:23,466:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:25,723:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:25,757:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 15:07:29,085:INFO:Calculating mean and std
2023-07-31 15:07:29,087:INFO:Creating metrics dataframe
2023-07-31 15:07:29,748:INFO:Uploading results into container
2023-07-31 15:07:29,749:INFO:Uploading model into container now
2023-07-31 15:07:29,749:INFO:_master_model_container: 8
2023-07-31 15:07:29,749:INFO:_display_container: 2
2023-07-31 15:07:29,750:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 15:07:29,750:INFO:create_model() successfully completed......................................
2023-07-31 15:07:29,832:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:29,832:INFO:Creating metrics dataframe
2023-07-31 15:07:29,847:INFO:Initializing Ada Boost Classifier
2023-07-31 15:07:29,847:INFO:Total runtime is 0.9292793432871501 minutes
2023-07-31 15:07:29,854:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:29,854:INFO:Initializing create_model()
2023-07-31 15:07:29,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:29,855:INFO:Checking exceptions
2023-07-31 15:07:29,855:INFO:Importing libraries
2023-07-31 15:07:29,855:INFO:Copying training dataset
2023-07-31 15:07:29,864:INFO:Defining folds
2023-07-31 15:07:29,864:INFO:Declaring metric variables
2023-07-31 15:07:29,870:INFO:Importing untrained model
2023-07-31 15:07:29,876:INFO:Ada Boost Classifier Imported successfully
2023-07-31 15:07:29,895:INFO:Starting cross validation
2023-07-31 15:07:29,898:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:37,398:INFO:Calculating mean and std
2023-07-31 15:07:37,399:INFO:Creating metrics dataframe
2023-07-31 15:07:38,092:INFO:Uploading results into container
2023-07-31 15:07:38,093:INFO:Uploading model into container now
2023-07-31 15:07:38,094:INFO:_master_model_container: 9
2023-07-31 15:07:38,094:INFO:_display_container: 2
2023-07-31 15:07:38,094:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-07-31 15:07:38,094:INFO:create_model() successfully completed......................................
2023-07-31 15:07:38,185:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:38,186:INFO:Creating metrics dataframe
2023-07-31 15:07:38,204:INFO:Initializing Gradient Boosting Classifier
2023-07-31 15:07:38,204:INFO:Total runtime is 1.0685624718666078 minutes
2023-07-31 15:07:38,212:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:38,213:INFO:Initializing create_model()
2023-07-31 15:07:38,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:38,213:INFO:Checking exceptions
2023-07-31 15:07:38,213:INFO:Importing libraries
2023-07-31 15:07:38,213:INFO:Copying training dataset
2023-07-31 15:07:38,222:INFO:Defining folds
2023-07-31 15:07:38,222:INFO:Declaring metric variables
2023-07-31 15:07:38,229:INFO:Importing untrained model
2023-07-31 15:07:38,235:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 15:07:38,249:INFO:Starting cross validation
2023-07-31 15:07:38,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:41,074:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:41,075:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:41,076:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:41,078:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:41,108:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:47,746:INFO:Calculating mean and std
2023-07-31 15:07:47,748:INFO:Creating metrics dataframe
2023-07-31 15:07:48,446:INFO:Uploading results into container
2023-07-31 15:07:48,447:INFO:Uploading model into container now
2023-07-31 15:07:48,448:INFO:_master_model_container: 10
2023-07-31 15:07:48,448:INFO:_display_container: 2
2023-07-31 15:07:48,449:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:07:48,449:INFO:create_model() successfully completed......................................
2023-07-31 15:07:48,537:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:48,538:INFO:Creating metrics dataframe
2023-07-31 15:07:48,554:INFO:Initializing Linear Discriminant Analysis
2023-07-31 15:07:48,554:INFO:Total runtime is 1.2410583972930909 minutes
2023-07-31 15:07:48,559:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:48,559:INFO:Initializing create_model()
2023-07-31 15:07:48,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:48,559:INFO:Checking exceptions
2023-07-31 15:07:48,560:INFO:Importing libraries
2023-07-31 15:07:48,560:INFO:Copying training dataset
2023-07-31 15:07:48,567:INFO:Defining folds
2023-07-31 15:07:48,568:INFO:Declaring metric variables
2023-07-31 15:07:48,573:INFO:Importing untrained model
2023-07-31 15:07:48,578:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 15:07:48,591:INFO:Starting cross validation
2023-07-31 15:07:48,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:55,585:INFO:Calculating mean and std
2023-07-31 15:07:55,586:INFO:Creating metrics dataframe
2023-07-31 15:07:56,303:INFO:Uploading results into container
2023-07-31 15:07:56,304:INFO:Uploading model into container now
2023-07-31 15:07:56,304:INFO:_master_model_container: 11
2023-07-31 15:07:56,305:INFO:_display_container: 2
2023-07-31 15:07:56,305:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 15:07:56,305:INFO:create_model() successfully completed......................................
2023-07-31 15:07:56,389:INFO:SubProcess create_model() end ==================================
2023-07-31 15:07:56,390:INFO:Creating metrics dataframe
2023-07-31 15:07:56,407:INFO:Initializing Extra Trees Classifier
2023-07-31 15:07:56,408:INFO:Total runtime is 1.371966870625814 minutes
2023-07-31 15:07:56,414:INFO:SubProcess create_model() called ==================================
2023-07-31 15:07:56,414:INFO:Initializing create_model()
2023-07-31 15:07:56,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:07:56,414:INFO:Checking exceptions
2023-07-31 15:07:56,415:INFO:Importing libraries
2023-07-31 15:07:56,415:INFO:Copying training dataset
2023-07-31 15:07:56,425:INFO:Defining folds
2023-07-31 15:07:56,426:INFO:Declaring metric variables
2023-07-31 15:07:56,435:INFO:Importing untrained model
2023-07-31 15:07:56,444:INFO:Extra Trees Classifier Imported successfully
2023-07-31 15:07:56,463:INFO:Starting cross validation
2023-07-31 15:07:56,466:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:07:59,124:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:07:59,169:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 15:08:07,137:INFO:Calculating mean and std
2023-07-31 15:08:07,138:INFO:Creating metrics dataframe
2023-07-31 15:08:07,962:INFO:Uploading results into container
2023-07-31 15:08:07,963:INFO:Uploading model into container now
2023-07-31 15:08:07,964:INFO:_master_model_container: 12
2023-07-31 15:08:07,964:INFO:_display_container: 2
2023-07-31 15:08:07,965:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-07-31 15:08:07,965:INFO:create_model() successfully completed......................................
2023-07-31 15:08:08,057:INFO:SubProcess create_model() end ==================================
2023-07-31 15:08:08,057:INFO:Creating metrics dataframe
2023-07-31 15:08:08,076:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 15:08:08,076:INFO:Total runtime is 1.5664257486661277 minutes
2023-07-31 15:08:08,082:INFO:SubProcess create_model() called ==================================
2023-07-31 15:08:08,083:INFO:Initializing create_model()
2023-07-31 15:08:08,083:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:08:08,083:INFO:Checking exceptions
2023-07-31 15:08:08,083:INFO:Importing libraries
2023-07-31 15:08:08,083:INFO:Copying training dataset
2023-07-31 15:08:08,094:INFO:Defining folds
2023-07-31 15:08:08,094:INFO:Declaring metric variables
2023-07-31 15:08:08,102:INFO:Importing untrained model
2023-07-31 15:08:08,110:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 15:08:08,135:INFO:Starting cross validation
2023-07-31 15:08:08,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:08:15,747:INFO:Calculating mean and std
2023-07-31 15:08:15,749:INFO:Creating metrics dataframe
2023-07-31 15:08:16,553:INFO:Uploading results into container
2023-07-31 15:08:16,555:INFO:Uploading model into container now
2023-07-31 15:08:16,556:INFO:_master_model_container: 13
2023-07-31 15:08:16,556:INFO:_display_container: 2
2023-07-31 15:08:16,558:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 15:08:16,558:INFO:create_model() successfully completed......................................
2023-07-31 15:08:16,657:INFO:SubProcess create_model() end ==================================
2023-07-31 15:08:16,657:INFO:Creating metrics dataframe
2023-07-31 15:08:16,678:INFO:Initializing Dummy Classifier
2023-07-31 15:08:16,679:INFO:Total runtime is 1.709809156258901 minutes
2023-07-31 15:08:16,684:INFO:SubProcess create_model() called ==================================
2023-07-31 15:08:16,685:INFO:Initializing create_model()
2023-07-31 15:08:16,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EEF0593580>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:08:16,685:INFO:Checking exceptions
2023-07-31 15:08:16,686:INFO:Importing libraries
2023-07-31 15:08:16,686:INFO:Copying training dataset
2023-07-31 15:08:16,699:INFO:Defining folds
2023-07-31 15:08:16,699:INFO:Declaring metric variables
2023-07-31 15:08:16,709:INFO:Importing untrained model
2023-07-31 15:08:16,718:INFO:Dummy Classifier Imported successfully
2023-07-31 15:08:16,733:INFO:Starting cross validation
2023-07-31 15:08:16,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 15:08:17,706:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:17,782:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:17,851:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:17,903:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:17,922:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:17,969:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:18,062:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:18,206:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:20,038:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:20,136:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 15:08:23,380:INFO:Calculating mean and std
2023-07-31 15:08:23,381:INFO:Creating metrics dataframe
2023-07-31 15:08:24,185:INFO:Uploading results into container
2023-07-31 15:08:24,186:INFO:Uploading model into container now
2023-07-31 15:08:24,187:INFO:_master_model_container: 14
2023-07-31 15:08:24,187:INFO:_display_container: 2
2023-07-31 15:08:24,187:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-07-31 15:08:24,187:INFO:create_model() successfully completed......................................
2023-07-31 15:08:24,271:INFO:SubProcess create_model() end ==================================
2023-07-31 15:08:24,272:INFO:Creating metrics dataframe
2023-07-31 15:08:24,305:INFO:Initializing create_model()
2023-07-31 15:08:24,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EEFA8802B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 15:08:24,306:INFO:Checking exceptions
2023-07-31 15:08:24,310:INFO:Importing libraries
2023-07-31 15:08:24,310:INFO:Copying training dataset
2023-07-31 15:08:24,319:INFO:Defining folds
2023-07-31 15:08:24,320:INFO:Declaring metric variables
2023-07-31 15:08:24,320:INFO:Importing untrained model
2023-07-31 15:08:24,320:INFO:Declaring custom model
2023-07-31 15:08:24,321:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 15:08:24,323:INFO:Cross validation set to False
2023-07-31 15:08:24,323:INFO:Fitting Model
2023-07-31 15:08:26,021:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:08:26,022:INFO:create_model() successfully completed......................................
2023-07-31 15:08:26,160:INFO:_master_model_container: 14
2023-07-31 15:08:26,160:INFO:_display_container: 2
2023-07-31 15:08:26,161:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 15:08:26,161:INFO:compare_models() successfully completed......................................
2023-07-31 22:50:09,093:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 22:50:09,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 22:50:09,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 22:50:09,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-07-31 22:50:11,637:INFO:PyCaret ClassificationExperiment
2023-07-31 22:50:11,637:INFO:Logging name: clf-default-name
2023-07-31 22:50:11,637:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-07-31 22:50:11,637:INFO:version 3.0.4
2023-07-31 22:50:11,637:INFO:Initializing setup()
2023-07-31 22:50:11,637:INFO:self.USI: 3ff7
2023-07-31 22:50:11,637:INFO:self._variable_keys: {'idx', 'exp_id', 'y_train', 'X', 'USI', 'seed', 'gpu_param', 'data', '_available_plots', 'exp_name_log', '_ml_usecase', 'logging_param', 'target_param', 'fold_shuffle_param', 'y', 'fix_imbalance', 'X_test', 'is_multiclass', 'pipeline', 'n_jobs_param', 'X_train', 'log_plots_param', 'memory', 'html_param', 'fold_groups_param', 'gpu_n_jobs_param', 'fold_generator', 'y_test'}
2023-07-31 22:50:11,637:INFO:Checking environment
2023-07-31 22:50:11,638:INFO:python_version: 3.9.13
2023-07-31 22:50:11,638:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-07-31 22:50:11,638:INFO:machine: AMD64
2023-07-31 22:50:11,638:INFO:platform: Windows-10-10.0.19045-SP0
2023-07-31 22:50:11,649:INFO:Memory: svmem(total=17055166464, available=8621162496, percent=49.5, used=8434003968, free=8621162496)
2023-07-31 22:50:11,650:INFO:Physical Core: 4
2023-07-31 22:50:11,650:INFO:Logical Core: 8
2023-07-31 22:50:11,650:INFO:Checking libraries
2023-07-31 22:50:11,650:INFO:System:
2023-07-31 22:50:11,650:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-07-31 22:50:11,650:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-07-31 22:50:11,650:INFO:   machine: Windows-10-10.0.19045-SP0
2023-07-31 22:50:11,650:INFO:PyCaret required dependencies:
2023-07-31 22:50:11,654:INFO:                 pip: 22.0.4
2023-07-31 22:50:11,654:INFO:          setuptools: 58.1.0
2023-07-31 22:50:11,654:INFO:             pycaret: 3.0.4
2023-07-31 22:50:11,654:INFO:             IPython: 8.13.1
2023-07-31 22:50:11,654:INFO:          ipywidgets: 8.0.7
2023-07-31 22:50:11,654:INFO:                tqdm: 4.65.0
2023-07-31 22:50:11,654:INFO:               numpy: 1.23.0
2023-07-31 22:50:11,654:INFO:              pandas: 1.5.3
2023-07-31 22:50:11,654:INFO:              jinja2: 3.1.2
2023-07-31 22:50:11,654:INFO:               scipy: 1.10.1
2023-07-31 22:50:11,655:INFO:              joblib: 1.2.0
2023-07-31 22:50:11,655:INFO:             sklearn: 1.2.2
2023-07-31 22:50:11,655:INFO:                pyod: 1.1.0
2023-07-31 22:50:11,655:INFO:            imblearn: 0.11.0
2023-07-31 22:50:11,655:INFO:   category_encoders: 2.6.1
2023-07-31 22:50:11,655:INFO:            lightgbm: 3.3.5
2023-07-31 22:50:11,655:INFO:               numba: 0.57.1
2023-07-31 22:50:11,655:INFO:            requests: 2.31.0
2023-07-31 22:50:11,655:INFO:          matplotlib: 3.7.1
2023-07-31 22:50:11,655:INFO:          scikitplot: 0.3.7
2023-07-31 22:50:11,655:INFO:         yellowbrick: 1.5
2023-07-31 22:50:11,655:INFO:              plotly: 5.15.0
2023-07-31 22:50:11,655:INFO:    plotly-resampler: Not installed
2023-07-31 22:50:11,655:INFO:             kaleido: 0.2.1
2023-07-31 22:50:11,655:INFO:           schemdraw: 0.15
2023-07-31 22:50:11,655:INFO:         statsmodels: 0.14.0
2023-07-31 22:50:11,655:INFO:              sktime: 0.20.0
2023-07-31 22:50:11,655:INFO:               tbats: 1.1.3
2023-07-31 22:50:11,655:INFO:            pmdarima: 2.0.3
2023-07-31 22:50:11,655:INFO:              psutil: 5.9.5
2023-07-31 22:50:11,655:INFO:          markupsafe: 2.1.3
2023-07-31 22:50:11,656:INFO:             pickle5: Not installed
2023-07-31 22:50:11,656:INFO:         cloudpickle: 2.2.1
2023-07-31 22:50:11,656:INFO:         deprecation: 2.1.0
2023-07-31 22:50:11,656:INFO:              xxhash: 3.2.0
2023-07-31 22:50:11,656:INFO:           wurlitzer: Not installed
2023-07-31 22:50:11,656:INFO:PyCaret optional dependencies:
2023-07-31 22:50:11,672:INFO:                shap: Not installed
2023-07-31 22:50:11,672:INFO:           interpret: Not installed
2023-07-31 22:50:11,672:INFO:                umap: Not installed
2023-07-31 22:50:11,672:INFO:    pandas_profiling: 4.3.1
2023-07-31 22:50:11,672:INFO:  explainerdashboard: Not installed
2023-07-31 22:50:11,672:INFO:             autoviz: Not installed
2023-07-31 22:50:11,672:INFO:           fairlearn: Not installed
2023-07-31 22:50:11,672:INFO:          deepchecks: Not installed
2023-07-31 22:50:11,672:INFO:             xgboost: Not installed
2023-07-31 22:50:11,672:INFO:            catboost: Not installed
2023-07-31 22:50:11,672:INFO:              kmodes: Not installed
2023-07-31 22:50:11,673:INFO:             mlxtend: 0.22.0
2023-07-31 22:50:11,673:INFO:       statsforecast: Not installed
2023-07-31 22:50:11,673:INFO:        tune_sklearn: Not installed
2023-07-31 22:50:11,673:INFO:                 ray: Not installed
2023-07-31 22:50:11,673:INFO:            hyperopt: Not installed
2023-07-31 22:50:11,673:INFO:              optuna: Not installed
2023-07-31 22:50:11,673:INFO:               skopt: Not installed
2023-07-31 22:50:11,673:INFO:              mlflow: Not installed
2023-07-31 22:50:11,673:INFO:              gradio: Not installed
2023-07-31 22:50:11,673:INFO:             fastapi: Not installed
2023-07-31 22:50:11,673:INFO:             uvicorn: Not installed
2023-07-31 22:50:11,673:INFO:              m2cgen: Not installed
2023-07-31 22:50:11,673:INFO:           evidently: Not installed
2023-07-31 22:50:11,673:INFO:               fugue: Not installed
2023-07-31 22:50:11,673:INFO:           streamlit: Not installed
2023-07-31 22:50:11,673:INFO:             prophet: Not installed
2023-07-31 22:50:11,673:INFO:None
2023-07-31 22:50:11,673:INFO:Set up data.
2023-07-31 22:50:11,724:INFO:Set up train/test split.
2023-07-31 22:50:11,758:INFO:Set up index.
2023-07-31 22:50:11,758:INFO:Set up folding strategy.
2023-07-31 22:50:11,758:INFO:Assigning column types.
2023-07-31 22:50:11,762:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-07-31 22:50:11,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 22:50:11,827:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 22:50:11,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,121:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-07-31 22:50:12,122:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 22:50:12,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,155:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-07-31 22:50:12,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 22:50:12,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,309:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-07-31 22:50:12,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,343:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-07-31 22:50:12,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:12,519:INFO:Preparing preprocessing pipeline...
2023-07-31 22:50:12,530:INFO:Set up simple imputation.
2023-07-31 22:50:12,535:INFO:Set up encoding of categorical features.
2023-07-31 22:50:12,536:INFO:Set up removing multicollinearity.
2023-07-31 22:50:12,536:INFO:Set up feature normalization.
2023-07-31 22:50:12,755:INFO:Finished creating preprocessing pipeline.
2023-07-31 22:50:12,763:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-07-31 22:50:12,763:INFO:Creating final display dataframe.
2023-07-31 22:50:13,153:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8161, 10)
4        Transformed data shape        (8161, 31)
5   Transformed train set shape        (6528, 31)
6    Transformed test set shape        (1633, 31)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                -1
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              3ff7
2023-07-31 22:50:13,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:13,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:13,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:13,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-07-31 22:50:13,354:INFO:setup() successfully completed in 2.36s...............
2023-07-31 22:50:23,745:INFO:Initializing compare_models()
2023-07-31 22:50:23,745:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-07-31 22:50:23,746:INFO:Checking exceptions
2023-07-31 22:50:23,754:INFO:Preparing display monitor
2023-07-31 22:50:23,790:INFO:Initializing Logistic Regression
2023-07-31 22:50:23,790:INFO:Total runtime is 0.0 minutes
2023-07-31 22:50:23,795:INFO:SubProcess create_model() called ==================================
2023-07-31 22:50:23,795:INFO:Initializing create_model()
2023-07-31 22:50:23,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:50:23,796:INFO:Checking exceptions
2023-07-31 22:50:23,796:INFO:Importing libraries
2023-07-31 22:50:23,796:INFO:Copying training dataset
2023-07-31 22:50:23,803:INFO:Defining folds
2023-07-31 22:50:23,804:INFO:Declaring metric variables
2023-07-31 22:50:23,807:INFO:Importing untrained model
2023-07-31 22:50:23,813:INFO:Logistic Regression Imported successfully
2023-07-31 22:50:23,824:INFO:Starting cross validation
2023-07-31 22:50:23,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:50:37,233:INFO:Calculating mean and std
2023-07-31 22:50:37,235:INFO:Creating metrics dataframe
2023-07-31 22:50:37,864:INFO:Uploading results into container
2023-07-31 22:50:37,865:INFO:Uploading model into container now
2023-07-31 22:50:37,865:INFO:_master_model_container: 1
2023-07-31 22:50:37,865:INFO:_display_container: 2
2023-07-31 22:50:37,866:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-07-31 22:50:37,866:INFO:create_model() successfully completed......................................
2023-07-31 22:50:38,015:INFO:SubProcess create_model() end ==================================
2023-07-31 22:50:38,016:INFO:Creating metrics dataframe
2023-07-31 22:50:38,031:INFO:Initializing K Neighbors Classifier
2023-07-31 22:50:38,031:INFO:Total runtime is 0.23735004266103107 minutes
2023-07-31 22:50:38,038:INFO:SubProcess create_model() called ==================================
2023-07-31 22:50:38,039:INFO:Initializing create_model()
2023-07-31 22:50:38,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:50:38,039:INFO:Checking exceptions
2023-07-31 22:50:38,039:INFO:Importing libraries
2023-07-31 22:50:38,039:INFO:Copying training dataset
2023-07-31 22:50:38,049:INFO:Defining folds
2023-07-31 22:50:38,050:INFO:Declaring metric variables
2023-07-31 22:50:38,056:INFO:Importing untrained model
2023-07-31 22:50:38,062:INFO:K Neighbors Classifier Imported successfully
2023-07-31 22:50:38,075:INFO:Starting cross validation
2023-07-31 22:50:38,078:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:50:44,299:INFO:Calculating mean and std
2023-07-31 22:50:44,300:INFO:Creating metrics dataframe
2023-07-31 22:50:44,993:INFO:Uploading results into container
2023-07-31 22:50:44,993:INFO:Uploading model into container now
2023-07-31 22:50:44,994:INFO:_master_model_container: 2
2023-07-31 22:50:44,994:INFO:_display_container: 2
2023-07-31 22:50:44,994:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-07-31 22:50:44,994:INFO:create_model() successfully completed......................................
2023-07-31 22:50:45,084:INFO:SubProcess create_model() end ==================================
2023-07-31 22:50:45,085:INFO:Creating metrics dataframe
2023-07-31 22:50:45,098:INFO:Initializing Naive Bayes
2023-07-31 22:50:45,098:INFO:Total runtime is 0.35513318777084346 minutes
2023-07-31 22:50:45,103:INFO:SubProcess create_model() called ==================================
2023-07-31 22:50:45,103:INFO:Initializing create_model()
2023-07-31 22:50:45,103:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:50:45,104:INFO:Checking exceptions
2023-07-31 22:50:45,104:INFO:Importing libraries
2023-07-31 22:50:45,104:INFO:Copying training dataset
2023-07-31 22:50:45,112:INFO:Defining folds
2023-07-31 22:50:45,112:INFO:Declaring metric variables
2023-07-31 22:50:45,118:INFO:Importing untrained model
2023-07-31 22:50:45,124:INFO:Naive Bayes Imported successfully
2023-07-31 22:50:45,137:INFO:Starting cross validation
2023-07-31 22:50:45,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:50:51,181:INFO:Calculating mean and std
2023-07-31 22:50:51,182:INFO:Creating metrics dataframe
2023-07-31 22:50:51,856:INFO:Uploading results into container
2023-07-31 22:50:51,856:INFO:Uploading model into container now
2023-07-31 22:50:51,857:INFO:_master_model_container: 3
2023-07-31 22:50:51,857:INFO:_display_container: 2
2023-07-31 22:50:51,857:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-07-31 22:50:51,857:INFO:create_model() successfully completed......................................
2023-07-31 22:50:51,945:INFO:SubProcess create_model() end ==================================
2023-07-31 22:50:51,945:INFO:Creating metrics dataframe
2023-07-31 22:50:51,960:INFO:Initializing Decision Tree Classifier
2023-07-31 22:50:51,960:INFO:Total runtime is 0.46949998935063675 minutes
2023-07-31 22:50:51,965:INFO:SubProcess create_model() called ==================================
2023-07-31 22:50:51,965:INFO:Initializing create_model()
2023-07-31 22:50:51,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:50:51,966:INFO:Checking exceptions
2023-07-31 22:50:51,966:INFO:Importing libraries
2023-07-31 22:50:51,966:INFO:Copying training dataset
2023-07-31 22:50:51,977:INFO:Defining folds
2023-07-31 22:50:51,978:INFO:Declaring metric variables
2023-07-31 22:50:51,983:INFO:Importing untrained model
2023-07-31 22:50:51,990:INFO:Decision Tree Classifier Imported successfully
2023-07-31 22:50:52,005:INFO:Starting cross validation
2023-07-31 22:50:52,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:50:58,385:INFO:Calculating mean and std
2023-07-31 22:50:58,387:INFO:Creating metrics dataframe
2023-07-31 22:50:59,084:INFO:Uploading results into container
2023-07-31 22:50:59,086:INFO:Uploading model into container now
2023-07-31 22:50:59,087:INFO:_master_model_container: 4
2023-07-31 22:50:59,087:INFO:_display_container: 2
2023-07-31 22:50:59,088:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-07-31 22:50:59,088:INFO:create_model() successfully completed......................................
2023-07-31 22:50:59,184:INFO:SubProcess create_model() end ==================================
2023-07-31 22:50:59,184:INFO:Creating metrics dataframe
2023-07-31 22:50:59,197:INFO:Initializing SVM - Linear Kernel
2023-07-31 22:50:59,197:INFO:Total runtime is 0.5901018818219502 minutes
2023-07-31 22:50:59,202:INFO:SubProcess create_model() called ==================================
2023-07-31 22:50:59,203:INFO:Initializing create_model()
2023-07-31 22:50:59,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:50:59,203:INFO:Checking exceptions
2023-07-31 22:50:59,203:INFO:Importing libraries
2023-07-31 22:50:59,203:INFO:Copying training dataset
2023-07-31 22:50:59,212:INFO:Defining folds
2023-07-31 22:50:59,212:INFO:Declaring metric variables
2023-07-31 22:50:59,217:INFO:Importing untrained model
2023-07-31 22:50:59,222:INFO:SVM - Linear Kernel Imported successfully
2023-07-31 22:50:59,233:INFO:Starting cross validation
2023-07-31 22:50:59,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:00,475:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,495:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,500:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,500:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,504:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,514:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,538:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:00,548:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:02,325:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:02,349:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-07-31 22:51:05,696:INFO:Calculating mean and std
2023-07-31 22:51:05,698:INFO:Creating metrics dataframe
2023-07-31 22:51:06,418:INFO:Uploading results into container
2023-07-31 22:51:06,418:INFO:Uploading model into container now
2023-07-31 22:51:06,419:INFO:_master_model_container: 5
2023-07-31 22:51:06,419:INFO:_display_container: 2
2023-07-31 22:51:06,420:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-07-31 22:51:06,420:INFO:create_model() successfully completed......................................
2023-07-31 22:51:06,518:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:06,518:INFO:Creating metrics dataframe
2023-07-31 22:51:06,533:INFO:Initializing Ridge Classifier
2023-07-31 22:51:06,534:INFO:Total runtime is 0.7123852729797363 minutes
2023-07-31 22:51:06,539:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:06,540:INFO:Initializing create_model()
2023-07-31 22:51:06,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:06,541:INFO:Checking exceptions
2023-07-31 22:51:06,541:INFO:Importing libraries
2023-07-31 22:51:06,541:INFO:Copying training dataset
2023-07-31 22:51:06,549:INFO:Defining folds
2023-07-31 22:51:06,550:INFO:Declaring metric variables
2023-07-31 22:51:06,557:INFO:Importing untrained model
2023-07-31 22:51:06,563:INFO:Ridge Classifier Imported successfully
2023-07-31 22:51:06,575:INFO:Starting cross validation
2023-07-31 22:51:06,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:07,659:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,677:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,764:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,768:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,843:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,882:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,908:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:07,948:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:09,659:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:09,659:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-07-31 22:51:13,205:INFO:Calculating mean and std
2023-07-31 22:51:13,207:INFO:Creating metrics dataframe
2023-07-31 22:51:13,953:INFO:Uploading results into container
2023-07-31 22:51:13,954:INFO:Uploading model into container now
2023-07-31 22:51:13,955:INFO:_master_model_container: 6
2023-07-31 22:51:13,955:INFO:_display_container: 2
2023-07-31 22:51:13,955:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-07-31 22:51:13,956:INFO:create_model() successfully completed......................................
2023-07-31 22:51:14,049:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:14,049:INFO:Creating metrics dataframe
2023-07-31 22:51:14,066:INFO:Initializing Random Forest Classifier
2023-07-31 22:51:14,066:INFO:Total runtime is 0.8379250208536784 minutes
2023-07-31 22:51:14,072:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:14,072:INFO:Initializing create_model()
2023-07-31 22:51:14,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:14,073:INFO:Checking exceptions
2023-07-31 22:51:14,073:INFO:Importing libraries
2023-07-31 22:51:14,074:INFO:Copying training dataset
2023-07-31 22:51:14,084:INFO:Defining folds
2023-07-31 22:51:14,084:INFO:Declaring metric variables
2023-07-31 22:51:14,091:INFO:Importing untrained model
2023-07-31 22:51:14,096:INFO:Random Forest Classifier Imported successfully
2023-07-31 22:51:14,114:INFO:Starting cross validation
2023-07-31 22:51:14,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:16,833:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 22:51:16,834:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 22:51:16,886:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 22:51:24,883:INFO:Calculating mean and std
2023-07-31 22:51:24,885:INFO:Creating metrics dataframe
2023-07-31 22:51:25,680:INFO:Uploading results into container
2023-07-31 22:51:25,681:INFO:Uploading model into container now
2023-07-31 22:51:25,681:INFO:_master_model_container: 7
2023-07-31 22:51:25,682:INFO:_display_container: 2
2023-07-31 22:51:25,682:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-07-31 22:51:25,682:INFO:create_model() successfully completed......................................
2023-07-31 22:51:25,781:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:25,781:INFO:Creating metrics dataframe
2023-07-31 22:51:25,797:INFO:Initializing Quadratic Discriminant Analysis
2023-07-31 22:51:25,797:INFO:Total runtime is 1.0334426403045653 minutes
2023-07-31 22:51:25,802:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:25,802:INFO:Initializing create_model()
2023-07-31 22:51:25,802:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:25,802:INFO:Checking exceptions
2023-07-31 22:51:25,802:INFO:Importing libraries
2023-07-31 22:51:25,803:INFO:Copying training dataset
2023-07-31 22:51:25,812:INFO:Defining folds
2023-07-31 22:51:25,812:INFO:Declaring metric variables
2023-07-31 22:51:25,816:INFO:Importing untrained model
2023-07-31 22:51:25,823:INFO:Quadratic Discriminant Analysis Imported successfully
2023-07-31 22:51:25,835:INFO:Starting cross validation
2023-07-31 22:51:25,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:26,404:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,404:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,405:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,478:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,480:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,525:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,533:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:26,544:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:28,948:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:28,957:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-07-31 22:51:33,012:INFO:Calculating mean and std
2023-07-31 22:51:33,013:INFO:Creating metrics dataframe
2023-07-31 22:51:33,849:INFO:Uploading results into container
2023-07-31 22:51:33,850:INFO:Uploading model into container now
2023-07-31 22:51:33,850:INFO:_master_model_container: 8
2023-07-31 22:51:33,850:INFO:_display_container: 2
2023-07-31 22:51:33,850:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-07-31 22:51:33,851:INFO:create_model() successfully completed......................................
2023-07-31 22:51:33,941:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:33,941:INFO:Creating metrics dataframe
2023-07-31 22:51:33,958:INFO:Initializing Ada Boost Classifier
2023-07-31 22:51:33,958:INFO:Total runtime is 1.169456934928894 minutes
2023-07-31 22:51:33,962:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:33,963:INFO:Initializing create_model()
2023-07-31 22:51:33,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:33,963:INFO:Checking exceptions
2023-07-31 22:51:33,963:INFO:Importing libraries
2023-07-31 22:51:33,964:INFO:Copying training dataset
2023-07-31 22:51:33,973:INFO:Defining folds
2023-07-31 22:51:33,973:INFO:Declaring metric variables
2023-07-31 22:51:33,978:INFO:Importing untrained model
2023-07-31 22:51:33,983:INFO:Ada Boost Classifier Imported successfully
2023-07-31 22:51:33,997:INFO:Starting cross validation
2023-07-31 22:51:33,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:42,987:INFO:Calculating mean and std
2023-07-31 22:51:42,989:INFO:Creating metrics dataframe
2023-07-31 22:51:43,862:INFO:Uploading results into container
2023-07-31 22:51:43,863:INFO:Uploading model into container now
2023-07-31 22:51:43,864:INFO:_master_model_container: 9
2023-07-31 22:51:43,864:INFO:_display_container: 2
2023-07-31 22:51:43,864:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-07-31 22:51:43,864:INFO:create_model() successfully completed......................................
2023-07-31 22:51:43,969:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:43,969:INFO:Creating metrics dataframe
2023-07-31 22:51:43,986:INFO:Initializing Gradient Boosting Classifier
2023-07-31 22:51:43,986:INFO:Total runtime is 1.336591056982676 minutes
2023-07-31 22:51:43,993:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:43,994:INFO:Initializing create_model()
2023-07-31 22:51:43,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:43,994:INFO:Checking exceptions
2023-07-31 22:51:43,995:INFO:Importing libraries
2023-07-31 22:51:43,995:INFO:Copying training dataset
2023-07-31 22:51:44,003:INFO:Defining folds
2023-07-31 22:51:44,003:INFO:Declaring metric variables
2023-07-31 22:51:44,011:INFO:Importing untrained model
2023-07-31 22:51:44,016:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 22:51:44,032:INFO:Starting cross validation
2023-07-31 22:51:44,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:51:54,279:INFO:Calculating mean and std
2023-07-31 22:51:54,281:INFO:Creating metrics dataframe
2023-07-31 22:51:55,153:INFO:Uploading results into container
2023-07-31 22:51:55,154:INFO:Uploading model into container now
2023-07-31 22:51:55,155:INFO:_master_model_container: 10
2023-07-31 22:51:55,156:INFO:_display_container: 2
2023-07-31 22:51:55,157:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 22:51:55,157:INFO:create_model() successfully completed......................................
2023-07-31 22:51:55,251:INFO:SubProcess create_model() end ==================================
2023-07-31 22:51:55,251:INFO:Creating metrics dataframe
2023-07-31 22:51:55,266:INFO:Initializing Linear Discriminant Analysis
2023-07-31 22:51:55,266:INFO:Total runtime is 1.524590754508972 minutes
2023-07-31 22:51:55,272:INFO:SubProcess create_model() called ==================================
2023-07-31 22:51:55,273:INFO:Initializing create_model()
2023-07-31 22:51:55,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:51:55,273:INFO:Checking exceptions
2023-07-31 22:51:55,273:INFO:Importing libraries
2023-07-31 22:51:55,273:INFO:Copying training dataset
2023-07-31 22:51:55,284:INFO:Defining folds
2023-07-31 22:51:55,284:INFO:Declaring metric variables
2023-07-31 22:51:55,290:INFO:Importing untrained model
2023-07-31 22:51:55,297:INFO:Linear Discriminant Analysis Imported successfully
2023-07-31 22:51:55,314:INFO:Starting cross validation
2023-07-31 22:51:55,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:52:02,978:INFO:Calculating mean and std
2023-07-31 22:52:02,979:INFO:Creating metrics dataframe
2023-07-31 22:52:03,875:INFO:Uploading results into container
2023-07-31 22:52:03,876:INFO:Uploading model into container now
2023-07-31 22:52:03,877:INFO:_master_model_container: 11
2023-07-31 22:52:03,877:INFO:_display_container: 2
2023-07-31 22:52:03,878:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-07-31 22:52:03,878:INFO:create_model() successfully completed......................................
2023-07-31 22:52:03,970:INFO:SubProcess create_model() end ==================================
2023-07-31 22:52:03,970:INFO:Creating metrics dataframe
2023-07-31 22:52:03,992:INFO:Initializing Extra Trees Classifier
2023-07-31 22:52:03,992:INFO:Total runtime is 1.6700235962867735 minutes
2023-07-31 22:52:03,998:INFO:SubProcess create_model() called ==================================
2023-07-31 22:52:03,999:INFO:Initializing create_model()
2023-07-31 22:52:03,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:52:03,999:INFO:Checking exceptions
2023-07-31 22:52:03,999:INFO:Importing libraries
2023-07-31 22:52:03,999:INFO:Copying training dataset
2023-07-31 22:52:04,010:INFO:Defining folds
2023-07-31 22:52:04,011:INFO:Declaring metric variables
2023-07-31 22:52:04,019:INFO:Importing untrained model
2023-07-31 22:52:04,028:INFO:Extra Trees Classifier Imported successfully
2023-07-31 22:52:04,046:INFO:Starting cross validation
2023-07-31 22:52:04,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:52:06,922:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-07-31 22:52:16,283:INFO:Calculating mean and std
2023-07-31 22:52:16,284:INFO:Creating metrics dataframe
2023-07-31 22:52:17,238:INFO:Uploading results into container
2023-07-31 22:52:17,240:INFO:Uploading model into container now
2023-07-31 22:52:17,242:INFO:_master_model_container: 12
2023-07-31 22:52:17,242:INFO:_display_container: 2
2023-07-31 22:52:17,243:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-07-31 22:52:17,243:INFO:create_model() successfully completed......................................
2023-07-31 22:52:17,353:INFO:SubProcess create_model() end ==================================
2023-07-31 22:52:17,353:INFO:Creating metrics dataframe
2023-07-31 22:52:17,368:INFO:Initializing Light Gradient Boosting Machine
2023-07-31 22:52:17,368:INFO:Total runtime is 1.8929569482803343 minutes
2023-07-31 22:52:17,373:INFO:SubProcess create_model() called ==================================
2023-07-31 22:52:17,374:INFO:Initializing create_model()
2023-07-31 22:52:17,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:52:17,375:INFO:Checking exceptions
2023-07-31 22:52:17,375:INFO:Importing libraries
2023-07-31 22:52:17,375:INFO:Copying training dataset
2023-07-31 22:52:17,384:INFO:Defining folds
2023-07-31 22:52:17,384:INFO:Declaring metric variables
2023-07-31 22:52:17,392:INFO:Importing untrained model
2023-07-31 22:52:17,399:INFO:Light Gradient Boosting Machine Imported successfully
2023-07-31 22:52:17,416:INFO:Starting cross validation
2023-07-31 22:52:17,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:52:26,345:INFO:Calculating mean and std
2023-07-31 22:52:26,347:INFO:Creating metrics dataframe
2023-07-31 22:52:27,320:INFO:Uploading results into container
2023-07-31 22:52:27,321:INFO:Uploading model into container now
2023-07-31 22:52:27,322:INFO:_master_model_container: 13
2023-07-31 22:52:27,323:INFO:_display_container: 2
2023-07-31 22:52:27,323:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-07-31 22:52:27,324:INFO:create_model() successfully completed......................................
2023-07-31 22:52:27,424:INFO:SubProcess create_model() end ==================================
2023-07-31 22:52:27,424:INFO:Creating metrics dataframe
2023-07-31 22:52:27,440:INFO:Initializing Dummy Classifier
2023-07-31 22:52:27,440:INFO:Total runtime is 2.0608330527941385 minutes
2023-07-31 22:52:27,445:INFO:SubProcess create_model() called ==================================
2023-07-31 22:52:27,446:INFO:Initializing create_model()
2023-07-31 22:52:27,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C08EA7DDC0>, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:52:27,446:INFO:Checking exceptions
2023-07-31 22:52:27,446:INFO:Importing libraries
2023-07-31 22:52:27,446:INFO:Copying training dataset
2023-07-31 22:52:27,454:INFO:Defining folds
2023-07-31 22:52:27,455:INFO:Declaring metric variables
2023-07-31 22:52:27,464:INFO:Importing untrained model
2023-07-31 22:52:27,469:INFO:Dummy Classifier Imported successfully
2023-07-31 22:52:27,482:INFO:Starting cross validation
2023-07-31 22:52:27,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-07-31 22:52:28,402:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,462:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,466:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,506:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,506:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,554:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,587:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:28,599:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:30,972:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:31,151:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-07-31 22:52:35,572:INFO:Calculating mean and std
2023-07-31 22:52:35,574:INFO:Creating metrics dataframe
2023-07-31 22:52:36,536:INFO:Uploading results into container
2023-07-31 22:52:36,538:INFO:Uploading model into container now
2023-07-31 22:52:36,538:INFO:_master_model_container: 14
2023-07-31 22:52:36,538:INFO:_display_container: 2
2023-07-31 22:52:36,539:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-07-31 22:52:36,539:INFO:create_model() successfully completed......................................
2023-07-31 22:52:36,632:INFO:SubProcess create_model() end ==================================
2023-07-31 22:52:36,632:INFO:Creating metrics dataframe
2023-07-31 22:52:36,672:INFO:Initializing create_model()
2023-07-31 22:52:36,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C086013250>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-07-31 22:52:36,672:INFO:Checking exceptions
2023-07-31 22:52:36,676:INFO:Importing libraries
2023-07-31 22:52:36,676:INFO:Copying training dataset
2023-07-31 22:52:36,685:INFO:Defining folds
2023-07-31 22:52:36,685:INFO:Declaring metric variables
2023-07-31 22:52:36,686:INFO:Importing untrained model
2023-07-31 22:52:36,686:INFO:Declaring custom model
2023-07-31 22:52:36,688:INFO:Gradient Boosting Classifier Imported successfully
2023-07-31 22:52:36,692:INFO:Cross validation set to False
2023-07-31 22:52:36,692:INFO:Fitting Model
2023-07-31 22:52:38,493:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 22:52:38,493:INFO:create_model() successfully completed......................................
2023-07-31 22:52:38,630:INFO:_master_model_container: 14
2023-07-31 22:52:38,631:INFO:_display_container: 2
2023-07-31 22:52:38,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-07-31 22:52:38,631:INFO:compare_models() successfully completed......................................
2023-08-01 06:51:39,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 06:51:39,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 06:51:39,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 06:51:39,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 06:51:41,160:INFO:PyCaret ClassificationExperiment
2023-08-01 06:51:41,160:INFO:Logging name: clf-default-name
2023-08-01 06:51:41,160:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 06:51:41,160:INFO:version 3.0.4
2023-08-01 06:51:41,160:INFO:Initializing setup()
2023-08-01 06:51:41,160:INFO:self.USI: 8872
2023-08-01 06:51:41,160:INFO:self._variable_keys: {'y', 'y_train', 'X_test', 'html_param', 'fold_groups_param', 'target_param', '_available_plots', 'data', 'fold_generator', 'fix_imbalance', 'USI', 'logging_param', 'seed', 'n_jobs_param', 'y_test', 'log_plots_param', 'exp_id', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'gpu_param', 'idx', 'X_train', 'fold_shuffle_param', 'X', 'memory'}
2023-08-01 06:51:41,160:INFO:Checking environment
2023-08-01 06:51:41,160:INFO:python_version: 3.9.13
2023-08-01 06:51:41,160:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 06:51:41,160:INFO:machine: AMD64
2023-08-01 06:51:41,160:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-01 06:51:41,162:INFO:Memory: svmem(total=33737928704, available=23884439552, percent=29.2, used=9853489152, free=23884439552)
2023-08-01 06:51:41,162:INFO:Physical Core: 8
2023-08-01 06:51:41,162:INFO:Logical Core: 16
2023-08-01 06:51:41,162:INFO:Checking libraries
2023-08-01 06:51:41,162:INFO:System:
2023-08-01 06:51:41,162:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 06:51:41,162:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 06:51:41,162:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-01 06:51:41,162:INFO:PyCaret required dependencies:
2023-08-01 06:51:41,227:INFO:                 pip: 22.0.4
2023-08-01 06:51:41,227:INFO:          setuptools: 58.1.0
2023-08-01 06:51:41,227:INFO:             pycaret: 3.0.4
2023-08-01 06:51:41,227:INFO:             IPython: 8.13.1
2023-08-01 06:51:41,227:INFO:          ipywidgets: 8.0.7
2023-08-01 06:51:41,227:INFO:                tqdm: 4.65.0
2023-08-01 06:51:41,227:INFO:               numpy: 1.23.0
2023-08-01 06:51:41,227:INFO:              pandas: 1.5.3
2023-08-01 06:51:41,227:INFO:              jinja2: 3.1.2
2023-08-01 06:51:41,227:INFO:               scipy: 1.10.1
2023-08-01 06:51:41,227:INFO:              joblib: 1.3.1
2023-08-01 06:51:41,227:INFO:             sklearn: 1.2.2
2023-08-01 06:51:41,227:INFO:                pyod: 1.1.0
2023-08-01 06:51:41,227:INFO:            imblearn: 0.11.0
2023-08-01 06:51:41,227:INFO:   category_encoders: 2.6.1
2023-08-01 06:51:41,227:INFO:            lightgbm: 4.0.0
2023-08-01 06:51:41,227:INFO:               numba: 0.57.1
2023-08-01 06:51:41,227:INFO:            requests: 2.31.0
2023-08-01 06:51:41,227:INFO:          matplotlib: 3.7.1
2023-08-01 06:51:41,227:INFO:          scikitplot: 0.3.7
2023-08-01 06:51:41,227:INFO:         yellowbrick: 1.5
2023-08-01 06:51:41,227:INFO:              plotly: 5.15.0
2023-08-01 06:51:41,227:INFO:    plotly-resampler: Not installed
2023-08-01 06:51:41,227:INFO:             kaleido: 0.2.1
2023-08-01 06:51:41,227:INFO:           schemdraw: 0.15
2023-08-01 06:51:41,227:INFO:         statsmodels: 0.14.0
2023-08-01 06:51:41,227:INFO:              sktime: 0.20.1
2023-08-01 06:51:41,227:INFO:               tbats: 1.1.3
2023-08-01 06:51:41,227:INFO:            pmdarima: 2.0.3
2023-08-01 06:51:41,227:INFO:              psutil: 5.9.5
2023-08-01 06:51:41,227:INFO:          markupsafe: 2.1.3
2023-08-01 06:51:41,227:INFO:             pickle5: Not installed
2023-08-01 06:51:41,227:INFO:         cloudpickle: 2.2.1
2023-08-01 06:51:41,227:INFO:         deprecation: 2.1.0
2023-08-01 06:51:41,227:INFO:              xxhash: 3.2.0
2023-08-01 06:51:41,227:INFO:           wurlitzer: Not installed
2023-08-01 06:51:41,227:INFO:PyCaret optional dependencies:
2023-08-01 06:51:41,235:INFO:                shap: 0.42.1
2023-08-01 06:51:41,235:INFO:           interpret: Not installed
2023-08-01 06:51:41,235:INFO:                umap: 0.5.3
2023-08-01 06:51:41,235:INFO:    pandas_profiling: Not installed
2023-08-01 06:51:41,243:INFO:  explainerdashboard: 0.4.2.2
2023-08-01 06:51:41,243:INFO:             autoviz: 0.1.730
2023-08-01 06:51:41,243:INFO:           fairlearn: Not installed
2023-08-01 06:51:41,243:INFO:          deepchecks: Not installed
2023-08-01 06:51:41,243:INFO:             xgboost: 1.7.6
2023-08-01 06:51:41,243:INFO:            catboost: Not installed
2023-08-01 06:51:41,243:INFO:              kmodes: Not installed
2023-08-01 06:51:41,243:INFO:             mlxtend: Not installed
2023-08-01 06:51:41,243:INFO:       statsforecast: Not installed
2023-08-01 06:51:41,243:INFO:        tune_sklearn: Not installed
2023-08-01 06:51:41,243:INFO:                 ray: Not installed
2023-08-01 06:51:41,243:INFO:            hyperopt: Not installed
2023-08-01 06:51:41,243:INFO:              optuna: Not installed
2023-08-01 06:51:41,243:INFO:               skopt: Not installed
2023-08-01 06:51:41,243:INFO:              mlflow: Not installed
2023-08-01 06:51:41,243:INFO:              gradio: Not installed
2023-08-01 06:51:41,243:INFO:             fastapi: Not installed
2023-08-01 06:51:41,243:INFO:             uvicorn: Not installed
2023-08-01 06:51:41,243:INFO:              m2cgen: Not installed
2023-08-01 06:51:41,243:INFO:           evidently: Not installed
2023-08-01 06:51:41,243:INFO:               fugue: Not installed
2023-08-01 06:51:41,243:INFO:           streamlit: Not installed
2023-08-01 06:51:41,243:INFO:             prophet: Not installed
2023-08-01 06:51:41,243:INFO:None
2023-08-01 06:51:41,243:INFO:Set up data.
2023-08-01 06:51:41,252:INFO:Set up train/test split.
2023-08-01 06:51:41,252:INFO:Set up index.
2023-08-01 06:51:41,252:INFO:Set up folding strategy.
2023-08-01 06:51:41,252:INFO:Assigning column types.
2023-08-01 06:51:41,260:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 06:51:41,292:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,292:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,316:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,381:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,413:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,429:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,429:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 06:51:41,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,487:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:51:41,535:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,543:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 06:51:41,591:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,647:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:41,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:41,655:INFO:Preparing preprocessing pipeline...
2023-08-01 06:51:41,655:INFO:Set up simple imputation.
2023-08-01 06:51:41,655:INFO:Set up encoding of categorical features.
2023-08-01 06:51:41,655:INFO:Set up removing multicollinearity.
2023-08-01 06:51:41,655:INFO:Set up feature normalization.
2023-08-01 06:51:41,777:INFO:Finished creating preprocessing pipeline.
2023-08-01 06:51:41,777:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=No...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 06:51:41,777:INFO:Creating final display dataframe.
2023-08-01 06:51:41,978:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 11)
4        Transformed data shape        (8136, 31)
5   Transformed train set shape        (6508, 31)
6    Transformed test set shape        (1628, 31)
7              Numeric features                 6
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                -1
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              8872
2023-08-01 06:51:42,042:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:42,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:42,098:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:51:42,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:51:42,098:INFO:setup() successfully completed in 1.91s...............
2023-08-01 06:51:54,461:INFO:Initializing compare_models()
2023-08-01 06:51:54,461:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 06:51:54,461:INFO:Checking exceptions
2023-08-01 06:51:54,470:INFO:Preparing display monitor
2023-08-01 06:51:54,492:INFO:Initializing Logistic Regression
2023-08-01 06:51:54,492:INFO:Total runtime is 0.0 minutes
2023-08-01 06:51:54,493:INFO:SubProcess create_model() called ==================================
2023-08-01 06:51:54,493:INFO:Initializing create_model()
2023-08-01 06:51:54,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:51:54,493:INFO:Checking exceptions
2023-08-01 06:51:54,493:INFO:Importing libraries
2023-08-01 06:51:54,493:INFO:Copying training dataset
2023-08-01 06:51:54,493:INFO:Defining folds
2023-08-01 06:51:54,493:INFO:Declaring metric variables
2023-08-01 06:51:54,501:INFO:Importing untrained model
2023-08-01 06:51:54,501:INFO:Logistic Regression Imported successfully
2023-08-01 06:51:54,509:INFO:Starting cross validation
2023-08-01 06:51:54,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:05,667:INFO:Calculating mean and std
2023-08-01 06:52:05,667:INFO:Creating metrics dataframe
2023-08-01 06:52:06,309:INFO:Uploading results into container
2023-08-01 06:52:06,312:INFO:Uploading model into container now
2023-08-01 06:52:06,312:INFO:_master_model_container: 1
2023-08-01 06:52:06,312:INFO:_display_container: 2
2023-08-01 06:52:06,312:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 06:52:06,312:INFO:create_model() successfully completed......................................
2023-08-01 06:52:06,409:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:06,409:INFO:Creating metrics dataframe
2023-08-01 06:52:06,416:INFO:Initializing K Neighbors Classifier
2023-08-01 06:52:06,416:INFO:Total runtime is 0.19873397350311278 minutes
2023-08-01 06:52:06,416:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:06,416:INFO:Initializing create_model()
2023-08-01 06:52:06,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:06,416:INFO:Checking exceptions
2023-08-01 06:52:06,416:INFO:Importing libraries
2023-08-01 06:52:06,416:INFO:Copying training dataset
2023-08-01 06:52:06,424:INFO:Defining folds
2023-08-01 06:52:06,424:INFO:Declaring metric variables
2023-08-01 06:52:06,424:INFO:Importing untrained model
2023-08-01 06:52:06,432:INFO:K Neighbors Classifier Imported successfully
2023-08-01 06:52:06,432:INFO:Starting cross validation
2023-08-01 06:52:06,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:12,152:INFO:Calculating mean and std
2023-08-01 06:52:12,152:INFO:Creating metrics dataframe
2023-08-01 06:52:12,807:INFO:Uploading results into container
2023-08-01 06:52:12,807:INFO:Uploading model into container now
2023-08-01 06:52:12,807:INFO:_master_model_container: 2
2023-08-01 06:52:12,807:INFO:_display_container: 2
2023-08-01 06:52:12,807:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 06:52:12,807:INFO:create_model() successfully completed......................................
2023-08-01 06:52:12,911:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:12,911:INFO:Creating metrics dataframe
2023-08-01 06:52:12,911:INFO:Initializing Naive Bayes
2023-08-01 06:52:12,911:INFO:Total runtime is 0.3069827079772949 minutes
2023-08-01 06:52:12,919:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:12,919:INFO:Initializing create_model()
2023-08-01 06:52:12,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:12,919:INFO:Checking exceptions
2023-08-01 06:52:12,919:INFO:Importing libraries
2023-08-01 06:52:12,919:INFO:Copying training dataset
2023-08-01 06:52:12,921:INFO:Defining folds
2023-08-01 06:52:12,921:INFO:Declaring metric variables
2023-08-01 06:52:12,927:INFO:Importing untrained model
2023-08-01 06:52:12,927:INFO:Naive Bayes Imported successfully
2023-08-01 06:52:12,927:INFO:Starting cross validation
2023-08-01 06:52:12,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:17,955:INFO:Calculating mean and std
2023-08-01 06:52:17,955:INFO:Creating metrics dataframe
2023-08-01 06:52:18,596:INFO:Uploading results into container
2023-08-01 06:52:18,596:INFO:Uploading model into container now
2023-08-01 06:52:18,596:INFO:_master_model_container: 3
2023-08-01 06:52:18,596:INFO:_display_container: 2
2023-08-01 06:52:18,596:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 06:52:18,596:INFO:create_model() successfully completed......................................
2023-08-01 06:52:18,692:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:18,692:INFO:Creating metrics dataframe
2023-08-01 06:52:18,700:INFO:Initializing Decision Tree Classifier
2023-08-01 06:52:18,700:INFO:Total runtime is 0.40346998771031695 minutes
2023-08-01 06:52:18,700:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:18,708:INFO:Initializing create_model()
2023-08-01 06:52:18,708:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:18,708:INFO:Checking exceptions
2023-08-01 06:52:18,708:INFO:Importing libraries
2023-08-01 06:52:18,708:INFO:Copying training dataset
2023-08-01 06:52:18,708:INFO:Defining folds
2023-08-01 06:52:18,708:INFO:Declaring metric variables
2023-08-01 06:52:18,708:INFO:Importing untrained model
2023-08-01 06:52:18,716:INFO:Decision Tree Classifier Imported successfully
2023-08-01 06:52:18,716:INFO:Starting cross validation
2023-08-01 06:52:18,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:23,776:INFO:Calculating mean and std
2023-08-01 06:52:23,776:INFO:Creating metrics dataframe
2023-08-01 06:52:24,418:INFO:Uploading results into container
2023-08-01 06:52:24,418:INFO:Uploading model into container now
2023-08-01 06:52:24,418:INFO:_master_model_container: 4
2023-08-01 06:52:24,418:INFO:_display_container: 2
2023-08-01 06:52:24,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 06:52:24,418:INFO:create_model() successfully completed......................................
2023-08-01 06:52:24,515:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:24,515:INFO:Creating metrics dataframe
2023-08-01 06:52:24,523:INFO:Initializing SVM - Linear Kernel
2023-08-01 06:52:24,523:INFO:Total runtime is 0.500509758790334 minutes
2023-08-01 06:52:24,523:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:24,523:INFO:Initializing create_model()
2023-08-01 06:52:24,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:24,523:INFO:Checking exceptions
2023-08-01 06:52:24,523:INFO:Importing libraries
2023-08-01 06:52:24,523:INFO:Copying training dataset
2023-08-01 06:52:24,531:INFO:Defining folds
2023-08-01 06:52:24,531:INFO:Declaring metric variables
2023-08-01 06:52:24,531:INFO:Importing untrained model
2023-08-01 06:52:24,536:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 06:52:24,539:INFO:Starting cross validation
2023-08-01 06:52:24,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:24,837:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,837:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,837:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,845:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,845:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,854:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:24,862:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:52:29,621:INFO:Calculating mean and std
2023-08-01 06:52:29,621:INFO:Creating metrics dataframe
2023-08-01 06:52:30,257:INFO:Uploading results into container
2023-08-01 06:52:30,257:INFO:Uploading model into container now
2023-08-01 06:52:30,257:INFO:_master_model_container: 5
2023-08-01 06:52:30,257:INFO:_display_container: 2
2023-08-01 06:52:30,265:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 06:52:30,265:INFO:create_model() successfully completed......................................
2023-08-01 06:52:30,362:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:30,362:INFO:Creating metrics dataframe
2023-08-01 06:52:30,370:INFO:Initializing Ridge Classifier
2023-08-01 06:52:30,370:INFO:Total runtime is 0.5979583223660786 minutes
2023-08-01 06:52:30,370:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:30,370:INFO:Initializing create_model()
2023-08-01 06:52:30,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:30,370:INFO:Checking exceptions
2023-08-01 06:52:30,370:INFO:Importing libraries
2023-08-01 06:52:30,370:INFO:Copying training dataset
2023-08-01 06:52:30,370:INFO:Defining folds
2023-08-01 06:52:30,378:INFO:Declaring metric variables
2023-08-01 06:52:30,378:INFO:Importing untrained model
2023-08-01 06:52:30,378:INFO:Ridge Classifier Imported successfully
2023-08-01 06:52:30,386:INFO:Starting cross validation
2023-08-01 06:52:30,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:30,627:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,643:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,643:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,651:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,651:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,651:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,660:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,660:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,668:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:30,668:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:52:35,381:INFO:Calculating mean and std
2023-08-01 06:52:35,381:INFO:Creating metrics dataframe
2023-08-01 06:52:36,031:INFO:Uploading results into container
2023-08-01 06:52:36,031:INFO:Uploading model into container now
2023-08-01 06:52:36,031:INFO:_master_model_container: 6
2023-08-01 06:52:36,031:INFO:_display_container: 2
2023-08-01 06:52:36,031:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 06:52:36,031:INFO:create_model() successfully completed......................................
2023-08-01 06:52:36,127:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:36,127:INFO:Creating metrics dataframe
2023-08-01 06:52:36,135:INFO:Initializing Random Forest Classifier
2023-08-01 06:52:36,135:INFO:Total runtime is 0.6940492232640584 minutes
2023-08-01 06:52:36,143:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:36,143:INFO:Initializing create_model()
2023-08-01 06:52:36,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:36,143:INFO:Checking exceptions
2023-08-01 06:52:36,143:INFO:Importing libraries
2023-08-01 06:52:36,143:INFO:Copying training dataset
2023-08-01 06:52:36,143:INFO:Defining folds
2023-08-01 06:52:36,143:INFO:Declaring metric variables
2023-08-01 06:52:36,151:INFO:Importing untrained model
2023-08-01 06:52:36,151:INFO:Random Forest Classifier Imported successfully
2023-08-01 06:52:36,154:INFO:Starting cross validation
2023-08-01 06:52:36,159:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:41,984:INFO:Calculating mean and std
2023-08-01 06:52:41,984:INFO:Creating metrics dataframe
2023-08-01 06:52:42,631:INFO:Uploading results into container
2023-08-01 06:52:42,631:INFO:Uploading model into container now
2023-08-01 06:52:42,631:INFO:_master_model_container: 7
2023-08-01 06:52:42,631:INFO:_display_container: 2
2023-08-01 06:52:42,631:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:52:42,631:INFO:create_model() successfully completed......................................
2023-08-01 06:52:42,728:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:42,728:INFO:Creating metrics dataframe
2023-08-01 06:52:42,736:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 06:52:42,736:INFO:Total runtime is 0.8040572365125019 minutes
2023-08-01 06:52:42,744:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:42,744:INFO:Initializing create_model()
2023-08-01 06:52:42,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:42,744:INFO:Checking exceptions
2023-08-01 06:52:42,744:INFO:Importing libraries
2023-08-01 06:52:42,744:INFO:Copying training dataset
2023-08-01 06:52:42,744:INFO:Defining folds
2023-08-01 06:52:42,744:INFO:Declaring metric variables
2023-08-01 06:52:42,752:INFO:Importing untrained model
2023-08-01 06:52:42,752:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 06:52:42,760:INFO:Starting cross validation
2023-08-01 06:52:42,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,954:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,970:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,986:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,994:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:42,994:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:52:47,858:INFO:Calculating mean and std
2023-08-01 06:52:47,858:INFO:Creating metrics dataframe
2023-08-01 06:52:48,491:INFO:Uploading results into container
2023-08-01 06:52:48,491:INFO:Uploading model into container now
2023-08-01 06:52:48,491:INFO:_master_model_container: 8
2023-08-01 06:52:48,491:INFO:_display_container: 2
2023-08-01 06:52:48,499:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 06:52:48,499:INFO:create_model() successfully completed......................................
2023-08-01 06:52:48,596:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:48,596:INFO:Creating metrics dataframe
2023-08-01 06:52:48,596:INFO:Initializing Ada Boost Classifier
2023-08-01 06:52:48,596:INFO:Total runtime is 0.9017316261927286 minutes
2023-08-01 06:52:48,604:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:48,604:INFO:Initializing create_model()
2023-08-01 06:52:48,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:48,604:INFO:Checking exceptions
2023-08-01 06:52:48,604:INFO:Importing libraries
2023-08-01 06:52:48,604:INFO:Copying training dataset
2023-08-01 06:52:48,604:INFO:Defining folds
2023-08-01 06:52:48,604:INFO:Declaring metric variables
2023-08-01 06:52:48,612:INFO:Importing untrained model
2023-08-01 06:52:48,612:INFO:Ada Boost Classifier Imported successfully
2023-08-01 06:52:48,612:INFO:Starting cross validation
2023-08-01 06:52:48,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:52:54,089:INFO:Calculating mean and std
2023-08-01 06:52:54,090:INFO:Creating metrics dataframe
2023-08-01 06:52:54,749:INFO:Uploading results into container
2023-08-01 06:52:54,749:INFO:Uploading model into container now
2023-08-01 06:52:54,749:INFO:_master_model_container: 9
2023-08-01 06:52:54,749:INFO:_display_container: 2
2023-08-01 06:52:54,749:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 06:52:54,749:INFO:create_model() successfully completed......................................
2023-08-01 06:52:54,847:INFO:SubProcess create_model() end ==================================
2023-08-01 06:52:54,847:INFO:Creating metrics dataframe
2023-08-01 06:52:54,855:INFO:Initializing Gradient Boosting Classifier
2023-08-01 06:52:54,855:INFO:Total runtime is 1.0060431202252704 minutes
2023-08-01 06:52:54,855:INFO:SubProcess create_model() called ==================================
2023-08-01 06:52:54,863:INFO:Initializing create_model()
2023-08-01 06:52:54,863:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:52:54,863:INFO:Checking exceptions
2023-08-01 06:52:54,863:INFO:Importing libraries
2023-08-01 06:52:54,863:INFO:Copying training dataset
2023-08-01 06:52:54,863:INFO:Defining folds
2023-08-01 06:52:54,863:INFO:Declaring metric variables
2023-08-01 06:52:54,863:INFO:Importing untrained model
2023-08-01 06:52:54,871:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 06:52:54,874:INFO:Starting cross validation
2023-08-01 06:52:54,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:00,586:INFO:Calculating mean and std
2023-08-01 06:53:00,586:INFO:Creating metrics dataframe
2023-08-01 06:53:01,230:INFO:Uploading results into container
2023-08-01 06:53:01,230:INFO:Uploading model into container now
2023-08-01 06:53:01,230:INFO:_master_model_container: 10
2023-08-01 06:53:01,230:INFO:_display_container: 2
2023-08-01 06:53:01,230:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:53:01,230:INFO:create_model() successfully completed......................................
2023-08-01 06:53:01,335:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:01,335:INFO:Creating metrics dataframe
2023-08-01 06:53:01,342:INFO:Initializing Linear Discriminant Analysis
2023-08-01 06:53:01,342:INFO:Total runtime is 1.1141734798749285 minutes
2023-08-01 06:53:01,342:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:01,342:INFO:Initializing create_model()
2023-08-01 06:53:01,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:01,342:INFO:Checking exceptions
2023-08-01 06:53:01,342:INFO:Importing libraries
2023-08-01 06:53:01,342:INFO:Copying training dataset
2023-08-01 06:53:01,350:INFO:Defining folds
2023-08-01 06:53:01,350:INFO:Declaring metric variables
2023-08-01 06:53:01,350:INFO:Importing untrained model
2023-08-01 06:53:01,350:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 06:53:01,358:INFO:Starting cross validation
2023-08-01 06:53:01,358:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:06,505:INFO:Calculating mean and std
2023-08-01 06:53:06,505:INFO:Creating metrics dataframe
2023-08-01 06:53:07,164:INFO:Uploading results into container
2023-08-01 06:53:07,164:INFO:Uploading model into container now
2023-08-01 06:53:07,164:INFO:_master_model_container: 11
2023-08-01 06:53:07,164:INFO:_display_container: 2
2023-08-01 06:53:07,164:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 06:53:07,164:INFO:create_model() successfully completed......................................
2023-08-01 06:53:07,262:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:07,262:INFO:Creating metrics dataframe
2023-08-01 06:53:07,270:INFO:Initializing Extra Trees Classifier
2023-08-01 06:53:07,270:INFO:Total runtime is 1.2129655758539832 minutes
2023-08-01 06:53:07,270:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:07,270:INFO:Initializing create_model()
2023-08-01 06:53:07,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:07,270:INFO:Checking exceptions
2023-08-01 06:53:07,270:INFO:Importing libraries
2023-08-01 06:53:07,270:INFO:Copying training dataset
2023-08-01 06:53:07,278:INFO:Defining folds
2023-08-01 06:53:07,278:INFO:Declaring metric variables
2023-08-01 06:53:07,278:INFO:Importing untrained model
2023-08-01 06:53:07,278:INFO:Extra Trees Classifier Imported successfully
2023-08-01 06:53:07,286:INFO:Starting cross validation
2023-08-01 06:53:07,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:13,217:INFO:Calculating mean and std
2023-08-01 06:53:13,217:INFO:Creating metrics dataframe
2023-08-01 06:53:13,871:INFO:Uploading results into container
2023-08-01 06:53:13,871:INFO:Uploading model into container now
2023-08-01 06:53:13,871:INFO:_master_model_container: 12
2023-08-01 06:53:13,871:INFO:_display_container: 2
2023-08-01 06:53:13,880:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:53:13,880:INFO:create_model() successfully completed......................................
2023-08-01 06:53:13,976:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:13,976:INFO:Creating metrics dataframe
2023-08-01 06:53:13,984:INFO:Initializing Extreme Gradient Boosting
2023-08-01 06:53:13,984:INFO:Total runtime is 1.3248699585596717 minutes
2023-08-01 06:53:13,984:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:13,984:INFO:Initializing create_model()
2023-08-01 06:53:13,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:13,984:INFO:Checking exceptions
2023-08-01 06:53:13,984:INFO:Importing libraries
2023-08-01 06:53:13,984:INFO:Copying training dataset
2023-08-01 06:53:13,992:INFO:Defining folds
2023-08-01 06:53:13,992:INFO:Declaring metric variables
2023-08-01 06:53:13,992:INFO:Importing untrained model
2023-08-01 06:53:14,000:INFO:Extreme Gradient Boosting Imported successfully
2023-08-01 06:53:14,000:INFO:Starting cross validation
2023-08-01 06:53:14,007:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:21,424:INFO:Calculating mean and std
2023-08-01 06:53:21,424:INFO:Creating metrics dataframe
2023-08-01 06:53:22,104:INFO:Uploading results into container
2023-08-01 06:53:22,104:INFO:Uploading model into container now
2023-08-01 06:53:22,104:INFO:_master_model_container: 13
2023-08-01 06:53:22,104:INFO:_display_container: 2
2023-08-01 06:53:22,104:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-01 06:53:22,104:INFO:create_model() successfully completed......................................
2023-08-01 06:53:22,209:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:22,209:INFO:Creating metrics dataframe
2023-08-01 06:53:22,218:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 06:53:22,218:INFO:Total runtime is 1.462091517448425 minutes
2023-08-01 06:53:22,222:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:22,222:INFO:Initializing create_model()
2023-08-01 06:53:22,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:22,222:INFO:Checking exceptions
2023-08-01 06:53:22,222:INFO:Importing libraries
2023-08-01 06:53:22,222:INFO:Copying training dataset
2023-08-01 06:53:22,226:INFO:Defining folds
2023-08-01 06:53:22,226:INFO:Declaring metric variables
2023-08-01 06:53:22,226:INFO:Importing untrained model
2023-08-01 06:53:22,226:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 06:53:22,234:INFO:Starting cross validation
2023-08-01 06:53:22,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:29,687:INFO:Calculating mean and std
2023-08-01 06:53:29,687:INFO:Creating metrics dataframe
2023-08-01 06:53:30,358:INFO:Uploading results into container
2023-08-01 06:53:30,366:INFO:Uploading model into container now
2023-08-01 06:53:30,366:INFO:_master_model_container: 14
2023-08-01 06:53:30,366:INFO:_display_container: 2
2023-08-01 06:53:30,366:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 06:53:30,366:INFO:create_model() successfully completed......................................
2023-08-01 06:53:30,471:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:30,471:INFO:Creating metrics dataframe
2023-08-01 06:53:30,479:INFO:Initializing Dummy Classifier
2023-08-01 06:53:30,479:INFO:Total runtime is 1.5997817317644754 minutes
2023-08-01 06:53:30,479:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:30,479:INFO:Initializing create_model()
2023-08-01 06:53:30,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018488A18940>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:30,479:INFO:Checking exceptions
2023-08-01 06:53:30,479:INFO:Importing libraries
2023-08-01 06:53:30,479:INFO:Copying training dataset
2023-08-01 06:53:30,487:INFO:Defining folds
2023-08-01 06:53:30,487:INFO:Declaring metric variables
2023-08-01 06:53:30,487:INFO:Importing untrained model
2023-08-01 06:53:30,487:INFO:Dummy Classifier Imported successfully
2023-08-01 06:53:30,495:INFO:Starting cross validation
2023-08-01 06:53:30,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:53:30,861:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,869:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,869:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,877:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,877:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,877:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,885:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:30,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:53:36,161:INFO:Calculating mean and std
2023-08-01 06:53:36,161:INFO:Creating metrics dataframe
2023-08-01 06:53:36,824:INFO:Uploading results into container
2023-08-01 06:53:36,824:INFO:Uploading model into container now
2023-08-01 06:53:36,824:INFO:_master_model_container: 15
2023-08-01 06:53:36,824:INFO:_display_container: 2
2023-08-01 06:53:36,824:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 06:53:36,824:INFO:create_model() successfully completed......................................
2023-08-01 06:53:36,921:INFO:SubProcess create_model() end ==================================
2023-08-01 06:53:36,921:INFO:Creating metrics dataframe
2023-08-01 06:53:36,941:INFO:Initializing create_model()
2023-08-01 06:53:36,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506466D60>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:36,941:INFO:Checking exceptions
2023-08-01 06:53:36,941:INFO:Importing libraries
2023-08-01 06:53:36,941:INFO:Copying training dataset
2023-08-01 06:53:36,945:INFO:Defining folds
2023-08-01 06:53:36,945:INFO:Declaring metric variables
2023-08-01 06:53:36,945:INFO:Importing untrained model
2023-08-01 06:53:36,945:INFO:Declaring custom model
2023-08-01 06:53:36,945:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 06:53:36,945:INFO:Cross validation set to False
2023-08-01 06:53:36,945:INFO:Fitting Model
2023-08-01 06:53:37,915:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:53:37,915:INFO:create_model() successfully completed......................................
2023-08-01 06:53:38,044:INFO:_master_model_container: 15
2023-08-01 06:53:38,044:INFO:_display_container: 2
2023-08-01 06:53:38,044:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:53:38,044:INFO:compare_models() successfully completed......................................
2023-08-01 06:53:52,696:INFO:PyCaret ClassificationExperiment
2023-08-01 06:53:52,696:INFO:Logging name: clf-default-name
2023-08-01 06:53:52,696:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 06:53:52,696:INFO:version 3.0.4
2023-08-01 06:53:52,696:INFO:Initializing setup()
2023-08-01 06:53:52,696:INFO:self.USI: 2d79
2023-08-01 06:53:52,696:INFO:self._variable_keys: {'y', 'y_train', 'X_test', 'html_param', 'fold_groups_param', 'target_param', '_available_plots', 'data', 'fold_generator', 'fix_imbalance', 'USI', 'logging_param', 'seed', 'n_jobs_param', 'y_test', 'log_plots_param', 'exp_id', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'gpu_param', 'idx', 'X_train', 'fold_shuffle_param', 'X', 'memory'}
2023-08-01 06:53:52,696:INFO:Checking environment
2023-08-01 06:53:52,696:INFO:python_version: 3.9.13
2023-08-01 06:53:52,696:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 06:53:52,696:INFO:machine: AMD64
2023-08-01 06:53:52,696:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-01 06:53:52,704:INFO:Memory: svmem(total=33737928704, available=21642346496, percent=35.9, used=12095582208, free=21642346496)
2023-08-01 06:53:52,704:INFO:Physical Core: 8
2023-08-01 06:53:52,704:INFO:Logical Core: 16
2023-08-01 06:53:52,704:INFO:Checking libraries
2023-08-01 06:53:52,704:INFO:System:
2023-08-01 06:53:52,704:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 06:53:52,704:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 06:53:52,704:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-01 06:53:52,704:INFO:PyCaret required dependencies:
2023-08-01 06:53:52,704:INFO:                 pip: 22.0.4
2023-08-01 06:53:52,704:INFO:          setuptools: 58.1.0
2023-08-01 06:53:52,704:INFO:             pycaret: 3.0.4
2023-08-01 06:53:52,704:INFO:             IPython: 8.13.1
2023-08-01 06:53:52,704:INFO:          ipywidgets: 8.0.7
2023-08-01 06:53:52,704:INFO:                tqdm: 4.65.0
2023-08-01 06:53:52,704:INFO:               numpy: 1.23.0
2023-08-01 06:53:52,704:INFO:              pandas: 1.5.3
2023-08-01 06:53:52,704:INFO:              jinja2: 3.1.2
2023-08-01 06:53:52,704:INFO:               scipy: 1.10.1
2023-08-01 06:53:52,704:INFO:              joblib: 1.3.1
2023-08-01 06:53:52,704:INFO:             sklearn: 1.2.2
2023-08-01 06:53:52,704:INFO:                pyod: 1.1.0
2023-08-01 06:53:52,704:INFO:            imblearn: 0.11.0
2023-08-01 06:53:52,704:INFO:   category_encoders: 2.6.1
2023-08-01 06:53:52,704:INFO:            lightgbm: 4.0.0
2023-08-01 06:53:52,704:INFO:               numba: 0.57.1
2023-08-01 06:53:52,704:INFO:            requests: 2.31.0
2023-08-01 06:53:52,704:INFO:          matplotlib: 3.7.1
2023-08-01 06:53:52,704:INFO:          scikitplot: 0.3.7
2023-08-01 06:53:52,704:INFO:         yellowbrick: 1.5
2023-08-01 06:53:52,704:INFO:              plotly: 5.15.0
2023-08-01 06:53:52,704:INFO:    plotly-resampler: Not installed
2023-08-01 06:53:52,704:INFO:             kaleido: 0.2.1
2023-08-01 06:53:52,704:INFO:           schemdraw: 0.15
2023-08-01 06:53:52,704:INFO:         statsmodels: 0.14.0
2023-08-01 06:53:52,704:INFO:              sktime: 0.20.1
2023-08-01 06:53:52,704:INFO:               tbats: 1.1.3
2023-08-01 06:53:52,704:INFO:            pmdarima: 2.0.3
2023-08-01 06:53:52,704:INFO:              psutil: 5.9.5
2023-08-01 06:53:52,704:INFO:          markupsafe: 2.1.3
2023-08-01 06:53:52,704:INFO:             pickle5: Not installed
2023-08-01 06:53:52,704:INFO:         cloudpickle: 2.2.1
2023-08-01 06:53:52,704:INFO:         deprecation: 2.1.0
2023-08-01 06:53:52,704:INFO:              xxhash: 3.2.0
2023-08-01 06:53:52,704:INFO:           wurlitzer: Not installed
2023-08-01 06:53:52,704:INFO:PyCaret optional dependencies:
2023-08-01 06:53:52,704:INFO:                shap: 0.42.1
2023-08-01 06:53:52,704:INFO:           interpret: Not installed
2023-08-01 06:53:52,704:INFO:                umap: 0.5.3
2023-08-01 06:53:52,704:INFO:    pandas_profiling: Not installed
2023-08-01 06:53:52,704:INFO:  explainerdashboard: 0.4.2.2
2023-08-01 06:53:52,704:INFO:             autoviz: 0.1.730
2023-08-01 06:53:52,704:INFO:           fairlearn: Not installed
2023-08-01 06:53:52,704:INFO:          deepchecks: Not installed
2023-08-01 06:53:52,704:INFO:             xgboost: 1.7.6
2023-08-01 06:53:52,704:INFO:            catboost: Not installed
2023-08-01 06:53:52,704:INFO:              kmodes: Not installed
2023-08-01 06:53:52,704:INFO:             mlxtend: Not installed
2023-08-01 06:53:52,704:INFO:       statsforecast: Not installed
2023-08-01 06:53:52,704:INFO:        tune_sklearn: Not installed
2023-08-01 06:53:52,704:INFO:                 ray: Not installed
2023-08-01 06:53:52,704:INFO:            hyperopt: Not installed
2023-08-01 06:53:52,704:INFO:              optuna: Not installed
2023-08-01 06:53:52,704:INFO:               skopt: Not installed
2023-08-01 06:53:52,704:INFO:              mlflow: Not installed
2023-08-01 06:53:52,704:INFO:              gradio: Not installed
2023-08-01 06:53:52,704:INFO:             fastapi: Not installed
2023-08-01 06:53:52,704:INFO:             uvicorn: Not installed
2023-08-01 06:53:52,704:INFO:              m2cgen: Not installed
2023-08-01 06:53:52,704:INFO:           evidently: Not installed
2023-08-01 06:53:52,704:INFO:               fugue: Not installed
2023-08-01 06:53:52,704:INFO:           streamlit: Not installed
2023-08-01 06:53:52,704:INFO:             prophet: Not installed
2023-08-01 06:53:52,704:INFO:None
2023-08-01 06:53:52,704:INFO:Set up data.
2023-08-01 06:53:52,713:INFO:Set up train/test split.
2023-08-01 06:53:52,721:INFO:Set up index.
2023-08-01 06:53:52,721:INFO:Set up folding strategy.
2023-08-01 06:53:52,721:INFO:Assigning column types.
2023-08-01 06:53:52,721:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 06:53:52,753:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,753:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,777:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:52,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:52,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,809:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,833:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:52,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:52,833:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 06:53:52,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,889:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:52,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:52,921:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:53:52,945:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:52,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:52,945:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 06:53:53,001:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:53,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:53,058:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:53,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:53,058:INFO:Preparing preprocessing pipeline...
2023-08-01 06:53:53,058:INFO:Set up simple imputation.
2023-08-01 06:53:53,066:INFO:Set up encoding of categorical features.
2023-08-01 06:53:53,066:INFO:Set up removing multicollinearity.
2023-08-01 06:53:53,066:INFO:Set up feature normalization.
2023-08-01 06:53:53,180:INFO:Finished creating preprocessing pipeline.
2023-08-01 06:53:53,269:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=No...
-1                      0                     0                     0   
-2                      0                     0                     0   

     reserved_room_type_3  
 1                      1  
 2                      0  
 3                      1  
 4                      0  
 5                      1  
 6                      0  
 7                      1  
 8                      0  
 9                      1  
 10                     0  
-1                      0  
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 06:53:53,269:INFO:Creating final display dataframe.
2023-08-01 06:53:53,462:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 11)  
4                                          (8136, 19)  
5                                          (6508, 19)  
6                                          (1628, 19)  
7                                                   6  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             zscore  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               2d79  
2023-08-01 06:53:53,527:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:53,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:53,585:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:53:53,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:53:53,585:INFO:setup() successfully completed in 1.58s...............
2023-08-01 06:53:55,509:INFO:Initializing compare_models()
2023-08-01 06:53:55,509:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 06:53:55,509:INFO:Checking exceptions
2023-08-01 06:53:55,518:INFO:Preparing display monitor
2023-08-01 06:53:55,533:INFO:Initializing Logistic Regression
2023-08-01 06:53:55,533:INFO:Total runtime is 0.0 minutes
2023-08-01 06:53:55,533:INFO:SubProcess create_model() called ==================================
2023-08-01 06:53:55,533:INFO:Initializing create_model()
2023-08-01 06:53:55,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:53:55,533:INFO:Checking exceptions
2023-08-01 06:53:55,541:INFO:Importing libraries
2023-08-01 06:53:55,541:INFO:Copying training dataset
2023-08-01 06:53:55,541:INFO:Defining folds
2023-08-01 06:53:55,541:INFO:Declaring metric variables
2023-08-01 06:53:55,549:INFO:Importing untrained model
2023-08-01 06:53:55,549:INFO:Logistic Regression Imported successfully
2023-08-01 06:53:55,557:INFO:Starting cross validation
2023-08-01 06:53:55,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:01,154:INFO:Calculating mean and std
2023-08-01 06:54:01,154:INFO:Creating metrics dataframe
2023-08-01 06:54:01,836:INFO:Uploading results into container
2023-08-01 06:54:01,836:INFO:Uploading model into container now
2023-08-01 06:54:01,836:INFO:_master_model_container: 1
2023-08-01 06:54:01,836:INFO:_display_container: 2
2023-08-01 06:54:01,836:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 06:54:01,836:INFO:create_model() successfully completed......................................
2023-08-01 06:54:01,944:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:01,944:INFO:Creating metrics dataframe
2023-08-01 06:54:01,944:INFO:Initializing K Neighbors Classifier
2023-08-01 06:54:01,944:INFO:Total runtime is 0.10685821771621704 minutes
2023-08-01 06:54:01,952:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:01,952:INFO:Initializing create_model()
2023-08-01 06:54:01,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:01,952:INFO:Checking exceptions
2023-08-01 06:54:01,952:INFO:Importing libraries
2023-08-01 06:54:01,952:INFO:Copying training dataset
2023-08-01 06:54:01,952:INFO:Defining folds
2023-08-01 06:54:01,952:INFO:Declaring metric variables
2023-08-01 06:54:01,960:INFO:Importing untrained model
2023-08-01 06:54:01,960:INFO:K Neighbors Classifier Imported successfully
2023-08-01 06:54:01,960:INFO:Starting cross validation
2023-08-01 06:54:01,968:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:03,443:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:54:07,809:INFO:Calculating mean and std
2023-08-01 06:54:07,809:INFO:Creating metrics dataframe
2023-08-01 06:54:08,482:INFO:Uploading results into container
2023-08-01 06:54:08,482:INFO:Uploading model into container now
2023-08-01 06:54:08,482:INFO:_master_model_container: 2
2023-08-01 06:54:08,482:INFO:_display_container: 2
2023-08-01 06:54:08,482:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 06:54:08,482:INFO:create_model() successfully completed......................................
2023-08-01 06:54:08,594:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:08,594:INFO:Creating metrics dataframe
2023-08-01 06:54:08,602:INFO:Initializing Naive Bayes
2023-08-01 06:54:08,602:INFO:Total runtime is 0.21783158381779988 minutes
2023-08-01 06:54:08,602:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:08,602:INFO:Initializing create_model()
2023-08-01 06:54:08,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:08,602:INFO:Checking exceptions
2023-08-01 06:54:08,602:INFO:Importing libraries
2023-08-01 06:54:08,602:INFO:Copying training dataset
2023-08-01 06:54:08,610:INFO:Defining folds
2023-08-01 06:54:08,610:INFO:Declaring metric variables
2023-08-01 06:54:08,610:INFO:Importing untrained model
2023-08-01 06:54:08,610:INFO:Naive Bayes Imported successfully
2023-08-01 06:54:08,618:INFO:Starting cross validation
2023-08-01 06:54:08,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:14,001:INFO:Calculating mean and std
2023-08-01 06:54:14,001:INFO:Creating metrics dataframe
2023-08-01 06:54:14,686:INFO:Uploading results into container
2023-08-01 06:54:14,686:INFO:Uploading model into container now
2023-08-01 06:54:14,686:INFO:_master_model_container: 3
2023-08-01 06:54:14,686:INFO:_display_container: 2
2023-08-01 06:54:14,686:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 06:54:14,686:INFO:create_model() successfully completed......................................
2023-08-01 06:54:14,791:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:14,791:INFO:Creating metrics dataframe
2023-08-01 06:54:14,799:INFO:Initializing Decision Tree Classifier
2023-08-01 06:54:14,799:INFO:Total runtime is 0.32110997835795085 minutes
2023-08-01 06:54:14,805:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:14,805:INFO:Initializing create_model()
2023-08-01 06:54:14,805:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:14,805:INFO:Checking exceptions
2023-08-01 06:54:14,805:INFO:Importing libraries
2023-08-01 06:54:14,805:INFO:Copying training dataset
2023-08-01 06:54:14,807:INFO:Defining folds
2023-08-01 06:54:14,807:INFO:Declaring metric variables
2023-08-01 06:54:14,807:INFO:Importing untrained model
2023-08-01 06:54:14,815:INFO:Decision Tree Classifier Imported successfully
2023-08-01 06:54:14,815:INFO:Starting cross validation
2023-08-01 06:54:14,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:20,071:INFO:Calculating mean and std
2023-08-01 06:54:20,071:INFO:Creating metrics dataframe
2023-08-01 06:54:20,743:INFO:Uploading results into container
2023-08-01 06:54:20,743:INFO:Uploading model into container now
2023-08-01 06:54:20,743:INFO:_master_model_container: 4
2023-08-01 06:54:20,743:INFO:_display_container: 2
2023-08-01 06:54:20,743:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 06:54:20,743:INFO:create_model() successfully completed......................................
2023-08-01 06:54:20,839:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:20,839:INFO:Creating metrics dataframe
2023-08-01 06:54:20,847:INFO:Initializing SVM - Linear Kernel
2023-08-01 06:54:20,847:INFO:Total runtime is 0.42190597852071127 minutes
2023-08-01 06:54:20,855:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:20,855:INFO:Initializing create_model()
2023-08-01 06:54:20,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:20,855:INFO:Checking exceptions
2023-08-01 06:54:20,855:INFO:Importing libraries
2023-08-01 06:54:20,855:INFO:Copying training dataset
2023-08-01 06:54:20,855:INFO:Defining folds
2023-08-01 06:54:20,855:INFO:Declaring metric variables
2023-08-01 06:54:20,863:INFO:Importing untrained model
2023-08-01 06:54:20,863:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 06:54:20,863:INFO:Starting cross validation
2023-08-01 06:54:20,871:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:21,115:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,123:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,132:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,132:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,140:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,148:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,156:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,156:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,165:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:21,173:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:54:26,127:INFO:Calculating mean and std
2023-08-01 06:54:26,127:INFO:Creating metrics dataframe
2023-08-01 06:54:26,798:INFO:Uploading results into container
2023-08-01 06:54:26,798:INFO:Uploading model into container now
2023-08-01 06:54:26,798:INFO:_master_model_container: 5
2023-08-01 06:54:26,798:INFO:_display_container: 2
2023-08-01 06:54:26,798:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 06:54:26,798:INFO:create_model() successfully completed......................................
2023-08-01 06:54:26,895:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:26,895:INFO:Creating metrics dataframe
2023-08-01 06:54:26,903:INFO:Initializing Ridge Classifier
2023-08-01 06:54:26,903:INFO:Total runtime is 0.5228367726008097 minutes
2023-08-01 06:54:26,903:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:26,903:INFO:Initializing create_model()
2023-08-01 06:54:26,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:26,903:INFO:Checking exceptions
2023-08-01 06:54:26,903:INFO:Importing libraries
2023-08-01 06:54:26,903:INFO:Copying training dataset
2023-08-01 06:54:26,911:INFO:Defining folds
2023-08-01 06:54:26,911:INFO:Declaring metric variables
2023-08-01 06:54:26,911:INFO:Importing untrained model
2023-08-01 06:54:26,917:INFO:Ridge Classifier Imported successfully
2023-08-01 06:54:26,919:INFO:Starting cross validation
2023-08-01 06:54:26,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:27,137:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,145:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,145:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,145:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,145:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,145:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,153:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,161:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,161:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:27,186:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:54:32,074:INFO:Calculating mean and std
2023-08-01 06:54:32,074:INFO:Creating metrics dataframe
2023-08-01 06:54:32,747:INFO:Uploading results into container
2023-08-01 06:54:32,747:INFO:Uploading model into container now
2023-08-01 06:54:32,747:INFO:_master_model_container: 6
2023-08-01 06:54:32,755:INFO:_display_container: 2
2023-08-01 06:54:32,755:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 06:54:32,755:INFO:create_model() successfully completed......................................
2023-08-01 06:54:32,851:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:32,851:INFO:Creating metrics dataframe
2023-08-01 06:54:32,859:INFO:Initializing Random Forest Classifier
2023-08-01 06:54:32,859:INFO:Total runtime is 0.6221037228902181 minutes
2023-08-01 06:54:32,859:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:32,859:INFO:Initializing create_model()
2023-08-01 06:54:32,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:32,859:INFO:Checking exceptions
2023-08-01 06:54:32,859:INFO:Importing libraries
2023-08-01 06:54:32,859:INFO:Copying training dataset
2023-08-01 06:54:32,867:INFO:Defining folds
2023-08-01 06:54:32,867:INFO:Declaring metric variables
2023-08-01 06:54:32,867:INFO:Importing untrained model
2023-08-01 06:54:32,867:INFO:Random Forest Classifier Imported successfully
2023-08-01 06:54:32,875:INFO:Starting cross validation
2023-08-01 06:54:32,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:38,873:INFO:Calculating mean and std
2023-08-01 06:54:38,873:INFO:Creating metrics dataframe
2023-08-01 06:54:39,554:INFO:Uploading results into container
2023-08-01 06:54:39,562:INFO:Uploading model into container now
2023-08-01 06:54:39,562:INFO:_master_model_container: 7
2023-08-01 06:54:39,562:INFO:_display_container: 2
2023-08-01 06:54:39,562:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:54:39,562:INFO:create_model() successfully completed......................................
2023-08-01 06:54:39,659:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:39,659:INFO:Creating metrics dataframe
2023-08-01 06:54:39,667:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 06:54:39,667:INFO:Total runtime is 0.7355711460113525 minutes
2023-08-01 06:54:39,675:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:39,675:INFO:Initializing create_model()
2023-08-01 06:54:39,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:39,675:INFO:Checking exceptions
2023-08-01 06:54:39,675:INFO:Importing libraries
2023-08-01 06:54:39,675:INFO:Copying training dataset
2023-08-01 06:54:39,675:INFO:Defining folds
2023-08-01 06:54:39,675:INFO:Declaring metric variables
2023-08-01 06:54:39,683:INFO:Importing untrained model
2023-08-01 06:54:39,683:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 06:54:39,691:INFO:Starting cross validation
2023-08-01 06:54:39,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:39,846:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,846:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,853:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,861:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,869:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,869:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,877:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,877:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,885:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,885:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:54:39,893:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,893:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,893:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,926:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,937:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,937:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,937:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,942:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,950:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,958:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,958:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,958:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,974:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,982:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:39,998:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 06:54:40,007:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:54:44,987:INFO:Calculating mean and std
2023-08-01 06:54:44,987:INFO:Creating metrics dataframe
2023-08-01 06:54:45,660:INFO:Uploading results into container
2023-08-01 06:54:45,660:INFO:Uploading model into container now
2023-08-01 06:54:45,660:INFO:_master_model_container: 8
2023-08-01 06:54:45,660:INFO:_display_container: 2
2023-08-01 06:54:45,668:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 06:54:45,668:INFO:create_model() successfully completed......................................
2023-08-01 06:54:45,764:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:45,764:INFO:Creating metrics dataframe
2023-08-01 06:54:45,772:INFO:Initializing Ada Boost Classifier
2023-08-01 06:54:45,772:INFO:Total runtime is 0.8373244086901347 minutes
2023-08-01 06:54:45,772:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:45,772:INFO:Initializing create_model()
2023-08-01 06:54:45,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:45,772:INFO:Checking exceptions
2023-08-01 06:54:45,772:INFO:Importing libraries
2023-08-01 06:54:45,772:INFO:Copying training dataset
2023-08-01 06:54:45,780:INFO:Defining folds
2023-08-01 06:54:45,780:INFO:Declaring metric variables
2023-08-01 06:54:45,780:INFO:Importing untrained model
2023-08-01 06:54:45,780:INFO:Ada Boost Classifier Imported successfully
2023-08-01 06:54:45,788:INFO:Starting cross validation
2023-08-01 06:54:45,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:51,483:INFO:Calculating mean and std
2023-08-01 06:54:51,483:INFO:Creating metrics dataframe
2023-08-01 06:54:52,167:INFO:Uploading results into container
2023-08-01 06:54:52,167:INFO:Uploading model into container now
2023-08-01 06:54:52,167:INFO:_master_model_container: 9
2023-08-01 06:54:52,167:INFO:_display_container: 2
2023-08-01 06:54:52,167:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 06:54:52,167:INFO:create_model() successfully completed......................................
2023-08-01 06:54:52,272:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:52,272:INFO:Creating metrics dataframe
2023-08-01 06:54:52,279:INFO:Initializing Gradient Boosting Classifier
2023-08-01 06:54:52,279:INFO:Total runtime is 0.9457769672075907 minutes
2023-08-01 06:54:52,279:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:52,279:INFO:Initializing create_model()
2023-08-01 06:54:52,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:52,279:INFO:Checking exceptions
2023-08-01 06:54:52,279:INFO:Importing libraries
2023-08-01 06:54:52,279:INFO:Copying training dataset
2023-08-01 06:54:52,287:INFO:Defining folds
2023-08-01 06:54:52,287:INFO:Declaring metric variables
2023-08-01 06:54:52,287:INFO:Importing untrained model
2023-08-01 06:54:52,287:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 06:54:52,295:INFO:Starting cross validation
2023-08-01 06:54:52,295:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:54:58,115:INFO:Calculating mean and std
2023-08-01 06:54:58,115:INFO:Creating metrics dataframe
2023-08-01 06:54:58,806:INFO:Uploading results into container
2023-08-01 06:54:58,806:INFO:Uploading model into container now
2023-08-01 06:54:58,806:INFO:_master_model_container: 10
2023-08-01 06:54:58,806:INFO:_display_container: 2
2023-08-01 06:54:58,806:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:54:58,806:INFO:create_model() successfully completed......................................
2023-08-01 06:54:58,904:INFO:SubProcess create_model() end ==================================
2023-08-01 06:54:58,904:INFO:Creating metrics dataframe
2023-08-01 06:54:58,912:INFO:Initializing Linear Discriminant Analysis
2023-08-01 06:54:58,912:INFO:Total runtime is 1.0563249230384826 minutes
2023-08-01 06:54:58,920:INFO:SubProcess create_model() called ==================================
2023-08-01 06:54:58,920:INFO:Initializing create_model()
2023-08-01 06:54:58,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:54:58,920:INFO:Checking exceptions
2023-08-01 06:54:58,920:INFO:Importing libraries
2023-08-01 06:54:58,921:INFO:Copying training dataset
2023-08-01 06:54:58,921:INFO:Defining folds
2023-08-01 06:54:58,921:INFO:Declaring metric variables
2023-08-01 06:54:58,928:INFO:Importing untrained model
2023-08-01 06:54:58,928:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 06:54:58,928:INFO:Starting cross validation
2023-08-01 06:54:58,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:55:04,272:INFO:Calculating mean and std
2023-08-01 06:55:04,272:INFO:Creating metrics dataframe
2023-08-01 06:55:04,956:INFO:Uploading results into container
2023-08-01 06:55:04,956:INFO:Uploading model into container now
2023-08-01 06:55:04,964:INFO:_master_model_container: 11
2023-08-01 06:55:04,964:INFO:_display_container: 2
2023-08-01 06:55:04,964:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 06:55:04,964:INFO:create_model() successfully completed......................................
2023-08-01 06:55:05,061:INFO:SubProcess create_model() end ==================================
2023-08-01 06:55:05,061:INFO:Creating metrics dataframe
2023-08-01 06:55:05,073:INFO:Initializing Extra Trees Classifier
2023-08-01 06:55:05,073:INFO:Total runtime is 1.159001310666402 minutes
2023-08-01 06:55:05,073:INFO:SubProcess create_model() called ==================================
2023-08-01 06:55:05,073:INFO:Initializing create_model()
2023-08-01 06:55:05,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:55:05,073:INFO:Checking exceptions
2023-08-01 06:55:05,073:INFO:Importing libraries
2023-08-01 06:55:05,073:INFO:Copying training dataset
2023-08-01 06:55:05,077:INFO:Defining folds
2023-08-01 06:55:05,077:INFO:Declaring metric variables
2023-08-01 06:55:05,077:INFO:Importing untrained model
2023-08-01 06:55:05,085:INFO:Extra Trees Classifier Imported successfully
2023-08-01 06:55:05,085:INFO:Starting cross validation
2023-08-01 06:55:05,085:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:55:11,178:INFO:Calculating mean and std
2023-08-01 06:55:11,178:INFO:Creating metrics dataframe
2023-08-01 06:55:11,863:INFO:Uploading results into container
2023-08-01 06:55:11,863:INFO:Uploading model into container now
2023-08-01 06:55:11,863:INFO:_master_model_container: 12
2023-08-01 06:55:11,863:INFO:_display_container: 2
2023-08-01 06:55:11,863:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:55:11,863:INFO:create_model() successfully completed......................................
2023-08-01 06:55:11,960:INFO:SubProcess create_model() end ==================================
2023-08-01 06:55:11,960:INFO:Creating metrics dataframe
2023-08-01 06:55:11,968:INFO:Initializing Extreme Gradient Boosting
2023-08-01 06:55:11,968:INFO:Total runtime is 1.2739204963048298 minutes
2023-08-01 06:55:11,976:INFO:SubProcess create_model() called ==================================
2023-08-01 06:55:11,976:INFO:Initializing create_model()
2023-08-01 06:55:11,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:55:11,976:INFO:Checking exceptions
2023-08-01 06:55:11,976:INFO:Importing libraries
2023-08-01 06:55:11,976:INFO:Copying training dataset
2023-08-01 06:55:11,976:INFO:Defining folds
2023-08-01 06:55:11,976:INFO:Declaring metric variables
2023-08-01 06:55:11,984:INFO:Importing untrained model
2023-08-01 06:55:11,987:INFO:Extreme Gradient Boosting Imported successfully
2023-08-01 06:55:11,992:INFO:Starting cross validation
2023-08-01 06:55:11,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:55:18,243:INFO:Calculating mean and std
2023-08-01 06:55:18,243:INFO:Creating metrics dataframe
2023-08-01 06:55:18,932:INFO:Uploading results into container
2023-08-01 06:55:18,932:INFO:Uploading model into container now
2023-08-01 06:55:18,932:INFO:_master_model_container: 13
2023-08-01 06:55:18,932:INFO:_display_container: 2
2023-08-01 06:55:18,932:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-01 06:55:18,932:INFO:create_model() successfully completed......................................
2023-08-01 06:55:19,029:INFO:SubProcess create_model() end ==================================
2023-08-01 06:55:19,029:INFO:Creating metrics dataframe
2023-08-01 06:55:19,037:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 06:55:19,037:INFO:Total runtime is 1.3917418837547302 minutes
2023-08-01 06:55:19,045:INFO:SubProcess create_model() called ==================================
2023-08-01 06:55:19,045:INFO:Initializing create_model()
2023-08-01 06:55:19,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:55:19,045:INFO:Checking exceptions
2023-08-01 06:55:19,045:INFO:Importing libraries
2023-08-01 06:55:19,045:INFO:Copying training dataset
2023-08-01 06:55:19,045:INFO:Defining folds
2023-08-01 06:55:19,045:INFO:Declaring metric variables
2023-08-01 06:55:19,053:INFO:Importing untrained model
2023-08-01 06:55:19,053:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 06:55:19,061:INFO:Starting cross validation
2023-08-01 06:55:19,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:55:22,350:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.47s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:55:26,403:INFO:Calculating mean and std
2023-08-01 06:55:26,403:INFO:Creating metrics dataframe
2023-08-01 06:55:27,103:INFO:Uploading results into container
2023-08-01 06:55:27,103:INFO:Uploading model into container now
2023-08-01 06:55:27,103:INFO:_master_model_container: 14
2023-08-01 06:55:27,103:INFO:_display_container: 2
2023-08-01 06:55:27,111:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 06:55:27,111:INFO:create_model() successfully completed......................................
2023-08-01 06:55:27,207:INFO:SubProcess create_model() end ==================================
2023-08-01 06:55:27,207:INFO:Creating metrics dataframe
2023-08-01 06:55:27,215:INFO:Initializing Dummy Classifier
2023-08-01 06:55:27,215:INFO:Total runtime is 1.5280464967091878 minutes
2023-08-01 06:55:27,215:INFO:SubProcess create_model() called ==================================
2023-08-01 06:55:27,215:INFO:Initializing create_model()
2023-08-01 06:55:27,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506FCE400>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:55:27,215:INFO:Checking exceptions
2023-08-01 06:55:27,215:INFO:Importing libraries
2023-08-01 06:55:27,215:INFO:Copying training dataset
2023-08-01 06:55:27,223:INFO:Defining folds
2023-08-01 06:55:27,223:INFO:Declaring metric variables
2023-08-01 06:55:27,223:INFO:Importing untrained model
2023-08-01 06:55:27,231:INFO:Dummy Classifier Imported successfully
2023-08-01 06:55:27,231:INFO:Starting cross validation
2023-08-01 06:55:27,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:55:27,496:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,504:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,512:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,512:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,520:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,520:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,528:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,528:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,528:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:27,528:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:55:32,729:INFO:Calculating mean and std
2023-08-01 06:55:32,729:INFO:Creating metrics dataframe
2023-08-01 06:55:33,422:INFO:Uploading results into container
2023-08-01 06:55:33,422:INFO:Uploading model into container now
2023-08-01 06:55:33,422:INFO:_master_model_container: 15
2023-08-01 06:55:33,422:INFO:_display_container: 2
2023-08-01 06:55:33,422:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 06:55:33,422:INFO:create_model() successfully completed......................................
2023-08-01 06:55:33,526:INFO:SubProcess create_model() end ==================================
2023-08-01 06:55:33,526:INFO:Creating metrics dataframe
2023-08-01 06:55:33,544:INFO:Initializing create_model()
2023-08-01 06:55:33,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018488A18F10>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:55:33,544:INFO:Checking exceptions
2023-08-01 06:55:33,544:INFO:Importing libraries
2023-08-01 06:55:33,544:INFO:Copying training dataset
2023-08-01 06:55:33,550:INFO:Defining folds
2023-08-01 06:55:33,550:INFO:Declaring metric variables
2023-08-01 06:55:33,550:INFO:Importing untrained model
2023-08-01 06:55:33,550:INFO:Declaring custom model
2023-08-01 06:55:33,550:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 06:55:33,550:INFO:Cross validation set to False
2023-08-01 06:55:33,550:INFO:Fitting Model
2023-08-01 06:55:34,487:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:55:34,487:INFO:create_model() successfully completed......................................
2023-08-01 06:55:34,612:INFO:_master_model_container: 15
2023-08-01 06:55:34,612:INFO:_display_container: 2
2023-08-01 06:55:34,612:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:55:34,612:INFO:compare_models() successfully completed......................................
2023-08-01 06:56:23,800:INFO:PyCaret ClassificationExperiment
2023-08-01 06:56:23,800:INFO:Logging name: clf-default-name
2023-08-01 06:56:23,800:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 06:56:23,800:INFO:version 3.0.4
2023-08-01 06:56:23,800:INFO:Initializing setup()
2023-08-01 06:56:23,800:INFO:self.USI: 8a5f
2023-08-01 06:56:23,800:INFO:self._variable_keys: {'y', 'y_train', 'X_test', 'html_param', 'fold_groups_param', 'target_param', '_available_plots', 'data', 'fold_generator', 'fix_imbalance', 'USI', 'logging_param', 'seed', 'n_jobs_param', 'y_test', 'log_plots_param', 'exp_id', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'gpu_param', 'idx', 'X_train', 'fold_shuffle_param', 'X', 'memory'}
2023-08-01 06:56:23,800:INFO:Checking environment
2023-08-01 06:56:23,800:INFO:python_version: 3.9.13
2023-08-01 06:56:23,800:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 06:56:23,800:INFO:machine: AMD64
2023-08-01 06:56:23,800:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-01 06:56:23,808:INFO:Memory: svmem(total=33737928704, available=21613768704, percent=35.9, used=12124160000, free=21613768704)
2023-08-01 06:56:23,808:INFO:Physical Core: 8
2023-08-01 06:56:23,808:INFO:Logical Core: 16
2023-08-01 06:56:23,808:INFO:Checking libraries
2023-08-01 06:56:23,808:INFO:System:
2023-08-01 06:56:23,808:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 06:56:23,808:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 06:56:23,808:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-01 06:56:23,808:INFO:PyCaret required dependencies:
2023-08-01 06:56:23,808:INFO:                 pip: 22.0.4
2023-08-01 06:56:23,808:INFO:          setuptools: 58.1.0
2023-08-01 06:56:23,808:INFO:             pycaret: 3.0.4
2023-08-01 06:56:23,808:INFO:             IPython: 8.13.1
2023-08-01 06:56:23,808:INFO:          ipywidgets: 8.0.7
2023-08-01 06:56:23,808:INFO:                tqdm: 4.65.0
2023-08-01 06:56:23,808:INFO:               numpy: 1.23.0
2023-08-01 06:56:23,808:INFO:              pandas: 1.5.3
2023-08-01 06:56:23,808:INFO:              jinja2: 3.1.2
2023-08-01 06:56:23,808:INFO:               scipy: 1.10.1
2023-08-01 06:56:23,808:INFO:              joblib: 1.3.1
2023-08-01 06:56:23,808:INFO:             sklearn: 1.2.2
2023-08-01 06:56:23,808:INFO:                pyod: 1.1.0
2023-08-01 06:56:23,808:INFO:            imblearn: 0.11.0
2023-08-01 06:56:23,808:INFO:   category_encoders: 2.6.1
2023-08-01 06:56:23,808:INFO:            lightgbm: 4.0.0
2023-08-01 06:56:23,808:INFO:               numba: 0.57.1
2023-08-01 06:56:23,808:INFO:            requests: 2.31.0
2023-08-01 06:56:23,808:INFO:          matplotlib: 3.7.1
2023-08-01 06:56:23,808:INFO:          scikitplot: 0.3.7
2023-08-01 06:56:23,808:INFO:         yellowbrick: 1.5
2023-08-01 06:56:23,808:INFO:              plotly: 5.15.0
2023-08-01 06:56:23,808:INFO:    plotly-resampler: Not installed
2023-08-01 06:56:23,808:INFO:             kaleido: 0.2.1
2023-08-01 06:56:23,808:INFO:           schemdraw: 0.15
2023-08-01 06:56:23,808:INFO:         statsmodels: 0.14.0
2023-08-01 06:56:23,808:INFO:              sktime: 0.20.1
2023-08-01 06:56:23,808:INFO:               tbats: 1.1.3
2023-08-01 06:56:23,808:INFO:            pmdarima: 2.0.3
2023-08-01 06:56:23,808:INFO:              psutil: 5.9.5
2023-08-01 06:56:23,808:INFO:          markupsafe: 2.1.3
2023-08-01 06:56:23,808:INFO:             pickle5: Not installed
2023-08-01 06:56:23,808:INFO:         cloudpickle: 2.2.1
2023-08-01 06:56:23,808:INFO:         deprecation: 2.1.0
2023-08-01 06:56:23,808:INFO:              xxhash: 3.2.0
2023-08-01 06:56:23,808:INFO:           wurlitzer: Not installed
2023-08-01 06:56:23,808:INFO:PyCaret optional dependencies:
2023-08-01 06:56:23,808:INFO:                shap: 0.42.1
2023-08-01 06:56:23,808:INFO:           interpret: Not installed
2023-08-01 06:56:23,808:INFO:                umap: 0.5.3
2023-08-01 06:56:23,808:INFO:    pandas_profiling: Not installed
2023-08-01 06:56:23,808:INFO:  explainerdashboard: 0.4.2.2
2023-08-01 06:56:23,808:INFO:             autoviz: 0.1.730
2023-08-01 06:56:23,808:INFO:           fairlearn: Not installed
2023-08-01 06:56:23,808:INFO:          deepchecks: Not installed
2023-08-01 06:56:23,808:INFO:             xgboost: 1.7.6
2023-08-01 06:56:23,808:INFO:            catboost: Not installed
2023-08-01 06:56:23,808:INFO:              kmodes: Not installed
2023-08-01 06:56:23,808:INFO:             mlxtend: Not installed
2023-08-01 06:56:23,808:INFO:       statsforecast: Not installed
2023-08-01 06:56:23,808:INFO:        tune_sklearn: Not installed
2023-08-01 06:56:23,808:INFO:                 ray: Not installed
2023-08-01 06:56:23,808:INFO:            hyperopt: Not installed
2023-08-01 06:56:23,808:INFO:              optuna: Not installed
2023-08-01 06:56:23,808:INFO:               skopt: Not installed
2023-08-01 06:56:23,808:INFO:              mlflow: Not installed
2023-08-01 06:56:23,808:INFO:              gradio: Not installed
2023-08-01 06:56:23,808:INFO:             fastapi: Not installed
2023-08-01 06:56:23,808:INFO:             uvicorn: Not installed
2023-08-01 06:56:23,808:INFO:              m2cgen: Not installed
2023-08-01 06:56:23,808:INFO:           evidently: Not installed
2023-08-01 06:56:23,808:INFO:               fugue: Not installed
2023-08-01 06:56:23,808:INFO:           streamlit: Not installed
2023-08-01 06:56:23,808:INFO:             prophet: Not installed
2023-08-01 06:56:23,808:INFO:None
2023-08-01 06:56:23,808:INFO:Set up data.
2023-08-01 06:56:23,816:INFO:Set up train/test split.
2023-08-01 06:56:23,824:INFO:Set up index.
2023-08-01 06:56:23,824:INFO:Set up folding strategy.
2023-08-01 06:56:23,824:INFO:Assigning column types.
2023-08-01 06:56:23,824:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 06:56:23,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:56:23,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:56:23,880:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:23,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:23,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 06:56:23,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:56:23,937:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:23,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:23,937:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 06:56:23,969:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:56:23,993:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:23,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:24,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 06:56:24,050:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:24,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:24,050:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 06:56:24,106:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:24,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:24,162:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:24,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:24,162:INFO:Preparing preprocessing pipeline...
2023-08-01 06:56:24,162:INFO:Set up simple imputation.
2023-08-01 06:56:24,170:INFO:Set up encoding of categorical features.
2023-08-01 06:56:24,170:INFO:Set up polynomial features.
2023-08-01 06:56:24,170:INFO:Set up removing multicollinearity.
2023-08-01 06:56:24,170:INFO:Set up feature normalization.
2023-08-01 06:56:24,619:INFO:Finished creating preprocessing pipeline.
2023-08-01 06:56:24,707:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=No...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 06:56:24,707:INFO:Creating final display dataframe.
2023-08-01 06:56:24,965:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15          Polynomial features   
16            Polynomial degree   
17     Remove multicollinearity   
18  Multicollinearity threshold   
19                    Normalize   
20             Normalize method   
21               Fold Generator   
22                  Fold Number   
23                     CPU Jobs   
24                      Use GPU   
25               Log Experiment   
26              Experiment Name   
27                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 11)  
4                                         (8136, 132)  
5                                         (6508, 132)  
6                                         (1628, 132)  
7                                                   6  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                  2  
17                                               True  
18                                                0.8  
19                                               True  
20                                             zscore  
21                                    StratifiedKFold  
22                                                 10  
23                                                 -1  
24                                              False  
25                                              False  
26                                   clf-default-name  
27                                               8a5f  
2023-08-01 06:56:25,022:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:25,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:25,078:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 06:56:25,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 06:56:25,086:INFO:setup() successfully completed in 2.02s...............
2023-08-01 06:56:33,296:INFO:Initializing compare_models()
2023-08-01 06:56:33,296:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 06:56:33,296:INFO:Checking exceptions
2023-08-01 06:56:33,305:INFO:Preparing display monitor
2023-08-01 06:56:33,320:INFO:Initializing Logistic Regression
2023-08-01 06:56:33,320:INFO:Total runtime is 0.0 minutes
2023-08-01 06:56:33,328:INFO:SubProcess create_model() called ==================================
2023-08-01 06:56:33,328:INFO:Initializing create_model()
2023-08-01 06:56:33,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:56:33,328:INFO:Checking exceptions
2023-08-01 06:56:33,328:INFO:Importing libraries
2023-08-01 06:56:33,328:INFO:Copying training dataset
2023-08-01 06:56:33,328:INFO:Defining folds
2023-08-01 06:56:33,328:INFO:Declaring metric variables
2023-08-01 06:56:33,336:INFO:Importing untrained model
2023-08-01 06:56:33,336:INFO:Logistic Regression Imported successfully
2023-08-01 06:56:33,344:INFO:Starting cross validation
2023-08-01 06:56:33,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:56:40,239:INFO:Calculating mean and std
2023-08-01 06:56:40,240:INFO:Creating metrics dataframe
2023-08-01 06:56:40,939:INFO:Uploading results into container
2023-08-01 06:56:40,939:INFO:Uploading model into container now
2023-08-01 06:56:40,939:INFO:_master_model_container: 1
2023-08-01 06:56:40,939:INFO:_display_container: 2
2023-08-01 06:56:40,939:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 06:56:40,939:INFO:create_model() successfully completed......................................
2023-08-01 06:56:41,043:INFO:SubProcess create_model() end ==================================
2023-08-01 06:56:41,043:INFO:Creating metrics dataframe
2023-08-01 06:56:41,051:INFO:Initializing K Neighbors Classifier
2023-08-01 06:56:41,051:INFO:Total runtime is 0.12884929180145263 minutes
2023-08-01 06:56:41,051:INFO:SubProcess create_model() called ==================================
2023-08-01 06:56:41,051:INFO:Initializing create_model()
2023-08-01 06:56:41,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:56:41,051:INFO:Checking exceptions
2023-08-01 06:56:41,051:INFO:Importing libraries
2023-08-01 06:56:41,051:INFO:Copying training dataset
2023-08-01 06:56:41,060:INFO:Defining folds
2023-08-01 06:56:41,060:INFO:Declaring metric variables
2023-08-01 06:56:41,060:INFO:Importing untrained model
2023-08-01 06:56:41,060:INFO:K Neighbors Classifier Imported successfully
2023-08-01 06:56:41,068:INFO:Starting cross validation
2023-08-01 06:56:41,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:56:42,545:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:56:47,318:INFO:Calculating mean and std
2023-08-01 06:56:47,318:INFO:Creating metrics dataframe
2023-08-01 06:56:48,021:INFO:Uploading results into container
2023-08-01 06:56:48,021:INFO:Uploading model into container now
2023-08-01 06:56:48,021:INFO:_master_model_container: 2
2023-08-01 06:56:48,021:INFO:_display_container: 2
2023-08-01 06:56:48,021:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 06:56:48,021:INFO:create_model() successfully completed......................................
2023-08-01 06:56:48,125:INFO:SubProcess create_model() end ==================================
2023-08-01 06:56:48,125:INFO:Creating metrics dataframe
2023-08-01 06:56:48,125:INFO:Initializing Naive Bayes
2023-08-01 06:56:48,133:INFO:Total runtime is 0.24687843322753905 minutes
2023-08-01 06:56:48,133:INFO:SubProcess create_model() called ==================================
2023-08-01 06:56:48,133:INFO:Initializing create_model()
2023-08-01 06:56:48,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:56:48,133:INFO:Checking exceptions
2023-08-01 06:56:48,133:INFO:Importing libraries
2023-08-01 06:56:48,133:INFO:Copying training dataset
2023-08-01 06:56:48,133:INFO:Defining folds
2023-08-01 06:56:48,133:INFO:Declaring metric variables
2023-08-01 06:56:48,141:INFO:Importing untrained model
2023-08-01 06:56:48,141:INFO:Naive Bayes Imported successfully
2023-08-01 06:56:48,149:INFO:Starting cross validation
2023-08-01 06:56:48,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:56:49,090:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:56:53,876:INFO:Calculating mean and std
2023-08-01 06:56:53,876:INFO:Creating metrics dataframe
2023-08-01 06:56:54,580:INFO:Uploading results into container
2023-08-01 06:56:54,588:INFO:Uploading model into container now
2023-08-01 06:56:54,588:INFO:_master_model_container: 3
2023-08-01 06:56:54,588:INFO:_display_container: 2
2023-08-01 06:56:54,588:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 06:56:54,588:INFO:create_model() successfully completed......................................
2023-08-01 06:56:54,685:INFO:SubProcess create_model() end ==================================
2023-08-01 06:56:54,685:INFO:Creating metrics dataframe
2023-08-01 06:56:54,693:INFO:Initializing Decision Tree Classifier
2023-08-01 06:56:54,693:INFO:Total runtime is 0.3562078992525736 minutes
2023-08-01 06:56:54,693:INFO:SubProcess create_model() called ==================================
2023-08-01 06:56:54,693:INFO:Initializing create_model()
2023-08-01 06:56:54,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:56:54,693:INFO:Checking exceptions
2023-08-01 06:56:54,693:INFO:Importing libraries
2023-08-01 06:56:54,693:INFO:Copying training dataset
2023-08-01 06:56:54,693:INFO:Defining folds
2023-08-01 06:56:54,693:INFO:Declaring metric variables
2023-08-01 06:56:54,701:INFO:Importing untrained model
2023-08-01 06:56:54,701:INFO:Decision Tree Classifier Imported successfully
2023-08-01 06:56:54,709:INFO:Starting cross validation
2023-08-01 06:56:54,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:00,390:INFO:Calculating mean and std
2023-08-01 06:57:00,392:INFO:Creating metrics dataframe
2023-08-01 06:57:01,093:INFO:Uploading results into container
2023-08-01 06:57:01,093:INFO:Uploading model into container now
2023-08-01 06:57:01,093:INFO:_master_model_container: 4
2023-08-01 06:57:01,093:INFO:_display_container: 2
2023-08-01 06:57:01,094:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 06:57:01,094:INFO:create_model() successfully completed......................................
2023-08-01 06:57:01,189:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:01,189:INFO:Creating metrics dataframe
2023-08-01 06:57:01,197:INFO:Initializing SVM - Linear Kernel
2023-08-01 06:57:01,197:INFO:Total runtime is 0.46461668411890666 minutes
2023-08-01 06:57:01,197:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:01,197:INFO:Initializing create_model()
2023-08-01 06:57:01,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:01,197:INFO:Checking exceptions
2023-08-01 06:57:01,197:INFO:Importing libraries
2023-08-01 06:57:01,197:INFO:Copying training dataset
2023-08-01 06:57:01,205:INFO:Defining folds
2023-08-01 06:57:01,205:INFO:Declaring metric variables
2023-08-01 06:57:01,205:INFO:Importing untrained model
2023-08-01 06:57:01,205:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 06:57:01,213:INFO:Starting cross validation
2023-08-01 06:57:01,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:01,818:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,842:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,858:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,866:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,866:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,883:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,899:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,907:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,907:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:01,924:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 06:57:07,068:INFO:Calculating mean and std
2023-08-01 06:57:07,068:INFO:Creating metrics dataframe
2023-08-01 06:57:07,785:INFO:Uploading results into container
2023-08-01 06:57:07,785:INFO:Uploading model into container now
2023-08-01 06:57:07,785:INFO:_master_model_container: 5
2023-08-01 06:57:07,785:INFO:_display_container: 2
2023-08-01 06:57:07,785:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 06:57:07,785:INFO:create_model() successfully completed......................................
2023-08-01 06:57:07,882:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:07,882:INFO:Creating metrics dataframe
2023-08-01 06:57:07,890:INFO:Initializing Ridge Classifier
2023-08-01 06:57:07,890:INFO:Total runtime is 0.5761576374371846 minutes
2023-08-01 06:57:07,890:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:07,890:INFO:Initializing create_model()
2023-08-01 06:57:07,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:07,890:INFO:Checking exceptions
2023-08-01 06:57:07,890:INFO:Importing libraries
2023-08-01 06:57:07,890:INFO:Copying training dataset
2023-08-01 06:57:07,898:INFO:Defining folds
2023-08-01 06:57:07,898:INFO:Declaring metric variables
2023-08-01 06:57:07,898:INFO:Importing untrained model
2023-08-01 06:57:07,898:INFO:Ridge Classifier Imported successfully
2023-08-01 06:57:07,906:INFO:Starting cross validation
2023-08-01 06:57:07,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:08,262:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,262:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,270:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,278:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,295:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,295:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,295:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,319:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,335:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:08,343:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 06:57:13,568:INFO:Calculating mean and std
2023-08-01 06:57:13,568:INFO:Creating metrics dataframe
2023-08-01 06:57:14,292:INFO:Uploading results into container
2023-08-01 06:57:14,292:INFO:Uploading model into container now
2023-08-01 06:57:14,292:INFO:_master_model_container: 6
2023-08-01 06:57:14,292:INFO:_display_container: 2
2023-08-01 06:57:14,292:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 06:57:14,292:INFO:create_model() successfully completed......................................
2023-08-01 06:57:14,388:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:14,388:INFO:Creating metrics dataframe
2023-08-01 06:57:14,396:INFO:Initializing Random Forest Classifier
2023-08-01 06:57:14,396:INFO:Total runtime is 0.6846051851908366 minutes
2023-08-01 06:57:14,404:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:14,404:INFO:Initializing create_model()
2023-08-01 06:57:14,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:14,404:INFO:Checking exceptions
2023-08-01 06:57:14,404:INFO:Importing libraries
2023-08-01 06:57:14,404:INFO:Copying training dataset
2023-08-01 06:57:14,404:INFO:Defining folds
2023-08-01 06:57:14,404:INFO:Declaring metric variables
2023-08-01 06:57:14,412:INFO:Importing untrained model
2023-08-01 06:57:14,412:INFO:Random Forest Classifier Imported successfully
2023-08-01 06:57:14,412:INFO:Starting cross validation
2023-08-01 06:57:14,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:21,300:INFO:Calculating mean and std
2023-08-01 06:57:21,301:INFO:Creating metrics dataframe
2023-08-01 06:57:22,023:INFO:Uploading results into container
2023-08-01 06:57:22,023:INFO:Uploading model into container now
2023-08-01 06:57:22,023:INFO:_master_model_container: 7
2023-08-01 06:57:22,023:INFO:_display_container: 2
2023-08-01 06:57:22,023:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:57:22,023:INFO:create_model() successfully completed......................................
2023-08-01 06:57:22,126:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:22,126:INFO:Creating metrics dataframe
2023-08-01 06:57:22,134:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 06:57:22,134:INFO:Total runtime is 0.8135665376981099 minutes
2023-08-01 06:57:22,134:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:22,134:INFO:Initializing create_model()
2023-08-01 06:57:22,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:22,134:INFO:Checking exceptions
2023-08-01 06:57:22,134:INFO:Importing libraries
2023-08-01 06:57:22,134:INFO:Copying training dataset
2023-08-01 06:57:22,142:INFO:Defining folds
2023-08-01 06:57:22,142:INFO:Declaring metric variables
2023-08-01 06:57:22,142:INFO:Importing untrained model
2023-08-01 06:57:22,142:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 06:57:22,150:INFO:Starting cross validation
2023-08-01 06:57:22,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:22,463:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,503:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,523:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,523:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,527:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,535:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,544:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,560:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,560:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:22,568:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 06:57:28,070:INFO:Calculating mean and std
2023-08-01 06:57:28,070:INFO:Creating metrics dataframe
2023-08-01 06:57:28,783:INFO:Uploading results into container
2023-08-01 06:57:28,783:INFO:Uploading model into container now
2023-08-01 06:57:28,783:INFO:_master_model_container: 8
2023-08-01 06:57:28,783:INFO:_display_container: 2
2023-08-01 06:57:28,783:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 06:57:28,783:INFO:create_model() successfully completed......................................
2023-08-01 06:57:28,887:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:28,887:INFO:Creating metrics dataframe
2023-08-01 06:57:28,895:INFO:Initializing Ada Boost Classifier
2023-08-01 06:57:28,895:INFO:Total runtime is 0.9262560804684957 minutes
2023-08-01 06:57:28,895:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:28,895:INFO:Initializing create_model()
2023-08-01 06:57:28,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:28,895:INFO:Checking exceptions
2023-08-01 06:57:28,895:INFO:Importing libraries
2023-08-01 06:57:28,895:INFO:Copying training dataset
2023-08-01 06:57:28,903:INFO:Defining folds
2023-08-01 06:57:28,903:INFO:Declaring metric variables
2023-08-01 06:57:28,903:INFO:Importing untrained model
2023-08-01 06:57:28,911:INFO:Ada Boost Classifier Imported successfully
2023-08-01 06:57:28,911:INFO:Starting cross validation
2023-08-01 06:57:28,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:35,688:INFO:Calculating mean and std
2023-08-01 06:57:35,688:INFO:Creating metrics dataframe
2023-08-01 06:57:36,403:INFO:Uploading results into container
2023-08-01 06:57:36,403:INFO:Uploading model into container now
2023-08-01 06:57:36,403:INFO:_master_model_container: 9
2023-08-01 06:57:36,403:INFO:_display_container: 2
2023-08-01 06:57:36,403:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 06:57:36,403:INFO:create_model() successfully completed......................................
2023-08-01 06:57:36,506:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:36,506:INFO:Creating metrics dataframe
2023-08-01 06:57:36,514:INFO:Initializing Gradient Boosting Classifier
2023-08-01 06:57:36,514:INFO:Total runtime is 1.0532360792160034 minutes
2023-08-01 06:57:36,514:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:36,514:INFO:Initializing create_model()
2023-08-01 06:57:36,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:36,514:INFO:Checking exceptions
2023-08-01 06:57:36,514:INFO:Importing libraries
2023-08-01 06:57:36,514:INFO:Copying training dataset
2023-08-01 06:57:36,522:INFO:Defining folds
2023-08-01 06:57:36,522:INFO:Declaring metric variables
2023-08-01 06:57:36,522:INFO:Importing untrained model
2023-08-01 06:57:36,522:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 06:57:36,530:INFO:Starting cross validation
2023-08-01 06:57:36,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:43,901:INFO:Calculating mean and std
2023-08-01 06:57:43,901:INFO:Creating metrics dataframe
2023-08-01 06:57:44,623:INFO:Uploading results into container
2023-08-01 06:57:44,631:INFO:Uploading model into container now
2023-08-01 06:57:44,631:INFO:_master_model_container: 10
2023-08-01 06:57:44,631:INFO:_display_container: 2
2023-08-01 06:57:44,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 06:57:44,631:INFO:create_model() successfully completed......................................
2023-08-01 06:57:44,728:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:44,728:INFO:Creating metrics dataframe
2023-08-01 06:57:44,736:INFO:Initializing Linear Discriminant Analysis
2023-08-01 06:57:44,736:INFO:Total runtime is 1.1902681509653728 minutes
2023-08-01 06:57:44,744:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:44,744:INFO:Initializing create_model()
2023-08-01 06:57:44,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:44,744:INFO:Checking exceptions
2023-08-01 06:57:44,744:INFO:Importing libraries
2023-08-01 06:57:44,744:INFO:Copying training dataset
2023-08-01 06:57:44,744:INFO:Defining folds
2023-08-01 06:57:44,744:INFO:Declaring metric variables
2023-08-01 06:57:44,744:INFO:Importing untrained model
2023-08-01 06:57:44,752:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 06:57:44,757:INFO:Starting cross validation
2023-08-01 06:57:44,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:50,861:INFO:Calculating mean and std
2023-08-01 06:57:50,861:INFO:Creating metrics dataframe
2023-08-01 06:57:51,595:INFO:Uploading results into container
2023-08-01 06:57:51,595:INFO:Uploading model into container now
2023-08-01 06:57:51,595:INFO:_master_model_container: 11
2023-08-01 06:57:51,595:INFO:_display_container: 2
2023-08-01 06:57:51,595:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 06:57:51,595:INFO:create_model() successfully completed......................................
2023-08-01 06:57:51,691:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:51,691:INFO:Creating metrics dataframe
2023-08-01 06:57:51,699:INFO:Initializing Extra Trees Classifier
2023-08-01 06:57:51,699:INFO:Total runtime is 1.3063135027885437 minutes
2023-08-01 06:57:51,707:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:51,707:INFO:Initializing create_model()
2023-08-01 06:57:51,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:51,707:INFO:Checking exceptions
2023-08-01 06:57:51,707:INFO:Importing libraries
2023-08-01 06:57:51,707:INFO:Copying training dataset
2023-08-01 06:57:51,707:INFO:Defining folds
2023-08-01 06:57:51,707:INFO:Declaring metric variables
2023-08-01 06:57:51,715:INFO:Importing untrained model
2023-08-01 06:57:51,715:INFO:Extra Trees Classifier Imported successfully
2023-08-01 06:57:51,715:INFO:Starting cross validation
2023-08-01 06:57:51,723:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:57:58,665:INFO:Calculating mean and std
2023-08-01 06:57:58,665:INFO:Creating metrics dataframe
2023-08-01 06:57:59,399:INFO:Uploading results into container
2023-08-01 06:57:59,399:INFO:Uploading model into container now
2023-08-01 06:57:59,399:INFO:_master_model_container: 12
2023-08-01 06:57:59,407:INFO:_display_container: 2
2023-08-01 06:57:59,407:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 06:57:59,407:INFO:create_model() successfully completed......................................
2023-08-01 06:57:59,505:INFO:SubProcess create_model() end ==================================
2023-08-01 06:57:59,505:INFO:Creating metrics dataframe
2023-08-01 06:57:59,513:INFO:Initializing Extreme Gradient Boosting
2023-08-01 06:57:59,513:INFO:Total runtime is 1.436544132232666 minutes
2023-08-01 06:57:59,513:INFO:SubProcess create_model() called ==================================
2023-08-01 06:57:59,513:INFO:Initializing create_model()
2023-08-01 06:57:59,513:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:57:59,513:INFO:Checking exceptions
2023-08-01 06:57:59,513:INFO:Importing libraries
2023-08-01 06:57:59,513:INFO:Copying training dataset
2023-08-01 06:57:59,521:INFO:Defining folds
2023-08-01 06:57:59,521:INFO:Declaring metric variables
2023-08-01 06:57:59,521:INFO:Importing untrained model
2023-08-01 06:57:59,521:INFO:Extreme Gradient Boosting Imported successfully
2023-08-01 06:57:59,529:INFO:Starting cross validation
2023-08-01 06:57:59,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:58:03,740:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.40s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:03,756:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:03,812:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.35s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:04,012:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:04,028:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.48s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:04,284:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:04,388:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:04,948:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:05,576:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:10,993:INFO:Calculating mean and std
2023-08-01 06:58:10,993:INFO:Creating metrics dataframe
2023-08-01 06:58:11,733:INFO:Uploading results into container
2023-08-01 06:58:11,733:INFO:Uploading model into container now
2023-08-01 06:58:11,733:INFO:_master_model_container: 13
2023-08-01 06:58:11,733:INFO:_display_container: 2
2023-08-01 06:58:11,733:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-01 06:58:11,733:INFO:create_model() successfully completed......................................
2023-08-01 06:58:11,830:INFO:SubProcess create_model() end ==================================
2023-08-01 06:58:11,830:INFO:Creating metrics dataframe
2023-08-01 06:58:11,839:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 06:58:11,839:INFO:Total runtime is 1.6419742544492086 minutes
2023-08-01 06:58:11,847:INFO:SubProcess create_model() called ==================================
2023-08-01 06:58:11,847:INFO:Initializing create_model()
2023-08-01 06:58:11,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:58:11,847:INFO:Checking exceptions
2023-08-01 06:58:11,847:INFO:Importing libraries
2023-08-01 06:58:11,847:INFO:Copying training dataset
2023-08-01 06:58:11,847:INFO:Defining folds
2023-08-01 06:58:11,847:INFO:Declaring metric variables
2023-08-01 06:58:11,847:INFO:Importing untrained model
2023-08-01 06:58:11,855:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 06:58:11,855:INFO:Starting cross validation
2023-08-01 06:58:11,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:58:13,967:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:13,991:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:15,143:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.23s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 06:58:20,331:INFO:Calculating mean and std
2023-08-01 06:58:20,331:INFO:Creating metrics dataframe
2023-08-01 06:58:21,099:INFO:Uploading results into container
2023-08-01 06:58:21,099:INFO:Uploading model into container now
2023-08-01 06:58:21,107:INFO:_master_model_container: 14
2023-08-01 06:58:21,107:INFO:_display_container: 2
2023-08-01 06:58:21,107:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 06:58:21,107:INFO:create_model() successfully completed......................................
2023-08-01 06:58:21,203:INFO:SubProcess create_model() end ==================================
2023-08-01 06:58:21,203:INFO:Creating metrics dataframe
2023-08-01 06:58:21,211:INFO:Initializing Dummy Classifier
2023-08-01 06:58:21,211:INFO:Total runtime is 1.7981811086336772 minutes
2023-08-01 06:58:21,219:INFO:SubProcess create_model() called ==================================
2023-08-01 06:58:21,219:INFO:Initializing create_model()
2023-08-01 06:58:21,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018506E58100>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:58:21,219:INFO:Checking exceptions
2023-08-01 06:58:21,219:INFO:Importing libraries
2023-08-01 06:58:21,219:INFO:Copying training dataset
2023-08-01 06:58:21,219:INFO:Defining folds
2023-08-01 06:58:21,219:INFO:Declaring metric variables
2023-08-01 06:58:21,219:INFO:Importing untrained model
2023-08-01 06:58:21,227:INFO:Dummy Classifier Imported successfully
2023-08-01 06:58:21,227:INFO:Starting cross validation
2023-08-01 06:58:21,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 06:58:21,597:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,629:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,653:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,661:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,661:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,669:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,677:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,685:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,694:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:21,694:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 06:58:27,193:INFO:Calculating mean and std
2023-08-01 06:58:27,193:INFO:Creating metrics dataframe
2023-08-01 06:58:27,929:INFO:Uploading results into container
2023-08-01 06:58:27,937:INFO:Uploading model into container now
2023-08-01 06:58:27,937:INFO:_master_model_container: 15
2023-08-01 06:58:27,937:INFO:_display_container: 2
2023-08-01 06:58:27,937:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 06:58:27,937:INFO:create_model() successfully completed......................................
2023-08-01 06:58:28,033:INFO:SubProcess create_model() end ==================================
2023-08-01 06:58:28,033:INFO:Creating metrics dataframe
2023-08-01 06:58:28,049:INFO:Initializing create_model()
2023-08-01 06:58:28,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018506AEE8B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 06:58:28,049:INFO:Checking exceptions
2023-08-01 06:58:28,049:INFO:Importing libraries
2023-08-01 06:58:28,049:INFO:Copying training dataset
2023-08-01 06:58:28,049:INFO:Defining folds
2023-08-01 06:58:28,049:INFO:Declaring metric variables
2023-08-01 06:58:28,049:INFO:Importing untrained model
2023-08-01 06:58:28,049:INFO:Declaring custom model
2023-08-01 06:58:28,049:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 06:58:28,057:INFO:Cross validation set to False
2023-08-01 06:58:28,057:INFO:Fitting Model
2023-08-01 06:58:28,193:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-01 06:58:28,193:INFO:[LightGBM] [Info] Number of positive: 1536, number of negative: 4972
2023-08-01 06:58:28,193:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.
2023-08-01 06:58:28,193:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-01 06:58:28,193:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-01 06:58:28,193:INFO:[LightGBM] [Info] Total Bins 676
2023-08-01 06:58:28,193:INFO:[LightGBM] [Info] Number of data points in the train set: 6508, number of used features: 93
2023-08-01 06:58:28,202:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.236017 -> initscore=-1.174641
2023-08-01 06:58:28,202:INFO:[LightGBM] [Info] Start training from score -1.174641
2023-08-01 06:58:28,844:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 06:58:28,844:INFO:create_model() successfully completed......................................
2023-08-01 06:58:28,965:INFO:_master_model_container: 15
2023-08-01 06:58:28,965:INFO:_display_container: 2
2023-08-01 06:58:28,965:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 06:58:28,965:INFO:compare_models() successfully completed......................................
2023-08-01 07:03:04,550:INFO:PyCaret ClassificationExperiment
2023-08-01 07:03:04,550:INFO:Logging name: clf-default-name
2023-08-01 07:03:04,550:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 07:03:04,550:INFO:version 3.0.4
2023-08-01 07:03:04,550:INFO:Initializing setup()
2023-08-01 07:03:04,550:INFO:self.USI: 953e
2023-08-01 07:03:04,550:INFO:self._variable_keys: {'y', 'y_train', 'X_test', 'html_param', 'fold_groups_param', 'target_param', '_available_plots', 'data', 'fold_generator', 'fix_imbalance', 'USI', 'logging_param', 'seed', 'n_jobs_param', 'y_test', 'log_plots_param', 'exp_id', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'pipeline', 'is_multiclass', 'gpu_param', 'idx', 'X_train', 'fold_shuffle_param', 'X', 'memory'}
2023-08-01 07:03:04,550:INFO:Checking environment
2023-08-01 07:03:04,550:INFO:python_version: 3.9.13
2023-08-01 07:03:04,551:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 07:03:04,551:INFO:machine: AMD64
2023-08-01 07:03:04,551:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-01 07:03:04,555:INFO:Memory: svmem(total=33737928704, available=21410328576, percent=36.5, used=12327600128, free=21410328576)
2023-08-01 07:03:04,555:INFO:Physical Core: 8
2023-08-01 07:03:04,555:INFO:Logical Core: 16
2023-08-01 07:03:04,555:INFO:Checking libraries
2023-08-01 07:03:04,555:INFO:System:
2023-08-01 07:03:04,555:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 07:03:04,555:INFO:executable: c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 07:03:04,555:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-01 07:03:04,555:INFO:PyCaret required dependencies:
2023-08-01 07:03:04,555:INFO:                 pip: 22.0.4
2023-08-01 07:03:04,555:INFO:          setuptools: 58.1.0
2023-08-01 07:03:04,555:INFO:             pycaret: 3.0.4
2023-08-01 07:03:04,555:INFO:             IPython: 8.13.1
2023-08-01 07:03:04,555:INFO:          ipywidgets: 8.0.7
2023-08-01 07:03:04,555:INFO:                tqdm: 4.65.0
2023-08-01 07:03:04,555:INFO:               numpy: 1.23.0
2023-08-01 07:03:04,555:INFO:              pandas: 1.5.3
2023-08-01 07:03:04,556:INFO:              jinja2: 3.1.2
2023-08-01 07:03:04,556:INFO:               scipy: 1.10.1
2023-08-01 07:03:04,556:INFO:              joblib: 1.3.1
2023-08-01 07:03:04,556:INFO:             sklearn: 1.2.2
2023-08-01 07:03:04,556:INFO:                pyod: 1.1.0
2023-08-01 07:03:04,556:INFO:            imblearn: 0.11.0
2023-08-01 07:03:04,556:INFO:   category_encoders: 2.6.1
2023-08-01 07:03:04,556:INFO:            lightgbm: 4.0.0
2023-08-01 07:03:04,556:INFO:               numba: 0.57.1
2023-08-01 07:03:04,556:INFO:            requests: 2.31.0
2023-08-01 07:03:04,556:INFO:          matplotlib: 3.7.1
2023-08-01 07:03:04,556:INFO:          scikitplot: 0.3.7
2023-08-01 07:03:04,556:INFO:         yellowbrick: 1.5
2023-08-01 07:03:04,556:INFO:              plotly: 5.15.0
2023-08-01 07:03:04,556:INFO:    plotly-resampler: Not installed
2023-08-01 07:03:04,556:INFO:             kaleido: 0.2.1
2023-08-01 07:03:04,556:INFO:           schemdraw: 0.15
2023-08-01 07:03:04,556:INFO:         statsmodels: 0.14.0
2023-08-01 07:03:04,556:INFO:              sktime: 0.20.1
2023-08-01 07:03:04,556:INFO:               tbats: 1.1.3
2023-08-01 07:03:04,556:INFO:            pmdarima: 2.0.3
2023-08-01 07:03:04,556:INFO:              psutil: 5.9.5
2023-08-01 07:03:04,556:INFO:          markupsafe: 2.1.3
2023-08-01 07:03:04,556:INFO:             pickle5: Not installed
2023-08-01 07:03:04,556:INFO:         cloudpickle: 2.2.1
2023-08-01 07:03:04,556:INFO:         deprecation: 2.1.0
2023-08-01 07:03:04,556:INFO:              xxhash: 3.2.0
2023-08-01 07:03:04,556:INFO:           wurlitzer: Not installed
2023-08-01 07:03:04,556:INFO:PyCaret optional dependencies:
2023-08-01 07:03:04,556:INFO:                shap: 0.42.1
2023-08-01 07:03:04,556:INFO:           interpret: Not installed
2023-08-01 07:03:04,556:INFO:                umap: 0.5.3
2023-08-01 07:03:04,556:INFO:    pandas_profiling: Not installed
2023-08-01 07:03:04,556:INFO:  explainerdashboard: 0.4.2.2
2023-08-01 07:03:04,556:INFO:             autoviz: 0.1.730
2023-08-01 07:03:04,556:INFO:           fairlearn: Not installed
2023-08-01 07:03:04,556:INFO:          deepchecks: Not installed
2023-08-01 07:03:04,556:INFO:             xgboost: 1.7.6
2023-08-01 07:03:04,556:INFO:            catboost: Not installed
2023-08-01 07:03:04,556:INFO:              kmodes: Not installed
2023-08-01 07:03:04,557:INFO:             mlxtend: Not installed
2023-08-01 07:03:04,557:INFO:       statsforecast: Not installed
2023-08-01 07:03:04,557:INFO:        tune_sklearn: Not installed
2023-08-01 07:03:04,557:INFO:                 ray: Not installed
2023-08-01 07:03:04,557:INFO:            hyperopt: Not installed
2023-08-01 07:03:04,557:INFO:              optuna: Not installed
2023-08-01 07:03:04,557:INFO:               skopt: Not installed
2023-08-01 07:03:04,557:INFO:              mlflow: Not installed
2023-08-01 07:03:04,557:INFO:              gradio: Not installed
2023-08-01 07:03:04,557:INFO:             fastapi: Not installed
2023-08-01 07:03:04,557:INFO:             uvicorn: Not installed
2023-08-01 07:03:04,557:INFO:              m2cgen: Not installed
2023-08-01 07:03:04,557:INFO:           evidently: Not installed
2023-08-01 07:03:04,557:INFO:               fugue: Not installed
2023-08-01 07:03:04,557:INFO:           streamlit: Not installed
2023-08-01 07:03:04,557:INFO:             prophet: Not installed
2023-08-01 07:03:04,557:INFO:None
2023-08-01 07:03:04,557:INFO:Set up data.
2023-08-01 07:03:04,563:INFO:Set up train/test split.
2023-08-01 07:03:04,567:INFO:Set up index.
2023-08-01 07:03:04,568:INFO:Set up folding strategy.
2023-08-01 07:03:04,568:INFO:Assigning column types.
2023-08-01 07:03:04,570:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 07:03:04,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,625:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,661:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,682:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,685:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,685:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 07:03:04,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,739:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,775:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 07:03:04,796:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,798:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 07:03:04,852:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,909:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:04,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:04,912:INFO:Preparing preprocessing pipeline...
2023-08-01 07:03:04,913:INFO:Set up simple imputation.
2023-08-01 07:03:04,915:INFO:Set up encoding of categorical features.
2023-08-01 07:03:04,915:INFO:Set up polynomial features.
2023-08-01 07:03:04,915:INFO:Set up removing multicollinearity.
2023-08-01 07:03:04,915:INFO:Set up feature normalization.
2023-08-01 07:03:20,230:INFO:Finished creating preprocessing pipeline.
2023-08-01 07:03:20,327:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\ASUS\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests',
                                             'Cluster'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=No...
                                    transformer=PolynomialFeatures(degree=3,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 07:03:20,327:INFO:Creating final display dataframe.
2023-08-01 07:03:21,156:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15          Polynomial features   
16            Polynomial degree   
17     Remove multicollinearity   
18  Multicollinearity threshold   
19                    Normalize   
20             Normalize method   
21               Fold Generator   
22                  Fold Number   
23                     CPU Jobs   
24                      Use GPU   
25               Log Experiment   
26              Experiment Name   
27                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 11)  
4                                         (8136, 651)  
5                                         (6508, 651)  
6                                         (1628, 651)  
7                                                   6  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                  3  
17                                               True  
18                                                0.8  
19                                               True  
20                                             zscore  
21                                    StratifiedKFold  
22                                                 10  
23                                                 -1  
24                                              False  
25                                              False  
26                                   clf-default-name  
27                                               953e  
2023-08-01 07:03:21,220:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:21,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:21,278:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-01 07:03:21,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 07:03:21,280:INFO:setup() successfully completed in 17.33s...............
2023-08-01 07:05:17,333:INFO:Initializing compare_models()
2023-08-01 07:05:17,334:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 07:05:17,334:INFO:Checking exceptions
2023-08-01 07:05:17,337:INFO:Preparing display monitor
2023-08-01 07:05:17,350:INFO:Initializing Logistic Regression
2023-08-01 07:05:17,350:INFO:Total runtime is 0.0 minutes
2023-08-01 07:05:17,352:INFO:SubProcess create_model() called ==================================
2023-08-01 07:05:17,353:INFO:Initializing create_model()
2023-08-01 07:05:17,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:05:17,353:INFO:Checking exceptions
2023-08-01 07:05:17,353:INFO:Importing libraries
2023-08-01 07:05:17,353:INFO:Copying training dataset
2023-08-01 07:05:17,357:INFO:Defining folds
2023-08-01 07:05:17,357:INFO:Declaring metric variables
2023-08-01 07:05:17,360:INFO:Importing untrained model
2023-08-01 07:05:17,363:INFO:Logistic Regression Imported successfully
2023-08-01 07:05:17,367:INFO:Starting cross validation
2023-08-01 07:05:17,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:05:39,352:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:45,781:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:45,906:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:45,990:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,085:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,179:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,338:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,430:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,528:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:46,553:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:51,151:INFO:Calculating mean and std
2023-08-01 07:05:51,151:INFO:Creating metrics dataframe
2023-08-01 07:05:51,908:INFO:Uploading results into container
2023-08-01 07:05:51,909:INFO:Uploading model into container now
2023-08-01 07:05:51,909:INFO:_master_model_container: 1
2023-08-01 07:05:51,910:INFO:_display_container: 2
2023-08-01 07:05:51,910:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 07:05:51,910:INFO:create_model() successfully completed......................................
2023-08-01 07:05:52,017:INFO:SubProcess create_model() end ==================================
2023-08-01 07:05:52,017:INFO:Creating metrics dataframe
2023-08-01 07:05:52,022:INFO:Initializing K Neighbors Classifier
2023-08-01 07:05:52,022:INFO:Total runtime is 0.5778551419576009 minutes
2023-08-01 07:05:52,024:INFO:SubProcess create_model() called ==================================
2023-08-01 07:05:52,025:INFO:Initializing create_model()
2023-08-01 07:05:52,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:05:52,025:INFO:Checking exceptions
2023-08-01 07:05:52,025:INFO:Importing libraries
2023-08-01 07:05:52,025:INFO:Copying training dataset
2023-08-01 07:05:52,028:INFO:Defining folds
2023-08-01 07:05:52,028:INFO:Declaring metric variables
2023-08-01 07:05:52,031:INFO:Importing untrained model
2023-08-01 07:05:52,034:INFO:K Neighbors Classifier Imported successfully
2023-08-01 07:05:52,038:INFO:Starting cross validation
2023-08-01 07:05:52,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:05:53,418:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:53,446:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:53,461:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:53,469:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:55,649:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:55,702:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:05:56,046:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.54s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:00,046:INFO:Calculating mean and std
2023-08-01 07:06:00,047:INFO:Creating metrics dataframe
2023-08-01 07:06:00,791:INFO:Uploading results into container
2023-08-01 07:06:00,792:INFO:Uploading model into container now
2023-08-01 07:06:00,792:INFO:_master_model_container: 2
2023-08-01 07:06:00,792:INFO:_display_container: 2
2023-08-01 07:06:00,792:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 07:06:00,792:INFO:create_model() successfully completed......................................
2023-08-01 07:06:00,894:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:00,894:INFO:Creating metrics dataframe
2023-08-01 07:06:00,901:INFO:Initializing Naive Bayes
2023-08-01 07:06:00,901:INFO:Total runtime is 0.725845710436503 minutes
2023-08-01 07:06:00,903:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:00,903:INFO:Initializing create_model()
2023-08-01 07:06:00,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:00,903:INFO:Checking exceptions
2023-08-01 07:06:00,904:INFO:Importing libraries
2023-08-01 07:06:00,904:INFO:Copying training dataset
2023-08-01 07:06:00,908:INFO:Defining folds
2023-08-01 07:06:00,908:INFO:Declaring metric variables
2023-08-01 07:06:00,910:INFO:Importing untrained model
2023-08-01 07:06:00,913:INFO:Naive Bayes Imported successfully
2023-08-01 07:06:00,917:INFO:Starting cross validation
2023-08-01 07:06:00,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:02,613:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,643:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,650:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,653:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,679:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,758:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,797:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,833:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,834:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:02,850:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:08,612:INFO:Calculating mean and std
2023-08-01 07:06:08,614:INFO:Creating metrics dataframe
2023-08-01 07:06:09,376:INFO:Uploading results into container
2023-08-01 07:06:09,377:INFO:Uploading model into container now
2023-08-01 07:06:09,377:INFO:_master_model_container: 3
2023-08-01 07:06:09,377:INFO:_display_container: 2
2023-08-01 07:06:09,377:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 07:06:09,377:INFO:create_model() successfully completed......................................
2023-08-01 07:06:09,480:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:09,480:INFO:Creating metrics dataframe
2023-08-01 07:06:09,487:INFO:Initializing Decision Tree Classifier
2023-08-01 07:06:09,487:INFO:Total runtime is 0.8689428806304931 minutes
2023-08-01 07:06:09,489:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:09,489:INFO:Initializing create_model()
2023-08-01 07:06:09,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:09,489:INFO:Checking exceptions
2023-08-01 07:06:09,489:INFO:Importing libraries
2023-08-01 07:06:09,490:INFO:Copying training dataset
2023-08-01 07:06:09,493:INFO:Defining folds
2023-08-01 07:06:09,493:INFO:Declaring metric variables
2023-08-01 07:06:09,496:INFO:Importing untrained model
2023-08-01 07:06:09,499:INFO:Decision Tree Classifier Imported successfully
2023-08-01 07:06:09,503:INFO:Starting cross validation
2023-08-01 07:06:09,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:11,114:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,134:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,138:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,185:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,260:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,301:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,321:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,340:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,347:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:11,351:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:17,190:INFO:Calculating mean and std
2023-08-01 07:06:17,191:INFO:Creating metrics dataframe
2023-08-01 07:06:17,985:INFO:Uploading results into container
2023-08-01 07:06:17,986:INFO:Uploading model into container now
2023-08-01 07:06:17,986:INFO:_master_model_container: 4
2023-08-01 07:06:17,986:INFO:_display_container: 2
2023-08-01 07:06:17,986:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 07:06:17,986:INFO:create_model() successfully completed......................................
2023-08-01 07:06:18,089:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:18,089:INFO:Creating metrics dataframe
2023-08-01 07:06:18,097:INFO:Initializing SVM - Linear Kernel
2023-08-01 07:06:18,097:INFO:Total runtime is 1.0124420046806335 minutes
2023-08-01 07:06:18,100:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:18,100:INFO:Initializing create_model()
2023-08-01 07:06:18,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:18,100:INFO:Checking exceptions
2023-08-01 07:06:18,100:INFO:Importing libraries
2023-08-01 07:06:18,100:INFO:Copying training dataset
2023-08-01 07:06:18,104:INFO:Defining folds
2023-08-01 07:06:18,104:INFO:Declaring metric variables
2023-08-01 07:06:18,106:INFO:Importing untrained model
2023-08-01 07:06:18,109:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 07:06:18,113:INFO:Starting cross validation
2023-08-01 07:06:18,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:20,385:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,394:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,429:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,436:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,504:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,514:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,549:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,559:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,572:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,581:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,603:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,608:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,622:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,633:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,641:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,649:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,845:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:20,853:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:20,991:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:21,001:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 07:06:26,563:INFO:Calculating mean and std
2023-08-01 07:06:26,564:INFO:Creating metrics dataframe
2023-08-01 07:06:27,337:INFO:Uploading results into container
2023-08-01 07:06:27,338:INFO:Uploading model into container now
2023-08-01 07:06:27,338:INFO:_master_model_container: 5
2023-08-01 07:06:27,338:INFO:_display_container: 2
2023-08-01 07:06:27,338:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 07:06:27,338:INFO:create_model() successfully completed......................................
2023-08-01 07:06:27,442:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:27,442:INFO:Creating metrics dataframe
2023-08-01 07:06:27,449:INFO:Initializing Ridge Classifier
2023-08-01 07:06:27,449:INFO:Total runtime is 1.1683077295621236 minutes
2023-08-01 07:06:27,452:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:27,452:INFO:Initializing create_model()
2023-08-01 07:06:27,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:27,452:INFO:Checking exceptions
2023-08-01 07:06:27,452:INFO:Importing libraries
2023-08-01 07:06:27,452:INFO:Copying training dataset
2023-08-01 07:06:27,456:INFO:Defining folds
2023-08-01 07:06:27,456:INFO:Declaring metric variables
2023-08-01 07:06:27,458:INFO:Importing untrained model
2023-08-01 07:06:27,460:INFO:Ridge Classifier Imported successfully
2023-08-01 07:06:27,465:INFO:Starting cross validation
2023-08-01 07:06:27,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:29,311:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,320:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,321:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,322:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,328:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,330:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,333:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,333:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,337:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,339:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,342:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,345:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,360:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,366:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,393:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,399:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,402:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,405:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:29,429:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:29,436:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 07:06:35,686:INFO:Calculating mean and std
2023-08-01 07:06:35,687:INFO:Creating metrics dataframe
2023-08-01 07:06:36,503:INFO:Uploading results into container
2023-08-01 07:06:36,503:INFO:Uploading model into container now
2023-08-01 07:06:36,504:INFO:_master_model_container: 6
2023-08-01 07:06:36,504:INFO:_display_container: 2
2023-08-01 07:06:36,504:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 07:06:36,504:INFO:create_model() successfully completed......................................
2023-08-01 07:06:36,609:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:36,609:INFO:Creating metrics dataframe
2023-08-01 07:06:36,616:INFO:Initializing Random Forest Classifier
2023-08-01 07:06:36,616:INFO:Total runtime is 1.3210986097653707 minutes
2023-08-01 07:06:36,618:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:36,619:INFO:Initializing create_model()
2023-08-01 07:06:36,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:36,619:INFO:Checking exceptions
2023-08-01 07:06:36,619:INFO:Importing libraries
2023-08-01 07:06:36,619:INFO:Copying training dataset
2023-08-01 07:06:36,623:INFO:Defining folds
2023-08-01 07:06:36,623:INFO:Declaring metric variables
2023-08-01 07:06:36,626:INFO:Importing untrained model
2023-08-01 07:06:36,628:INFO:Random Forest Classifier Imported successfully
2023-08-01 07:06:36,632:INFO:Starting cross validation
2023-08-01 07:06:36,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:39,525:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:06:39,965:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:06:41,755:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:41,759:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,085:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,093:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,107:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,123:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,131:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,135:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,155:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:42,186:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:48,384:INFO:Calculating mean and std
2023-08-01 07:06:48,385:INFO:Creating metrics dataframe
2023-08-01 07:06:49,171:INFO:Uploading results into container
2023-08-01 07:06:49,171:INFO:Uploading model into container now
2023-08-01 07:06:49,172:INFO:_master_model_container: 7
2023-08-01 07:06:49,172:INFO:_display_container: 2
2023-08-01 07:06:49,172:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 07:06:49,172:INFO:create_model() successfully completed......................................
2023-08-01 07:06:49,276:INFO:SubProcess create_model() end ==================================
2023-08-01 07:06:49,276:INFO:Creating metrics dataframe
2023-08-01 07:06:49,283:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 07:06:49,283:INFO:Total runtime is 1.5322168310483297 minutes
2023-08-01 07:06:49,285:INFO:SubProcess create_model() called ==================================
2023-08-01 07:06:49,286:INFO:Initializing create_model()
2023-08-01 07:06:49,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:06:49,286:INFO:Checking exceptions
2023-08-01 07:06:49,286:INFO:Importing libraries
2023-08-01 07:06:49,286:INFO:Copying training dataset
2023-08-01 07:06:49,291:INFO:Defining folds
2023-08-01 07:06:49,291:INFO:Declaring metric variables
2023-08-01 07:06:49,294:INFO:Importing untrained model
2023-08-01 07:06:49,295:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 07:06:49,299:INFO:Starting cross validation
2023-08-01 07:06:49,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:06:51,194:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,399:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,415:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,425:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,433:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,441:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,452:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,453:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,492:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:51,586:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 07:06:53,322:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,397:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,414:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,435:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,435:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,435:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,446:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,461:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,465:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:53,496:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:06:59,854:INFO:Calculating mean and std
2023-08-01 07:06:59,855:INFO:Creating metrics dataframe
2023-08-01 07:07:00,663:INFO:Uploading results into container
2023-08-01 07:07:00,664:INFO:Uploading model into container now
2023-08-01 07:07:00,665:INFO:_master_model_container: 8
2023-08-01 07:07:00,665:INFO:_display_container: 2
2023-08-01 07:07:00,666:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 07:07:00,666:INFO:create_model() successfully completed......................................
2023-08-01 07:07:00,773:INFO:SubProcess create_model() end ==================================
2023-08-01 07:07:00,773:INFO:Creating metrics dataframe
2023-08-01 07:07:00,781:INFO:Initializing Ada Boost Classifier
2023-08-01 07:07:00,781:INFO:Total runtime is 1.7238410512606304 minutes
2023-08-01 07:07:00,783:INFO:SubProcess create_model() called ==================================
2023-08-01 07:07:00,783:INFO:Initializing create_model()
2023-08-01 07:07:00,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:07:00,783:INFO:Checking exceptions
2023-08-01 07:07:00,783:INFO:Importing libraries
2023-08-01 07:07:00,783:INFO:Copying training dataset
2023-08-01 07:07:00,787:INFO:Defining folds
2023-08-01 07:07:00,787:INFO:Declaring metric variables
2023-08-01 07:07:00,789:INFO:Importing untrained model
2023-08-01 07:07:00,792:INFO:Ada Boost Classifier Imported successfully
2023-08-01 07:07:00,796:INFO:Starting cross validation
2023-08-01 07:07:00,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:07:06,021:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,125:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,133:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,136:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,165:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,184:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,188:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,191:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,274:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:06,322:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:12,638:INFO:Calculating mean and std
2023-08-01 07:07:12,639:INFO:Creating metrics dataframe
2023-08-01 07:07:13,446:INFO:Uploading results into container
2023-08-01 07:07:13,447:INFO:Uploading model into container now
2023-08-01 07:07:13,447:INFO:_master_model_container: 9
2023-08-01 07:07:13,448:INFO:_display_container: 2
2023-08-01 07:07:13,448:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 07:07:13,448:INFO:create_model() successfully completed......................................
2023-08-01 07:07:13,553:INFO:SubProcess create_model() end ==================================
2023-08-01 07:07:13,553:INFO:Creating metrics dataframe
2023-08-01 07:07:13,561:INFO:Initializing Gradient Boosting Classifier
2023-08-01 07:07:13,561:INFO:Total runtime is 1.9368367870648702 minutes
2023-08-01 07:07:13,563:INFO:SubProcess create_model() called ==================================
2023-08-01 07:07:13,564:INFO:Initializing create_model()
2023-08-01 07:07:13,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:07:13,564:INFO:Checking exceptions
2023-08-01 07:07:13,564:INFO:Importing libraries
2023-08-01 07:07:13,564:INFO:Copying training dataset
2023-08-01 07:07:13,567:INFO:Defining folds
2023-08-01 07:07:13,567:INFO:Declaring metric variables
2023-08-01 07:07:13,570:INFO:Importing untrained model
2023-08-01 07:07:13,571:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 07:07:13,576:INFO:Starting cross validation
2023-08-01 07:07:13,582:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:07:17,943:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,449:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,476:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,478:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,496:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,507:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,537:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,561:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,587:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:18,597:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:24,452:INFO:Calculating mean and std
2023-08-01 07:07:24,453:INFO:Creating metrics dataframe
2023-08-01 07:07:25,260:INFO:Uploading results into container
2023-08-01 07:07:25,261:INFO:Uploading model into container now
2023-08-01 07:07:25,261:INFO:_master_model_container: 10
2023-08-01 07:07:25,261:INFO:_display_container: 2
2023-08-01 07:07:25,261:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 07:07:25,262:INFO:create_model() successfully completed......................................
2023-08-01 07:07:25,365:INFO:SubProcess create_model() end ==================================
2023-08-01 07:07:25,365:INFO:Creating metrics dataframe
2023-08-01 07:07:25,373:INFO:Initializing Linear Discriminant Analysis
2023-08-01 07:07:25,374:INFO:Total runtime is 2.1337334791819256 minutes
2023-08-01 07:07:25,377:INFO:SubProcess create_model() called ==================================
2023-08-01 07:07:25,377:INFO:Initializing create_model()
2023-08-01 07:07:25,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:07:25,377:INFO:Checking exceptions
2023-08-01 07:07:25,377:INFO:Importing libraries
2023-08-01 07:07:25,377:INFO:Copying training dataset
2023-08-01 07:07:25,381:INFO:Defining folds
2023-08-01 07:07:25,381:INFO:Declaring metric variables
2023-08-01 07:07:25,384:INFO:Importing untrained model
2023-08-01 07:07:25,387:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 07:07:25,390:INFO:Starting cross validation
2023-08-01 07:07:25,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:07:28,779:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,796:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,854:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,864:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,869:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,879:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,898:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,908:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,948:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:28,951:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:35,189:INFO:Calculating mean and std
2023-08-01 07:07:35,190:INFO:Creating metrics dataframe
2023-08-01 07:07:36,014:INFO:Uploading results into container
2023-08-01 07:07:36,015:INFO:Uploading model into container now
2023-08-01 07:07:36,015:INFO:_master_model_container: 11
2023-08-01 07:07:36,015:INFO:_display_container: 2
2023-08-01 07:07:36,016:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 07:07:36,016:INFO:create_model() successfully completed......................................
2023-08-01 07:07:36,120:INFO:SubProcess create_model() end ==================================
2023-08-01 07:07:36,120:INFO:Creating metrics dataframe
2023-08-01 07:07:36,129:INFO:Initializing Extra Trees Classifier
2023-08-01 07:07:36,129:INFO:Total runtime is 2.312971059481303 minutes
2023-08-01 07:07:36,132:INFO:SubProcess create_model() called ==================================
2023-08-01 07:07:36,132:INFO:Initializing create_model()
2023-08-01 07:07:36,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:07:36,132:INFO:Checking exceptions
2023-08-01 07:07:36,132:INFO:Importing libraries
2023-08-01 07:07:36,132:INFO:Copying training dataset
2023-08-01 07:07:36,136:INFO:Defining folds
2023-08-01 07:07:36,136:INFO:Declaring metric variables
2023-08-01 07:07:36,138:INFO:Importing untrained model
2023-08-01 07:07:36,140:INFO:Extra Trees Classifier Imported successfully
2023-08-01 07:07:36,144:INFO:Starting cross validation
2023-08-01 07:07:36,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:07:40,093:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:40,159:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:40,189:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:40,337:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:40,745:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:40,884:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

2023-08-01 07:07:41,825:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:41,829:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:41,844:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:41,901:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:41,912:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:42,130:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:42,164:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:42,164:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:42,164:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:42,416:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:07:48,417:INFO:Calculating mean and std
2023-08-01 07:07:48,418:INFO:Creating metrics dataframe
2023-08-01 07:07:49,270:INFO:Uploading results into container
2023-08-01 07:07:49,271:INFO:Uploading model into container now
2023-08-01 07:07:49,271:INFO:_master_model_container: 12
2023-08-01 07:07:49,271:INFO:_display_container: 2
2023-08-01 07:07:49,271:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 07:07:49,271:INFO:create_model() successfully completed......................................
2023-08-01 07:07:49,374:INFO:SubProcess create_model() end ==================================
2023-08-01 07:07:49,374:INFO:Creating metrics dataframe
2023-08-01 07:07:49,382:INFO:Initializing Extreme Gradient Boosting
2023-08-01 07:07:49,382:INFO:Total runtime is 2.5338662664095564 minutes
2023-08-01 07:07:49,385:INFO:SubProcess create_model() called ==================================
2023-08-01 07:07:49,385:INFO:Initializing create_model()
2023-08-01 07:07:49,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:07:49,385:INFO:Checking exceptions
2023-08-01 07:07:49,385:INFO:Importing libraries
2023-08-01 07:07:49,385:INFO:Copying training dataset
2023-08-01 07:07:49,389:INFO:Defining folds
2023-08-01 07:07:49,389:INFO:Declaring metric variables
2023-08-01 07:07:49,391:INFO:Importing untrained model
2023-08-01 07:07:49,394:INFO:Extreme Gradient Boosting Imported successfully
2023-08-01 07:07:49,397:INFO:Starting cross validation
2023-08-01 07:07:49,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:07:53,984:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:01,576:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,172:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,259:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,284:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,309:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,447:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,453:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,476:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:02,624:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:07,572:INFO:Calculating mean and std
2023-08-01 07:08:07,573:INFO:Creating metrics dataframe
2023-08-01 07:08:08,414:INFO:Uploading results into container
2023-08-01 07:08:08,415:INFO:Uploading model into container now
2023-08-01 07:08:08,415:INFO:_master_model_container: 13
2023-08-01 07:08:08,415:INFO:_display_container: 2
2023-08-01 07:08:08,416:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-01 07:08:08,416:INFO:create_model() successfully completed......................................
2023-08-01 07:08:08,519:INFO:SubProcess create_model() end ==================================
2023-08-01 07:08:08,519:INFO:Creating metrics dataframe
2023-08-01 07:08:08,527:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 07:08:08,527:INFO:Total runtime is 2.8529500166575117 minutes
2023-08-01 07:08:08,530:INFO:SubProcess create_model() called ==================================
2023-08-01 07:08:08,530:INFO:Initializing create_model()
2023-08-01 07:08:08,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:08:08,530:INFO:Checking exceptions
2023-08-01 07:08:08,530:INFO:Importing libraries
2023-08-01 07:08:08,530:INFO:Copying training dataset
2023-08-01 07:08:08,535:INFO:Defining folds
2023-08-01 07:08:08,535:INFO:Declaring metric variables
2023-08-01 07:08:08,537:INFO:Importing untrained model
2023-08-01 07:08:08,539:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 07:08:08,543:INFO:Starting cross validation
2023-08-01 07:08:08,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:08:11,086:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:11,122:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:11,169:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:11,180:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:11,906:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.18s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:13,328:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.40s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:14,020:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:14,128:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:14,591:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:14,689:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:18,750:INFO:Calculating mean and std
2023-08-01 07:08:18,751:INFO:Creating metrics dataframe
2023-08-01 07:08:19,609:INFO:Uploading results into container
2023-08-01 07:08:19,610:INFO:Uploading model into container now
2023-08-01 07:08:19,610:INFO:_master_model_container: 14
2023-08-01 07:08:19,610:INFO:_display_container: 2
2023-08-01 07:08:19,611:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 07:08:19,611:INFO:create_model() successfully completed......................................
2023-08-01 07:08:19,718:INFO:SubProcess create_model() end ==================================
2023-08-01 07:08:19,718:INFO:Creating metrics dataframe
2023-08-01 07:08:19,726:INFO:Initializing Dummy Classifier
2023-08-01 07:08:19,726:INFO:Total runtime is 3.0396004756291712 minutes
2023-08-01 07:08:19,728:INFO:SubProcess create_model() called ==================================
2023-08-01 07:08:19,728:INFO:Initializing create_model()
2023-08-01 07:08:19,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001850615BB80>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:08:19,729:INFO:Checking exceptions
2023-08-01 07:08:19,729:INFO:Importing libraries
2023-08-01 07:08:19,729:INFO:Copying training dataset
2023-08-01 07:08:19,733:INFO:Defining folds
2023-08-01 07:08:19,733:INFO:Declaring metric variables
2023-08-01 07:08:19,735:INFO:Importing untrained model
2023-08-01 07:08:19,738:INFO:Dummy Classifier Imported successfully
2023-08-01 07:08:19,742:INFO:Starting cross validation
2023-08-01 07:08:19,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 07:08:20,962:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:20,963:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,002:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,020:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,021:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,022:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,025:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,049:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,052:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,057:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,064:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,066:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,072:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 07:08:21,085:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,093:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,117:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,118:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,119:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,119:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:21,134:WARNING:c:\Users\ASUS\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 07:08:27,472:INFO:Calculating mean and std
2023-08-01 07:08:27,473:INFO:Creating metrics dataframe
2023-08-01 07:08:28,324:INFO:Uploading results into container
2023-08-01 07:08:28,325:INFO:Uploading model into container now
2023-08-01 07:08:28,325:INFO:_master_model_container: 15
2023-08-01 07:08:28,325:INFO:_display_container: 2
2023-08-01 07:08:28,325:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 07:08:28,325:INFO:create_model() successfully completed......................................
2023-08-01 07:08:28,428:INFO:SubProcess create_model() end ==================================
2023-08-01 07:08:28,429:INFO:Creating metrics dataframe
2023-08-01 07:08:28,443:INFO:Initializing create_model()
2023-08-01 07:08:28,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001850618F040>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 07:08:28,443:INFO:Checking exceptions
2023-08-01 07:08:28,445:INFO:Importing libraries
2023-08-01 07:08:28,445:INFO:Copying training dataset
2023-08-01 07:08:28,449:INFO:Defining folds
2023-08-01 07:08:28,449:INFO:Declaring metric variables
2023-08-01 07:08:28,449:INFO:Importing untrained model
2023-08-01 07:08:28,449:INFO:Declaring custom model
2023-08-01 07:08:28,449:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 07:08:28,453:INFO:Cross validation set to False
2023-08-01 07:08:28,453:INFO:Fitting Model
2023-08-01 07:08:28,788:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-01 07:08:28,789:INFO:[LightGBM] [Info] Number of positive: 1536, number of negative: 4972
2023-08-01 07:08:28,794:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002440 seconds.
2023-08-01 07:08:28,794:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-01 07:08:28,794:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-01 07:08:28,795:INFO:[LightGBM] [Info] Total Bins 1472
2023-08-01 07:08:28,795:INFO:[LightGBM] [Info] Number of data points in the train set: 6508, number of used features: 222
2023-08-01 07:08:28,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.236017 -> initscore=-1.174641
2023-08-01 07:08:28,796:INFO:[LightGBM] [Info] Start training from score -1.174641
2023-08-01 07:08:29,722:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 07:08:29,722:INFO:create_model() successfully completed......................................
2023-08-01 07:08:29,843:INFO:_master_model_container: 15
2023-08-01 07:08:29,843:INFO:_display_container: 2
2023-08-01 07:08:29,844:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-01 07:08:29,844:INFO:compare_models() successfully completed......................................
2023-08-01 18:51:19,918:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 18:51:19,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 18:51:19,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 18:51:19,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 18:51:24,812:INFO:PyCaret ClassificationExperiment
2023-08-01 18:51:24,812:INFO:Logging name: clf-default-name
2023-08-01 18:51:24,812:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 18:51:24,812:INFO:version 3.0.4
2023-08-01 18:51:24,812:INFO:Initializing setup()
2023-08-01 18:51:24,812:INFO:self.USI: 990e
2023-08-01 18:51:24,812:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 18:51:24,812:INFO:Checking environment
2023-08-01 18:51:24,812:INFO:python_version: 3.9.13
2023-08-01 18:51:24,812:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 18:51:24,812:INFO:machine: AMD64
2023-08-01 18:51:24,812:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 18:51:24,815:INFO:Memory: svmem(total=17055166464, available=9910628352, percent=41.9, used=7144538112, free=9910628352)
2023-08-01 18:51:24,815:INFO:Physical Core: 4
2023-08-01 18:51:24,815:INFO:Logical Core: 8
2023-08-01 18:51:24,815:INFO:Checking libraries
2023-08-01 18:51:24,815:INFO:System:
2023-08-01 18:51:24,815:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 18:51:24,815:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 18:51:24,815:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 18:51:24,816:INFO:PyCaret required dependencies:
2023-08-01 18:51:24,818:INFO:                 pip: 22.0.4
2023-08-01 18:51:24,818:INFO:          setuptools: 58.1.0
2023-08-01 18:51:24,818:INFO:             pycaret: 3.0.4
2023-08-01 18:51:24,818:INFO:             IPython: 8.13.1
2023-08-01 18:51:24,818:INFO:          ipywidgets: 8.0.7
2023-08-01 18:51:24,818:INFO:                tqdm: 4.65.0
2023-08-01 18:51:24,818:INFO:               numpy: 1.23.0
2023-08-01 18:51:24,818:INFO:              pandas: 1.5.3
2023-08-01 18:51:24,818:INFO:              jinja2: 3.1.2
2023-08-01 18:51:24,818:INFO:               scipy: 1.10.1
2023-08-01 18:51:24,818:INFO:              joblib: 1.2.0
2023-08-01 18:51:24,818:INFO:             sklearn: 1.2.2
2023-08-01 18:51:24,818:INFO:                pyod: 1.1.0
2023-08-01 18:51:24,818:INFO:            imblearn: 0.11.0
2023-08-01 18:51:24,818:INFO:   category_encoders: 2.6.1
2023-08-01 18:51:24,818:INFO:            lightgbm: 3.3.5
2023-08-01 18:51:24,819:INFO:               numba: 0.57.1
2023-08-01 18:51:24,819:INFO:            requests: 2.31.0
2023-08-01 18:51:24,819:INFO:          matplotlib: 3.7.1
2023-08-01 18:51:24,819:INFO:          scikitplot: 0.3.7
2023-08-01 18:51:24,819:INFO:         yellowbrick: 1.5
2023-08-01 18:51:24,819:INFO:              plotly: 5.15.0
2023-08-01 18:51:24,819:INFO:    plotly-resampler: Not installed
2023-08-01 18:51:24,819:INFO:             kaleido: 0.2.1
2023-08-01 18:51:24,819:INFO:           schemdraw: 0.15
2023-08-01 18:51:24,819:INFO:         statsmodels: 0.14.0
2023-08-01 18:51:24,819:INFO:              sktime: 0.20.0
2023-08-01 18:51:24,819:INFO:               tbats: 1.1.3
2023-08-01 18:51:24,819:INFO:            pmdarima: 2.0.3
2023-08-01 18:51:24,819:INFO:              psutil: 5.9.5
2023-08-01 18:51:24,819:INFO:          markupsafe: 2.1.3
2023-08-01 18:51:24,819:INFO:             pickle5: Not installed
2023-08-01 18:51:24,819:INFO:         cloudpickle: 2.2.1
2023-08-01 18:51:24,819:INFO:         deprecation: 2.1.0
2023-08-01 18:51:24,819:INFO:              xxhash: 3.2.0
2023-08-01 18:51:24,820:INFO:           wurlitzer: Not installed
2023-08-01 18:51:24,820:INFO:PyCaret optional dependencies:
2023-08-01 18:51:24,837:INFO:                shap: Not installed
2023-08-01 18:51:24,837:INFO:           interpret: Not installed
2023-08-01 18:51:24,837:INFO:                umap: Not installed
2023-08-01 18:51:24,837:INFO:    pandas_profiling: 4.3.1
2023-08-01 18:51:24,837:INFO:  explainerdashboard: Not installed
2023-08-01 18:51:24,837:INFO:             autoviz: Not installed
2023-08-01 18:51:24,837:INFO:           fairlearn: Not installed
2023-08-01 18:51:24,837:INFO:          deepchecks: Not installed
2023-08-01 18:51:24,837:INFO:             xgboost: Not installed
2023-08-01 18:51:24,837:INFO:            catboost: Not installed
2023-08-01 18:51:24,837:INFO:              kmodes: Not installed
2023-08-01 18:51:24,837:INFO:             mlxtend: 0.22.0
2023-08-01 18:51:24,839:INFO:       statsforecast: Not installed
2023-08-01 18:51:24,839:INFO:        tune_sklearn: Not installed
2023-08-01 18:51:24,839:INFO:                 ray: Not installed
2023-08-01 18:51:24,839:INFO:            hyperopt: Not installed
2023-08-01 18:51:24,839:INFO:              optuna: Not installed
2023-08-01 18:51:24,839:INFO:               skopt: Not installed
2023-08-01 18:51:24,839:INFO:              mlflow: Not installed
2023-08-01 18:51:24,839:INFO:              gradio: Not installed
2023-08-01 18:51:24,839:INFO:             fastapi: Not installed
2023-08-01 18:51:24,839:INFO:             uvicorn: Not installed
2023-08-01 18:51:24,839:INFO:              m2cgen: Not installed
2023-08-01 18:51:24,839:INFO:           evidently: Not installed
2023-08-01 18:51:24,839:INFO:               fugue: Not installed
2023-08-01 18:51:24,839:INFO:           streamlit: Not installed
2023-08-01 18:51:24,839:INFO:             prophet: Not installed
2023-08-01 18:51:24,839:INFO:None
2023-08-01 18:51:24,839:INFO:Set up data.
2023-08-01 18:51:24,851:INFO:Set up train/test split.
2023-08-01 18:51:24,861:INFO:Set up index.
2023-08-01 18:51:24,861:INFO:Set up folding strategy.
2023-08-01 18:51:24,861:INFO:Assigning column types.
2023-08-01 18:51:24,866:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 18:51:24,918:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 18:51:24,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 18:51:25,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 18:51:25,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 18:51:25,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,348:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,349:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 18:51:25,423:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 18:51:25,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,502:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 18:51:25,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,545:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 18:51:25,646:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 18:51:25,741:INFO:Preparing preprocessing pipeline...
2023-08-01 18:51:25,742:INFO:Set up simple imputation.
2023-08-01 18:51:25,746:INFO:Set up encoding of categorical features.
2023-08-01 18:51:25,746:INFO:Set up polynomial features.
2023-08-01 18:51:25,746:INFO:Set up removing multicollinearity.
2023-08-01 18:51:25,746:INFO:Set up feature normalization.
2023-08-01 18:51:55,043:INFO:Finished creating preprocessing pipeline.
2023-08-01 18:51:55,289:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-08-01 19:08:19,025:INFO:PyCaret ClassificationExperiment
2023-08-01 19:08:19,025:INFO:Logging name: clf-default-name
2023-08-01 19:08:19,025:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 19:08:19,025:INFO:version 3.0.4
2023-08-01 19:08:19,025:INFO:Initializing setup()
2023-08-01 19:08:19,025:INFO:self.USI: ac4c
2023-08-01 19:08:19,025:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 19:08:19,025:INFO:Checking environment
2023-08-01 19:08:19,026:INFO:python_version: 3.9.13
2023-08-01 19:08:19,026:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 19:08:19,026:INFO:machine: AMD64
2023-08-01 19:08:19,026:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 19:08:19,028:INFO:Memory: svmem(total=17055166464, available=10030481408, percent=41.2, used=7024685056, free=10030481408)
2023-08-01 19:08:19,028:INFO:Physical Core: 4
2023-08-01 19:08:19,028:INFO:Logical Core: 8
2023-08-01 19:08:19,028:INFO:Checking libraries
2023-08-01 19:08:19,028:INFO:System:
2023-08-01 19:08:19,028:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 19:08:19,028:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 19:08:19,029:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 19:08:19,029:INFO:PyCaret required dependencies:
2023-08-01 19:08:19,029:INFO:                 pip: 22.0.4
2023-08-01 19:08:19,029:INFO:          setuptools: 58.1.0
2023-08-01 19:08:19,029:INFO:             pycaret: 3.0.4
2023-08-01 19:08:19,029:INFO:             IPython: 8.13.1
2023-08-01 19:08:19,029:INFO:          ipywidgets: 8.0.7
2023-08-01 19:08:19,029:INFO:                tqdm: 4.65.0
2023-08-01 19:08:19,029:INFO:               numpy: 1.23.0
2023-08-01 19:08:19,029:INFO:              pandas: 1.5.3
2023-08-01 19:08:19,029:INFO:              jinja2: 3.1.2
2023-08-01 19:08:19,029:INFO:               scipy: 1.10.1
2023-08-01 19:08:19,029:INFO:              joblib: 1.2.0
2023-08-01 19:08:19,029:INFO:             sklearn: 1.2.2
2023-08-01 19:08:19,029:INFO:                pyod: 1.1.0
2023-08-01 19:08:19,029:INFO:            imblearn: 0.11.0
2023-08-01 19:08:19,029:INFO:   category_encoders: 2.6.1
2023-08-01 19:08:19,029:INFO:            lightgbm: 3.3.5
2023-08-01 19:08:19,029:INFO:               numba: 0.57.1
2023-08-01 19:08:19,029:INFO:            requests: 2.31.0
2023-08-01 19:08:19,029:INFO:          matplotlib: 3.7.1
2023-08-01 19:08:19,029:INFO:          scikitplot: 0.3.7
2023-08-01 19:08:19,030:INFO:         yellowbrick: 1.5
2023-08-01 19:08:19,030:INFO:              plotly: 5.15.0
2023-08-01 19:08:19,030:INFO:    plotly-resampler: Not installed
2023-08-01 19:08:19,030:INFO:             kaleido: 0.2.1
2023-08-01 19:08:19,030:INFO:           schemdraw: 0.15
2023-08-01 19:08:19,030:INFO:         statsmodels: 0.14.0
2023-08-01 19:08:19,030:INFO:              sktime: 0.20.0
2023-08-01 19:08:19,030:INFO:               tbats: 1.1.3
2023-08-01 19:08:19,030:INFO:            pmdarima: 2.0.3
2023-08-01 19:08:19,030:INFO:              psutil: 5.9.5
2023-08-01 19:08:19,030:INFO:          markupsafe: 2.1.3
2023-08-01 19:08:19,030:INFO:             pickle5: Not installed
2023-08-01 19:08:19,030:INFO:         cloudpickle: 2.2.1
2023-08-01 19:08:19,030:INFO:         deprecation: 2.1.0
2023-08-01 19:08:19,030:INFO:              xxhash: 3.2.0
2023-08-01 19:08:19,031:INFO:           wurlitzer: Not installed
2023-08-01 19:08:19,031:INFO:PyCaret optional dependencies:
2023-08-01 19:08:19,031:INFO:                shap: Not installed
2023-08-01 19:08:19,031:INFO:           interpret: Not installed
2023-08-01 19:08:19,031:INFO:                umap: Not installed
2023-08-01 19:08:19,031:INFO:    pandas_profiling: 4.3.1
2023-08-01 19:08:19,031:INFO:  explainerdashboard: Not installed
2023-08-01 19:08:19,031:INFO:             autoviz: Not installed
2023-08-01 19:08:19,031:INFO:           fairlearn: Not installed
2023-08-01 19:08:19,031:INFO:          deepchecks: Not installed
2023-08-01 19:08:19,031:INFO:             xgboost: Not installed
2023-08-01 19:08:19,031:INFO:            catboost: Not installed
2023-08-01 19:08:19,031:INFO:              kmodes: Not installed
2023-08-01 19:08:19,031:INFO:             mlxtend: 0.22.0
2023-08-01 19:08:19,032:INFO:       statsforecast: Not installed
2023-08-01 19:08:19,032:INFO:        tune_sklearn: Not installed
2023-08-01 19:08:19,032:INFO:                 ray: Not installed
2023-08-01 19:08:19,032:INFO:            hyperopt: Not installed
2023-08-01 19:08:19,032:INFO:              optuna: Not installed
2023-08-01 19:08:19,032:INFO:               skopt: Not installed
2023-08-01 19:08:19,032:INFO:              mlflow: Not installed
2023-08-01 19:08:19,032:INFO:              gradio: Not installed
2023-08-01 19:08:19,032:INFO:             fastapi: Not installed
2023-08-01 19:08:19,032:INFO:             uvicorn: Not installed
2023-08-01 19:08:19,032:INFO:              m2cgen: Not installed
2023-08-01 19:08:19,032:INFO:           evidently: Not installed
2023-08-01 19:08:19,032:INFO:               fugue: Not installed
2023-08-01 19:08:19,032:INFO:           streamlit: Not installed
2023-08-01 19:08:19,033:INFO:             prophet: Not installed
2023-08-01 19:08:19,033:INFO:None
2023-08-01 19:08:19,033:INFO:Set up data.
2023-08-01 19:08:19,044:INFO:Set up train/test split.
2023-08-01 19:08:19,051:INFO:Set up index.
2023-08-01 19:08:19,052:INFO:Set up folding strategy.
2023-08-01 19:08:19,052:INFO:Assigning column types.
2023-08-01 19:08:19,057:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 19:08:19,103:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,180:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,210:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 19:08:19,259:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,336:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:08:19,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,365:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 19:08:19,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:19,520:INFO:Preparing preprocessing pipeline...
2023-08-01 19:08:19,521:INFO:Set up simple imputation.
2023-08-01 19:08:19,524:INFO:Set up encoding of categorical features.
2023-08-01 19:08:19,524:INFO:Set up removing multicollinearity.
2023-08-01 19:08:19,524:INFO:Set up feature normalization.
2023-08-01 19:08:19,717:INFO:Finished creating preprocessing pipeline.
2023-08-01 19:08:19,945:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-08-01 19:08:19,945:INFO:Creating final display dataframe.
2023-08-01 19:08:20,299:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 18)  
5                                          (6508, 18)  
6                                          (1628, 18)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             robust  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               ac4c  
2023-08-01 19:08:20,419:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:20,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:20,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:20,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:08:20,506:INFO:setup() successfully completed in 2.04s...............
2023-08-01 19:08:47,428:INFO:Initializing compare_models()
2023-08-01 19:08:47,429:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:08:47,429:INFO:Checking exceptions
2023-08-01 19:08:47,438:INFO:Preparing display monitor
2023-08-01 19:08:47,477:INFO:Initializing Logistic Regression
2023-08-01 19:08:47,478:INFO:Total runtime is 1.6999244689941406e-05 minutes
2023-08-01 19:08:47,484:INFO:SubProcess create_model() called ==================================
2023-08-01 19:08:47,486:INFO:Initializing create_model()
2023-08-01 19:08:47,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:08:47,487:INFO:Checking exceptions
2023-08-01 19:08:47,487:INFO:Importing libraries
2023-08-01 19:08:47,487:INFO:Copying training dataset
2023-08-01 19:08:47,496:INFO:Defining folds
2023-08-01 19:08:47,496:INFO:Declaring metric variables
2023-08-01 19:08:47,502:INFO:Importing untrained model
2023-08-01 19:08:47,508:INFO:Logistic Regression Imported successfully
2023-08-01 19:08:47,519:INFO:Starting cross validation
2023-08-01 19:08:47,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:08:54,802:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:08:56,221:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,241:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,338:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,420:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,428:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,531:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:56,578:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:57,368:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:08:58,357:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:01,730:INFO:Calculating mean and std
2023-08-01 19:09:01,731:INFO:Creating metrics dataframe
2023-08-01 19:09:02,391:INFO:Uploading results into container
2023-08-01 19:09:02,392:INFO:Uploading model into container now
2023-08-01 19:09:02,392:INFO:_master_model_container: 1
2023-08-01 19:09:02,392:INFO:_display_container: 2
2023-08-01 19:09:02,393:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:09:02,393:INFO:create_model() successfully completed......................................
2023-08-01 19:09:02,532:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:02,532:INFO:Creating metrics dataframe
2023-08-01 19:09:02,545:INFO:Initializing K Neighbors Classifier
2023-08-01 19:09:02,545:INFO:Total runtime is 0.25113345781962076 minutes
2023-08-01 19:09:02,552:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:02,553:INFO:Initializing create_model()
2023-08-01 19:09:02,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:02,553:INFO:Checking exceptions
2023-08-01 19:09:02,553:INFO:Importing libraries
2023-08-01 19:09:02,553:INFO:Copying training dataset
2023-08-01 19:09:02,563:INFO:Defining folds
2023-08-01 19:09:02,563:INFO:Declaring metric variables
2023-08-01 19:09:02,568:INFO:Importing untrained model
2023-08-01 19:09:02,573:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:09:02,583:INFO:Starting cross validation
2023-08-01 19:09:02,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:03,863:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:04,941:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:04,948:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:04,957:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:05,001:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:05,016:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:05,064:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:05,070:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:05,979:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:10,579:INFO:Calculating mean and std
2023-08-01 19:09:10,581:INFO:Creating metrics dataframe
2023-08-01 19:09:11,272:INFO:Uploading results into container
2023-08-01 19:09:11,272:INFO:Uploading model into container now
2023-08-01 19:09:11,273:INFO:_master_model_container: 2
2023-08-01 19:09:11,274:INFO:_display_container: 2
2023-08-01 19:09:11,274:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:09:11,274:INFO:create_model() successfully completed......................................
2023-08-01 19:09:11,400:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:11,400:INFO:Creating metrics dataframe
2023-08-01 19:09:11,413:INFO:Initializing Naive Bayes
2023-08-01 19:09:11,413:INFO:Total runtime is 0.39893331527709963 minutes
2023-08-01 19:09:11,417:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:11,418:INFO:Initializing create_model()
2023-08-01 19:09:11,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:11,418:INFO:Checking exceptions
2023-08-01 19:09:11,418:INFO:Importing libraries
2023-08-01 19:09:11,418:INFO:Copying training dataset
2023-08-01 19:09:11,427:INFO:Defining folds
2023-08-01 19:09:11,427:INFO:Declaring metric variables
2023-08-01 19:09:11,431:INFO:Importing untrained model
2023-08-01 19:09:11,439:INFO:Naive Bayes Imported successfully
2023-08-01 19:09:11,448:INFO:Starting cross validation
2023-08-01 19:09:11,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:12,749:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:13,829:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:13,837:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:13,868:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:13,887:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:13,989:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:14,003:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:14,048:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:14,973:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:19,405:INFO:Calculating mean and std
2023-08-01 19:09:19,407:INFO:Creating metrics dataframe
2023-08-01 19:09:20,214:INFO:Uploading results into container
2023-08-01 19:09:20,215:INFO:Uploading model into container now
2023-08-01 19:09:20,216:INFO:_master_model_container: 3
2023-08-01 19:09:20,217:INFO:_display_container: 2
2023-08-01 19:09:20,217:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:09:20,218:INFO:create_model() successfully completed......................................
2023-08-01 19:09:20,392:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:20,392:INFO:Creating metrics dataframe
2023-08-01 19:09:20,435:INFO:Initializing Decision Tree Classifier
2023-08-01 19:09:20,436:INFO:Total runtime is 0.5493170261383057 minutes
2023-08-01 19:09:20,443:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:20,443:INFO:Initializing create_model()
2023-08-01 19:09:20,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:20,444:INFO:Checking exceptions
2023-08-01 19:09:20,444:INFO:Importing libraries
2023-08-01 19:09:20,444:INFO:Copying training dataset
2023-08-01 19:09:20,460:INFO:Defining folds
2023-08-01 19:09:20,460:INFO:Declaring metric variables
2023-08-01 19:09:20,469:INFO:Importing untrained model
2023-08-01 19:09:20,479:INFO:Decision Tree Classifier Imported successfully
2023-08-01 19:09:20,501:INFO:Starting cross validation
2023-08-01 19:09:20,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:22,003:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:22,054:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:22,157:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:22,213:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:09:22,609:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:22,664:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 19:09:22,909:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-01 19:09:23,602:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:09:23,689:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:09:24,495:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:25,170:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:25,551:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:25,615:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:25,702:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:25,828:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:26,490:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:26,678:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:28,383:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:28,491:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:31,265:INFO:Calculating mean and std
2023-08-01 19:09:31,266:INFO:Creating metrics dataframe
2023-08-01 19:09:31,967:INFO:Uploading results into container
2023-08-01 19:09:31,968:INFO:Uploading model into container now
2023-08-01 19:09:31,968:INFO:_master_model_container: 4
2023-08-01 19:09:31,968:INFO:_display_container: 2
2023-08-01 19:09:31,968:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 19:09:31,969:INFO:create_model() successfully completed......................................
2023-08-01 19:09:32,083:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:32,084:INFO:Creating metrics dataframe
2023-08-01 19:09:32,096:INFO:Initializing SVM - Linear Kernel
2023-08-01 19:09:32,096:INFO:Total runtime is 0.7436500231424967 minutes
2023-08-01 19:09:32,101:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:32,101:INFO:Initializing create_model()
2023-08-01 19:09:32,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:32,101:INFO:Checking exceptions
2023-08-01 19:09:32,101:INFO:Importing libraries
2023-08-01 19:09:32,102:INFO:Copying training dataset
2023-08-01 19:09:32,108:INFO:Defining folds
2023-08-01 19:09:32,109:INFO:Declaring metric variables
2023-08-01 19:09:32,113:INFO:Importing untrained model
2023-08-01 19:09:32,119:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 19:09:32,129:INFO:Starting cross validation
2023-08-01 19:09:32,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:34,414:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,427:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,435:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,438:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,443:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,447:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,492:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,501:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:34,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:36,074:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:36,084:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:09:39,884:INFO:Calculating mean and std
2023-08-01 19:09:39,885:INFO:Creating metrics dataframe
2023-08-01 19:09:40,607:INFO:Uploading results into container
2023-08-01 19:09:40,608:INFO:Uploading model into container now
2023-08-01 19:09:40,608:INFO:_master_model_container: 5
2023-08-01 19:09:40,608:INFO:_display_container: 2
2023-08-01 19:09:40,609:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 19:09:40,609:INFO:create_model() successfully completed......................................
2023-08-01 19:09:40,729:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:40,730:INFO:Creating metrics dataframe
2023-08-01 19:09:40,742:INFO:Initializing Ridge Classifier
2023-08-01 19:09:40,743:INFO:Total runtime is 0.8877688527107239 minutes
2023-08-01 19:09:40,747:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:40,748:INFO:Initializing create_model()
2023-08-01 19:09:40,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:40,748:INFO:Checking exceptions
2023-08-01 19:09:40,748:INFO:Importing libraries
2023-08-01 19:09:40,748:INFO:Copying training dataset
2023-08-01 19:09:40,756:INFO:Defining folds
2023-08-01 19:09:40,756:INFO:Declaring metric variables
2023-08-01 19:09:40,760:INFO:Importing untrained model
2023-08-01 19:09:40,766:INFO:Ridge Classifier Imported successfully
2023-08-01 19:09:40,774:INFO:Starting cross validation
2023-08-01 19:09:40,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:41,226:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,105:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,111:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,132:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,137:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,155:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,161:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,336:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,342:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,710:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,716:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,723:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,728:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:43,732:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:43,738:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:44,912:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:45,056:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:45,061:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:09:48,275:INFO:Calculating mean and std
2023-08-01 19:09:48,277:INFO:Creating metrics dataframe
2023-08-01 19:09:49,076:INFO:Uploading results into container
2023-08-01 19:09:49,078:INFO:Uploading model into container now
2023-08-01 19:09:49,079:INFO:_master_model_container: 6
2023-08-01 19:09:49,079:INFO:_display_container: 2
2023-08-01 19:09:49,079:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 19:09:49,080:INFO:create_model() successfully completed......................................
2023-08-01 19:09:49,239:INFO:SubProcess create_model() end ==================================
2023-08-01 19:09:49,239:INFO:Creating metrics dataframe
2023-08-01 19:09:49,253:INFO:Initializing Random Forest Classifier
2023-08-01 19:09:49,254:INFO:Total runtime is 1.0296262423197429 minutes
2023-08-01 19:09:49,258:INFO:SubProcess create_model() called ==================================
2023-08-01 19:09:49,258:INFO:Initializing create_model()
2023-08-01 19:09:49,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:09:49,259:INFO:Checking exceptions
2023-08-01 19:09:49,259:INFO:Importing libraries
2023-08-01 19:09:49,259:INFO:Copying training dataset
2023-08-01 19:09:49,266:INFO:Defining folds
2023-08-01 19:09:49,266:INFO:Declaring metric variables
2023-08-01 19:09:49,271:INFO:Importing untrained model
2023-08-01 19:09:49,278:INFO:Random Forest Classifier Imported successfully
2023-08-01 19:09:49,289:INFO:Starting cross validation
2023-08-01 19:09:49,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:09:51,744:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:09:51,772:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:09:51,783:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:09:51,794:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:09:51,805:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:09:54,189:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,255:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,310:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,316:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,326:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,426:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,504:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:09:54,866:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:01,250:INFO:Calculating mean and std
2023-08-01 19:10:01,252:INFO:Creating metrics dataframe
2023-08-01 19:10:02,057:INFO:Uploading results into container
2023-08-01 19:10:02,058:INFO:Uploading model into container now
2023-08-01 19:10:02,059:INFO:_master_model_container: 7
2023-08-01 19:10:02,059:INFO:_display_container: 2
2023-08-01 19:10:02,059:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:10:02,059:INFO:create_model() successfully completed......................................
2023-08-01 19:10:02,188:INFO:SubProcess create_model() end ==================================
2023-08-01 19:10:02,188:INFO:Creating metrics dataframe
2023-08-01 19:10:02,201:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 19:10:02,201:INFO:Total runtime is 1.245404311021169 minutes
2023-08-01 19:10:02,206:INFO:SubProcess create_model() called ==================================
2023-08-01 19:10:02,207:INFO:Initializing create_model()
2023-08-01 19:10:02,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:10:02,207:INFO:Checking exceptions
2023-08-01 19:10:02,207:INFO:Importing libraries
2023-08-01 19:10:02,207:INFO:Copying training dataset
2023-08-01 19:10:02,215:INFO:Defining folds
2023-08-01 19:10:02,215:INFO:Declaring metric variables
2023-08-01 19:10:02,220:INFO:Importing untrained model
2023-08-01 19:10:02,226:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 19:10:02,236:INFO:Starting cross validation
2023-08-01 19:10:02,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:10:02,654:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,655:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,659:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,674:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,699:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,709:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,721:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:02,726:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:04,908:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:04,908:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:04,912:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,912:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,912:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:04,924:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,924:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,924:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:04,948:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:04,951:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,952:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,954:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:04,980:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,980:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,981:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:04,983:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,984:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,984:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:04,990:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:04,994:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,995:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:04,995:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,032:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:05,032:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,033:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,033:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,056:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,057:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,057:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,058:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:05,060:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:05,063:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:05,064:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:05,069:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:05,074:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,074:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,075:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,085:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:05,089:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,089:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,089:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,158:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,158:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,159:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,164:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:05,165:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,165:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:05,166:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:05,171:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:06,780:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:06,823:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:10:06,881:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,881:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,881:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:06,923:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,923:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,924:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:06,989:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,989:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:06,990:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:06,992:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:07,028:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:07,029:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:10:07,029:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:10:07,031:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:10:11,156:INFO:Calculating mean and std
2023-08-01 19:10:11,157:INFO:Creating metrics dataframe
2023-08-01 19:10:11,997:INFO:Uploading results into container
2023-08-01 19:10:11,998:INFO:Uploading model into container now
2023-08-01 19:10:11,999:INFO:_master_model_container: 8
2023-08-01 19:10:11,999:INFO:_display_container: 2
2023-08-01 19:10:12,000:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 19:10:12,000:INFO:create_model() successfully completed......................................
2023-08-01 19:10:12,131:INFO:SubProcess create_model() end ==================================
2023-08-01 19:10:12,132:INFO:Creating metrics dataframe
2023-08-01 19:10:12,147:INFO:Initializing Ada Boost Classifier
2023-08-01 19:10:12,148:INFO:Total runtime is 1.4111992001533509 minutes
2023-08-01 19:10:12,152:INFO:SubProcess create_model() called ==================================
2023-08-01 19:10:12,153:INFO:Initializing create_model()
2023-08-01 19:10:12,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:10:12,154:INFO:Checking exceptions
2023-08-01 19:10:12,154:INFO:Importing libraries
2023-08-01 19:10:12,154:INFO:Copying training dataset
2023-08-01 19:10:12,163:INFO:Defining folds
2023-08-01 19:10:12,164:INFO:Declaring metric variables
2023-08-01 19:10:12,171:INFO:Importing untrained model
2023-08-01 19:10:12,195:INFO:Ada Boost Classifier Imported successfully
2023-08-01 19:10:12,215:INFO:Starting cross validation
2023-08-01 19:10:12,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:10:15,976:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:15,978:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:15,997:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:16,058:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:16,061:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:16,150:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:16,243:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:16,246:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:23,749:INFO:Calculating mean and std
2023-08-01 19:10:23,751:INFO:Creating metrics dataframe
2023-08-01 19:10:24,591:INFO:Uploading results into container
2023-08-01 19:10:24,591:INFO:Uploading model into container now
2023-08-01 19:10:24,592:INFO:_master_model_container: 9
2023-08-01 19:10:24,592:INFO:_display_container: 2
2023-08-01 19:10:24,593:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 19:10:24,593:INFO:create_model() successfully completed......................................
2023-08-01 19:10:24,725:INFO:SubProcess create_model() end ==================================
2023-08-01 19:10:24,725:INFO:Creating metrics dataframe
2023-08-01 19:10:24,742:INFO:Initializing Gradient Boosting Classifier
2023-08-01 19:10:24,743:INFO:Total runtime is 1.6211164315541586 minutes
2023-08-01 19:10:24,747:INFO:SubProcess create_model() called ==================================
2023-08-01 19:10:24,748:INFO:Initializing create_model()
2023-08-01 19:10:24,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:10:24,748:INFO:Checking exceptions
2023-08-01 19:10:24,748:INFO:Importing libraries
2023-08-01 19:10:24,748:INFO:Copying training dataset
2023-08-01 19:10:24,757:INFO:Defining folds
2023-08-01 19:10:24,757:INFO:Declaring metric variables
2023-08-01 19:10:24,763:INFO:Importing untrained model
2023-08-01 19:10:24,768:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:10:24,782:INFO:Starting cross validation
2023-08-01 19:10:24,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:10:28,890:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:28,953:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,063:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,074:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,113:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,149:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,269:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:29,288:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:33,786:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:33,991:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:37,597:INFO:Calculating mean and std
2023-08-01 19:10:37,599:INFO:Creating metrics dataframe
2023-08-01 19:10:38,526:INFO:Uploading results into container
2023-08-01 19:10:38,528:INFO:Uploading model into container now
2023-08-01 19:10:38,529:INFO:_master_model_container: 10
2023-08-01 19:10:38,529:INFO:_display_container: 2
2023-08-01 19:10:38,530:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:10:38,530:INFO:create_model() successfully completed......................................
2023-08-01 19:10:38,676:INFO:SubProcess create_model() end ==================================
2023-08-01 19:10:38,677:INFO:Creating metrics dataframe
2023-08-01 19:10:38,697:INFO:Initializing Linear Discriminant Analysis
2023-08-01 19:10:38,697:INFO:Total runtime is 1.853682585557302 minutes
2023-08-01 19:10:38,702:INFO:SubProcess create_model() called ==================================
2023-08-01 19:10:38,703:INFO:Initializing create_model()
2023-08-01 19:10:38,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:10:38,704:INFO:Checking exceptions
2023-08-01 19:10:38,704:INFO:Importing libraries
2023-08-01 19:10:38,704:INFO:Copying training dataset
2023-08-01 19:10:38,716:INFO:Defining folds
2023-08-01 19:10:38,717:INFO:Declaring metric variables
2023-08-01 19:10:38,724:INFO:Importing untrained model
2023-08-01 19:10:38,731:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 19:10:38,746:INFO:Starting cross validation
2023-08-01 19:10:38,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:10:41,601:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,683:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,728:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,731:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,770:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,850:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,865:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:41,894:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:48,618:INFO:Calculating mean and std
2023-08-01 19:10:48,619:INFO:Creating metrics dataframe
2023-08-01 19:10:49,545:INFO:Uploading results into container
2023-08-01 19:10:49,546:INFO:Uploading model into container now
2023-08-01 19:10:49,547:INFO:_master_model_container: 11
2023-08-01 19:10:49,547:INFO:_display_container: 2
2023-08-01 19:10:49,548:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 19:10:49,548:INFO:create_model() successfully completed......................................
2023-08-01 19:10:49,682:INFO:SubProcess create_model() end ==================================
2023-08-01 19:10:49,683:INFO:Creating metrics dataframe
2023-08-01 19:10:49,701:INFO:Initializing Extra Trees Classifier
2023-08-01 19:10:49,701:INFO:Total runtime is 2.037082636356354 minutes
2023-08-01 19:10:49,706:INFO:SubProcess create_model() called ==================================
2023-08-01 19:10:49,707:INFO:Initializing create_model()
2023-08-01 19:10:49,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:10:49,707:INFO:Checking exceptions
2023-08-01 19:10:49,707:INFO:Importing libraries
2023-08-01 19:10:49,707:INFO:Copying training dataset
2023-08-01 19:10:49,717:INFO:Defining folds
2023-08-01 19:10:49,717:INFO:Declaring metric variables
2023-08-01 19:10:49,724:INFO:Importing untrained model
2023-08-01 19:10:49,730:INFO:Extra Trees Classifier Imported successfully
2023-08-01 19:10:49,746:INFO:Starting cross validation
2023-08-01 19:10:49,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:10:52,098:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:10:52,143:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:10:52,165:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:10:55,001:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,036:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,051:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,103:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,119:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,169:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,321:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:10:55,705:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:03,160:INFO:Calculating mean and std
2023-08-01 19:11:03,161:INFO:Creating metrics dataframe
2023-08-01 19:11:04,097:INFO:Uploading results into container
2023-08-01 19:11:04,098:INFO:Uploading model into container now
2023-08-01 19:11:04,099:INFO:_master_model_container: 12
2023-08-01 19:11:04,099:INFO:_display_container: 2
2023-08-01 19:11:04,099:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:11:04,100:INFO:create_model() successfully completed......................................
2023-08-01 19:11:04,236:INFO:SubProcess create_model() end ==================================
2023-08-01 19:11:04,236:INFO:Creating metrics dataframe
2023-08-01 19:11:04,256:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 19:11:04,256:INFO:Total runtime is 2.279666070143382 minutes
2023-08-01 19:11:04,261:INFO:SubProcess create_model() called ==================================
2023-08-01 19:11:04,262:INFO:Initializing create_model()
2023-08-01 19:11:04,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:11:04,262:INFO:Checking exceptions
2023-08-01 19:11:04,262:INFO:Importing libraries
2023-08-01 19:11:04,262:INFO:Copying training dataset
2023-08-01 19:11:04,271:INFO:Defining folds
2023-08-01 19:11:04,271:INFO:Declaring metric variables
2023-08-01 19:11:04,278:INFO:Importing untrained model
2023-08-01 19:11:04,284:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 19:11:04,298:INFO:Starting cross validation
2023-08-01 19:11:04,300:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:11:06,784:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-01 19:11:07,999:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,018:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,062:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,086:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,094:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,165:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:08,205:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:09,235:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:15,570:INFO:Calculating mean and std
2023-08-01 19:11:15,571:INFO:Creating metrics dataframe
2023-08-01 19:11:16,565:INFO:Uploading results into container
2023-08-01 19:11:16,567:INFO:Uploading model into container now
2023-08-01 19:11:16,567:INFO:_master_model_container: 13
2023-08-01 19:11:16,567:INFO:_display_container: 2
2023-08-01 19:11:16,568:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 19:11:16,568:INFO:create_model() successfully completed......................................
2023-08-01 19:11:16,699:INFO:SubProcess create_model() end ==================================
2023-08-01 19:11:16,699:INFO:Creating metrics dataframe
2023-08-01 19:11:16,716:INFO:Initializing Dummy Classifier
2023-08-01 19:11:16,716:INFO:Total runtime is 2.487332614262899 minutes
2023-08-01 19:11:16,721:INFO:SubProcess create_model() called ==================================
2023-08-01 19:11:16,722:INFO:Initializing create_model()
2023-08-01 19:11:16,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C706181DF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:11:16,722:INFO:Checking exceptions
2023-08-01 19:11:16,722:INFO:Importing libraries
2023-08-01 19:11:16,722:INFO:Copying training dataset
2023-08-01 19:11:16,734:INFO:Defining folds
2023-08-01 19:11:16,734:INFO:Declaring metric variables
2023-08-01 19:11:16,741:INFO:Importing untrained model
2023-08-01 19:11:16,747:INFO:Dummy Classifier Imported successfully
2023-08-01 19:11:16,765:INFO:Starting cross validation
2023-08-01 19:11:16,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:11:19,746:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,764:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,817:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,905:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,917:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,919:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:19,921:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:19,926:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,936:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:19,946:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:19,981:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:20,034:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:20,052:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:20,053:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:20,057:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:20,101:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:22,368:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:23,665:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:11:23,674:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:11:27,633:INFO:Calculating mean and std
2023-08-01 19:11:27,634:INFO:Creating metrics dataframe
2023-08-01 19:11:28,681:INFO:Uploading results into container
2023-08-01 19:11:28,682:INFO:Uploading model into container now
2023-08-01 19:11:28,682:INFO:_master_model_container: 14
2023-08-01 19:11:28,683:INFO:_display_container: 2
2023-08-01 19:11:28,683:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 19:11:28,683:INFO:create_model() successfully completed......................................
2023-08-01 19:11:28,823:INFO:SubProcess create_model() end ==================================
2023-08-01 19:11:28,824:INFO:Creating metrics dataframe
2023-08-01 19:11:28,857:INFO:Initializing create_model()
2023-08-01 19:11:28,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:11:28,858:INFO:Checking exceptions
2023-08-01 19:11:28,861:INFO:Importing libraries
2023-08-01 19:11:28,861:INFO:Copying training dataset
2023-08-01 19:11:28,868:INFO:Defining folds
2023-08-01 19:11:28,869:INFO:Declaring metric variables
2023-08-01 19:11:28,869:INFO:Importing untrained model
2023-08-01 19:11:28,869:INFO:Declaring custom model
2023-08-01 19:11:28,870:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:11:28,872:INFO:Cross validation set to False
2023-08-01 19:11:28,872:INFO:Fitting Model
2023-08-01 19:11:30,546:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:11:30,546:INFO:create_model() successfully completed......................................
2023-08-01 19:11:30,742:INFO:_master_model_container: 14
2023-08-01 19:11:30,742:INFO:_display_container: 2
2023-08-01 19:11:30,743:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:11:30,743:INFO:compare_models() successfully completed......................................
2023-08-01 19:14:07,410:INFO:Initializing compare_models()
2023-08-01 19:14:07,410:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced Accucary, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced Accucary', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:14:07,410:INFO:Checking exceptions
2023-08-01 19:14:07,418:INFO:Preparing display monitor
2023-08-01 19:14:07,469:INFO:Initializing Logistic Regression
2023-08-01 19:14:07,470:INFO:Total runtime is 1.6689300537109375e-05 minutes
2023-08-01 19:14:07,476:INFO:SubProcess create_model() called ==================================
2023-08-01 19:14:07,477:INFO:Initializing create_model()
2023-08-01 19:14:07,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C705E518E0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:14:07,477:INFO:Checking exceptions
2023-08-01 19:14:07,478:INFO:Importing libraries
2023-08-01 19:14:07,478:INFO:Copying training dataset
2023-08-01 19:14:07,490:INFO:Defining folds
2023-08-01 19:14:07,490:INFO:Declaring metric variables
2023-08-01 19:14:07,499:INFO:Importing untrained model
2023-08-01 19:14:07,506:INFO:Logistic Regression Imported successfully
2023-08-01 19:14:07,522:INFO:Starting cross validation
2023-08-01 19:14:07,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:14:09,238:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:14:09,343:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:14:10,936:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:10,974:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:11,127:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:11,151:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:11,242:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:11,260:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:11,969:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:12,104:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:14,907:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:14,927:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:18,987:INFO:Calculating mean and std
2023-08-01 19:14:18,989:INFO:Creating metrics dataframe
2023-08-01 19:14:20,004:INFO:Uploading results into container
2023-08-01 19:14:20,005:INFO:Uploading model into container now
2023-08-01 19:14:20,006:INFO:_master_model_container: 15
2023-08-01 19:14:20,006:INFO:_display_container: 3
2023-08-01 19:14:20,006:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:14:20,007:INFO:create_model() successfully completed......................................
2023-08-01 19:14:20,168:INFO:SubProcess create_model() end ==================================
2023-08-01 19:14:20,168:INFO:Creating metrics dataframe
2023-08-01 19:14:20,179:INFO:Initializing K Neighbors Classifier
2023-08-01 19:14:20,179:INFO:Total runtime is 0.2118329882621765 minutes
2023-08-01 19:14:20,185:INFO:SubProcess create_model() called ==================================
2023-08-01 19:14:20,186:INFO:Initializing create_model()
2023-08-01 19:14:20,186:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C705E518E0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:14:20,186:INFO:Checking exceptions
2023-08-01 19:14:20,187:INFO:Importing libraries
2023-08-01 19:14:20,187:INFO:Copying training dataset
2023-08-01 19:14:20,194:INFO:Defining folds
2023-08-01 19:14:20,194:INFO:Declaring metric variables
2023-08-01 19:14:20,202:INFO:Importing untrained model
2023-08-01 19:14:20,208:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:14:20,222:INFO:Starting cross validation
2023-08-01 19:14:20,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:14:23,553:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:23,582:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:23,625:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:23,654:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:24,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:24,618:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:24,803:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:27,948:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:29,286:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:33,460:INFO:Calculating mean and std
2023-08-01 19:14:33,463:INFO:Creating metrics dataframe
2023-08-01 19:14:34,992:INFO:Uploading results into container
2023-08-01 19:14:34,993:INFO:Uploading model into container now
2023-08-01 19:14:34,994:INFO:_master_model_container: 16
2023-08-01 19:14:34,994:INFO:_display_container: 3
2023-08-01 19:14:34,995:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:14:34,995:INFO:create_model() successfully completed......................................
2023-08-01 19:14:35,218:INFO:SubProcess create_model() end ==================================
2023-08-01 19:14:35,219:INFO:Creating metrics dataframe
2023-08-01 19:14:35,240:INFO:Initializing Naive Bayes
2023-08-01 19:14:35,240:INFO:Total runtime is 0.4628496686617533 minutes
2023-08-01 19:14:35,246:INFO:SubProcess create_model() called ==================================
2023-08-01 19:14:35,247:INFO:Initializing create_model()
2023-08-01 19:14:35,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C705E518E0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:14:35,249:INFO:Checking exceptions
2023-08-01 19:14:35,249:INFO:Importing libraries
2023-08-01 19:14:35,249:INFO:Copying training dataset
2023-08-01 19:14:35,262:INFO:Defining folds
2023-08-01 19:14:35,263:INFO:Declaring metric variables
2023-08-01 19:14:35,274:INFO:Importing untrained model
2023-08-01 19:14:35,284:INFO:Naive Bayes Imported successfully
2023-08-01 19:14:35,300:INFO:Starting cross validation
2023-08-01 19:14:35,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:14:38,583:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:38,710:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:38,745:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:38,954:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:39,753:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:39,813:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:40,255:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:14:42,013:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:42,678:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:46,722:INFO:Calculating mean and std
2023-08-01 19:14:46,723:INFO:Creating metrics dataframe
2023-08-01 19:14:47,938:INFO:Uploading results into container
2023-08-01 19:14:47,939:INFO:Uploading model into container now
2023-08-01 19:14:47,940:INFO:_master_model_container: 17
2023-08-01 19:14:47,940:INFO:_display_container: 3
2023-08-01 19:14:47,940:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:14:47,940:INFO:create_model() successfully completed......................................
2023-08-01 19:14:48,114:INFO:SubProcess create_model() end ==================================
2023-08-01 19:14:48,115:INFO:Creating metrics dataframe
2023-08-01 19:14:48,138:INFO:Initializing Decision Tree Classifier
2023-08-01 19:14:48,139:INFO:Total runtime is 0.6778252085049947 minutes
2023-08-01 19:14:48,145:INFO:SubProcess create_model() called ==================================
2023-08-01 19:14:48,145:INFO:Initializing create_model()
2023-08-01 19:14:48,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C705E518E0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:14:48,146:INFO:Checking exceptions
2023-08-01 19:14:48,146:INFO:Importing libraries
2023-08-01 19:14:48,146:INFO:Copying training dataset
2023-08-01 19:14:48,165:INFO:Defining folds
2023-08-01 19:14:48,166:INFO:Declaring metric variables
2023-08-01 19:14:48,177:INFO:Importing untrained model
2023-08-01 19:14:48,190:INFO:Decision Tree Classifier Imported successfully
2023-08-01 19:14:48,208:INFO:Starting cross validation
2023-08-01 19:14:48,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:14:50,203:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:14:52,173:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:52,574:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:52,684:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:52,731:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:14:54,133:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:35:48,698:INFO:Initializing compare_models()
2023-08-01 19:35:48,698:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced Accucary, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced Accucary', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:35:48,698:INFO:Checking exceptions
2023-08-01 19:35:48,703:INFO:Preparing display monitor
2023-08-01 19:35:48,740:INFO:Initializing Logistic Regression
2023-08-01 19:35:48,740:INFO:Total runtime is 0.0 minutes
2023-08-01 19:35:48,745:INFO:SubProcess create_model() called ==================================
2023-08-01 19:35:48,745:INFO:Initializing create_model()
2023-08-01 19:35:48,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:35:48,745:INFO:Checking exceptions
2023-08-01 19:35:48,746:INFO:Importing libraries
2023-08-01 19:35:48,746:INFO:Copying training dataset
2023-08-01 19:35:48,754:INFO:Defining folds
2023-08-01 19:35:48,754:INFO:Declaring metric variables
2023-08-01 19:35:48,761:INFO:Importing untrained model
2023-08-01 19:35:48,767:INFO:Logistic Regression Imported successfully
2023-08-01 19:35:48,782:INFO:Starting cross validation
2023-08-01 19:35:48,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:02,678:INFO:Calculating mean and std
2023-08-01 19:36:02,679:INFO:Creating metrics dataframe
2023-08-01 19:36:03,557:INFO:Uploading results into container
2023-08-01 19:36:03,558:INFO:Uploading model into container now
2023-08-01 19:36:03,559:INFO:_master_model_container: 18
2023-08-01 19:36:03,559:INFO:_display_container: 3
2023-08-01 19:36:03,560:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:36:03,560:INFO:create_model() successfully completed......................................
2023-08-01 19:36:04,854:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:04,854:INFO:Creating metrics dataframe
2023-08-01 19:36:04,866:INFO:Initializing K Neighbors Classifier
2023-08-01 19:36:04,866:INFO:Total runtime is 0.2687666575113932 minutes
2023-08-01 19:36:04,869:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:04,870:INFO:Initializing create_model()
2023-08-01 19:36:04,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:04,871:INFO:Checking exceptions
2023-08-01 19:36:04,871:INFO:Importing libraries
2023-08-01 19:36:04,871:INFO:Copying training dataset
2023-08-01 19:36:04,879:INFO:Defining folds
2023-08-01 19:36:04,879:INFO:Declaring metric variables
2023-08-01 19:36:04,884:INFO:Importing untrained model
2023-08-01 19:36:04,891:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:36:04,899:INFO:Starting cross validation
2023-08-01 19:36:04,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:12,341:INFO:Calculating mean and std
2023-08-01 19:36:12,342:INFO:Creating metrics dataframe
2023-08-01 19:36:13,286:INFO:Uploading results into container
2023-08-01 19:36:13,287:INFO:Uploading model into container now
2023-08-01 19:36:13,288:INFO:_master_model_container: 19
2023-08-01 19:36:13,288:INFO:_display_container: 3
2023-08-01 19:36:13,289:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:36:13,290:INFO:create_model() successfully completed......................................
2023-08-01 19:36:13,454:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:13,455:INFO:Creating metrics dataframe
2023-08-01 19:36:13,473:INFO:Initializing Naive Bayes
2023-08-01 19:36:13,473:INFO:Total runtime is 0.41221714814503985 minutes
2023-08-01 19:36:13,480:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:13,481:INFO:Initializing create_model()
2023-08-01 19:36:13,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:13,481:INFO:Checking exceptions
2023-08-01 19:36:13,481:INFO:Importing libraries
2023-08-01 19:36:13,481:INFO:Copying training dataset
2023-08-01 19:36:13,492:INFO:Defining folds
2023-08-01 19:36:13,493:INFO:Declaring metric variables
2023-08-01 19:36:13,499:INFO:Importing untrained model
2023-08-01 19:36:13,509:INFO:Naive Bayes Imported successfully
2023-08-01 19:36:13,524:INFO:Starting cross validation
2023-08-01 19:36:13,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:20,587:INFO:Calculating mean and std
2023-08-01 19:36:20,588:INFO:Creating metrics dataframe
2023-08-01 19:36:21,513:INFO:Uploading results into container
2023-08-01 19:36:21,514:INFO:Uploading model into container now
2023-08-01 19:36:21,515:INFO:_master_model_container: 20
2023-08-01 19:36:21,515:INFO:_display_container: 3
2023-08-01 19:36:21,515:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:36:21,516:INFO:create_model() successfully completed......................................
2023-08-01 19:36:21,663:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:21,663:INFO:Creating metrics dataframe
2023-08-01 19:36:21,676:INFO:Initializing Decision Tree Classifier
2023-08-01 19:36:21,676:INFO:Total runtime is 0.5489333073298136 minutes
2023-08-01 19:36:21,680:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:21,681:INFO:Initializing create_model()
2023-08-01 19:36:21,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:21,681:INFO:Checking exceptions
2023-08-01 19:36:21,682:INFO:Importing libraries
2023-08-01 19:36:21,682:INFO:Copying training dataset
2023-08-01 19:36:21,691:INFO:Defining folds
2023-08-01 19:36:21,692:INFO:Declaring metric variables
2023-08-01 19:36:21,697:INFO:Importing untrained model
2023-08-01 19:36:21,702:INFO:Decision Tree Classifier Imported successfully
2023-08-01 19:36:21,716:INFO:Starting cross validation
2023-08-01 19:36:21,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:28,831:INFO:Calculating mean and std
2023-08-01 19:36:28,833:INFO:Creating metrics dataframe
2023-08-01 19:36:29,795:INFO:Uploading results into container
2023-08-01 19:36:29,796:INFO:Uploading model into container now
2023-08-01 19:36:29,796:INFO:_master_model_container: 21
2023-08-01 19:36:29,796:INFO:_display_container: 3
2023-08-01 19:36:29,797:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 19:36:29,797:INFO:create_model() successfully completed......................................
2023-08-01 19:36:29,950:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:29,950:INFO:Creating metrics dataframe
2023-08-01 19:36:29,967:INFO:Initializing SVM - Linear Kernel
2023-08-01 19:36:29,967:INFO:Total runtime is 0.6871166626612345 minutes
2023-08-01 19:36:29,972:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:29,973:INFO:Initializing create_model()
2023-08-01 19:36:29,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:29,974:INFO:Checking exceptions
2023-08-01 19:36:29,974:INFO:Importing libraries
2023-08-01 19:36:29,974:INFO:Copying training dataset
2023-08-01 19:36:29,981:INFO:Defining folds
2023-08-01 19:36:29,982:INFO:Declaring metric variables
2023-08-01 19:36:29,987:INFO:Importing untrained model
2023-08-01 19:36:29,995:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 19:36:30,008:INFO:Starting cross validation
2023-08-01 19:36:30,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:30,450:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,519:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,546:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,559:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,579:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,583:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,585:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:30,602:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:32,726:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:32,751:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:36:37,322:INFO:Calculating mean and std
2023-08-01 19:36:37,324:INFO:Creating metrics dataframe
2023-08-01 19:36:38,269:INFO:Uploading results into container
2023-08-01 19:36:38,270:INFO:Uploading model into container now
2023-08-01 19:36:38,271:INFO:_master_model_container: 22
2023-08-01 19:36:38,271:INFO:_display_container: 3
2023-08-01 19:36:38,272:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 19:36:38,272:INFO:create_model() successfully completed......................................
2023-08-01 19:36:38,436:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:38,436:INFO:Creating metrics dataframe
2023-08-01 19:36:38,456:INFO:Initializing Ridge Classifier
2023-08-01 19:36:38,456:INFO:Total runtime is 0.8286000927289326 minutes
2023-08-01 19:36:38,463:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:38,463:INFO:Initializing create_model()
2023-08-01 19:36:38,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:38,463:INFO:Checking exceptions
2023-08-01 19:36:38,464:INFO:Importing libraries
2023-08-01 19:36:38,464:INFO:Copying training dataset
2023-08-01 19:36:38,473:INFO:Defining folds
2023-08-01 19:36:38,474:INFO:Declaring metric variables
2023-08-01 19:36:38,480:INFO:Importing untrained model
2023-08-01 19:36:38,487:INFO:Ridge Classifier Imported successfully
2023-08-01 19:36:38,503:INFO:Starting cross validation
2023-08-01 19:36:38,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:38,920:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:38,968:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:39,018:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:39,023:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:39,054:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:39,078:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:39,101:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:41,139:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:41,230:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:36:41,235:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:42,612:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:36:42,617:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:36:46,146:INFO:Calculating mean and std
2023-08-01 19:36:46,148:INFO:Creating metrics dataframe
2023-08-01 19:36:47,121:INFO:Uploading results into container
2023-08-01 19:36:47,122:INFO:Uploading model into container now
2023-08-01 19:36:47,122:INFO:_master_model_container: 23
2023-08-01 19:36:47,123:INFO:_display_container: 3
2023-08-01 19:36:47,123:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 19:36:47,124:INFO:create_model() successfully completed......................................
2023-08-01 19:36:47,280:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:47,280:INFO:Creating metrics dataframe
2023-08-01 19:36:47,296:INFO:Initializing Random Forest Classifier
2023-08-01 19:36:47,297:INFO:Total runtime is 0.9759419004122416 minutes
2023-08-01 19:36:47,302:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:47,302:INFO:Initializing create_model()
2023-08-01 19:36:47,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:47,303:INFO:Checking exceptions
2023-08-01 19:36:47,303:INFO:Importing libraries
2023-08-01 19:36:47,303:INFO:Copying training dataset
2023-08-01 19:36:47,312:INFO:Defining folds
2023-08-01 19:36:47,312:INFO:Declaring metric variables
2023-08-01 19:36:47,317:INFO:Importing untrained model
2023-08-01 19:36:47,322:INFO:Random Forest Classifier Imported successfully
2023-08-01 19:36:47,336:INFO:Starting cross validation
2023-08-01 19:36:47,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:55,800:INFO:Calculating mean and std
2023-08-01 19:36:55,801:INFO:Creating metrics dataframe
2023-08-01 19:36:56,802:INFO:Uploading results into container
2023-08-01 19:36:56,804:INFO:Uploading model into container now
2023-08-01 19:36:56,804:INFO:_master_model_container: 24
2023-08-01 19:36:56,805:INFO:_display_container: 3
2023-08-01 19:36:56,805:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:36:56,805:INFO:create_model() successfully completed......................................
2023-08-01 19:36:56,985:INFO:SubProcess create_model() end ==================================
2023-08-01 19:36:56,985:INFO:Creating metrics dataframe
2023-08-01 19:36:57,002:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 19:36:57,002:INFO:Total runtime is 1.1376920779546102 minutes
2023-08-01 19:36:57,006:INFO:SubProcess create_model() called ==================================
2023-08-01 19:36:57,006:INFO:Initializing create_model()
2023-08-01 19:36:57,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:36:57,007:INFO:Checking exceptions
2023-08-01 19:36:57,007:INFO:Importing libraries
2023-08-01 19:36:57,007:INFO:Copying training dataset
2023-08-01 19:36:57,015:INFO:Defining folds
2023-08-01 19:36:57,015:INFO:Declaring metric variables
2023-08-01 19:36:57,020:INFO:Importing untrained model
2023-08-01 19:36:57,027:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 19:36:57,040:INFO:Starting cross validation
2023-08-01 19:36:57,045:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:36:57,444:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,453:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,471:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,496:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,497:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,507:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,507:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,508:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,514:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,534:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,535:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,535:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,539:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,550:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,550:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,550:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,554:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,555:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,555:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,556:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,556:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,556:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,564:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:57,570:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,570:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,571:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,572:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:57,589:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,589:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,598:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,600:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,600:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,601:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,612:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,613:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,613:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,616:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,616:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,617:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,619:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:57,620:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:57,627:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:57,628:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,628:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,629:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,634:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:57,660:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,660:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:57,661:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:36:57,667:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:36:59,840:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:59,868:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:36:59,953:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:59,953:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:36:59,953:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:37:00,084:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:00,084:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:00,085:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:37:00,086:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:37:01,197:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:01,199:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:01,199:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:01,200:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:37:01,227:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:01,227:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:37:01,228:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:37:01,232:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:37:04,826:INFO:Calculating mean and std
2023-08-01 19:37:04,828:INFO:Creating metrics dataframe
2023-08-01 19:37:05,850:INFO:Uploading results into container
2023-08-01 19:37:05,851:INFO:Uploading model into container now
2023-08-01 19:37:05,851:INFO:_master_model_container: 25
2023-08-01 19:37:05,852:INFO:_display_container: 3
2023-08-01 19:37:05,852:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 19:37:05,853:INFO:create_model() successfully completed......................................
2023-08-01 19:37:06,002:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:06,002:INFO:Creating metrics dataframe
2023-08-01 19:37:06,018:INFO:Initializing Ada Boost Classifier
2023-08-01 19:37:06,018:INFO:Total runtime is 1.2879587411880493 minutes
2023-08-01 19:37:06,023:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:06,024:INFO:Initializing create_model()
2023-08-01 19:37:06,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:06,024:INFO:Checking exceptions
2023-08-01 19:37:06,024:INFO:Importing libraries
2023-08-01 19:37:06,024:INFO:Copying training dataset
2023-08-01 19:37:06,033:INFO:Defining folds
2023-08-01 19:37:06,033:INFO:Declaring metric variables
2023-08-01 19:37:06,038:INFO:Importing untrained model
2023-08-01 19:37:06,045:INFO:Ada Boost Classifier Imported successfully
2023-08-01 19:37:06,056:INFO:Starting cross validation
2023-08-01 19:37:06,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:14,243:INFO:Calculating mean and std
2023-08-01 19:37:14,246:INFO:Creating metrics dataframe
2023-08-01 19:37:15,298:INFO:Uploading results into container
2023-08-01 19:37:15,299:INFO:Uploading model into container now
2023-08-01 19:37:15,300:INFO:_master_model_container: 26
2023-08-01 19:37:15,300:INFO:_display_container: 3
2023-08-01 19:37:15,300:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 19:37:15,300:INFO:create_model() successfully completed......................................
2023-08-01 19:37:15,467:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:15,467:INFO:Creating metrics dataframe
2023-08-01 19:37:15,481:INFO:Initializing Gradient Boosting Classifier
2023-08-01 19:37:15,482:INFO:Total runtime is 1.4456919034322102 minutes
2023-08-01 19:37:15,487:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:15,488:INFO:Initializing create_model()
2023-08-01 19:37:15,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:15,488:INFO:Checking exceptions
2023-08-01 19:37:15,488:INFO:Importing libraries
2023-08-01 19:37:15,488:INFO:Copying training dataset
2023-08-01 19:37:15,499:INFO:Defining folds
2023-08-01 19:37:15,499:INFO:Declaring metric variables
2023-08-01 19:37:15,504:INFO:Importing untrained model
2023-08-01 19:37:15,512:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:37:15,527:INFO:Starting cross validation
2023-08-01 19:37:15,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:18,994:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,048:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,087:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,124:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,193:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,255:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,269:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:19,270:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:26,840:INFO:Calculating mean and std
2023-08-01 19:37:26,842:INFO:Creating metrics dataframe
2023-08-01 19:37:28,029:INFO:Uploading results into container
2023-08-01 19:37:28,030:INFO:Uploading model into container now
2023-08-01 19:37:28,031:INFO:_master_model_container: 27
2023-08-01 19:37:28,031:INFO:_display_container: 3
2023-08-01 19:37:28,032:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:37:28,032:INFO:create_model() successfully completed......................................
2023-08-01 19:37:28,191:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:28,191:INFO:Creating metrics dataframe
2023-08-01 19:37:28,211:INFO:Initializing Linear Discriminant Analysis
2023-08-01 19:37:28,211:INFO:Total runtime is 1.6578420917193095 minutes
2023-08-01 19:37:28,216:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:28,216:INFO:Initializing create_model()
2023-08-01 19:37:28,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:28,217:INFO:Checking exceptions
2023-08-01 19:37:28,217:INFO:Importing libraries
2023-08-01 19:37:28,217:INFO:Copying training dataset
2023-08-01 19:37:28,226:INFO:Defining folds
2023-08-01 19:37:28,227:INFO:Declaring metric variables
2023-08-01 19:37:28,234:INFO:Importing untrained model
2023-08-01 19:37:28,240:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 19:37:28,272:INFO:Starting cross validation
2023-08-01 19:37:28,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:32,698:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:36,522:INFO:Calculating mean and std
2023-08-01 19:37:36,524:INFO:Creating metrics dataframe
2023-08-01 19:37:37,583:INFO:Uploading results into container
2023-08-01 19:37:37,584:INFO:Uploading model into container now
2023-08-01 19:37:37,584:INFO:_master_model_container: 28
2023-08-01 19:37:37,584:INFO:_display_container: 3
2023-08-01 19:37:37,585:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 19:37:37,585:INFO:create_model() successfully completed......................................
2023-08-01 19:37:37,735:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:37,735:INFO:Creating metrics dataframe
2023-08-01 19:37:37,752:INFO:Initializing Extra Trees Classifier
2023-08-01 19:37:37,752:INFO:Total runtime is 1.8168588876724243 minutes
2023-08-01 19:37:37,757:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:37,757:INFO:Initializing create_model()
2023-08-01 19:37:37,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:37,758:INFO:Checking exceptions
2023-08-01 19:37:37,758:INFO:Importing libraries
2023-08-01 19:37:37,758:INFO:Copying training dataset
2023-08-01 19:37:37,771:INFO:Defining folds
2023-08-01 19:37:37,771:INFO:Declaring metric variables
2023-08-01 19:37:37,780:INFO:Importing untrained model
2023-08-01 19:37:37,787:INFO:Extra Trees Classifier Imported successfully
2023-08-01 19:37:37,806:INFO:Starting cross validation
2023-08-01 19:37:37,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:47,119:INFO:Calculating mean and std
2023-08-01 19:37:47,120:INFO:Creating metrics dataframe
2023-08-01 19:37:48,281:INFO:Uploading results into container
2023-08-01 19:37:48,282:INFO:Uploading model into container now
2023-08-01 19:37:48,283:INFO:_master_model_container: 29
2023-08-01 19:37:48,284:INFO:_display_container: 3
2023-08-01 19:37:48,284:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:37:48,285:INFO:create_model() successfully completed......................................
2023-08-01 19:37:48,434:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:48,435:INFO:Creating metrics dataframe
2023-08-01 19:37:48,455:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 19:37:48,455:INFO:Total runtime is 1.9952508846918742 minutes
2023-08-01 19:37:48,462:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:48,463:INFO:Initializing create_model()
2023-08-01 19:37:48,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:48,463:INFO:Checking exceptions
2023-08-01 19:37:48,463:INFO:Importing libraries
2023-08-01 19:37:48,463:INFO:Copying training dataset
2023-08-01 19:37:48,472:INFO:Defining folds
2023-08-01 19:37:48,472:INFO:Declaring metric variables
2023-08-01 19:37:48,479:INFO:Importing untrained model
2023-08-01 19:37:48,485:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 19:37:48,498:INFO:Starting cross validation
2023-08-01 19:37:48,501:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:53,420:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:53,653:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:37:57,544:INFO:Calculating mean and std
2023-08-01 19:37:57,546:INFO:Creating metrics dataframe
2023-08-01 19:37:58,636:INFO:Uploading results into container
2023-08-01 19:37:58,637:INFO:Uploading model into container now
2023-08-01 19:37:58,638:INFO:_master_model_container: 30
2023-08-01 19:37:58,638:INFO:_display_container: 3
2023-08-01 19:37:58,639:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 19:37:58,640:INFO:create_model() successfully completed......................................
2023-08-01 19:37:58,790:INFO:SubProcess create_model() end ==================================
2023-08-01 19:37:58,791:INFO:Creating metrics dataframe
2023-08-01 19:37:58,819:INFO:Initializing Dummy Classifier
2023-08-01 19:37:58,819:INFO:Total runtime is 2.1679842551549275 minutes
2023-08-01 19:37:58,825:INFO:SubProcess create_model() called ==================================
2023-08-01 19:37:58,825:INFO:Initializing create_model()
2023-08-01 19:37:58,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70387F850>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:37:58,826:INFO:Checking exceptions
2023-08-01 19:37:58,826:INFO:Importing libraries
2023-08-01 19:37:58,826:INFO:Copying training dataset
2023-08-01 19:37:58,838:INFO:Defining folds
2023-08-01 19:37:58,838:INFO:Declaring metric variables
2023-08-01 19:37:58,848:INFO:Importing untrained model
2023-08-01 19:37:58,858:INFO:Dummy Classifier Imported successfully
2023-08-01 19:37:58,879:INFO:Starting cross validation
2023-08-01 19:37:58,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:37:59,424:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,473:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,490:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,540:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,547:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,549:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,549:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:37:59,631:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:38:02,096:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:38:02,296:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:38:07,112:INFO:Calculating mean and std
2023-08-01 19:38:07,113:INFO:Creating metrics dataframe
2023-08-01 19:38:08,214:INFO:Uploading results into container
2023-08-01 19:38:08,215:INFO:Uploading model into container now
2023-08-01 19:38:08,215:INFO:_master_model_container: 31
2023-08-01 19:38:08,215:INFO:_display_container: 3
2023-08-01 19:38:08,216:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 19:38:08,216:INFO:create_model() successfully completed......................................
2023-08-01 19:38:08,371:INFO:SubProcess create_model() end ==================================
2023-08-01 19:38:08,372:INFO:Creating metrics dataframe
2023-08-01 19:38:08,414:INFO:Initializing create_model()
2023-08-01 19:38:08,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:38:08,415:INFO:Checking exceptions
2023-08-01 19:38:08,418:INFO:Importing libraries
2023-08-01 19:38:08,419:INFO:Copying training dataset
2023-08-01 19:38:08,428:INFO:Defining folds
2023-08-01 19:38:08,428:INFO:Declaring metric variables
2023-08-01 19:38:08,429:INFO:Importing untrained model
2023-08-01 19:38:08,429:INFO:Declaring custom model
2023-08-01 19:38:08,430:INFO:Naive Bayes Imported successfully
2023-08-01 19:38:08,431:INFO:Cross validation set to False
2023-08-01 19:38:08,432:INFO:Fitting Model
2023-08-01 19:38:09,402:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:38:09,402:INFO:create_model() successfully completed......................................
2023-08-01 19:38:09,707:INFO:_master_model_container: 31
2023-08-01 19:38:09,707:INFO:_display_container: 3
2023-08-01 19:38:09,708:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:38:09,708:INFO:compare_models() successfully completed......................................
2023-08-01 19:39:10,869:INFO:Initializing create_model()
2023-08-01 19:39:10,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:39:10,869:INFO:Checking exceptions
2023-08-01 19:39:10,895:INFO:Importing libraries
2023-08-01 19:39:10,896:INFO:Copying training dataset
2023-08-01 19:39:10,907:INFO:Defining folds
2023-08-01 19:39:10,907:INFO:Declaring metric variables
2023-08-01 19:39:10,917:INFO:Importing untrained model
2023-08-01 19:39:10,924:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:39:10,938:INFO:Starting cross validation
2023-08-01 19:39:10,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:39:12,703:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:39:12,717:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:39:15,759:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:39:15,892:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:39:19,602:INFO:Calculating mean and std
2023-08-01 19:39:19,604:INFO:Creating metrics dataframe
2023-08-01 19:39:19,610:INFO:Finalizing model
2023-08-01 19:39:20,891:INFO:Uploading results into container
2023-08-01 19:39:20,892:INFO:Uploading model into container now
2023-08-01 19:39:20,921:INFO:_master_model_container: 32
2023-08-01 19:39:20,922:INFO:_display_container: 4
2023-08-01 19:39:20,923:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:39:20,924:INFO:create_model() successfully completed......................................
2023-08-01 19:39:35,891:INFO:Initializing evaluate_model()
2023-08-01 19:39:35,891:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 19:39:35,978:INFO:Initializing plot_model()
2023-08-01 19:39:35,978:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:39:35,978:INFO:Checking exceptions
2023-08-01 19:39:35,985:INFO:Preloading libraries
2023-08-01 19:39:36,006:INFO:Copying training dataset
2023-08-01 19:39:36,006:INFO:Plot type: pipeline
2023-08-01 19:39:36,723:INFO:Visual Rendered Successfully
2023-08-01 19:39:36,893:INFO:plot_model() successfully completed......................................
2023-08-01 19:39:47,135:INFO:Initializing plot_model()
2023-08-01 19:39:47,135:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:39:47,136:INFO:Checking exceptions
2023-08-01 19:39:47,139:INFO:Preloading libraries
2023-08-01 19:39:47,149:INFO:Copying training dataset
2023-08-01 19:39:47,149:INFO:Plot type: threshold
2023-08-01 19:39:47,541:INFO:Fitting Model
2023-08-01 19:40:27,255:INFO:Initializing plot_model()
2023-08-01 19:40:27,255:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:40:27,255:INFO:Checking exceptions
2023-08-01 19:40:27,262:INFO:Preloading libraries
2023-08-01 19:40:27,271:INFO:Copying training dataset
2023-08-01 19:40:27,271:INFO:Plot type: feature_all
2023-08-01 19:40:27,353:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 19:40:27,747:INFO:Visual Rendered Successfully
2023-08-01 19:40:27,941:INFO:plot_model() successfully completed......................................
2023-08-01 19:41:13,110:INFO:Initializing plot_model()
2023-08-01 19:41:13,110:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:41:13,110:INFO:Checking exceptions
2023-08-01 19:41:13,116:INFO:Preloading libraries
2023-08-01 19:41:13,124:INFO:Copying training dataset
2023-08-01 19:41:13,124:INFO:Plot type: feature
2023-08-01 19:41:13,124:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 19:41:13,379:INFO:Visual Rendered Successfully
2023-08-01 19:41:13,564:INFO:plot_model() successfully completed......................................
2023-08-01 19:41:28,651:INFO:Initializing plot_model()
2023-08-01 19:41:28,652:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:41:28,652:INFO:Checking exceptions
2023-08-01 19:41:28,656:INFO:Preloading libraries
2023-08-01 19:41:28,665:INFO:Copying training dataset
2023-08-01 19:41:28,665:INFO:Plot type: rfe
2023-08-01 19:41:29,083:INFO:Fitting Model
2023-08-01 19:45:08,342:INFO:Initializing create_model()
2023-08-01 19:45:08,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:45:08,342:INFO:Checking exceptions
2023-08-01 19:45:08,369:INFO:Importing libraries
2023-08-01 19:45:08,369:INFO:Copying training dataset
2023-08-01 19:45:08,379:INFO:Defining folds
2023-08-01 19:45:08,380:INFO:Declaring metric variables
2023-08-01 19:45:08,387:INFO:Importing untrained model
2023-08-01 19:45:08,394:INFO:Logistic Regression Imported successfully
2023-08-01 19:45:08,406:INFO:Starting cross validation
2023-08-01 19:45:08,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:45:25,779:INFO:Calculating mean and std
2023-08-01 19:45:25,782:INFO:Creating metrics dataframe
2023-08-01 19:45:25,790:INFO:Finalizing model
2023-08-01 19:45:27,507:INFO:Uploading results into container
2023-08-01 19:45:27,508:INFO:Uploading model into container now
2023-08-01 19:45:27,529:INFO:_master_model_container: 33
2023-08-01 19:45:27,529:INFO:_display_container: 5
2023-08-01 19:45:27,530:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:45:27,530:INFO:create_model() successfully completed......................................
2023-08-01 19:45:27,740:INFO:Initializing plot_model()
2023-08-01 19:45:27,741:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:45:27,742:INFO:Checking exceptions
2023-08-01 19:45:27,748:INFO:Preloading libraries
2023-08-01 19:45:27,780:INFO:Copying training dataset
2023-08-01 19:45:27,781:INFO:Plot type: parameter
2023-08-01 19:45:27,795:INFO:Visual Rendered Successfully
2023-08-01 19:45:27,998:INFO:plot_model() successfully completed......................................
2023-08-01 19:45:28,003:INFO:Initializing create_model()
2023-08-01 19:45:28,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:45:28,003:INFO:Checking exceptions
2023-08-01 19:45:28,025:INFO:Importing libraries
2023-08-01 19:45:28,025:INFO:Copying training dataset
2023-08-01 19:45:28,037:INFO:Defining folds
2023-08-01 19:45:28,037:INFO:Declaring metric variables
2023-08-01 19:45:28,043:INFO:Importing untrained model
2023-08-01 19:45:28,054:INFO:Logistic Regression Imported successfully
2023-08-01 19:45:28,069:INFO:Starting cross validation
2023-08-01 19:45:28,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:45:38,560:INFO:Calculating mean and std
2023-08-01 19:45:38,562:INFO:Creating metrics dataframe
2023-08-01 19:45:38,574:INFO:Finalizing model
2023-08-01 19:45:40,161:INFO:Uploading results into container
2023-08-01 19:45:40,163:INFO:Uploading model into container now
2023-08-01 19:45:40,184:INFO:_master_model_container: 34
2023-08-01 19:45:40,184:INFO:_display_container: 6
2023-08-01 19:45:40,185:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:45:40,186:INFO:create_model() successfully completed......................................
2023-08-01 19:45:44,527:INFO:Initializing evaluate_model()
2023-08-01 19:45:44,528:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 19:45:44,542:INFO:Initializing plot_model()
2023-08-01 19:45:44,542:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:45:44,542:INFO:Checking exceptions
2023-08-01 19:45:44,546:INFO:Preloading libraries
2023-08-01 19:45:44,546:INFO:Copying training dataset
2023-08-01 19:45:44,546:INFO:Plot type: pipeline
2023-08-01 19:45:44,831:INFO:Visual Rendered Successfully
2023-08-01 19:45:44,987:INFO:plot_model() successfully completed......................................
2023-08-01 19:45:47,203:INFO:Initializing plot_model()
2023-08-01 19:45:47,203:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70797EF40>, system=True)
2023-08-01 19:45:47,203:INFO:Checking exceptions
2023-08-01 19:45:47,207:INFO:Preloading libraries
2023-08-01 19:45:47,208:INFO:Copying training dataset
2023-08-01 19:45:47,208:INFO:Plot type: threshold
2023-08-01 19:45:47,883:INFO:Fitting Model
2023-08-01 19:46:52,330:INFO:PyCaret ClassificationExperiment
2023-08-01 19:46:52,330:INFO:Logging name: clf-default-name
2023-08-01 19:46:52,330:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 19:46:52,330:INFO:version 3.0.4
2023-08-01 19:46:52,330:INFO:Initializing setup()
2023-08-01 19:46:52,331:INFO:self.USI: 42fd
2023-08-01 19:46:52,331:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 19:46:52,331:INFO:Checking environment
2023-08-01 19:46:52,331:INFO:python_version: 3.9.13
2023-08-01 19:46:52,331:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 19:46:52,331:INFO:machine: AMD64
2023-08-01 19:46:52,331:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 19:46:52,337:INFO:Memory: svmem(total=17055166464, available=8815644672, percent=48.3, used=8239521792, free=8815644672)
2023-08-01 19:46:52,338:INFO:Physical Core: 4
2023-08-01 19:46:52,338:INFO:Logical Core: 8
2023-08-01 19:46:52,338:INFO:Checking libraries
2023-08-01 19:46:52,338:INFO:System:
2023-08-01 19:46:52,338:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 19:46:52,338:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 19:46:52,338:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 19:46:52,338:INFO:PyCaret required dependencies:
2023-08-01 19:46:52,340:INFO:                 pip: 22.0.4
2023-08-01 19:46:52,340:INFO:          setuptools: 58.1.0
2023-08-01 19:46:52,340:INFO:             pycaret: 3.0.4
2023-08-01 19:46:52,340:INFO:             IPython: 8.13.1
2023-08-01 19:46:52,340:INFO:          ipywidgets: 8.0.7
2023-08-01 19:46:52,340:INFO:                tqdm: 4.65.0
2023-08-01 19:46:52,340:INFO:               numpy: 1.23.0
2023-08-01 19:46:52,341:INFO:              pandas: 1.5.3
2023-08-01 19:46:52,341:INFO:              jinja2: 3.1.2
2023-08-01 19:46:52,341:INFO:               scipy: 1.10.1
2023-08-01 19:46:52,341:INFO:              joblib: 1.2.0
2023-08-01 19:46:52,341:INFO:             sklearn: 1.2.2
2023-08-01 19:46:52,341:INFO:                pyod: 1.1.0
2023-08-01 19:46:52,341:INFO:            imblearn: 0.11.0
2023-08-01 19:46:52,341:INFO:   category_encoders: 2.6.1
2023-08-01 19:46:52,341:INFO:            lightgbm: 3.3.5
2023-08-01 19:46:52,342:INFO:               numba: 0.57.1
2023-08-01 19:46:52,342:INFO:            requests: 2.31.0
2023-08-01 19:46:52,342:INFO:          matplotlib: 3.7.1
2023-08-01 19:46:52,342:INFO:          scikitplot: 0.3.7
2023-08-01 19:46:52,342:INFO:         yellowbrick: 1.5
2023-08-01 19:46:52,342:INFO:              plotly: 5.15.0
2023-08-01 19:46:52,342:INFO:    plotly-resampler: Not installed
2023-08-01 19:46:52,342:INFO:             kaleido: 0.2.1
2023-08-01 19:46:52,343:INFO:           schemdraw: 0.15
2023-08-01 19:46:52,343:INFO:         statsmodels: 0.14.0
2023-08-01 19:46:52,343:INFO:              sktime: 0.20.0
2023-08-01 19:46:52,343:INFO:               tbats: 1.1.3
2023-08-01 19:46:52,343:INFO:            pmdarima: 2.0.3
2023-08-01 19:46:52,343:INFO:              psutil: 5.9.5
2023-08-01 19:46:52,343:INFO:          markupsafe: 2.1.3
2023-08-01 19:46:52,343:INFO:             pickle5: Not installed
2023-08-01 19:46:52,344:INFO:         cloudpickle: 2.2.1
2023-08-01 19:46:52,344:INFO:         deprecation: 2.1.0
2023-08-01 19:46:52,344:INFO:              xxhash: 3.2.0
2023-08-01 19:46:52,344:INFO:           wurlitzer: Not installed
2023-08-01 19:46:52,344:INFO:PyCaret optional dependencies:
2023-08-01 19:46:52,344:INFO:                shap: Not installed
2023-08-01 19:46:52,344:INFO:           interpret: Not installed
2023-08-01 19:46:52,344:INFO:                umap: Not installed
2023-08-01 19:46:52,344:INFO:    pandas_profiling: 4.3.1
2023-08-01 19:46:52,344:INFO:  explainerdashboard: Not installed
2023-08-01 19:46:52,344:INFO:             autoviz: Not installed
2023-08-01 19:46:52,344:INFO:           fairlearn: Not installed
2023-08-01 19:46:52,344:INFO:          deepchecks: Not installed
2023-08-01 19:46:52,344:INFO:             xgboost: Not installed
2023-08-01 19:46:52,344:INFO:            catboost: Not installed
2023-08-01 19:46:52,344:INFO:              kmodes: Not installed
2023-08-01 19:46:52,344:INFO:             mlxtend: 0.22.0
2023-08-01 19:46:52,344:INFO:       statsforecast: Not installed
2023-08-01 19:46:52,344:INFO:        tune_sklearn: Not installed
2023-08-01 19:46:52,344:INFO:                 ray: Not installed
2023-08-01 19:46:52,344:INFO:            hyperopt: Not installed
2023-08-01 19:46:52,344:INFO:              optuna: Not installed
2023-08-01 19:46:52,344:INFO:               skopt: Not installed
2023-08-01 19:46:52,344:INFO:              mlflow: Not installed
2023-08-01 19:46:52,344:INFO:              gradio: Not installed
2023-08-01 19:46:52,346:INFO:             fastapi: Not installed
2023-08-01 19:46:52,346:INFO:             uvicorn: Not installed
2023-08-01 19:46:52,346:INFO:              m2cgen: Not installed
2023-08-01 19:46:52,346:INFO:           evidently: Not installed
2023-08-01 19:46:52,346:INFO:               fugue: Not installed
2023-08-01 19:46:52,346:INFO:           streamlit: Not installed
2023-08-01 19:46:52,346:INFO:             prophet: Not installed
2023-08-01 19:46:52,346:INFO:None
2023-08-01 19:46:52,346:INFO:Set up data.
2023-08-01 19:46:52,362:INFO:Set up train/test split.
2023-08-01 19:46:52,377:INFO:Set up index.
2023-08-01 19:46:52,377:INFO:Set up folding strategy.
2023-08-01 19:46:52,377:INFO:Assigning column types.
2023-08-01 19:46:52,385:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 19:46:52,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:46:52,457:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:46:52,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,612:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:46:52,613:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:46:52,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,665:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 19:46:52,772:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:46:52,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:52,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:46:53,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,008:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 19:46:53,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:53,229:INFO:Preparing preprocessing pipeline...
2023-08-01 19:46:53,230:INFO:Set up simple imputation.
2023-08-01 19:46:53,233:INFO:Set up encoding of categorical features.
2023-08-01 19:46:53,235:INFO:Set up removing multicollinearity.
2023-08-01 19:46:53,235:INFO:Set up feature normalization.
2023-08-01 19:46:53,410:INFO:Finished creating preprocessing pipeline.
2023-08-01 19:46:53,677:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-08-01 19:46:53,677:INFO:Creating final display dataframe.
2023-08-01 19:46:53,967:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 18)  
5                                          (6508, 18)  
6                                          (1628, 18)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             robust  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               42fd  
2023-08-01 19:46:54,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:54,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:54,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:54,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:46:54,226:INFO:setup() successfully completed in 2.81s...............
2023-08-01 19:50:17,638:INFO:PyCaret ClassificationExperiment
2023-08-01 19:50:17,638:INFO:Logging name: clf-default-name
2023-08-01 19:50:17,638:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 19:50:17,638:INFO:version 3.0.4
2023-08-01 19:50:17,638:INFO:Initializing setup()
2023-08-01 19:50:17,638:INFO:self.USI: 3632
2023-08-01 19:50:17,639:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 19:50:17,639:INFO:Checking environment
2023-08-01 19:50:17,639:INFO:python_version: 3.9.13
2023-08-01 19:50:17,639:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 19:50:17,639:INFO:machine: AMD64
2023-08-01 19:50:17,639:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 19:50:17,641:INFO:Memory: svmem(total=17055166464, available=8372359168, percent=50.9, used=8682807296, free=8372359168)
2023-08-01 19:50:17,641:INFO:Physical Core: 4
2023-08-01 19:50:17,642:INFO:Logical Core: 8
2023-08-01 19:50:17,642:INFO:Checking libraries
2023-08-01 19:50:17,642:INFO:System:
2023-08-01 19:50:17,642:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 19:50:17,642:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 19:50:17,642:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 19:50:17,642:INFO:PyCaret required dependencies:
2023-08-01 19:50:17,642:INFO:                 pip: 22.0.4
2023-08-01 19:50:17,642:INFO:          setuptools: 58.1.0
2023-08-01 19:50:17,642:INFO:             pycaret: 3.0.4
2023-08-01 19:50:17,643:INFO:             IPython: 8.13.1
2023-08-01 19:50:17,643:INFO:          ipywidgets: 8.0.7
2023-08-01 19:50:17,643:INFO:                tqdm: 4.65.0
2023-08-01 19:50:17,643:INFO:               numpy: 1.23.0
2023-08-01 19:50:17,643:INFO:              pandas: 1.5.3
2023-08-01 19:50:17,643:INFO:              jinja2: 3.1.2
2023-08-01 19:50:17,643:INFO:               scipy: 1.10.1
2023-08-01 19:50:17,643:INFO:              joblib: 1.2.0
2023-08-01 19:50:17,643:INFO:             sklearn: 1.2.2
2023-08-01 19:50:17,643:INFO:                pyod: 1.1.0
2023-08-01 19:50:17,643:INFO:            imblearn: 0.11.0
2023-08-01 19:50:17,643:INFO:   category_encoders: 2.6.1
2023-08-01 19:50:17,643:INFO:            lightgbm: 3.3.5
2023-08-01 19:50:17,644:INFO:               numba: 0.57.1
2023-08-01 19:50:17,644:INFO:            requests: 2.31.0
2023-08-01 19:50:17,644:INFO:          matplotlib: 3.7.1
2023-08-01 19:50:17,644:INFO:          scikitplot: 0.3.7
2023-08-01 19:50:17,644:INFO:         yellowbrick: 1.5
2023-08-01 19:50:17,644:INFO:              plotly: 5.15.0
2023-08-01 19:50:17,644:INFO:    plotly-resampler: Not installed
2023-08-01 19:50:17,644:INFO:             kaleido: 0.2.1
2023-08-01 19:50:17,644:INFO:           schemdraw: 0.15
2023-08-01 19:50:17,644:INFO:         statsmodels: 0.14.0
2023-08-01 19:50:17,644:INFO:              sktime: 0.20.0
2023-08-01 19:50:17,644:INFO:               tbats: 1.1.3
2023-08-01 19:50:17,644:INFO:            pmdarima: 2.0.3
2023-08-01 19:50:17,644:INFO:              psutil: 5.9.5
2023-08-01 19:50:17,644:INFO:          markupsafe: 2.1.3
2023-08-01 19:50:17,645:INFO:             pickle5: Not installed
2023-08-01 19:50:17,645:INFO:         cloudpickle: 2.2.1
2023-08-01 19:50:17,645:INFO:         deprecation: 2.1.0
2023-08-01 19:50:17,645:INFO:              xxhash: 3.2.0
2023-08-01 19:50:17,645:INFO:           wurlitzer: Not installed
2023-08-01 19:50:17,645:INFO:PyCaret optional dependencies:
2023-08-01 19:50:17,645:INFO:                shap: Not installed
2023-08-01 19:50:17,645:INFO:           interpret: Not installed
2023-08-01 19:50:17,645:INFO:                umap: Not installed
2023-08-01 19:50:17,645:INFO:    pandas_profiling: 4.3.1
2023-08-01 19:50:17,645:INFO:  explainerdashboard: Not installed
2023-08-01 19:50:17,645:INFO:             autoviz: Not installed
2023-08-01 19:50:17,645:INFO:           fairlearn: Not installed
2023-08-01 19:50:17,645:INFO:          deepchecks: Not installed
2023-08-01 19:50:17,645:INFO:             xgboost: Not installed
2023-08-01 19:50:17,645:INFO:            catboost: Not installed
2023-08-01 19:50:17,645:INFO:              kmodes: Not installed
2023-08-01 19:50:17,646:INFO:             mlxtend: 0.22.0
2023-08-01 19:50:17,646:INFO:       statsforecast: Not installed
2023-08-01 19:50:17,646:INFO:        tune_sklearn: Not installed
2023-08-01 19:50:17,646:INFO:                 ray: Not installed
2023-08-01 19:50:17,646:INFO:            hyperopt: Not installed
2023-08-01 19:50:17,646:INFO:              optuna: Not installed
2023-08-01 19:50:17,646:INFO:               skopt: Not installed
2023-08-01 19:50:17,646:INFO:              mlflow: Not installed
2023-08-01 19:50:17,646:INFO:              gradio: Not installed
2023-08-01 19:50:17,646:INFO:             fastapi: Not installed
2023-08-01 19:50:17,646:INFO:             uvicorn: Not installed
2023-08-01 19:50:17,646:INFO:              m2cgen: Not installed
2023-08-01 19:50:17,646:INFO:           evidently: Not installed
2023-08-01 19:50:17,646:INFO:               fugue: Not installed
2023-08-01 19:50:17,646:INFO:           streamlit: Not installed
2023-08-01 19:50:17,646:INFO:             prophet: Not installed
2023-08-01 19:50:17,647:INFO:None
2023-08-01 19:50:17,647:INFO:Set up data.
2023-08-01 19:50:17,657:INFO:Set up train/test split.
2023-08-01 19:50:17,666:INFO:Set up index.
2023-08-01 19:50:17,666:INFO:Set up folding strategy.
2023-08-01 19:50:17,666:INFO:Assigning column types.
2023-08-01 19:50:17,670:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 19:50:17,723:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:50:17,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:50:17,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:17,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:17,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:50:17,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:50:17,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:17,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:17,883:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 19:50:17,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:50:17,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:17,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,058:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:50:18,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,106:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 19:50:18,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:18,437:INFO:Preparing preprocessing pipeline...
2023-08-01 19:50:18,439:INFO:Set up simple imputation.
2023-08-01 19:50:18,442:INFO:Set up encoding of categorical features.
2023-08-01 19:50:18,443:INFO:Set up removing multicollinearity.
2023-08-01 19:50:18,443:INFO:Set up feature normalization.
2023-08-01 19:50:18,641:INFO:Finished creating preprocessing pipeline.
2023-08-01 19:50:18,892:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-08-01 19:50:18,892:INFO:Creating final display dataframe.
2023-08-01 19:50:19,088:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 18)  
5                                          (6508, 18)  
6                                          (1628, 18)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             robust  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               3632  
2023-08-01 19:50:19,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:19,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:19,313:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:19,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:50:19,314:INFO:setup() successfully completed in 2.38s...............
2023-08-01 19:50:28,757:INFO:Initializing compare_models()
2023-08-01 19:50:28,757:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced Accucary, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced Accucary', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:50:28,757:INFO:Checking exceptions
2023-08-01 19:50:40,154:INFO:Initializing compare_models()
2023-08-01 19:50:40,155:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:50:40,155:INFO:Checking exceptions
2023-08-01 19:50:40,169:INFO:Preparing display monitor
2023-08-01 19:50:40,254:INFO:Initializing Logistic Regression
2023-08-01 19:50:40,254:INFO:Total runtime is 0.0 minutes
2023-08-01 19:50:40,267:INFO:SubProcess create_model() called ==================================
2023-08-01 19:50:40,268:INFO:Initializing create_model()
2023-08-01 19:50:40,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:50:40,269:INFO:Checking exceptions
2023-08-01 19:50:40,269:INFO:Importing libraries
2023-08-01 19:50:40,269:INFO:Copying training dataset
2023-08-01 19:50:40,289:INFO:Defining folds
2023-08-01 19:50:40,290:INFO:Declaring metric variables
2023-08-01 19:50:40,301:INFO:Importing untrained model
2023-08-01 19:50:40,312:INFO:Logistic Regression Imported successfully
2023-08-01 19:50:40,339:INFO:Starting cross validation
2023-08-01 19:50:40,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:50:58,336:INFO:Calculating mean and std
2023-08-01 19:50:58,337:INFO:Creating metrics dataframe
2023-08-01 19:50:59,486:INFO:Uploading results into container
2023-08-01 19:50:59,487:INFO:Uploading model into container now
2023-08-01 19:50:59,488:INFO:_master_model_container: 1
2023-08-01 19:50:59,488:INFO:_display_container: 2
2023-08-01 19:50:59,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:50:59,489:INFO:create_model() successfully completed......................................
2023-08-01 19:50:59,693:INFO:SubProcess create_model() end ==================================
2023-08-01 19:50:59,693:INFO:Creating metrics dataframe
2023-08-01 19:50:59,710:INFO:Initializing K Neighbors Classifier
2023-08-01 19:50:59,710:INFO:Total runtime is 0.3242668390274048 minutes
2023-08-01 19:50:59,718:INFO:SubProcess create_model() called ==================================
2023-08-01 19:50:59,718:INFO:Initializing create_model()
2023-08-01 19:50:59,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:50:59,718:INFO:Checking exceptions
2023-08-01 19:50:59,718:INFO:Importing libraries
2023-08-01 19:50:59,719:INFO:Copying training dataset
2023-08-01 19:50:59,732:INFO:Defining folds
2023-08-01 19:50:59,732:INFO:Declaring metric variables
2023-08-01 19:50:59,738:INFO:Importing untrained model
2023-08-01 19:50:59,748:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:50:59,766:INFO:Starting cross validation
2023-08-01 19:50:59,769:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:08,946:INFO:Calculating mean and std
2023-08-01 19:51:08,948:INFO:Creating metrics dataframe
2023-08-01 19:51:10,303:INFO:Uploading results into container
2023-08-01 19:51:10,304:INFO:Uploading model into container now
2023-08-01 19:51:10,305:INFO:_master_model_container: 2
2023-08-01 19:51:10,305:INFO:_display_container: 2
2023-08-01 19:51:10,306:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:51:10,306:INFO:create_model() successfully completed......................................
2023-08-01 19:51:10,477:INFO:SubProcess create_model() end ==================================
2023-08-01 19:51:10,477:INFO:Creating metrics dataframe
2023-08-01 19:51:10,494:INFO:Initializing Naive Bayes
2023-08-01 19:51:10,494:INFO:Total runtime is 0.5040002663930256 minutes
2023-08-01 19:51:10,502:INFO:SubProcess create_model() called ==================================
2023-08-01 19:51:10,503:INFO:Initializing create_model()
2023-08-01 19:51:10,503:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:51:10,503:INFO:Checking exceptions
2023-08-01 19:51:10,503:INFO:Importing libraries
2023-08-01 19:51:10,503:INFO:Copying training dataset
2023-08-01 19:51:10,516:INFO:Defining folds
2023-08-01 19:51:10,516:INFO:Declaring metric variables
2023-08-01 19:51:10,524:INFO:Importing untrained model
2023-08-01 19:51:10,533:INFO:Naive Bayes Imported successfully
2023-08-01 19:51:10,551:INFO:Starting cross validation
2023-08-01 19:51:10,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:19,324:INFO:Calculating mean and std
2023-08-01 19:51:19,326:INFO:Creating metrics dataframe
2023-08-01 19:51:20,510:INFO:Uploading results into container
2023-08-01 19:51:20,511:INFO:Uploading model into container now
2023-08-01 19:51:20,512:INFO:_master_model_container: 3
2023-08-01 19:51:20,513:INFO:_display_container: 2
2023-08-01 19:51:20,513:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:51:20,514:INFO:create_model() successfully completed......................................
2023-08-01 19:51:20,687:INFO:SubProcess create_model() end ==================================
2023-08-01 19:51:20,687:INFO:Creating metrics dataframe
2023-08-01 19:51:20,704:INFO:Initializing Decision Tree Classifier
2023-08-01 19:51:20,704:INFO:Total runtime is 0.6741669217745463 minutes
2023-08-01 19:51:20,709:INFO:SubProcess create_model() called ==================================
2023-08-01 19:51:20,709:INFO:Initializing create_model()
2023-08-01 19:51:20,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:51:20,710:INFO:Checking exceptions
2023-08-01 19:51:20,710:INFO:Importing libraries
2023-08-01 19:51:20,710:INFO:Copying training dataset
2023-08-01 19:51:20,721:INFO:Defining folds
2023-08-01 19:51:20,722:INFO:Declaring metric variables
2023-08-01 19:51:20,730:INFO:Importing untrained model
2023-08-01 19:51:20,736:INFO:Decision Tree Classifier Imported successfully
2023-08-01 19:51:20,754:INFO:Starting cross validation
2023-08-01 19:51:20,757:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:29,576:INFO:Calculating mean and std
2023-08-01 19:51:29,578:INFO:Creating metrics dataframe
2023-08-01 19:51:30,787:INFO:Uploading results into container
2023-08-01 19:51:30,788:INFO:Uploading model into container now
2023-08-01 19:51:30,789:INFO:_master_model_container: 4
2023-08-01 19:51:30,789:INFO:_display_container: 2
2023-08-01 19:51:30,789:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 19:51:30,790:INFO:create_model() successfully completed......................................
2023-08-01 19:51:30,978:INFO:SubProcess create_model() end ==================================
2023-08-01 19:51:30,978:INFO:Creating metrics dataframe
2023-08-01 19:51:30,992:INFO:Initializing SVM - Linear Kernel
2023-08-01 19:51:30,992:INFO:Total runtime is 0.845633590221405 minutes
2023-08-01 19:51:30,998:INFO:SubProcess create_model() called ==================================
2023-08-01 19:51:30,998:INFO:Initializing create_model()
2023-08-01 19:51:30,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:51:30,999:INFO:Checking exceptions
2023-08-01 19:51:30,999:INFO:Importing libraries
2023-08-01 19:51:30,999:INFO:Copying training dataset
2023-08-01 19:51:31,007:INFO:Defining folds
2023-08-01 19:51:31,007:INFO:Declaring metric variables
2023-08-01 19:51:31,014:INFO:Importing untrained model
2023-08-01 19:51:31,021:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 19:51:31,038:INFO:Starting cross validation
2023-08-01 19:51:31,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:31,583:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,653:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,686:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,712:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,754:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,855:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,947:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:31,985:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:36,298:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:51:36,306:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:36,333:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:51:36,338:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:51:40,785:INFO:Calculating mean and std
2023-08-01 19:51:40,786:INFO:Creating metrics dataframe
2023-08-01 19:51:42,016:INFO:Uploading results into container
2023-08-01 19:51:42,017:INFO:Uploading model into container now
2023-08-01 19:51:42,018:INFO:_master_model_container: 5
2023-08-01 19:51:42,019:INFO:_display_container: 2
2023-08-01 19:51:42,019:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 19:51:42,020:INFO:create_model() successfully completed......................................
2023-08-01 19:51:42,189:INFO:SubProcess create_model() end ==================================
2023-08-01 19:51:42,189:INFO:Creating metrics dataframe
2023-08-01 19:51:42,204:INFO:Initializing Ridge Classifier
2023-08-01 19:51:42,205:INFO:Total runtime is 1.032516876856486 minutes
2023-08-01 19:51:42,209:INFO:SubProcess create_model() called ==================================
2023-08-01 19:51:42,210:INFO:Initializing create_model()
2023-08-01 19:51:42,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:51:42,211:INFO:Checking exceptions
2023-08-01 19:51:42,211:INFO:Importing libraries
2023-08-01 19:51:42,211:INFO:Copying training dataset
2023-08-01 19:51:42,221:INFO:Defining folds
2023-08-01 19:51:42,221:INFO:Declaring metric variables
2023-08-01 19:51:42,228:INFO:Importing untrained model
2023-08-01 19:51:42,236:INFO:Ridge Classifier Imported successfully
2023-08-01 19:51:42,256:INFO:Starting cross validation
2023-08-01 19:51:42,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:42,807:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,823:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,843:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,872:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,927:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,959:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,965:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:42,984:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:45,707:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:45,790:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:51:51,208:INFO:Calculating mean and std
2023-08-01 19:51:51,210:INFO:Creating metrics dataframe
2023-08-01 19:51:52,460:INFO:Uploading results into container
2023-08-01 19:51:52,461:INFO:Uploading model into container now
2023-08-01 19:51:52,462:INFO:_master_model_container: 6
2023-08-01 19:51:52,463:INFO:_display_container: 2
2023-08-01 19:51:52,465:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 19:51:52,465:INFO:create_model() successfully completed......................................
2023-08-01 19:51:52,655:INFO:SubProcess create_model() end ==================================
2023-08-01 19:51:52,655:INFO:Creating metrics dataframe
2023-08-01 19:51:52,675:INFO:Initializing Random Forest Classifier
2023-08-01 19:51:52,675:INFO:Total runtime is 1.2070170044898987 minutes
2023-08-01 19:51:52,683:INFO:SubProcess create_model() called ==================================
2023-08-01 19:51:52,684:INFO:Initializing create_model()
2023-08-01 19:51:52,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:51:52,684:INFO:Checking exceptions
2023-08-01 19:51:52,684:INFO:Importing libraries
2023-08-01 19:51:52,685:INFO:Copying training dataset
2023-08-01 19:51:52,695:INFO:Defining folds
2023-08-01 19:51:52,695:INFO:Declaring metric variables
2023-08-01 19:51:52,703:INFO:Importing untrained model
2023-08-01 19:51:52,712:INFO:Random Forest Classifier Imported successfully
2023-08-01 19:51:52,734:INFO:Starting cross validation
2023-08-01 19:51:52,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:51:59,632:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:51:59,973:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:04,203:INFO:Calculating mean and std
2023-08-01 19:52:04,205:INFO:Creating metrics dataframe
2023-08-01 19:52:05,455:INFO:Uploading results into container
2023-08-01 19:52:05,457:INFO:Uploading model into container now
2023-08-01 19:52:05,457:INFO:_master_model_container: 7
2023-08-01 19:52:05,457:INFO:_display_container: 2
2023-08-01 19:52:05,458:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:52:05,459:INFO:create_model() successfully completed......................................
2023-08-01 19:52:05,624:INFO:SubProcess create_model() end ==================================
2023-08-01 19:52:05,624:INFO:Creating metrics dataframe
2023-08-01 19:52:05,640:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 19:52:05,640:INFO:Total runtime is 1.423100221157074 minutes
2023-08-01 19:52:05,644:INFO:SubProcess create_model() called ==================================
2023-08-01 19:52:05,644:INFO:Initializing create_model()
2023-08-01 19:52:05,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:52:05,645:INFO:Checking exceptions
2023-08-01 19:52:05,645:INFO:Importing libraries
2023-08-01 19:52:05,645:INFO:Copying training dataset
2023-08-01 19:52:05,656:INFO:Defining folds
2023-08-01 19:52:05,656:INFO:Declaring metric variables
2023-08-01 19:52:05,662:INFO:Importing untrained model
2023-08-01 19:52:05,669:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 19:52:05,686:INFO:Starting cross validation
2023-08-01 19:52:05,691:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:52:06,172:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,196:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,204:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,228:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,250:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,269:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,269:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,270:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,274:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,274:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,275:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,276:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,278:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,308:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,308:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,309:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,320:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,321:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,322:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,335:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:06,337:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,337:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,338:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,343:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,343:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,344:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,346:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:06,351:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,352:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,353:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,354:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:06,400:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,401:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,402:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,409:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,409:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,410:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,410:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:06,419:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:06,429:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,432:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,433:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,441:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,441:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,442:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,467:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:06,523:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,523:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:06,524:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:06,532:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:09,309:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:09,371:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:52:09,420:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:09,420:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:09,421:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:09,456:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:09,456:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:09,457:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:09,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:10,999:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:11,003:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:11,003:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:11,003:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:11,083:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:11,083:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 19:52:11,083:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 19:52:11,087:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 19:52:15,305:INFO:Calculating mean and std
2023-08-01 19:52:15,306:INFO:Creating metrics dataframe
2023-08-01 19:52:16,573:INFO:Uploading results into container
2023-08-01 19:52:16,575:INFO:Uploading model into container now
2023-08-01 19:52:16,575:INFO:_master_model_container: 8
2023-08-01 19:52:16,576:INFO:_display_container: 2
2023-08-01 19:52:16,577:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 19:52:16,577:INFO:create_model() successfully completed......................................
2023-08-01 19:52:16,770:INFO:SubProcess create_model() end ==================================
2023-08-01 19:52:16,771:INFO:Creating metrics dataframe
2023-08-01 19:52:16,791:INFO:Initializing Ada Boost Classifier
2023-08-01 19:52:16,791:INFO:Total runtime is 1.6089502811431886 minutes
2023-08-01 19:52:16,796:INFO:SubProcess create_model() called ==================================
2023-08-01 19:52:16,797:INFO:Initializing create_model()
2023-08-01 19:52:16,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:52:16,798:INFO:Checking exceptions
2023-08-01 19:52:16,798:INFO:Importing libraries
2023-08-01 19:52:16,799:INFO:Copying training dataset
2023-08-01 19:52:16,809:INFO:Defining folds
2023-08-01 19:52:16,809:INFO:Declaring metric variables
2023-08-01 19:52:16,818:INFO:Importing untrained model
2023-08-01 19:52:16,826:INFO:Ada Boost Classifier Imported successfully
2023-08-01 19:52:16,847:INFO:Starting cross validation
2023-08-01 19:52:16,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:52:22,807:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:22,813:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:27,422:INFO:Calculating mean and std
2023-08-01 19:52:27,424:INFO:Creating metrics dataframe
2023-08-01 19:52:28,710:INFO:Uploading results into container
2023-08-01 19:52:28,712:INFO:Uploading model into container now
2023-08-01 19:52:28,713:INFO:_master_model_container: 9
2023-08-01 19:52:28,713:INFO:_display_container: 2
2023-08-01 19:52:28,714:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 19:52:28,714:INFO:create_model() successfully completed......................................
2023-08-01 19:52:28,896:INFO:SubProcess create_model() end ==================================
2023-08-01 19:52:28,896:INFO:Creating metrics dataframe
2023-08-01 19:52:28,920:INFO:Initializing Gradient Boosting Classifier
2023-08-01 19:52:28,920:INFO:Total runtime is 1.8111000021298729 minutes
2023-08-01 19:52:28,928:INFO:SubProcess create_model() called ==================================
2023-08-01 19:52:28,928:INFO:Initializing create_model()
2023-08-01 19:52:28,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:52:28,928:INFO:Checking exceptions
2023-08-01 19:52:28,928:INFO:Importing libraries
2023-08-01 19:52:28,929:INFO:Copying training dataset
2023-08-01 19:52:28,942:INFO:Defining folds
2023-08-01 19:52:28,942:INFO:Declaring metric variables
2023-08-01 19:52:28,949:INFO:Importing untrained model
2023-08-01 19:52:28,957:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:52:28,978:INFO:Starting cross validation
2023-08-01 19:52:28,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:52:39,411:INFO:Calculating mean and std
2023-08-01 19:52:39,413:INFO:Creating metrics dataframe
2023-08-01 19:52:40,713:INFO:Uploading results into container
2023-08-01 19:52:40,714:INFO:Uploading model into container now
2023-08-01 19:52:40,716:INFO:_master_model_container: 10
2023-08-01 19:52:40,717:INFO:_display_container: 2
2023-08-01 19:52:40,718:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:52:40,718:INFO:create_model() successfully completed......................................
2023-08-01 19:52:40,891:INFO:SubProcess create_model() end ==================================
2023-08-01 19:52:40,891:INFO:Creating metrics dataframe
2023-08-01 19:52:40,910:INFO:Initializing Linear Discriminant Analysis
2023-08-01 19:52:40,910:INFO:Total runtime is 2.010933307806651 minutes
2023-08-01 19:52:40,919:INFO:SubProcess create_model() called ==================================
2023-08-01 19:52:40,919:INFO:Initializing create_model()
2023-08-01 19:52:40,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:52:40,920:INFO:Checking exceptions
2023-08-01 19:52:40,921:INFO:Importing libraries
2023-08-01 19:52:40,921:INFO:Copying training dataset
2023-08-01 19:52:40,934:INFO:Defining folds
2023-08-01 19:52:40,935:INFO:Declaring metric variables
2023-08-01 19:52:40,943:INFO:Importing untrained model
2023-08-01 19:52:40,955:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 19:52:40,976:INFO:Starting cross validation
2023-08-01 19:52:40,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:52:46,466:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:50,859:INFO:Calculating mean and std
2023-08-01 19:52:50,861:INFO:Creating metrics dataframe
2023-08-01 19:52:52,226:INFO:Uploading results into container
2023-08-01 19:52:52,227:INFO:Uploading model into container now
2023-08-01 19:52:52,228:INFO:_master_model_container: 11
2023-08-01 19:52:52,228:INFO:_display_container: 2
2023-08-01 19:52:52,229:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 19:52:52,230:INFO:create_model() successfully completed......................................
2023-08-01 19:52:52,437:INFO:SubProcess create_model() end ==================================
2023-08-01 19:52:52,437:INFO:Creating metrics dataframe
2023-08-01 19:52:52,457:INFO:Initializing Extra Trees Classifier
2023-08-01 19:52:52,457:INFO:Total runtime is 2.2033757448196414 minutes
2023-08-01 19:52:52,463:INFO:SubProcess create_model() called ==================================
2023-08-01 19:52:52,463:INFO:Initializing create_model()
2023-08-01 19:52:52,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:52:52,464:INFO:Checking exceptions
2023-08-01 19:52:52,464:INFO:Importing libraries
2023-08-01 19:52:52,464:INFO:Copying training dataset
2023-08-01 19:52:52,476:INFO:Defining folds
2023-08-01 19:52:52,476:INFO:Declaring metric variables
2023-08-01 19:52:52,482:INFO:Importing untrained model
2023-08-01 19:52:52,489:INFO:Extra Trees Classifier Imported successfully
2023-08-01 19:52:52,506:INFO:Starting cross validation
2023-08-01 19:52:52,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:52:59,526:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:52:59,612:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:53:04,192:INFO:Calculating mean and std
2023-08-01 19:53:04,193:INFO:Creating metrics dataframe
2023-08-01 19:53:05,498:INFO:Uploading results into container
2023-08-01 19:53:05,500:INFO:Uploading model into container now
2023-08-01 19:53:05,503:INFO:_master_model_container: 12
2023-08-01 19:53:05,503:INFO:_display_container: 2
2023-08-01 19:53:05,505:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:53:05,505:INFO:create_model() successfully completed......................................
2023-08-01 19:53:05,727:INFO:SubProcess create_model() end ==================================
2023-08-01 19:53:05,727:INFO:Creating metrics dataframe
2023-08-01 19:53:05,749:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 19:53:05,749:INFO:Total runtime is 2.4249091784159345 minutes
2023-08-01 19:53:05,757:INFO:SubProcess create_model() called ==================================
2023-08-01 19:53:05,758:INFO:Initializing create_model()
2023-08-01 19:53:05,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:53:05,758:INFO:Checking exceptions
2023-08-01 19:53:05,758:INFO:Importing libraries
2023-08-01 19:53:05,758:INFO:Copying training dataset
2023-08-01 19:53:05,772:INFO:Defining folds
2023-08-01 19:53:05,772:INFO:Declaring metric variables
2023-08-01 19:53:05,779:INFO:Importing untrained model
2023-08-01 19:53:05,788:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 19:53:05,810:INFO:Starting cross validation
2023-08-01 19:53:05,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:53:16,215:INFO:Calculating mean and std
2023-08-01 19:53:16,216:INFO:Creating metrics dataframe
2023-08-01 19:53:17,579:INFO:Uploading results into container
2023-08-01 19:53:17,580:INFO:Uploading model into container now
2023-08-01 19:53:17,581:INFO:_master_model_container: 13
2023-08-01 19:53:17,581:INFO:_display_container: 2
2023-08-01 19:53:17,582:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 19:53:17,583:INFO:create_model() successfully completed......................................
2023-08-01 19:53:17,791:INFO:SubProcess create_model() end ==================================
2023-08-01 19:53:17,791:INFO:Creating metrics dataframe
2023-08-01 19:53:17,811:INFO:Initializing Dummy Classifier
2023-08-01 19:53:17,812:INFO:Total runtime is 2.625959153970083 minutes
2023-08-01 19:53:17,817:INFO:SubProcess create_model() called ==================================
2023-08-01 19:53:17,819:INFO:Initializing create_model()
2023-08-01 19:53:17,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70969A550>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:53:17,820:INFO:Checking exceptions
2023-08-01 19:53:17,820:INFO:Importing libraries
2023-08-01 19:53:17,820:INFO:Copying training dataset
2023-08-01 19:53:17,830:INFO:Defining folds
2023-08-01 19:53:17,830:INFO:Declaring metric variables
2023-08-01 19:53:17,837:INFO:Importing untrained model
2023-08-01 19:53:17,843:INFO:Dummy Classifier Imported successfully
2023-08-01 19:53:17,857:INFO:Starting cross validation
2023-08-01 19:53:17,862:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:53:18,501:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,573:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,592:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,610:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,649:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,695:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,700:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:18,726:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:21,776:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:23,578:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:53:23,638:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:53:27,967:INFO:Calculating mean and std
2023-08-01 19:53:27,970:INFO:Creating metrics dataframe
2023-08-01 19:53:29,257:INFO:Uploading results into container
2023-08-01 19:53:29,258:INFO:Uploading model into container now
2023-08-01 19:53:29,259:INFO:_master_model_container: 14
2023-08-01 19:53:29,259:INFO:_display_container: 2
2023-08-01 19:53:29,259:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 19:53:29,259:INFO:create_model() successfully completed......................................
2023-08-01 19:53:29,449:INFO:SubProcess create_model() end ==================================
2023-08-01 19:53:29,449:INFO:Creating metrics dataframe
2023-08-01 19:53:29,491:INFO:Initializing create_model()
2023-08-01 19:53:29,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70961DFD0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:53:29,492:INFO:Checking exceptions
2023-08-01 19:53:29,495:INFO:Importing libraries
2023-08-01 19:53:29,496:INFO:Copying training dataset
2023-08-01 19:53:29,506:INFO:Defining folds
2023-08-01 19:53:29,507:INFO:Declaring metric variables
2023-08-01 19:53:29,507:INFO:Importing untrained model
2023-08-01 19:53:29,507:INFO:Declaring custom model
2023-08-01 19:53:29,507:INFO:Naive Bayes Imported successfully
2023-08-01 19:53:29,510:INFO:Cross validation set to False
2023-08-01 19:53:29,510:INFO:Fitting Model
2023-08-01 19:53:30,446:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:53:30,446:INFO:create_model() successfully completed......................................
2023-08-01 19:53:30,808:INFO:_master_model_container: 14
2023-08-01 19:53:30,808:INFO:_display_container: 2
2023-08-01 19:53:30,809:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:53:30,809:INFO:compare_models() successfully completed......................................
2023-08-01 19:54:17,273:INFO:PyCaret ClassificationExperiment
2023-08-01 19:54:17,273:INFO:Logging name: clf-default-name
2023-08-01 19:54:17,273:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 19:54:17,274:INFO:version 3.0.4
2023-08-01 19:54:17,274:INFO:Initializing setup()
2023-08-01 19:54:17,274:INFO:self.USI: 6b49
2023-08-01 19:54:17,274:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 19:54:17,274:INFO:Checking environment
2023-08-01 19:54:17,274:INFO:python_version: 3.9.13
2023-08-01 19:54:17,274:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 19:54:17,275:INFO:machine: AMD64
2023-08-01 19:54:17,275:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 19:54:17,279:INFO:Memory: svmem(total=17055166464, available=8683208704, percent=49.1, used=8371957760, free=8683208704)
2023-08-01 19:54:17,279:INFO:Physical Core: 4
2023-08-01 19:54:17,280:INFO:Logical Core: 8
2023-08-01 19:54:17,280:INFO:Checking libraries
2023-08-01 19:54:17,280:INFO:System:
2023-08-01 19:54:17,280:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 19:54:17,280:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 19:54:17,280:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 19:54:17,280:INFO:PyCaret required dependencies:
2023-08-01 19:54:17,281:INFO:                 pip: 22.0.4
2023-08-01 19:54:17,281:INFO:          setuptools: 58.1.0
2023-08-01 19:54:17,281:INFO:             pycaret: 3.0.4
2023-08-01 19:54:17,282:INFO:             IPython: 8.13.1
2023-08-01 19:54:17,282:INFO:          ipywidgets: 8.0.7
2023-08-01 19:54:17,282:INFO:                tqdm: 4.65.0
2023-08-01 19:54:17,282:INFO:               numpy: 1.23.0
2023-08-01 19:54:17,282:INFO:              pandas: 1.5.3
2023-08-01 19:54:17,282:INFO:              jinja2: 3.1.2
2023-08-01 19:54:17,282:INFO:               scipy: 1.10.1
2023-08-01 19:54:17,283:INFO:              joblib: 1.2.0
2023-08-01 19:54:17,283:INFO:             sklearn: 1.2.2
2023-08-01 19:54:17,283:INFO:                pyod: 1.1.0
2023-08-01 19:54:17,283:INFO:            imblearn: 0.11.0
2023-08-01 19:54:17,283:INFO:   category_encoders: 2.6.1
2023-08-01 19:54:17,283:INFO:            lightgbm: 3.3.5
2023-08-01 19:54:17,283:INFO:               numba: 0.57.1
2023-08-01 19:54:17,283:INFO:            requests: 2.31.0
2023-08-01 19:54:17,283:INFO:          matplotlib: 3.7.1
2023-08-01 19:54:17,283:INFO:          scikitplot: 0.3.7
2023-08-01 19:54:17,283:INFO:         yellowbrick: 1.5
2023-08-01 19:54:17,284:INFO:              plotly: 5.15.0
2023-08-01 19:54:17,284:INFO:    plotly-resampler: Not installed
2023-08-01 19:54:17,284:INFO:             kaleido: 0.2.1
2023-08-01 19:54:17,284:INFO:           schemdraw: 0.15
2023-08-01 19:54:17,284:INFO:         statsmodels: 0.14.0
2023-08-01 19:54:17,284:INFO:              sktime: 0.20.0
2023-08-01 19:54:17,284:INFO:               tbats: 1.1.3
2023-08-01 19:54:17,284:INFO:            pmdarima: 2.0.3
2023-08-01 19:54:17,284:INFO:              psutil: 5.9.5
2023-08-01 19:54:17,284:INFO:          markupsafe: 2.1.3
2023-08-01 19:54:17,285:INFO:             pickle5: Not installed
2023-08-01 19:54:17,285:INFO:         cloudpickle: 2.2.1
2023-08-01 19:54:17,285:INFO:         deprecation: 2.1.0
2023-08-01 19:54:17,285:INFO:              xxhash: 3.2.0
2023-08-01 19:54:17,285:INFO:           wurlitzer: Not installed
2023-08-01 19:54:17,285:INFO:PyCaret optional dependencies:
2023-08-01 19:54:17,285:INFO:                shap: Not installed
2023-08-01 19:54:17,285:INFO:           interpret: Not installed
2023-08-01 19:54:17,285:INFO:                umap: Not installed
2023-08-01 19:54:17,285:INFO:    pandas_profiling: 4.3.1
2023-08-01 19:54:17,285:INFO:  explainerdashboard: Not installed
2023-08-01 19:54:17,286:INFO:             autoviz: Not installed
2023-08-01 19:54:17,286:INFO:           fairlearn: Not installed
2023-08-01 19:54:17,286:INFO:          deepchecks: Not installed
2023-08-01 19:54:17,286:INFO:             xgboost: Not installed
2023-08-01 19:54:17,286:INFO:            catboost: Not installed
2023-08-01 19:54:17,286:INFO:              kmodes: Not installed
2023-08-01 19:54:17,286:INFO:             mlxtend: 0.22.0
2023-08-01 19:54:17,286:INFO:       statsforecast: Not installed
2023-08-01 19:54:17,286:INFO:        tune_sklearn: Not installed
2023-08-01 19:54:17,286:INFO:                 ray: Not installed
2023-08-01 19:54:17,286:INFO:            hyperopt: Not installed
2023-08-01 19:54:17,287:INFO:              optuna: Not installed
2023-08-01 19:54:17,287:INFO:               skopt: Not installed
2023-08-01 19:54:17,287:INFO:              mlflow: Not installed
2023-08-01 19:54:17,287:INFO:              gradio: Not installed
2023-08-01 19:54:17,287:INFO:             fastapi: Not installed
2023-08-01 19:54:17,287:INFO:             uvicorn: Not installed
2023-08-01 19:54:17,287:INFO:              m2cgen: Not installed
2023-08-01 19:54:17,287:INFO:           evidently: Not installed
2023-08-01 19:54:17,287:INFO:               fugue: Not installed
2023-08-01 19:54:17,288:INFO:           streamlit: Not installed
2023-08-01 19:54:17,288:INFO:             prophet: Not installed
2023-08-01 19:54:17,288:INFO:None
2023-08-01 19:54:17,288:INFO:Set up data.
2023-08-01 19:54:17,308:INFO:Set up train/test split.
2023-08-01 19:54:17,326:INFO:Set up index.
2023-08-01 19:54:17,327:INFO:Set up folding strategy.
2023-08-01 19:54:17,327:INFO:Assigning column types.
2023-08-01 19:54:17,339:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 19:54:17,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:54:17,445:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:54:17,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 19:54:17,708:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:54:17,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,758:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,758:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 19:54:17,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:54:17,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:17,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 19:54:18,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,001:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 19:54:18,168:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:18,313:INFO:Preparing preprocessing pipeline...
2023-08-01 19:54:18,315:INFO:Set up simple imputation.
2023-08-01 19:54:18,321:INFO:Set up encoding of categorical features.
2023-08-01 19:54:18,322:INFO:Set up removing multicollinearity.
2023-08-01 19:54:18,322:INFO:Set up feature normalization.
2023-08-01 19:54:18,560:INFO:Finished creating preprocessing pipeline.
2023-08-01 19:54:18,866:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
-1                      0                     0                     0   
-2                      0                     0                     0   

     reserved_room_type_3  
 1                      1  
 2                      0  
 3                      1  
 4                      0  
 5                      1  
 6                      0  
 7                      1  
 8                      0  
 9                      1  
 10                     0  
-1                      0  
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 19:54:18,866:INFO:Creating final display dataframe.
2023-08-01 19:54:19,261:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 18)  
5                                          (6508, 18)  
6                                          (1628, 18)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             zscore  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               6b49  
2023-08-01 19:54:19,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:19,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:19,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:19,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 19:54:19,578:INFO:setup() successfully completed in 3.53s...............
2023-08-01 19:54:33,260:INFO:Initializing compare_models()
2023-08-01 19:54:33,261:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 19:54:33,261:INFO:Checking exceptions
2023-08-01 19:54:33,268:INFO:Preparing display monitor
2023-08-01 19:54:33,312:INFO:Initializing Logistic Regression
2023-08-01 19:54:33,312:INFO:Total runtime is 0.0 minutes
2023-08-01 19:54:33,319:INFO:SubProcess create_model() called ==================================
2023-08-01 19:54:33,320:INFO:Initializing create_model()
2023-08-01 19:54:33,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:54:33,321:INFO:Checking exceptions
2023-08-01 19:54:33,321:INFO:Importing libraries
2023-08-01 19:54:33,321:INFO:Copying training dataset
2023-08-01 19:54:33,332:INFO:Defining folds
2023-08-01 19:54:33,332:INFO:Declaring metric variables
2023-08-01 19:54:33,340:INFO:Importing untrained model
2023-08-01 19:54:33,348:INFO:Logistic Regression Imported successfully
2023-08-01 19:54:33,367:INFO:Starting cross validation
2023-08-01 19:54:33,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:54:35,641:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:54:37,796:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:37,927:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:37,947:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:37,975:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:38,006:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:38,034:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:38,085:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:39,417:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:42,863:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:43,009:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:47,207:INFO:Calculating mean and std
2023-08-01 19:54:47,208:INFO:Creating metrics dataframe
2023-08-01 19:54:48,403:INFO:Uploading results into container
2023-08-01 19:54:48,405:INFO:Uploading model into container now
2023-08-01 19:54:48,406:INFO:_master_model_container: 1
2023-08-01 19:54:48,406:INFO:_display_container: 2
2023-08-01 19:54:48,407:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 19:54:48,407:INFO:create_model() successfully completed......................................
2023-08-01 19:54:48,598:INFO:SubProcess create_model() end ==================================
2023-08-01 19:54:48,598:INFO:Creating metrics dataframe
2023-08-01 19:54:48,615:INFO:Initializing K Neighbors Classifier
2023-08-01 19:54:48,616:INFO:Total runtime is 0.25507659117380777 minutes
2023-08-01 19:54:48,622:INFO:SubProcess create_model() called ==================================
2023-08-01 19:54:48,623:INFO:Initializing create_model()
2023-08-01 19:54:48,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:54:48,623:INFO:Checking exceptions
2023-08-01 19:54:48,623:INFO:Importing libraries
2023-08-01 19:54:48,623:INFO:Copying training dataset
2023-08-01 19:54:48,638:INFO:Defining folds
2023-08-01 19:54:48,638:INFO:Declaring metric variables
2023-08-01 19:54:48,648:INFO:Importing untrained model
2023-08-01 19:54:48,656:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:54:48,671:INFO:Starting cross validation
2023-08-01 19:54:48,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:54:52,346:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,410:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,497:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,501:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,550:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,674:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,675:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:52,697:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:57,219:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:54:57,255:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:02,201:INFO:Calculating mean and std
2023-08-01 19:55:02,202:INFO:Creating metrics dataframe
2023-08-01 19:55:03,434:INFO:Uploading results into container
2023-08-01 19:55:03,436:INFO:Uploading model into container now
2023-08-01 19:55:03,437:INFO:_master_model_container: 2
2023-08-01 19:55:03,437:INFO:_display_container: 2
2023-08-01 19:55:03,437:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:55:03,437:INFO:create_model() successfully completed......................................
2023-08-01 19:55:03,621:INFO:SubProcess create_model() end ==================================
2023-08-01 19:55:03,622:INFO:Creating metrics dataframe
2023-08-01 19:55:03,636:INFO:Initializing Naive Bayes
2023-08-01 19:55:03,636:INFO:Total runtime is 0.5054098804791769 minutes
2023-08-01 19:55:03,644:INFO:SubProcess create_model() called ==================================
2023-08-01 19:55:03,644:INFO:Initializing create_model()
2023-08-01 19:55:03,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:55:03,644:INFO:Checking exceptions
2023-08-01 19:55:03,644:INFO:Importing libraries
2023-08-01 19:55:03,644:INFO:Copying training dataset
2023-08-01 19:55:03,653:INFO:Defining folds
2023-08-01 19:55:03,653:INFO:Declaring metric variables
2023-08-01 19:55:03,661:INFO:Importing untrained model
2023-08-01 19:55:03,672:INFO:Naive Bayes Imported successfully
2023-08-01 19:55:03,695:INFO:Starting cross validation
2023-08-01 19:55:03,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:55:07,367:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,413:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,462:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,466:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,479:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,494:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,536:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:07,584:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:12,058:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:12,059:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:16,422:INFO:Calculating mean and std
2023-08-01 19:55:16,425:INFO:Creating metrics dataframe
2023-08-01 19:55:17,638:INFO:Uploading results into container
2023-08-01 19:55:17,640:INFO:Uploading model into container now
2023-08-01 19:55:17,641:INFO:_master_model_container: 3
2023-08-01 19:55:17,642:INFO:_display_container: 2
2023-08-01 19:55:17,642:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 19:55:17,643:INFO:create_model() successfully completed......................................
2023-08-01 19:55:17,806:INFO:SubProcess create_model() end ==================================
2023-08-01 19:55:17,806:INFO:Creating metrics dataframe
2023-08-01 19:55:17,822:INFO:Initializing Decision Tree Classifier
2023-08-01 19:55:17,822:INFO:Total runtime is 0.7418432871500652 minutes
2023-08-01 19:55:17,830:INFO:SubProcess create_model() called ==================================
2023-08-01 19:55:17,830:INFO:Initializing create_model()
2023-08-01 19:55:17,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:55:17,830:INFO:Checking exceptions
2023-08-01 19:55:17,831:INFO:Importing libraries
2023-08-01 19:55:17,831:INFO:Copying training dataset
2023-08-01 19:55:17,844:INFO:Defining folds
2023-08-01 19:55:17,844:INFO:Declaring metric variables
2023-08-01 19:55:17,851:INFO:Importing untrained model
2023-08-01 19:55:17,860:INFO:Decision Tree Classifier Imported successfully
2023-08-01 19:55:17,875:INFO:Starting cross validation
2023-08-01 19:55:17,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:55:21,537:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,544:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,545:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,554:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,594:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,656:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,687:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:21,730:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:26,151:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:30,606:INFO:Calculating mean and std
2023-08-01 19:55:30,608:INFO:Creating metrics dataframe
2023-08-01 19:55:31,827:INFO:Uploading results into container
2023-08-01 19:55:31,828:INFO:Uploading model into container now
2023-08-01 19:55:31,829:INFO:_master_model_container: 4
2023-08-01 19:55:31,829:INFO:_display_container: 2
2023-08-01 19:55:31,830:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 19:55:31,830:INFO:create_model() successfully completed......................................
2023-08-01 19:55:31,994:INFO:SubProcess create_model() end ==================================
2023-08-01 19:55:31,994:INFO:Creating metrics dataframe
2023-08-01 19:55:32,010:INFO:Initializing SVM - Linear Kernel
2023-08-01 19:55:32,010:INFO:Total runtime is 0.9783098896344504 minutes
2023-08-01 19:55:32,016:INFO:SubProcess create_model() called ==================================
2023-08-01 19:55:32,017:INFO:Initializing create_model()
2023-08-01 19:55:32,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:55:32,017:INFO:Checking exceptions
2023-08-01 19:55:32,017:INFO:Importing libraries
2023-08-01 19:55:32,017:INFO:Copying training dataset
2023-08-01 19:55:32,030:INFO:Defining folds
2023-08-01 19:55:32,030:INFO:Declaring metric variables
2023-08-01 19:55:32,037:INFO:Importing untrained model
2023-08-01 19:55:32,047:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 19:55:32,061:INFO:Starting cross validation
2023-08-01 19:55:32,064:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:55:35,688:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:35,699:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:35,898:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:35,906:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,170:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,183:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,204:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,215:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,262:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,267:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,271:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,276:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,352:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,362:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:36,388:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:36,398:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:40,770:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:40,776:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:40,909:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:40,915:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 19:55:45,444:INFO:Calculating mean and std
2023-08-01 19:55:45,446:INFO:Creating metrics dataframe
2023-08-01 19:55:46,765:INFO:Uploading results into container
2023-08-01 19:55:46,766:INFO:Uploading model into container now
2023-08-01 19:55:46,767:INFO:_master_model_container: 5
2023-08-01 19:55:46,767:INFO:_display_container: 2
2023-08-01 19:55:46,768:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 19:55:46,769:INFO:create_model() successfully completed......................................
2023-08-01 19:55:46,963:INFO:SubProcess create_model() end ==================================
2023-08-01 19:55:46,963:INFO:Creating metrics dataframe
2023-08-01 19:55:46,982:INFO:Initializing Ridge Classifier
2023-08-01 19:55:46,982:INFO:Total runtime is 1.227836616834005 minutes
2023-08-01 19:55:46,988:INFO:SubProcess create_model() called ==================================
2023-08-01 19:55:46,989:INFO:Initializing create_model()
2023-08-01 19:55:46,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:55:46,989:INFO:Checking exceptions
2023-08-01 19:55:46,989:INFO:Importing libraries
2023-08-01 19:55:46,989:INFO:Copying training dataset
2023-08-01 19:55:47,004:INFO:Defining folds
2023-08-01 19:55:47,004:INFO:Declaring metric variables
2023-08-01 19:55:47,015:INFO:Importing untrained model
2023-08-01 19:55:47,023:INFO:Ridge Classifier Imported successfully
2023-08-01 19:55:47,042:INFO:Starting cross validation
2023-08-01 19:55:47,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:55:51,143:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,151:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,155:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,167:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,223:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,256:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,317:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,326:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,375:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,385:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,410:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,417:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,451:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,462:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:51,520:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:51,529:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:55,921:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:55,929:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:55:56,066:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:55:56,070:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 19:56:00,951:INFO:Calculating mean and std
2023-08-01 19:56:00,953:INFO:Creating metrics dataframe
2023-08-01 19:56:02,299:INFO:Uploading results into container
2023-08-01 19:56:02,300:INFO:Uploading model into container now
2023-08-01 19:56:02,301:INFO:_master_model_container: 6
2023-08-01 19:56:02,301:INFO:_display_container: 2
2023-08-01 19:56:02,302:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 19:56:02,302:INFO:create_model() successfully completed......................................
2023-08-01 19:56:02,506:INFO:SubProcess create_model() end ==================================
2023-08-01 19:56:02,506:INFO:Creating metrics dataframe
2023-08-01 19:56:02,527:INFO:Initializing Random Forest Classifier
2023-08-01 19:56:02,527:INFO:Total runtime is 1.4869200348854066 minutes
2023-08-01 19:56:02,534:INFO:SubProcess create_model() called ==================================
2023-08-01 19:56:02,535:INFO:Initializing create_model()
2023-08-01 19:56:02,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:56:02,535:INFO:Checking exceptions
2023-08-01 19:56:02,536:INFO:Importing libraries
2023-08-01 19:56:02,536:INFO:Copying training dataset
2023-08-01 19:56:02,550:INFO:Defining folds
2023-08-01 19:56:02,550:INFO:Declaring metric variables
2023-08-01 19:56:02,556:INFO:Importing untrained model
2023-08-01 19:56:02,568:INFO:Random Forest Classifier Imported successfully
2023-08-01 19:56:02,584:INFO:Starting cross validation
2023-08-01 19:56:02,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:56:05,811:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:56:05,842:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:56:05,850:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:56:05,854:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:56:05,893:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:56:09,638:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:09,654:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:09,722:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:09,725:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:09,879:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:09,883:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:10,082:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:10,160:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:16,700:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:16,785:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:21,578:INFO:Calculating mean and std
2023-08-01 19:56:21,580:INFO:Creating metrics dataframe
2023-08-01 19:56:22,917:INFO:Uploading results into container
2023-08-01 19:56:22,918:INFO:Uploading model into container now
2023-08-01 19:56:22,919:INFO:_master_model_container: 7
2023-08-01 19:56:22,919:INFO:_display_container: 2
2023-08-01 19:56:22,920:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:56:22,921:INFO:create_model() successfully completed......................................
2023-08-01 19:56:23,085:INFO:SubProcess create_model() end ==================================
2023-08-01 19:56:23,086:INFO:Creating metrics dataframe
2023-08-01 19:56:23,104:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 19:56:23,104:INFO:Total runtime is 1.8298699975013735 minutes
2023-08-01 19:56:23,110:INFO:SubProcess create_model() called ==================================
2023-08-01 19:56:23,111:INFO:Initializing create_model()
2023-08-01 19:56:23,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:56:23,112:INFO:Checking exceptions
2023-08-01 19:56:23,112:INFO:Importing libraries
2023-08-01 19:56:23,112:INFO:Copying training dataset
2023-08-01 19:56:23,122:INFO:Defining folds
2023-08-01 19:56:23,122:INFO:Declaring metric variables
2023-08-01 19:56:23,131:INFO:Importing untrained model
2023-08-01 19:56:23,138:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 19:56:23,152:INFO:Starting cross validation
2023-08-01 19:56:23,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:56:23,603:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,663:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,663:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,665:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,682:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,684:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,696:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:23,711:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:26,960:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:26,969:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:26,982:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:26,991:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:27,013:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:27,032:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:27,081:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:27,103:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:30,052:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:30,120:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 19:56:31,991:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:32,017:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:36,831:INFO:Calculating mean and std
2023-08-01 19:56:36,833:INFO:Creating metrics dataframe
2023-08-01 19:56:38,228:INFO:Uploading results into container
2023-08-01 19:56:38,230:INFO:Uploading model into container now
2023-08-01 19:56:38,231:INFO:_master_model_container: 8
2023-08-01 19:56:38,231:INFO:_display_container: 2
2023-08-01 19:56:38,231:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 19:56:38,231:INFO:create_model() successfully completed......................................
2023-08-01 19:56:38,402:INFO:SubProcess create_model() end ==================================
2023-08-01 19:56:38,402:INFO:Creating metrics dataframe
2023-08-01 19:56:38,418:INFO:Initializing Ada Boost Classifier
2023-08-01 19:56:38,419:INFO:Total runtime is 2.085119899113973 minutes
2023-08-01 19:56:38,424:INFO:SubProcess create_model() called ==================================
2023-08-01 19:56:38,424:INFO:Initializing create_model()
2023-08-01 19:56:38,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:56:38,424:INFO:Checking exceptions
2023-08-01 19:56:38,425:INFO:Importing libraries
2023-08-01 19:56:38,425:INFO:Copying training dataset
2023-08-01 19:56:38,434:INFO:Defining folds
2023-08-01 19:56:38,434:INFO:Declaring metric variables
2023-08-01 19:56:38,440:INFO:Importing untrained model
2023-08-01 19:56:38,447:INFO:Ada Boost Classifier Imported successfully
2023-08-01 19:56:38,459:INFO:Starting cross validation
2023-08-01 19:56:38,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:56:40,499:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:56:43,881:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,020:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,052:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,090:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,200:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,212:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:44,284:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:45,602:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:50,650:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:50,698:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:56:56,033:INFO:Calculating mean and std
2023-08-01 19:56:56,034:INFO:Creating metrics dataframe
2023-08-01 19:56:57,472:INFO:Uploading results into container
2023-08-01 19:56:57,474:INFO:Uploading model into container now
2023-08-01 19:56:57,475:INFO:_master_model_container: 9
2023-08-01 19:56:57,475:INFO:_display_container: 2
2023-08-01 19:56:57,475:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 19:56:57,476:INFO:create_model() successfully completed......................................
2023-08-01 19:56:57,685:INFO:SubProcess create_model() end ==================================
2023-08-01 19:56:57,685:INFO:Creating metrics dataframe
2023-08-01 19:56:57,708:INFO:Initializing Gradient Boosting Classifier
2023-08-01 19:56:57,709:INFO:Total runtime is 2.406619906425476 minutes
2023-08-01 19:56:57,719:INFO:SubProcess create_model() called ==================================
2023-08-01 19:56:57,720:INFO:Initializing create_model()
2023-08-01 19:56:57,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:56:57,720:INFO:Checking exceptions
2023-08-01 19:56:57,720:INFO:Importing libraries
2023-08-01 19:56:57,721:INFO:Copying training dataset
2023-08-01 19:56:57,738:INFO:Defining folds
2023-08-01 19:56:57,738:INFO:Declaring metric variables
2023-08-01 19:56:57,748:INFO:Importing untrained model
2023-08-01 19:56:57,758:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 19:56:57,775:INFO:Starting cross validation
2023-08-01 19:56:57,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:57:04,474:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,486:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,591:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,622:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,633:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,647:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,675:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:04,720:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:11,795:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:11,877:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:17,161:INFO:Calculating mean and std
2023-08-01 19:57:17,164:INFO:Creating metrics dataframe
2023-08-01 19:57:19,277:INFO:Uploading results into container
2023-08-01 19:57:19,280:INFO:Uploading model into container now
2023-08-01 19:57:19,281:INFO:_master_model_container: 10
2023-08-01 19:57:19,282:INFO:_display_container: 2
2023-08-01 19:57:19,282:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 19:57:19,283:INFO:create_model() successfully completed......................................
2023-08-01 19:57:19,501:INFO:SubProcess create_model() end ==================================
2023-08-01 19:57:19,503:INFO:Creating metrics dataframe
2023-08-01 19:57:19,545:INFO:Initializing Linear Discriminant Analysis
2023-08-01 19:57:19,545:INFO:Total runtime is 2.7705533345540365 minutes
2023-08-01 19:57:19,558:INFO:SubProcess create_model() called ==================================
2023-08-01 19:57:19,559:INFO:Initializing create_model()
2023-08-01 19:57:19,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:57:19,560:INFO:Checking exceptions
2023-08-01 19:57:19,560:INFO:Importing libraries
2023-08-01 19:57:19,560:INFO:Copying training dataset
2023-08-01 19:57:19,580:INFO:Defining folds
2023-08-01 19:57:19,581:INFO:Declaring metric variables
2023-08-01 19:57:19,594:INFO:Importing untrained model
2023-08-01 19:57:19,609:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 19:57:19,639:INFO:Starting cross validation
2023-08-01 19:57:19,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:57:24,671:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:25,051:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:25,125:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:25,318:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:25,593:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:25,636:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:26,036:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:26,114:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:30,035:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-01 19:57:31,368:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:32,681:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:39,874:INFO:Calculating mean and std
2023-08-01 19:57:39,876:INFO:Creating metrics dataframe
2023-08-01 19:57:41,858:INFO:Uploading results into container
2023-08-01 19:57:41,859:INFO:Uploading model into container now
2023-08-01 19:57:41,860:INFO:_master_model_container: 11
2023-08-01 19:57:41,861:INFO:_display_container: 2
2023-08-01 19:57:41,862:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 19:57:41,863:INFO:create_model() successfully completed......................................
2023-08-01 19:57:42,207:INFO:SubProcess create_model() end ==================================
2023-08-01 19:57:42,208:INFO:Creating metrics dataframe
2023-08-01 19:57:42,252:INFO:Initializing Extra Trees Classifier
2023-08-01 19:57:42,252:INFO:Total runtime is 3.1489954511324565 minutes
2023-08-01 19:57:42,265:INFO:SubProcess create_model() called ==================================
2023-08-01 19:57:42,266:INFO:Initializing create_model()
2023-08-01 19:57:42,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:57:42,268:INFO:Checking exceptions
2023-08-01 19:57:42,269:INFO:Importing libraries
2023-08-01 19:57:42,270:INFO:Copying training dataset
2023-08-01 19:57:42,293:INFO:Defining folds
2023-08-01 19:57:42,293:INFO:Declaring metric variables
2023-08-01 19:57:42,310:INFO:Importing untrained model
2023-08-01 19:57:42,331:INFO:Extra Trees Classifier Imported successfully
2023-08-01 19:57:42,370:INFO:Starting cross validation
2023-08-01 19:57:42,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:57:46,825:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:46,827:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:46,849:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:47,051:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:47,591:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:47,712:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:47,821:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 19:57:51,015:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-01 19:57:51,896:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:51,965:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:52,822:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:53,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:53,819:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 6.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:54,188:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 6.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:54,526:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:57:56,776:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 5.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:04,202:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:04,369:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:11,030:INFO:Calculating mean and std
2023-08-01 19:58:11,034:INFO:Creating metrics dataframe
2023-08-01 19:58:12,723:INFO:Uploading results into container
2023-08-01 19:58:12,725:INFO:Uploading model into container now
2023-08-01 19:58:12,726:INFO:_master_model_container: 12
2023-08-01 19:58:12,726:INFO:_display_container: 2
2023-08-01 19:58:12,728:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 19:58:12,729:INFO:create_model() successfully completed......................................
2023-08-01 19:58:12,928:INFO:SubProcess create_model() end ==================================
2023-08-01 19:58:12,928:INFO:Creating metrics dataframe
2023-08-01 19:58:12,951:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 19:58:12,951:INFO:Total runtime is 3.660645421346029 minutes
2023-08-01 19:58:12,958:INFO:SubProcess create_model() called ==================================
2023-08-01 19:58:12,958:INFO:Initializing create_model()
2023-08-01 19:58:12,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:58:12,959:INFO:Checking exceptions
2023-08-01 19:58:12,960:INFO:Importing libraries
2023-08-01 19:58:12,960:INFO:Copying training dataset
2023-08-01 19:58:12,974:INFO:Defining folds
2023-08-01 19:58:12,975:INFO:Declaring metric variables
2023-08-01 19:58:12,984:INFO:Importing untrained model
2023-08-01 19:58:12,991:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 19:58:13,013:INFO:Starting cross validation
2023-08-01 19:58:13,018:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:58:18,654:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:18,815:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:18,828:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:18,905:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:18,997:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:19,027:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:19,094:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:19,257:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:25,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:25,638:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:31,293:INFO:Calculating mean and std
2023-08-01 19:58:31,294:INFO:Creating metrics dataframe
2023-08-01 19:58:33,072:INFO:Uploading results into container
2023-08-01 19:58:33,074:INFO:Uploading model into container now
2023-08-01 19:58:33,075:INFO:_master_model_container: 13
2023-08-01 19:58:33,075:INFO:_display_container: 2
2023-08-01 19:58:33,076:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 19:58:33,077:INFO:create_model() successfully completed......................................
2023-08-01 19:58:33,312:INFO:SubProcess create_model() end ==================================
2023-08-01 19:58:33,312:INFO:Creating metrics dataframe
2023-08-01 19:58:33,343:INFO:Initializing Dummy Classifier
2023-08-01 19:58:33,343:INFO:Total runtime is 4.0005135138829555 minutes
2023-08-01 19:58:33,353:INFO:SubProcess create_model() called ==================================
2023-08-01 19:58:33,353:INFO:Initializing create_model()
2023-08-01 19:58:33,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C7088E0910>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:58:33,354:INFO:Checking exceptions
2023-08-01 19:58:33,354:INFO:Importing libraries
2023-08-01 19:58:33,354:INFO:Copying training dataset
2023-08-01 19:58:33,373:INFO:Defining folds
2023-08-01 19:58:33,373:INFO:Declaring metric variables
2023-08-01 19:58:33,385:INFO:Importing untrained model
2023-08-01 19:58:33,396:INFO:Dummy Classifier Imported successfully
2023-08-01 19:58:33,428:INFO:Starting cross validation
2023-08-01 19:58:33,436:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 19:58:36,390:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-01 19:58:38,152:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,242:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,303:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,373:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,421:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,437:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,457:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,540:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,588:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 4.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:38,617:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,691:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,771:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,808:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:38,895:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:40,230:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:40,389:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:45,392:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:45,452:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:45,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 19:58:45,546:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 19:58:51,085:INFO:Calculating mean and std
2023-08-01 19:58:51,086:INFO:Creating metrics dataframe
2023-08-01 19:58:52,791:INFO:Uploading results into container
2023-08-01 19:58:52,792:INFO:Uploading model into container now
2023-08-01 19:58:52,793:INFO:_master_model_container: 14
2023-08-01 19:58:52,793:INFO:_display_container: 2
2023-08-01 19:58:52,793:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 19:58:52,793:INFO:create_model() successfully completed......................................
2023-08-01 19:58:52,997:INFO:SubProcess create_model() end ==================================
2023-08-01 19:58:52,998:INFO:Creating metrics dataframe
2023-08-01 19:58:53,064:INFO:Initializing create_model()
2023-08-01 19:58:53,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 19:58:53,066:INFO:Checking exceptions
2023-08-01 19:58:53,073:INFO:Importing libraries
2023-08-01 19:58:53,073:INFO:Copying training dataset
2023-08-01 19:58:53,093:INFO:Defining folds
2023-08-01 19:58:53,093:INFO:Declaring metric variables
2023-08-01 19:58:53,094:INFO:Importing untrained model
2023-08-01 19:58:53,094:INFO:Declaring custom model
2023-08-01 19:58:53,095:INFO:K Neighbors Classifier Imported successfully
2023-08-01 19:58:53,099:INFO:Cross validation set to False
2023-08-01 19:58:53,099:INFO:Fitting Model
2023-08-01 19:58:54,753:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:58:54,753:INFO:create_model() successfully completed......................................
2023-08-01 19:58:55,001:INFO:_master_model_container: 14
2023-08-01 19:58:55,002:INFO:_display_container: 2
2023-08-01 19:58:55,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 19:58:55,003:INFO:compare_models() successfully completed......................................
2023-08-01 20:24:18,035:INFO:Initializing create_model()
2023-08-01 20:24:18,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:24:18,036:INFO:Checking exceptions
2023-08-01 20:24:18,079:INFO:Importing libraries
2023-08-01 20:24:18,079:INFO:Copying training dataset
2023-08-01 20:24:18,101:INFO:Defining folds
2023-08-01 20:24:18,102:INFO:Declaring metric variables
2023-08-01 20:24:18,132:INFO:Importing untrained model
2023-08-01 20:24:18,144:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 20:24:18,164:INFO:Starting cross validation
2023-08-01 20:24:18,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:24:32,059:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,063:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,200:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,344:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,446:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,516:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 3.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:32,543:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:33,066:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:24:43,923:INFO:Calculating mean and std
2023-08-01 20:24:43,925:INFO:Creating metrics dataframe
2023-08-01 20:24:43,932:INFO:Finalizing model
2023-08-01 20:24:46,029:INFO:Uploading results into container
2023-08-01 20:24:46,030:INFO:Uploading model into container now
2023-08-01 20:24:46,046:INFO:_master_model_container: 15
2023-08-01 20:24:46,046:INFO:_display_container: 3
2023-08-01 20:24:46,048:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 20:24:46,048:INFO:create_model() successfully completed......................................
2023-08-01 20:25:14,991:INFO:Initializing evaluate_model()
2023-08-01 20:25:14,992:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 20:25:15,006:INFO:Initializing plot_model()
2023-08-01 20:25:15,006:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, system=True)
2023-08-01 20:25:15,007:INFO:Checking exceptions
2023-08-01 20:25:15,011:INFO:Preloading libraries
2023-08-01 20:25:15,021:INFO:Copying training dataset
2023-08-01 20:25:15,021:INFO:Plot type: pipeline
2023-08-01 20:25:15,295:INFO:Visual Rendered Successfully
2023-08-01 20:25:15,481:INFO:plot_model() successfully completed......................................
2023-08-01 20:25:17,652:INFO:Initializing plot_model()
2023-08-01 20:25:17,653:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709411E20>, system=True)
2023-08-01 20:25:17,653:INFO:Checking exceptions
2023-08-01 20:25:17,657:INFO:Preloading libraries
2023-08-01 20:25:17,666:INFO:Copying training dataset
2023-08-01 20:25:17,667:INFO:Plot type: threshold
2023-08-01 20:25:18,077:INFO:Fitting Model
2023-08-01 20:26:14,106:INFO:PyCaret ClassificationExperiment
2023-08-01 20:26:14,106:INFO:Logging name: clf-default-name
2023-08-01 20:26:14,106:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 20:26:14,107:INFO:version 3.0.4
2023-08-01 20:26:14,107:INFO:Initializing setup()
2023-08-01 20:26:14,107:INFO:self.USI: 618f
2023-08-01 20:26:14,107:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 20:26:14,107:INFO:Checking environment
2023-08-01 20:26:14,107:INFO:python_version: 3.9.13
2023-08-01 20:26:14,107:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 20:26:14,107:INFO:machine: AMD64
2023-08-01 20:26:14,107:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 20:26:14,111:INFO:Memory: svmem(total=17055166464, available=7351345152, percent=56.9, used=9703821312, free=7351345152)
2023-08-01 20:26:14,111:INFO:Physical Core: 4
2023-08-01 20:26:14,111:INFO:Logical Core: 8
2023-08-01 20:26:14,111:INFO:Checking libraries
2023-08-01 20:26:14,111:INFO:System:
2023-08-01 20:26:14,111:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 20:26:14,111:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 20:26:14,111:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 20:26:14,111:INFO:PyCaret required dependencies:
2023-08-01 20:26:14,111:INFO:                 pip: 22.0.4
2023-08-01 20:26:14,111:INFO:          setuptools: 58.1.0
2023-08-01 20:26:14,111:INFO:             pycaret: 3.0.4
2023-08-01 20:26:14,111:INFO:             IPython: 8.13.1
2023-08-01 20:26:14,112:INFO:          ipywidgets: 8.0.7
2023-08-01 20:26:14,112:INFO:                tqdm: 4.65.0
2023-08-01 20:26:14,112:INFO:               numpy: 1.23.0
2023-08-01 20:26:14,112:INFO:              pandas: 1.5.3
2023-08-01 20:26:14,112:INFO:              jinja2: 3.1.2
2023-08-01 20:26:14,112:INFO:               scipy: 1.10.1
2023-08-01 20:26:14,112:INFO:              joblib: 1.2.0
2023-08-01 20:26:14,112:INFO:             sklearn: 1.2.2
2023-08-01 20:26:14,112:INFO:                pyod: 1.1.0
2023-08-01 20:26:14,112:INFO:            imblearn: 0.11.0
2023-08-01 20:26:14,112:INFO:   category_encoders: 2.6.1
2023-08-01 20:26:14,112:INFO:            lightgbm: 3.3.5
2023-08-01 20:26:14,112:INFO:               numba: 0.57.1
2023-08-01 20:26:14,112:INFO:            requests: 2.31.0
2023-08-01 20:26:14,112:INFO:          matplotlib: 3.7.1
2023-08-01 20:26:14,112:INFO:          scikitplot: 0.3.7
2023-08-01 20:26:14,112:INFO:         yellowbrick: 1.5
2023-08-01 20:26:14,112:INFO:              plotly: 5.15.0
2023-08-01 20:26:14,112:INFO:    plotly-resampler: Not installed
2023-08-01 20:26:14,112:INFO:             kaleido: 0.2.1
2023-08-01 20:26:14,113:INFO:           schemdraw: 0.15
2023-08-01 20:26:14,113:INFO:         statsmodels: 0.14.0
2023-08-01 20:26:14,113:INFO:              sktime: 0.20.0
2023-08-01 20:26:14,113:INFO:               tbats: 1.1.3
2023-08-01 20:26:14,113:INFO:            pmdarima: 2.0.3
2023-08-01 20:26:14,113:INFO:              psutil: 5.9.5
2023-08-01 20:26:14,113:INFO:          markupsafe: 2.1.3
2023-08-01 20:26:14,113:INFO:             pickle5: Not installed
2023-08-01 20:26:14,113:INFO:         cloudpickle: 2.2.1
2023-08-01 20:26:14,113:INFO:         deprecation: 2.1.0
2023-08-01 20:26:14,113:INFO:              xxhash: 3.2.0
2023-08-01 20:26:14,113:INFO:           wurlitzer: Not installed
2023-08-01 20:26:14,113:INFO:PyCaret optional dependencies:
2023-08-01 20:26:14,113:INFO:                shap: Not installed
2023-08-01 20:26:14,113:INFO:           interpret: Not installed
2023-08-01 20:26:14,113:INFO:                umap: Not installed
2023-08-01 20:26:14,113:INFO:    pandas_profiling: 4.3.1
2023-08-01 20:26:14,113:INFO:  explainerdashboard: Not installed
2023-08-01 20:26:14,113:INFO:             autoviz: Not installed
2023-08-01 20:26:14,113:INFO:           fairlearn: Not installed
2023-08-01 20:26:14,114:INFO:          deepchecks: Not installed
2023-08-01 20:26:14,114:INFO:             xgboost: Not installed
2023-08-01 20:26:14,114:INFO:            catboost: Not installed
2023-08-01 20:26:14,114:INFO:              kmodes: Not installed
2023-08-01 20:26:14,114:INFO:             mlxtend: 0.22.0
2023-08-01 20:26:14,114:INFO:       statsforecast: Not installed
2023-08-01 20:26:14,114:INFO:        tune_sklearn: Not installed
2023-08-01 20:26:14,114:INFO:                 ray: Not installed
2023-08-01 20:26:14,114:INFO:            hyperopt: Not installed
2023-08-01 20:26:14,114:INFO:              optuna: Not installed
2023-08-01 20:26:14,114:INFO:               skopt: Not installed
2023-08-01 20:26:14,114:INFO:              mlflow: Not installed
2023-08-01 20:26:14,114:INFO:              gradio: Not installed
2023-08-01 20:26:14,114:INFO:             fastapi: Not installed
2023-08-01 20:26:14,114:INFO:             uvicorn: Not installed
2023-08-01 20:26:14,114:INFO:              m2cgen: Not installed
2023-08-01 20:26:14,114:INFO:           evidently: Not installed
2023-08-01 20:26:14,114:INFO:               fugue: Not installed
2023-08-01 20:26:14,114:INFO:           streamlit: Not installed
2023-08-01 20:26:14,114:INFO:             prophet: Not installed
2023-08-01 20:26:14,114:INFO:None
2023-08-01 20:26:14,114:INFO:Set up data.
2023-08-01 20:26:14,126:INFO:Set up train/test split.
2023-08-01 20:26:14,134:INFO:Set up index.
2023-08-01 20:26:14,134:INFO:Set up folding strategy.
2023-08-01 20:26:14,134:INFO:Assigning column types.
2023-08-01 20:26:14,141:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 20:26:14,203:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,204:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,362:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,365:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,418:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 20:26:14,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:26:14,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,715:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 20:26:14,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:14,955:INFO:Preparing preprocessing pipeline...
2023-08-01 20:26:14,958:INFO:Set up simple imputation.
2023-08-01 20:26:14,962:INFO:Set up encoding of categorical features.
2023-08-01 20:26:14,962:INFO:Set up removing multicollinearity.
2023-08-01 20:26:14,963:INFO:Set up feature normalization.
2023-08-01 20:26:15,143:INFO:Finished creating preprocessing pipeline.
2023-08-01 20:26:15,355:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
-1                      0                     0                     0   
-2                      0                     0                     0   

     reserved_room_type_3  
 1                      1  
 2                      0  
 3                      1  
 4                      0  
 5                      1  
 6                      0  
 7                      1  
 8                      0  
 9                      1  
 10                     0  
-1                      0  
-2                      0  }],
                                                              return_df=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 20:26:15,355:INFO:Creating final display dataframe.
2023-08-01 20:26:15,734:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 18)  
5                                          (6508, 18)  
6                                          (1628, 18)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  BinaryEncoder(base=2, cols=None, drop_invarian...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             zscore  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               618f  
2023-08-01 20:26:15,870:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:15,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:15,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:15,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:26:15,965:INFO:setup() successfully completed in 2.81s...............
2023-08-01 20:26:20,369:INFO:Initializing compare_models()
2023-08-01 20:26:20,369:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 20:26:20,369:INFO:Checking exceptions
2023-08-01 20:26:20,377:INFO:Preparing display monitor
2023-08-01 20:26:20,411:INFO:Initializing Logistic Regression
2023-08-01 20:26:20,411:INFO:Total runtime is 0.0 minutes
2023-08-01 20:26:20,416:INFO:SubProcess create_model() called ==================================
2023-08-01 20:26:20,417:INFO:Initializing create_model()
2023-08-01 20:26:20,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:26:20,417:INFO:Checking exceptions
2023-08-01 20:26:20,417:INFO:Importing libraries
2023-08-01 20:26:20,417:INFO:Copying training dataset
2023-08-01 20:26:20,427:INFO:Defining folds
2023-08-01 20:26:20,427:INFO:Declaring metric variables
2023-08-01 20:26:20,433:INFO:Importing untrained model
2023-08-01 20:26:20,438:INFO:Logistic Regression Imported successfully
2023-08-01 20:26:20,451:INFO:Starting cross validation
2023-08-01 20:26:20,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:26:30,815:INFO:Calculating mean and std
2023-08-01 20:26:30,817:INFO:Creating metrics dataframe
2023-08-01 20:26:32,209:INFO:Uploading results into container
2023-08-01 20:26:32,211:INFO:Uploading model into container now
2023-08-01 20:26:32,213:INFO:_master_model_container: 1
2023-08-01 20:26:32,213:INFO:_display_container: 2
2023-08-01 20:26:32,214:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 20:26:32,214:INFO:create_model() successfully completed......................................
2023-08-01 20:26:33,189:INFO:SubProcess create_model() end ==================================
2023-08-01 20:26:33,189:INFO:Creating metrics dataframe
2023-08-01 20:26:33,202:INFO:Initializing K Neighbors Classifier
2023-08-01 20:26:33,202:INFO:Total runtime is 0.21317725976308186 minutes
2023-08-01 20:26:33,207:INFO:SubProcess create_model() called ==================================
2023-08-01 20:26:33,208:INFO:Initializing create_model()
2023-08-01 20:26:33,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:26:33,208:INFO:Checking exceptions
2023-08-01 20:26:33,209:INFO:Importing libraries
2023-08-01 20:26:33,209:INFO:Copying training dataset
2023-08-01 20:26:33,217:INFO:Defining folds
2023-08-01 20:26:33,217:INFO:Declaring metric variables
2023-08-01 20:26:33,222:INFO:Importing untrained model
2023-08-01 20:26:33,228:INFO:K Neighbors Classifier Imported successfully
2023-08-01 20:26:33,239:INFO:Starting cross validation
2023-08-01 20:26:33,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:26:46,344:INFO:Calculating mean and std
2023-08-01 20:26:46,347:INFO:Creating metrics dataframe
2023-08-01 20:26:48,046:INFO:Uploading results into container
2023-08-01 20:26:48,047:INFO:Uploading model into container now
2023-08-01 20:26:48,048:INFO:_master_model_container: 2
2023-08-01 20:26:48,048:INFO:_display_container: 2
2023-08-01 20:26:48,049:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 20:26:48,049:INFO:create_model() successfully completed......................................
2023-08-01 20:26:48,315:INFO:SubProcess create_model() end ==================================
2023-08-01 20:26:48,315:INFO:Creating metrics dataframe
2023-08-01 20:26:48,336:INFO:Initializing Naive Bayes
2023-08-01 20:26:48,337:INFO:Total runtime is 0.46541974544525144 minutes
2023-08-01 20:26:48,344:INFO:SubProcess create_model() called ==================================
2023-08-01 20:26:48,346:INFO:Initializing create_model()
2023-08-01 20:26:48,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:26:48,347:INFO:Checking exceptions
2023-08-01 20:26:48,347:INFO:Importing libraries
2023-08-01 20:26:48,347:INFO:Copying training dataset
2023-08-01 20:26:48,363:INFO:Defining folds
2023-08-01 20:26:48,363:INFO:Declaring metric variables
2023-08-01 20:26:48,371:INFO:Importing untrained model
2023-08-01 20:26:48,382:INFO:Naive Bayes Imported successfully
2023-08-01 20:26:48,398:INFO:Starting cross validation
2023-08-01 20:26:48,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:27:00,179:INFO:Calculating mean and std
2023-08-01 20:27:00,181:INFO:Creating metrics dataframe
2023-08-01 20:27:02,210:INFO:Uploading results into container
2023-08-01 20:27:02,212:INFO:Uploading model into container now
2023-08-01 20:27:02,213:INFO:_master_model_container: 3
2023-08-01 20:27:02,213:INFO:_display_container: 2
2023-08-01 20:27:02,214:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 20:27:02,215:INFO:create_model() successfully completed......................................
2023-08-01 20:27:02,406:INFO:SubProcess create_model() end ==================================
2023-08-01 20:27:02,407:INFO:Creating metrics dataframe
2023-08-01 20:27:02,428:INFO:Initializing Decision Tree Classifier
2023-08-01 20:27:02,428:INFO:Total runtime is 0.7002722740173339 minutes
2023-08-01 20:27:02,434:INFO:SubProcess create_model() called ==================================
2023-08-01 20:27:02,435:INFO:Initializing create_model()
2023-08-01 20:27:02,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:27:02,436:INFO:Checking exceptions
2023-08-01 20:27:02,436:INFO:Importing libraries
2023-08-01 20:27:02,437:INFO:Copying training dataset
2023-08-01 20:27:02,451:INFO:Defining folds
2023-08-01 20:27:02,452:INFO:Declaring metric variables
2023-08-01 20:27:02,461:INFO:Importing untrained model
2023-08-01 20:27:02,469:INFO:Decision Tree Classifier Imported successfully
2023-08-01 20:27:02,484:INFO:Starting cross validation
2023-08-01 20:27:02,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:27:09,752:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:27:15,845:INFO:Calculating mean and std
2023-08-01 20:27:15,847:INFO:Creating metrics dataframe
2023-08-01 20:27:17,164:INFO:Uploading results into container
2023-08-01 20:27:17,165:INFO:Uploading model into container now
2023-08-01 20:27:17,166:INFO:_master_model_container: 4
2023-08-01 20:27:17,166:INFO:_display_container: 2
2023-08-01 20:27:17,167:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 20:27:17,167:INFO:create_model() successfully completed......................................
2023-08-01 20:27:17,347:INFO:SubProcess create_model() end ==================================
2023-08-01 20:27:17,347:INFO:Creating metrics dataframe
2023-08-01 20:27:17,363:INFO:Initializing SVM - Linear Kernel
2023-08-01 20:27:17,363:INFO:Total runtime is 0.9491885503133137 minutes
2023-08-01 20:27:17,369:INFO:SubProcess create_model() called ==================================
2023-08-01 20:27:17,370:INFO:Initializing create_model()
2023-08-01 20:27:17,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:27:17,370:INFO:Checking exceptions
2023-08-01 20:27:17,371:INFO:Importing libraries
2023-08-01 20:27:17,371:INFO:Copying training dataset
2023-08-01 20:27:17,384:INFO:Defining folds
2023-08-01 20:27:17,385:INFO:Declaring metric variables
2023-08-01 20:27:17,394:INFO:Importing untrained model
2023-08-01 20:27:17,403:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 20:27:17,418:INFO:Starting cross validation
2023-08-01 20:27:17,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:27:18,113:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,121:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,136:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,176:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,279:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,306:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,383:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:18,521:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:23,622:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:23,640:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:27:31,042:INFO:Calculating mean and std
2023-08-01 20:27:31,047:INFO:Creating metrics dataframe
2023-08-01 20:27:33,062:INFO:Uploading results into container
2023-08-01 20:27:33,064:INFO:Uploading model into container now
2023-08-01 20:27:33,065:INFO:_master_model_container: 5
2023-08-01 20:27:33,066:INFO:_display_container: 2
2023-08-01 20:27:33,067:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 20:27:33,068:INFO:create_model() successfully completed......................................
2023-08-01 20:27:33,340:INFO:SubProcess create_model() end ==================================
2023-08-01 20:27:33,340:INFO:Creating metrics dataframe
2023-08-01 20:27:33,366:INFO:Initializing Ridge Classifier
2023-08-01 20:27:33,366:INFO:Total runtime is 1.215914503733317 minutes
2023-08-01 20:27:33,377:INFO:SubProcess create_model() called ==================================
2023-08-01 20:27:33,378:INFO:Initializing create_model()
2023-08-01 20:27:33,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:27:33,378:INFO:Checking exceptions
2023-08-01 20:27:33,378:INFO:Importing libraries
2023-08-01 20:27:33,379:INFO:Copying training dataset
2023-08-01 20:27:33,398:INFO:Defining folds
2023-08-01 20:27:33,399:INFO:Declaring metric variables
2023-08-01 20:27:33,409:INFO:Importing untrained model
2023-08-01 20:27:33,420:INFO:Ridge Classifier Imported successfully
2023-08-01 20:27:33,439:INFO:Starting cross validation
2023-08-01 20:27:33,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:27:34,129:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,132:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,167:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,213:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,235:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,236:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,267:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:34,498:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:38,048:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:38,115:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:27:46,604:INFO:Calculating mean and std
2023-08-01 20:27:46,605:INFO:Creating metrics dataframe
2023-08-01 20:27:48,241:INFO:Uploading results into container
2023-08-01 20:27:48,242:INFO:Uploading model into container now
2023-08-01 20:27:48,244:INFO:_master_model_container: 6
2023-08-01 20:27:48,245:INFO:_display_container: 2
2023-08-01 20:27:48,245:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 20:27:48,246:INFO:create_model() successfully completed......................................
2023-08-01 20:27:48,432:INFO:SubProcess create_model() end ==================================
2023-08-01 20:27:48,432:INFO:Creating metrics dataframe
2023-08-01 20:27:48,447:INFO:Initializing Random Forest Classifier
2023-08-01 20:27:48,447:INFO:Total runtime is 1.4672570824623108 minutes
2023-08-01 20:27:48,452:INFO:SubProcess create_model() called ==================================
2023-08-01 20:27:48,453:INFO:Initializing create_model()
2023-08-01 20:27:48,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:27:48,453:INFO:Checking exceptions
2023-08-01 20:27:48,453:INFO:Importing libraries
2023-08-01 20:27:48,453:INFO:Copying training dataset
2023-08-01 20:27:48,464:INFO:Defining folds
2023-08-01 20:27:48,465:INFO:Declaring metric variables
2023-08-01 20:27:48,472:INFO:Importing untrained model
2023-08-01 20:27:48,480:INFO:Random Forest Classifier Imported successfully
2023-08-01 20:27:48,494:INFO:Starting cross validation
2023-08-01 20:27:48,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:28:05,706:INFO:Calculating mean and std
2023-08-01 20:28:05,708:INFO:Creating metrics dataframe
2023-08-01 20:28:07,756:INFO:Uploading results into container
2023-08-01 20:28:07,758:INFO:Uploading model into container now
2023-08-01 20:28:07,758:INFO:_master_model_container: 7
2023-08-01 20:28:07,759:INFO:_display_container: 2
2023-08-01 20:28:07,761:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:28:07,761:INFO:create_model() successfully completed......................................
2023-08-01 20:28:08,015:INFO:SubProcess create_model() end ==================================
2023-08-01 20:28:08,016:INFO:Creating metrics dataframe
2023-08-01 20:28:08,042:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 20:28:08,042:INFO:Total runtime is 1.7938398599624634 minutes
2023-08-01 20:28:08,052:INFO:SubProcess create_model() called ==================================
2023-08-01 20:28:08,052:INFO:Initializing create_model()
2023-08-01 20:28:08,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:28:08,053:INFO:Checking exceptions
2023-08-01 20:28:08,053:INFO:Importing libraries
2023-08-01 20:28:08,054:INFO:Copying training dataset
2023-08-01 20:28:08,071:INFO:Defining folds
2023-08-01 20:28:08,071:INFO:Declaring metric variables
2023-08-01 20:28:08,083:INFO:Importing untrained model
2023-08-01 20:28:08,094:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 20:28:08,111:INFO:Starting cross validation
2023-08-01 20:28:08,117:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:28:08,657:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,701:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,771:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,776:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,798:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,814:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,867:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:08,873:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:13,621:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:13,647:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:28:22,168:INFO:Calculating mean and std
2023-08-01 20:28:22,169:INFO:Creating metrics dataframe
2023-08-01 20:28:23,639:INFO:Uploading results into container
2023-08-01 20:28:23,641:INFO:Uploading model into container now
2023-08-01 20:28:23,641:INFO:_master_model_container: 8
2023-08-01 20:28:23,641:INFO:_display_container: 2
2023-08-01 20:28:23,642:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 20:28:23,642:INFO:create_model() successfully completed......................................
2023-08-01 20:28:23,819:INFO:SubProcess create_model() end ==================================
2023-08-01 20:28:23,820:INFO:Creating metrics dataframe
2023-08-01 20:28:23,835:INFO:Initializing Ada Boost Classifier
2023-08-01 20:28:23,835:INFO:Total runtime is 2.0570671439170836 minutes
2023-08-01 20:28:23,841:INFO:SubProcess create_model() called ==================================
2023-08-01 20:28:23,841:INFO:Initializing create_model()
2023-08-01 20:28:23,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:28:23,841:INFO:Checking exceptions
2023-08-01 20:28:23,841:INFO:Importing libraries
2023-08-01 20:28:23,842:INFO:Copying training dataset
2023-08-01 20:28:23,853:INFO:Defining folds
2023-08-01 20:28:23,854:INFO:Declaring metric variables
2023-08-01 20:28:23,860:INFO:Importing untrained model
2023-08-01 20:28:23,871:INFO:Ada Boost Classifier Imported successfully
2023-08-01 20:28:23,886:INFO:Starting cross validation
2023-08-01 20:28:23,888:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:28:39,103:INFO:Calculating mean and std
2023-08-01 20:28:39,107:INFO:Creating metrics dataframe
2023-08-01 20:28:41,107:INFO:Uploading results into container
2023-08-01 20:28:41,108:INFO:Uploading model into container now
2023-08-01 20:28:41,110:INFO:_master_model_container: 9
2023-08-01 20:28:41,110:INFO:_display_container: 2
2023-08-01 20:28:41,113:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 20:28:41,113:INFO:create_model() successfully completed......................................
2023-08-01 20:28:41,353:INFO:SubProcess create_model() end ==================================
2023-08-01 20:28:41,353:INFO:Creating metrics dataframe
2023-08-01 20:28:41,386:INFO:Initializing Gradient Boosting Classifier
2023-08-01 20:28:41,387:INFO:Total runtime is 2.3496006647745764 minutes
2023-08-01 20:28:41,395:INFO:SubProcess create_model() called ==================================
2023-08-01 20:28:41,398:INFO:Initializing create_model()
2023-08-01 20:28:41,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:28:41,398:INFO:Checking exceptions
2023-08-01 20:28:41,399:INFO:Importing libraries
2023-08-01 20:28:41,399:INFO:Copying training dataset
2023-08-01 20:28:41,416:INFO:Defining folds
2023-08-01 20:28:41,416:INFO:Declaring metric variables
2023-08-01 20:28:41,426:INFO:Importing untrained model
2023-08-01 20:28:41,436:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 20:28:41,458:INFO:Starting cross validation
2023-08-01 20:28:41,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:28:48,272:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:28:48,326:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:28:53,686:INFO:Calculating mean and std
2023-08-01 20:28:53,687:INFO:Creating metrics dataframe
2023-08-01 20:28:55,169:INFO:Uploading results into container
2023-08-01 20:28:55,171:INFO:Uploading model into container now
2023-08-01 20:28:55,172:INFO:_master_model_container: 10
2023-08-01 20:28:55,172:INFO:_display_container: 2
2023-08-01 20:28:55,173:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 20:28:55,174:INFO:create_model() successfully completed......................................
2023-08-01 20:28:55,351:INFO:SubProcess create_model() end ==================================
2023-08-01 20:28:55,351:INFO:Creating metrics dataframe
2023-08-01 20:28:55,367:INFO:Initializing Linear Discriminant Analysis
2023-08-01 20:28:55,367:INFO:Total runtime is 2.5826003948847447 minutes
2023-08-01 20:28:55,372:INFO:SubProcess create_model() called ==================================
2023-08-01 20:28:55,372:INFO:Initializing create_model()
2023-08-01 20:28:55,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:28:55,372:INFO:Checking exceptions
2023-08-01 20:28:55,372:INFO:Importing libraries
2023-08-01 20:28:55,373:INFO:Copying training dataset
2023-08-01 20:28:55,384:INFO:Defining folds
2023-08-01 20:28:55,384:INFO:Declaring metric variables
2023-08-01 20:28:55,390:INFO:Importing untrained model
2023-08-01 20:28:55,397:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 20:28:55,414:INFO:Starting cross validation
2023-08-01 20:28:55,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:29:05,906:INFO:Calculating mean and std
2023-08-01 20:29:05,908:INFO:Creating metrics dataframe
2023-08-01 20:29:07,367:INFO:Uploading results into container
2023-08-01 20:29:07,369:INFO:Uploading model into container now
2023-08-01 20:29:07,370:INFO:_master_model_container: 11
2023-08-01 20:29:07,370:INFO:_display_container: 2
2023-08-01 20:29:07,370:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 20:29:07,371:INFO:create_model() successfully completed......................................
2023-08-01 20:29:07,551:INFO:SubProcess create_model() end ==================================
2023-08-01 20:29:07,551:INFO:Creating metrics dataframe
2023-08-01 20:29:07,567:INFO:Initializing Extra Trees Classifier
2023-08-01 20:29:07,568:INFO:Total runtime is 2.785950394471486 minutes
2023-08-01 20:29:07,573:INFO:SubProcess create_model() called ==================================
2023-08-01 20:29:07,574:INFO:Initializing create_model()
2023-08-01 20:29:07,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:29:07,574:INFO:Checking exceptions
2023-08-01 20:29:07,574:INFO:Importing libraries
2023-08-01 20:29:07,574:INFO:Copying training dataset
2023-08-01 20:29:07,585:INFO:Defining folds
2023-08-01 20:29:07,585:INFO:Declaring metric variables
2023-08-01 20:29:07,590:INFO:Importing untrained model
2023-08-01 20:29:07,601:INFO:Extra Trees Classifier Imported successfully
2023-08-01 20:29:07,623:INFO:Starting cross validation
2023-08-01 20:29:07,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:29:22,009:INFO:Calculating mean and std
2023-08-01 20:29:22,010:INFO:Creating metrics dataframe
2023-08-01 20:29:23,758:INFO:Uploading results into container
2023-08-01 20:29:23,760:INFO:Uploading model into container now
2023-08-01 20:29:23,760:INFO:_master_model_container: 12
2023-08-01 20:29:23,761:INFO:_display_container: 2
2023-08-01 20:29:23,761:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:29:23,762:INFO:create_model() successfully completed......................................
2023-08-01 20:29:23,977:INFO:SubProcess create_model() end ==================================
2023-08-01 20:29:23,977:INFO:Creating metrics dataframe
2023-08-01 20:29:23,998:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 20:29:23,998:INFO:Total runtime is 3.059783784548441 minutes
2023-08-01 20:29:24,005:INFO:SubProcess create_model() called ==================================
2023-08-01 20:29:24,005:INFO:Initializing create_model()
2023-08-01 20:29:24,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:29:24,006:INFO:Checking exceptions
2023-08-01 20:29:24,006:INFO:Importing libraries
2023-08-01 20:29:24,007:INFO:Copying training dataset
2023-08-01 20:29:24,021:INFO:Defining folds
2023-08-01 20:29:24,021:INFO:Declaring metric variables
2023-08-01 20:29:24,029:INFO:Importing untrained model
2023-08-01 20:29:24,037:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 20:29:24,073:INFO:Starting cross validation
2023-08-01 20:29:24,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:29:42,719:INFO:Calculating mean and std
2023-08-01 20:29:42,722:INFO:Creating metrics dataframe
2023-08-01 20:29:44,376:INFO:Uploading results into container
2023-08-01 20:29:44,377:INFO:Uploading model into container now
2023-08-01 20:29:44,378:INFO:_master_model_container: 13
2023-08-01 20:29:44,379:INFO:_display_container: 2
2023-08-01 20:29:44,380:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 20:29:44,380:INFO:create_model() successfully completed......................................
2023-08-01 20:29:44,580:INFO:SubProcess create_model() end ==================================
2023-08-01 20:29:44,580:INFO:Creating metrics dataframe
2023-08-01 20:29:44,603:INFO:Initializing Dummy Classifier
2023-08-01 20:29:44,603:INFO:Total runtime is 3.403200423717498 minutes
2023-08-01 20:29:44,612:INFO:SubProcess create_model() called ==================================
2023-08-01 20:29:44,612:INFO:Initializing create_model()
2023-08-01 20:29:44,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C708D5C880>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:29:44,613:INFO:Checking exceptions
2023-08-01 20:29:44,613:INFO:Importing libraries
2023-08-01 20:29:44,613:INFO:Copying training dataset
2023-08-01 20:29:44,627:INFO:Defining folds
2023-08-01 20:29:44,628:INFO:Declaring metric variables
2023-08-01 20:29:44,636:INFO:Importing untrained model
2023-08-01 20:29:44,645:INFO:Dummy Classifier Imported successfully
2023-08-01 20:29:44,669:INFO:Starting cross validation
2023-08-01 20:29:44,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:29:45,436:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,438:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,439:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,462:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,472:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,477:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,485:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:45,545:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:49,697:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:49,743:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:29:56,507:INFO:Calculating mean and std
2023-08-01 20:29:56,509:INFO:Creating metrics dataframe
2023-08-01 20:29:58,076:INFO:Uploading results into container
2023-08-01 20:29:58,077:INFO:Uploading model into container now
2023-08-01 20:29:58,078:INFO:_master_model_container: 14
2023-08-01 20:29:58,078:INFO:_display_container: 2
2023-08-01 20:29:58,079:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 20:29:58,079:INFO:create_model() successfully completed......................................
2023-08-01 20:29:58,273:INFO:SubProcess create_model() end ==================================
2023-08-01 20:29:58,274:INFO:Creating metrics dataframe
2023-08-01 20:29:58,313:INFO:Initializing create_model()
2023-08-01 20:29:58,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:29:58,314:INFO:Checking exceptions
2023-08-01 20:29:58,318:INFO:Importing libraries
2023-08-01 20:29:58,318:INFO:Copying training dataset
2023-08-01 20:29:58,330:INFO:Defining folds
2023-08-01 20:29:58,330:INFO:Declaring metric variables
2023-08-01 20:29:58,330:INFO:Importing untrained model
2023-08-01 20:29:58,330:INFO:Declaring custom model
2023-08-01 20:29:58,332:INFO:K Neighbors Classifier Imported successfully
2023-08-01 20:29:58,334:INFO:Cross validation set to False
2023-08-01 20:29:58,335:INFO:Fitting Model
2023-08-01 20:29:59,694:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 20:29:59,694:INFO:create_model() successfully completed......................................
2023-08-01 20:29:59,940:INFO:_master_model_container: 14
2023-08-01 20:29:59,941:INFO:_display_container: 2
2023-08-01 20:29:59,942:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 20:29:59,942:INFO:compare_models() successfully completed......................................
2023-08-01 20:31:31,254:INFO:Initializing create_model()
2023-08-01 20:31:31,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:31:31,255:INFO:Checking exceptions
2023-08-01 20:31:31,281:INFO:Importing libraries
2023-08-01 20:31:31,281:INFO:Copying training dataset
2023-08-01 20:31:31,293:INFO:Defining folds
2023-08-01 20:31:31,293:INFO:Declaring metric variables
2023-08-01 20:31:31,298:INFO:Importing untrained model
2023-08-01 20:31:31,306:INFO:K Neighbors Classifier Imported successfully
2023-08-01 20:31:31,319:INFO:Starting cross validation
2023-08-01 20:31:31,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:31:37,237:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:31:42,751:INFO:Calculating mean and std
2023-08-01 20:31:42,753:INFO:Creating metrics dataframe
2023-08-01 20:31:42,762:INFO:Finalizing model
2023-08-01 20:31:44,431:INFO:Uploading results into container
2023-08-01 20:31:44,433:INFO:Uploading model into container now
2023-08-01 20:31:44,450:INFO:_master_model_container: 15
2023-08-01 20:31:44,451:INFO:_display_container: 3
2023-08-01 20:31:44,451:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 20:31:44,451:INFO:create_model() successfully completed......................................
2023-08-01 20:31:56,497:INFO:Initializing evaluate_model()
2023-08-01 20:31:56,498:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 20:31:56,514:INFO:Initializing plot_model()
2023-08-01 20:31:56,514:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, system=True)
2023-08-01 20:31:56,514:INFO:Checking exceptions
2023-08-01 20:31:56,517:INFO:Preloading libraries
2023-08-01 20:31:56,518:INFO:Copying training dataset
2023-08-01 20:31:56,518:INFO:Plot type: pipeline
2023-08-01 20:31:56,771:INFO:Visual Rendered Successfully
2023-08-01 20:31:56,943:INFO:plot_model() successfully completed......................................
2023-08-01 20:32:00,149:INFO:Initializing plot_model()
2023-08-01 20:32:00,149:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709705040>, system=True)
2023-08-01 20:32:00,150:INFO:Checking exceptions
2023-08-01 20:32:00,153:INFO:Preloading libraries
2023-08-01 20:32:00,154:INFO:Copying training dataset
2023-08-01 20:32:00,154:INFO:Plot type: confusion_matrix
2023-08-01 20:32:00,454:INFO:Fitting Model
2023-08-01 20:32:35,338:INFO:PyCaret ClassificationExperiment
2023-08-01 20:32:35,338:INFO:Logging name: clf-default-name
2023-08-01 20:32:35,339:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 20:32:35,339:INFO:version 3.0.4
2023-08-01 20:32:35,339:INFO:Initializing setup()
2023-08-01 20:32:35,339:INFO:self.USI: 9e05
2023-08-01 20:32:35,339:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 20:32:35,340:INFO:Checking environment
2023-08-01 20:32:35,340:INFO:python_version: 3.9.13
2023-08-01 20:32:35,340:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 20:32:35,340:INFO:machine: AMD64
2023-08-01 20:32:35,340:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 20:32:35,345:INFO:Memory: svmem(total=17055166464, available=7277056000, percent=57.3, used=9778110464, free=7277056000)
2023-08-01 20:32:35,345:INFO:Physical Core: 4
2023-08-01 20:32:35,345:INFO:Logical Core: 8
2023-08-01 20:32:35,345:INFO:Checking libraries
2023-08-01 20:32:35,345:INFO:System:
2023-08-01 20:32:35,345:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 20:32:35,345:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 20:32:35,346:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 20:32:35,346:INFO:PyCaret required dependencies:
2023-08-01 20:32:35,346:INFO:                 pip: 22.0.4
2023-08-01 20:32:35,346:INFO:          setuptools: 58.1.0
2023-08-01 20:32:35,346:INFO:             pycaret: 3.0.4
2023-08-01 20:32:35,346:INFO:             IPython: 8.13.1
2023-08-01 20:32:35,346:INFO:          ipywidgets: 8.0.7
2023-08-01 20:32:35,346:INFO:                tqdm: 4.65.0
2023-08-01 20:32:35,346:INFO:               numpy: 1.23.0
2023-08-01 20:32:35,346:INFO:              pandas: 1.5.3
2023-08-01 20:32:35,346:INFO:              jinja2: 3.1.2
2023-08-01 20:32:35,346:INFO:               scipy: 1.10.1
2023-08-01 20:32:35,346:INFO:              joblib: 1.2.0
2023-08-01 20:32:35,346:INFO:             sklearn: 1.2.2
2023-08-01 20:32:35,347:INFO:                pyod: 1.1.0
2023-08-01 20:32:35,347:INFO:            imblearn: 0.11.0
2023-08-01 20:32:35,347:INFO:   category_encoders: 2.6.1
2023-08-01 20:32:35,347:INFO:            lightgbm: 3.3.5
2023-08-01 20:32:35,347:INFO:               numba: 0.57.1
2023-08-01 20:32:35,347:INFO:            requests: 2.31.0
2023-08-01 20:32:35,347:INFO:          matplotlib: 3.7.1
2023-08-01 20:32:35,347:INFO:          scikitplot: 0.3.7
2023-08-01 20:32:35,347:INFO:         yellowbrick: 1.5
2023-08-01 20:32:35,347:INFO:              plotly: 5.15.0
2023-08-01 20:32:35,347:INFO:    plotly-resampler: Not installed
2023-08-01 20:32:35,347:INFO:             kaleido: 0.2.1
2023-08-01 20:32:35,347:INFO:           schemdraw: 0.15
2023-08-01 20:32:35,347:INFO:         statsmodels: 0.14.0
2023-08-01 20:32:35,347:INFO:              sktime: 0.20.0
2023-08-01 20:32:35,347:INFO:               tbats: 1.1.3
2023-08-01 20:32:35,347:INFO:            pmdarima: 2.0.3
2023-08-01 20:32:35,348:INFO:              psutil: 5.9.5
2023-08-01 20:32:35,348:INFO:          markupsafe: 2.1.3
2023-08-01 20:32:35,348:INFO:             pickle5: Not installed
2023-08-01 20:32:35,348:INFO:         cloudpickle: 2.2.1
2023-08-01 20:32:35,348:INFO:         deprecation: 2.1.0
2023-08-01 20:32:35,348:INFO:              xxhash: 3.2.0
2023-08-01 20:32:35,348:INFO:           wurlitzer: Not installed
2023-08-01 20:32:35,348:INFO:PyCaret optional dependencies:
2023-08-01 20:32:35,348:INFO:                shap: Not installed
2023-08-01 20:32:35,348:INFO:           interpret: Not installed
2023-08-01 20:32:35,348:INFO:                umap: Not installed
2023-08-01 20:32:35,348:INFO:    pandas_profiling: 4.3.1
2023-08-01 20:32:35,348:INFO:  explainerdashboard: Not installed
2023-08-01 20:32:35,348:INFO:             autoviz: Not installed
2023-08-01 20:32:35,348:INFO:           fairlearn: Not installed
2023-08-01 20:32:35,348:INFO:          deepchecks: Not installed
2023-08-01 20:32:35,348:INFO:             xgboost: Not installed
2023-08-01 20:32:35,349:INFO:            catboost: Not installed
2023-08-01 20:32:35,349:INFO:              kmodes: Not installed
2023-08-01 20:32:35,349:INFO:             mlxtend: 0.22.0
2023-08-01 20:32:35,349:INFO:       statsforecast: Not installed
2023-08-01 20:32:35,349:INFO:        tune_sklearn: Not installed
2023-08-01 20:32:35,349:INFO:                 ray: Not installed
2023-08-01 20:32:35,349:INFO:            hyperopt: Not installed
2023-08-01 20:32:35,349:INFO:              optuna: Not installed
2023-08-01 20:32:35,349:INFO:               skopt: Not installed
2023-08-01 20:32:35,349:INFO:              mlflow: Not installed
2023-08-01 20:32:35,349:INFO:              gradio: Not installed
2023-08-01 20:32:35,349:INFO:             fastapi: Not installed
2023-08-01 20:32:35,349:INFO:             uvicorn: Not installed
2023-08-01 20:32:35,349:INFO:              m2cgen: Not installed
2023-08-01 20:32:35,349:INFO:           evidently: Not installed
2023-08-01 20:32:35,349:INFO:               fugue: Not installed
2023-08-01 20:32:35,349:INFO:           streamlit: Not installed
2023-08-01 20:32:35,350:INFO:             prophet: Not installed
2023-08-01 20:32:35,350:INFO:None
2023-08-01 20:32:35,350:INFO:Set up data.
2023-08-01 20:32:35,363:INFO:Set up train/test split.
2023-08-01 20:32:35,372:INFO:Set up index.
2023-08-01 20:32:35,373:INFO:Set up folding strategy.
2023-08-01 20:32:35,373:INFO:Assigning column types.
2023-08-01 20:32:35,379:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 20:32:35,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:32:35,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:32:35,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,748:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:32:35,749:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:32:35,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,798:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 20:32:35,868:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:32:35,916:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:35,977:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:32:36,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,016:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,016:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 20:32:36,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,230:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:32:36,231:INFO:Preparing preprocessing pipeline...
2023-08-01 20:32:36,233:INFO:Set up simple imputation.
2023-08-01 20:32:36,237:INFO:Set up encoding of categorical features.
2023-08-01 20:32:36,237:INFO:Set up removing multicollinearity.
2023-08-01 20:32:36,237:INFO:Set up feature normalization.
2023-08-01 20:32:36,409:INFO:Finished creating preprocessing pipeline.
2023-08-01 20:32:36,419:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_unknown='error',
                                                              max_categories=None,
                                                              min_frequency=None,
                                                              sparse='deprecated',
                                                              sparse_output=True))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 20:32:36,419:INFO:Creating final display dataframe.
2023-08-01 20:33:01,650:INFO:PyCaret ClassificationExperiment
2023-08-01 20:33:01,650:INFO:Logging name: clf-default-name
2023-08-01 20:33:01,651:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 20:33:01,651:INFO:version 3.0.4
2023-08-01 20:33:01,651:INFO:Initializing setup()
2023-08-01 20:33:01,651:INFO:self.USI: 3bf4
2023-08-01 20:33:01,651:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 20:33:01,651:INFO:Checking environment
2023-08-01 20:33:01,651:INFO:python_version: 3.9.13
2023-08-01 20:33:01,651:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 20:33:01,651:INFO:machine: AMD64
2023-08-01 20:33:01,651:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 20:33:01,654:INFO:Memory: svmem(total=17055166464, available=7324581888, percent=57.1, used=9730584576, free=7324581888)
2023-08-01 20:33:01,655:INFO:Physical Core: 4
2023-08-01 20:33:01,655:INFO:Logical Core: 8
2023-08-01 20:33:01,655:INFO:Checking libraries
2023-08-01 20:33:01,655:INFO:System:
2023-08-01 20:33:01,655:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 20:33:01,655:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 20:33:01,655:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 20:33:01,655:INFO:PyCaret required dependencies:
2023-08-01 20:33:01,655:INFO:                 pip: 22.0.4
2023-08-01 20:33:01,655:INFO:          setuptools: 58.1.0
2023-08-01 20:33:01,655:INFO:             pycaret: 3.0.4
2023-08-01 20:33:01,655:INFO:             IPython: 8.13.1
2023-08-01 20:33:01,655:INFO:          ipywidgets: 8.0.7
2023-08-01 20:33:01,655:INFO:                tqdm: 4.65.0
2023-08-01 20:33:01,655:INFO:               numpy: 1.23.0
2023-08-01 20:33:01,655:INFO:              pandas: 1.5.3
2023-08-01 20:33:01,656:INFO:              jinja2: 3.1.2
2023-08-01 20:33:01,656:INFO:               scipy: 1.10.1
2023-08-01 20:33:01,656:INFO:              joblib: 1.2.0
2023-08-01 20:33:01,656:INFO:             sklearn: 1.2.2
2023-08-01 20:33:01,656:INFO:                pyod: 1.1.0
2023-08-01 20:33:01,656:INFO:            imblearn: 0.11.0
2023-08-01 20:33:01,656:INFO:   category_encoders: 2.6.1
2023-08-01 20:33:01,656:INFO:            lightgbm: 3.3.5
2023-08-01 20:33:01,656:INFO:               numba: 0.57.1
2023-08-01 20:33:01,656:INFO:            requests: 2.31.0
2023-08-01 20:33:01,656:INFO:          matplotlib: 3.7.1
2023-08-01 20:33:01,657:INFO:          scikitplot: 0.3.7
2023-08-01 20:33:01,657:INFO:         yellowbrick: 1.5
2023-08-01 20:33:01,657:INFO:              plotly: 5.15.0
2023-08-01 20:33:01,657:INFO:    plotly-resampler: Not installed
2023-08-01 20:33:01,657:INFO:             kaleido: 0.2.1
2023-08-01 20:33:01,657:INFO:           schemdraw: 0.15
2023-08-01 20:33:01,657:INFO:         statsmodels: 0.14.0
2023-08-01 20:33:01,657:INFO:              sktime: 0.20.0
2023-08-01 20:33:01,657:INFO:               tbats: 1.1.3
2023-08-01 20:33:01,657:INFO:            pmdarima: 2.0.3
2023-08-01 20:33:01,657:INFO:              psutil: 5.9.5
2023-08-01 20:33:01,657:INFO:          markupsafe: 2.1.3
2023-08-01 20:33:01,657:INFO:             pickle5: Not installed
2023-08-01 20:33:01,657:INFO:         cloudpickle: 2.2.1
2023-08-01 20:33:01,657:INFO:         deprecation: 2.1.0
2023-08-01 20:33:01,657:INFO:              xxhash: 3.2.0
2023-08-01 20:33:01,658:INFO:           wurlitzer: Not installed
2023-08-01 20:33:01,658:INFO:PyCaret optional dependencies:
2023-08-01 20:33:01,658:INFO:                shap: Not installed
2023-08-01 20:33:01,658:INFO:           interpret: Not installed
2023-08-01 20:33:01,658:INFO:                umap: Not installed
2023-08-01 20:33:01,658:INFO:    pandas_profiling: 4.3.1
2023-08-01 20:33:01,658:INFO:  explainerdashboard: Not installed
2023-08-01 20:33:01,658:INFO:             autoviz: Not installed
2023-08-01 20:33:01,658:INFO:           fairlearn: Not installed
2023-08-01 20:33:01,658:INFO:          deepchecks: Not installed
2023-08-01 20:33:01,658:INFO:             xgboost: Not installed
2023-08-01 20:33:01,658:INFO:            catboost: Not installed
2023-08-01 20:33:01,658:INFO:              kmodes: Not installed
2023-08-01 20:33:01,658:INFO:             mlxtend: 0.22.0
2023-08-01 20:33:01,658:INFO:       statsforecast: Not installed
2023-08-01 20:33:01,658:INFO:        tune_sklearn: Not installed
2023-08-01 20:33:01,658:INFO:                 ray: Not installed
2023-08-01 20:33:01,659:INFO:            hyperopt: Not installed
2023-08-01 20:33:01,659:INFO:              optuna: Not installed
2023-08-01 20:33:01,659:INFO:               skopt: Not installed
2023-08-01 20:33:01,659:INFO:              mlflow: Not installed
2023-08-01 20:33:01,659:INFO:              gradio: Not installed
2023-08-01 20:33:01,659:INFO:             fastapi: Not installed
2023-08-01 20:33:01,659:INFO:             uvicorn: Not installed
2023-08-01 20:33:01,659:INFO:              m2cgen: Not installed
2023-08-01 20:33:01,659:INFO:           evidently: Not installed
2023-08-01 20:33:01,659:INFO:               fugue: Not installed
2023-08-01 20:33:01,659:INFO:           streamlit: Not installed
2023-08-01 20:33:01,659:INFO:             prophet: Not installed
2023-08-01 20:33:01,659:INFO:None
2023-08-01 20:33:01,659:INFO:Set up data.
2023-08-01 20:33:01,671:INFO:Set up train/test split.
2023-08-01 20:33:01,681:INFO:Set up index.
2023-08-01 20:33:01,681:INFO:Set up folding strategy.
2023-08-01 20:33:01,681:INFO:Assigning column types.
2023-08-01 20:33:01,687:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 20:33:01,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:33:01,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:33:01,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:01,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:01,885:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:33:01,887:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:33:01,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:01,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:01,969:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 20:33:02,221:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:33:02,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,333:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:33:02,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,380:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 20:33:02,518:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:02,643:INFO:Preparing preprocessing pipeline...
2023-08-01 20:33:02,645:INFO:Set up simple imputation.
2023-08-01 20:33:02,651:INFO:Set up encoding of categorical features.
2023-08-01 20:33:02,651:INFO:Set up removing multicollinearity.
2023-08-01 20:33:02,652:INFO:Set up feature normalization.
2023-08-01 20:33:03,053:INFO:Finished creating preprocessing pipeline.
2023-08-01 20:33:03,067:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 20:33:03,067:INFO:Creating final display dataframe.
2023-08-01 20:33:03,625:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              3bf4
2023-08-01 20:33:03,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:03,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:03,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:03,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:33:03,864:INFO:setup() successfully completed in 3.16s...............
2023-08-01 20:33:15,759:INFO:Initializing compare_models()
2023-08-01 20:33:15,759:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, include=None, fold=None, round=4, cross_validation=True, sort=Balanced, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 20:33:15,760:INFO:Checking exceptions
2023-08-01 20:33:15,766:INFO:Preparing display monitor
2023-08-01 20:33:15,804:INFO:Initializing Logistic Regression
2023-08-01 20:33:15,804:INFO:Total runtime is 0.0 minutes
2023-08-01 20:33:15,810:INFO:SubProcess create_model() called ==================================
2023-08-01 20:33:15,810:INFO:Initializing create_model()
2023-08-01 20:33:15,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:33:15,811:INFO:Checking exceptions
2023-08-01 20:33:15,811:INFO:Importing libraries
2023-08-01 20:33:15,811:INFO:Copying training dataset
2023-08-01 20:33:15,819:INFO:Defining folds
2023-08-01 20:33:15,819:INFO:Declaring metric variables
2023-08-01 20:33:15,826:INFO:Importing untrained model
2023-08-01 20:33:15,851:INFO:Logistic Regression Imported successfully
2023-08-01 20:33:15,884:INFO:Starting cross validation
2023-08-01 20:33:15,918:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:33:31,588:INFO:Calculating mean and std
2023-08-01 20:33:31,589:INFO:Creating metrics dataframe
2023-08-01 20:33:33,180:INFO:Uploading results into container
2023-08-01 20:33:33,182:INFO:Uploading model into container now
2023-08-01 20:33:33,182:INFO:_master_model_container: 1
2023-08-01 20:33:33,182:INFO:_display_container: 2
2023-08-01 20:33:33,182:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 20:33:33,182:INFO:create_model() successfully completed......................................
2023-08-01 20:33:33,393:INFO:SubProcess create_model() end ==================================
2023-08-01 20:33:33,393:INFO:Creating metrics dataframe
2023-08-01 20:33:33,410:INFO:Initializing K Neighbors Classifier
2023-08-01 20:33:33,412:INFO:Total runtime is 0.2934555729230245 minutes
2023-08-01 20:33:33,419:INFO:SubProcess create_model() called ==================================
2023-08-01 20:33:33,419:INFO:Initializing create_model()
2023-08-01 20:33:33,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:33:33,419:INFO:Checking exceptions
2023-08-01 20:33:33,419:INFO:Importing libraries
2023-08-01 20:33:33,419:INFO:Copying training dataset
2023-08-01 20:33:33,434:INFO:Defining folds
2023-08-01 20:33:33,434:INFO:Declaring metric variables
2023-08-01 20:33:33,444:INFO:Importing untrained model
2023-08-01 20:33:33,452:INFO:K Neighbors Classifier Imported successfully
2023-08-01 20:33:33,471:INFO:Starting cross validation
2023-08-01 20:33:33,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:33:47,396:INFO:Calculating mean and std
2023-08-01 20:33:47,397:INFO:Creating metrics dataframe
2023-08-01 20:33:49,045:INFO:Uploading results into container
2023-08-01 20:33:49,047:INFO:Uploading model into container now
2023-08-01 20:33:49,047:INFO:_master_model_container: 2
2023-08-01 20:33:49,048:INFO:_display_container: 2
2023-08-01 20:33:49,048:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 20:33:49,048:INFO:create_model() successfully completed......................................
2023-08-01 20:33:49,260:INFO:SubProcess create_model() end ==================================
2023-08-01 20:33:49,261:INFO:Creating metrics dataframe
2023-08-01 20:33:49,277:INFO:Initializing Naive Bayes
2023-08-01 20:33:49,277:INFO:Total runtime is 0.5578806320826213 minutes
2023-08-01 20:33:49,282:INFO:SubProcess create_model() called ==================================
2023-08-01 20:33:49,283:INFO:Initializing create_model()
2023-08-01 20:33:49,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:33:49,283:INFO:Checking exceptions
2023-08-01 20:33:49,283:INFO:Importing libraries
2023-08-01 20:33:49,283:INFO:Copying training dataset
2023-08-01 20:33:49,295:INFO:Defining folds
2023-08-01 20:33:49,295:INFO:Declaring metric variables
2023-08-01 20:33:49,301:INFO:Importing untrained model
2023-08-01 20:33:49,306:INFO:Naive Bayes Imported successfully
2023-08-01 20:33:49,321:INFO:Starting cross validation
2023-08-01 20:33:49,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:34:01,616:INFO:Calculating mean and std
2023-08-01 20:34:01,617:INFO:Creating metrics dataframe
2023-08-01 20:34:03,353:INFO:Uploading results into container
2023-08-01 20:34:03,354:INFO:Uploading model into container now
2023-08-01 20:34:03,355:INFO:_master_model_container: 3
2023-08-01 20:34:03,355:INFO:_display_container: 2
2023-08-01 20:34:03,356:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 20:34:03,356:INFO:create_model() successfully completed......................................
2023-08-01 20:34:03,550:INFO:SubProcess create_model() end ==================================
2023-08-01 20:34:03,550:INFO:Creating metrics dataframe
2023-08-01 20:34:03,565:INFO:Initializing Decision Tree Classifier
2023-08-01 20:34:03,565:INFO:Total runtime is 0.7960139632225037 minutes
2023-08-01 20:34:03,571:INFO:SubProcess create_model() called ==================================
2023-08-01 20:34:03,571:INFO:Initializing create_model()
2023-08-01 20:34:03,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:34:03,571:INFO:Checking exceptions
2023-08-01 20:34:03,572:INFO:Importing libraries
2023-08-01 20:34:03,572:INFO:Copying training dataset
2023-08-01 20:34:03,582:INFO:Defining folds
2023-08-01 20:34:03,583:INFO:Declaring metric variables
2023-08-01 20:34:03,590:INFO:Importing untrained model
2023-08-01 20:34:03,597:INFO:Decision Tree Classifier Imported successfully
2023-08-01 20:34:03,617:INFO:Starting cross validation
2023-08-01 20:34:03,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:34:16,046:INFO:Calculating mean and std
2023-08-01 20:34:16,048:INFO:Creating metrics dataframe
2023-08-01 20:34:17,708:INFO:Uploading results into container
2023-08-01 20:34:17,710:INFO:Uploading model into container now
2023-08-01 20:34:17,711:INFO:_master_model_container: 4
2023-08-01 20:34:17,711:INFO:_display_container: 2
2023-08-01 20:34:17,712:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 20:34:17,713:INFO:create_model() successfully completed......................................
2023-08-01 20:34:17,904:INFO:SubProcess create_model() end ==================================
2023-08-01 20:34:17,904:INFO:Creating metrics dataframe
2023-08-01 20:34:17,925:INFO:Initializing SVM - Linear Kernel
2023-08-01 20:34:17,925:INFO:Total runtime is 1.0353473027547202 minutes
2023-08-01 20:34:17,933:INFO:SubProcess create_model() called ==================================
2023-08-01 20:34:17,934:INFO:Initializing create_model()
2023-08-01 20:34:17,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:34:17,934:INFO:Checking exceptions
2023-08-01 20:34:17,934:INFO:Importing libraries
2023-08-01 20:34:17,934:INFO:Copying training dataset
2023-08-01 20:34:17,948:INFO:Defining folds
2023-08-01 20:34:17,948:INFO:Declaring metric variables
2023-08-01 20:34:17,957:INFO:Importing untrained model
2023-08-01 20:34:17,969:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 20:34:17,992:INFO:Starting cross validation
2023-08-01 20:34:17,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:34:19,345:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:19,579:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:19,585:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:19,648:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:19,665:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:20,051:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:20,169:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:24,893:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:24,902:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 20:34:32,390:INFO:Calculating mean and std
2023-08-01 20:34:32,392:INFO:Creating metrics dataframe
2023-08-01 20:34:34,008:INFO:Uploading results into container
2023-08-01 20:34:34,009:INFO:Uploading model into container now
2023-08-01 20:34:34,010:INFO:_master_model_container: 5
2023-08-01 20:34:34,010:INFO:_display_container: 2
2023-08-01 20:34:34,012:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 20:34:34,013:INFO:create_model() successfully completed......................................
2023-08-01 20:34:34,205:INFO:SubProcess create_model() end ==================================
2023-08-01 20:34:34,205:INFO:Creating metrics dataframe
2023-08-01 20:34:34,225:INFO:Initializing Ridge Classifier
2023-08-01 20:34:34,225:INFO:Total runtime is 1.3070146997769676 minutes
2023-08-01 20:34:34,232:INFO:SubProcess create_model() called ==================================
2023-08-01 20:34:34,233:INFO:Initializing create_model()
2023-08-01 20:34:34,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:34:34,233:INFO:Checking exceptions
2023-08-01 20:34:34,233:INFO:Importing libraries
2023-08-01 20:34:34,233:INFO:Copying training dataset
2023-08-01 20:34:34,242:INFO:Defining folds
2023-08-01 20:34:34,242:INFO:Declaring metric variables
2023-08-01 20:34:34,250:INFO:Importing untrained model
2023-08-01 20:34:34,259:INFO:Ridge Classifier Imported successfully
2023-08-01 20:34:34,285:INFO:Starting cross validation
2023-08-01 20:34:34,290:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:34:35,239:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,248:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,319:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,325:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,325:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,326:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,354:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:35,440:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:39,386:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:39,421:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 20:34:46,800:INFO:Calculating mean and std
2023-08-01 20:34:46,801:INFO:Creating metrics dataframe
2023-08-01 20:34:48,515:INFO:Uploading results into container
2023-08-01 20:34:48,516:INFO:Uploading model into container now
2023-08-01 20:34:48,517:INFO:_master_model_container: 6
2023-08-01 20:34:48,517:INFO:_display_container: 2
2023-08-01 20:34:48,517:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 20:34:48,518:INFO:create_model() successfully completed......................................
2023-08-01 20:34:48,712:INFO:SubProcess create_model() end ==================================
2023-08-01 20:34:48,712:INFO:Creating metrics dataframe
2023-08-01 20:34:48,730:INFO:Initializing Random Forest Classifier
2023-08-01 20:34:48,730:INFO:Total runtime is 1.5487571239471438 minutes
2023-08-01 20:34:48,737:INFO:SubProcess create_model() called ==================================
2023-08-01 20:34:48,737:INFO:Initializing create_model()
2023-08-01 20:34:48,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:34:48,738:INFO:Checking exceptions
2023-08-01 20:34:48,738:INFO:Importing libraries
2023-08-01 20:34:48,738:INFO:Copying training dataset
2023-08-01 20:34:48,750:INFO:Defining folds
2023-08-01 20:34:48,750:INFO:Declaring metric variables
2023-08-01 20:34:48,756:INFO:Importing untrained model
2023-08-01 20:34:48,766:INFO:Random Forest Classifier Imported successfully
2023-08-01 20:34:48,781:INFO:Starting cross validation
2023-08-01 20:34:48,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:34:52,250:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,301:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,307:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,317:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,507:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,560:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:52,592:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:34:53,401:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:53,420:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:53,575:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:53,667:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:53,668:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:53,879:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:34:54,166:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:35:07,021:INFO:Calculating mean and std
2023-08-01 20:35:07,023:INFO:Creating metrics dataframe
2023-08-01 20:35:08,801:INFO:Uploading results into container
2023-08-01 20:35:08,802:INFO:Uploading model into container now
2023-08-01 20:35:08,804:INFO:_master_model_container: 7
2023-08-01 20:35:08,804:INFO:_display_container: 2
2023-08-01 20:35:08,806:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:35:08,807:INFO:create_model() successfully completed......................................
2023-08-01 20:35:09,058:INFO:SubProcess create_model() end ==================================
2023-08-01 20:35:09,058:INFO:Creating metrics dataframe
2023-08-01 20:35:09,077:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 20:35:09,078:INFO:Total runtime is 1.887890168031057 minutes
2023-08-01 20:35:09,086:INFO:SubProcess create_model() called ==================================
2023-08-01 20:35:09,087:INFO:Initializing create_model()
2023-08-01 20:35:09,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:35:09,087:INFO:Checking exceptions
2023-08-01 20:35:09,087:INFO:Importing libraries
2023-08-01 20:35:09,087:INFO:Copying training dataset
2023-08-01 20:35:09,100:INFO:Defining folds
2023-08-01 20:35:09,100:INFO:Declaring metric variables
2023-08-01 20:35:09,108:INFO:Importing untrained model
2023-08-01 20:35:09,118:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 20:35:09,137:INFO:Starting cross validation
2023-08-01 20:35:09,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:35:09,649:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,651:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,676:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,705:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,740:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,768:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,772:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:09,807:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:10,817:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:35:15,336:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:15,373:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 20:35:22,853:INFO:Calculating mean and std
2023-08-01 20:35:22,854:INFO:Creating metrics dataframe
2023-08-01 20:35:24,507:INFO:Uploading results into container
2023-08-01 20:35:24,509:INFO:Uploading model into container now
2023-08-01 20:35:24,509:INFO:_master_model_container: 8
2023-08-01 20:35:24,510:INFO:_display_container: 2
2023-08-01 20:35:24,511:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 20:35:24,511:INFO:create_model() successfully completed......................................
2023-08-01 20:35:24,706:INFO:SubProcess create_model() end ==================================
2023-08-01 20:35:24,707:INFO:Creating metrics dataframe
2023-08-01 20:35:24,723:INFO:Initializing Ada Boost Classifier
2023-08-01 20:35:24,723:INFO:Total runtime is 2.148640374342601 minutes
2023-08-01 20:35:24,728:INFO:SubProcess create_model() called ==================================
2023-08-01 20:35:24,728:INFO:Initializing create_model()
2023-08-01 20:35:24,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:35:24,728:INFO:Checking exceptions
2023-08-01 20:35:24,729:INFO:Importing libraries
2023-08-01 20:35:24,729:INFO:Copying training dataset
2023-08-01 20:35:24,740:INFO:Defining folds
2023-08-01 20:35:24,740:INFO:Declaring metric variables
2023-08-01 20:35:24,748:INFO:Importing untrained model
2023-08-01 20:35:24,756:INFO:Ada Boost Classifier Imported successfully
2023-08-01 20:35:24,773:INFO:Starting cross validation
2023-08-01 20:35:24,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:35:27,575:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:35:41,836:INFO:Calculating mean and std
2023-08-01 20:35:41,837:INFO:Creating metrics dataframe
2023-08-01 20:35:43,583:INFO:Uploading results into container
2023-08-01 20:35:43,585:INFO:Uploading model into container now
2023-08-01 20:35:43,586:INFO:_master_model_container: 9
2023-08-01 20:35:43,586:INFO:_display_container: 2
2023-08-01 20:35:43,587:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 20:35:43,588:INFO:create_model() successfully completed......................................
2023-08-01 20:35:43,819:INFO:SubProcess create_model() end ==================================
2023-08-01 20:35:43,819:INFO:Creating metrics dataframe
2023-08-01 20:35:43,843:INFO:Initializing Gradient Boosting Classifier
2023-08-01 20:35:43,844:INFO:Total runtime is 2.467325337727865 minutes
2023-08-01 20:35:43,852:INFO:SubProcess create_model() called ==================================
2023-08-01 20:35:43,853:INFO:Initializing create_model()
2023-08-01 20:35:43,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:35:43,853:INFO:Checking exceptions
2023-08-01 20:35:43,853:INFO:Importing libraries
2023-08-01 20:35:43,854:INFO:Copying training dataset
2023-08-01 20:35:43,867:INFO:Defining folds
2023-08-01 20:35:43,867:INFO:Declaring metric variables
2023-08-01 20:35:43,874:INFO:Importing untrained model
2023-08-01 20:35:43,886:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 20:35:43,908:INFO:Starting cross validation
2023-08-01 20:35:43,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:35:47,456:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:35:47,460:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:35:47,473:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:01,556:INFO:Calculating mean and std
2023-08-01 20:36:01,557:INFO:Creating metrics dataframe
2023-08-01 20:36:03,235:INFO:Uploading results into container
2023-08-01 20:36:03,237:INFO:Uploading model into container now
2023-08-01 20:36:03,238:INFO:_master_model_container: 10
2023-08-01 20:36:03,238:INFO:_display_container: 2
2023-08-01 20:36:03,240:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 20:36:03,240:INFO:create_model() successfully completed......................................
2023-08-01 20:36:03,434:INFO:SubProcess create_model() end ==================================
2023-08-01 20:36:03,435:INFO:Creating metrics dataframe
2023-08-01 20:36:03,454:INFO:Initializing Linear Discriminant Analysis
2023-08-01 20:36:03,454:INFO:Total runtime is 2.7941586176554365 minutes
2023-08-01 20:36:03,460:INFO:SubProcess create_model() called ==================================
2023-08-01 20:36:03,460:INFO:Initializing create_model()
2023-08-01 20:36:03,461:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:36:03,461:INFO:Checking exceptions
2023-08-01 20:36:03,461:INFO:Importing libraries
2023-08-01 20:36:03,461:INFO:Copying training dataset
2023-08-01 20:36:03,473:INFO:Defining folds
2023-08-01 20:36:03,473:INFO:Declaring metric variables
2023-08-01 20:36:03,480:INFO:Importing untrained model
2023-08-01 20:36:03,487:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 20:36:03,505:INFO:Starting cross validation
2023-08-01 20:36:03,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:36:05,200:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:17,999:INFO:Calculating mean and std
2023-08-01 20:36:18,002:INFO:Creating metrics dataframe
2023-08-01 20:36:19,847:INFO:Uploading results into container
2023-08-01 20:36:19,849:INFO:Uploading model into container now
2023-08-01 20:36:19,850:INFO:_master_model_container: 11
2023-08-01 20:36:19,851:INFO:_display_container: 2
2023-08-01 20:36:19,852:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 20:36:19,852:INFO:create_model() successfully completed......................................
2023-08-01 20:36:20,077:INFO:SubProcess create_model() end ==================================
2023-08-01 20:36:20,077:INFO:Creating metrics dataframe
2023-08-01 20:36:20,107:INFO:Initializing Extra Trees Classifier
2023-08-01 20:36:20,108:INFO:Total runtime is 3.0717253128687543 minutes
2023-08-01 20:36:20,117:INFO:SubProcess create_model() called ==================================
2023-08-01 20:36:20,117:INFO:Initializing create_model()
2023-08-01 20:36:20,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:36:20,118:INFO:Checking exceptions
2023-08-01 20:36:20,118:INFO:Importing libraries
2023-08-01 20:36:20,119:INFO:Copying training dataset
2023-08-01 20:36:20,132:INFO:Defining folds
2023-08-01 20:36:20,133:INFO:Declaring metric variables
2023-08-01 20:36:20,142:INFO:Importing untrained model
2023-08-01 20:36:20,155:INFO:Extra Trees Classifier Imported successfully
2023-08-01 20:36:20,177:INFO:Starting cross validation
2023-08-01 20:36:20,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:36:24,318:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,372:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,476:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,551:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,610:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,761:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:24,871:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 20:36:25,620:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:25,658:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:25,698:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:25,742:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:25,944:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:26,071:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:26,195:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:26,448:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 20:36:41,196:INFO:Calculating mean and std
2023-08-01 20:36:41,199:INFO:Creating metrics dataframe
2023-08-01 20:36:43,078:INFO:Uploading results into container
2023-08-01 20:36:43,079:INFO:Uploading model into container now
2023-08-01 20:36:43,080:INFO:_master_model_container: 12
2023-08-01 20:36:43,080:INFO:_display_container: 2
2023-08-01 20:36:43,081:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:36:43,081:INFO:create_model() successfully completed......................................
2023-08-01 20:36:43,287:INFO:SubProcess create_model() end ==================================
2023-08-01 20:36:43,288:INFO:Creating metrics dataframe
2023-08-01 20:36:43,310:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 20:36:43,310:INFO:Total runtime is 3.458434045314789 minutes
2023-08-01 20:36:43,317:INFO:SubProcess create_model() called ==================================
2023-08-01 20:36:43,318:INFO:Initializing create_model()
2023-08-01 20:36:43,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:36:43,318:INFO:Checking exceptions
2023-08-01 20:36:43,318:INFO:Importing libraries
2023-08-01 20:36:43,318:INFO:Copying training dataset
2023-08-01 20:36:43,331:INFO:Defining folds
2023-08-01 20:36:43,331:INFO:Declaring metric variables
2023-08-01 20:36:43,339:INFO:Importing untrained model
2023-08-01 20:36:43,347:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 20:36:43,368:INFO:Starting cross validation
2023-08-01 20:36:43,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:36:59,109:INFO:Calculating mean and std
2023-08-01 20:36:59,110:INFO:Creating metrics dataframe
2023-08-01 20:37:01,018:INFO:Uploading results into container
2023-08-01 20:37:01,020:INFO:Uploading model into container now
2023-08-01 20:37:01,020:INFO:_master_model_container: 13
2023-08-01 20:37:01,020:INFO:_display_container: 2
2023-08-01 20:37:01,021:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 20:37:01,021:INFO:create_model() successfully completed......................................
2023-08-01 20:37:01,232:INFO:SubProcess create_model() end ==================================
2023-08-01 20:37:01,232:INFO:Creating metrics dataframe
2023-08-01 20:37:01,252:INFO:Initializing Dummy Classifier
2023-08-01 20:37:01,252:INFO:Total runtime is 3.7574673533439635 minutes
2023-08-01 20:37:01,257:INFO:SubProcess create_model() called ==================================
2023-08-01 20:37:01,258:INFO:Initializing create_model()
2023-08-01 20:37:01,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70904E0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:37:01,258:INFO:Checking exceptions
2023-08-01 20:37:01,258:INFO:Importing libraries
2023-08-01 20:37:01,258:INFO:Copying training dataset
2023-08-01 20:37:01,267:INFO:Defining folds
2023-08-01 20:37:01,268:INFO:Declaring metric variables
2023-08-01 20:37:01,275:INFO:Importing untrained model
2023-08-01 20:37:01,283:INFO:Dummy Classifier Imported successfully
2023-08-01 20:37:01,304:INFO:Starting cross validation
2023-08-01 20:37:01,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 20:37:02,586:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,644:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,649:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,676:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,679:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,744:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:02,891:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:03,064:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:06,946:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:07,053:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 20:37:15,705:INFO:Calculating mean and std
2023-08-01 20:37:15,706:INFO:Creating metrics dataframe
2023-08-01 20:37:17,544:INFO:Uploading results into container
2023-08-01 20:37:17,545:INFO:Uploading model into container now
2023-08-01 20:37:17,546:INFO:_master_model_container: 14
2023-08-01 20:37:17,546:INFO:_display_container: 2
2023-08-01 20:37:17,546:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 20:37:17,547:INFO:create_model() successfully completed......................................
2023-08-01 20:37:17,756:INFO:SubProcess create_model() end ==================================
2023-08-01 20:37:17,756:INFO:Creating metrics dataframe
2023-08-01 20:37:17,794:INFO:Initializing create_model()
2023-08-01 20:37:17,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:37:17,794:INFO:Checking exceptions
2023-08-01 20:37:17,797:INFO:Importing libraries
2023-08-01 20:37:17,797:INFO:Copying training dataset
2023-08-01 20:37:17,810:INFO:Defining folds
2023-08-01 20:37:17,810:INFO:Declaring metric variables
2023-08-01 20:37:17,811:INFO:Importing untrained model
2023-08-01 20:37:17,811:INFO:Declaring custom model
2023-08-01 20:37:17,813:INFO:Random Forest Classifier Imported successfully
2023-08-01 20:37:17,815:INFO:Cross validation set to False
2023-08-01 20:37:17,815:INFO:Fitting Model
2023-08-01 20:37:20,065:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:37:20,065:INFO:create_model() successfully completed......................................
2023-08-01 20:37:20,332:INFO:_master_model_container: 14
2023-08-01 20:37:20,332:INFO:_display_container: 2
2023-08-01 20:37:20,335:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 20:37:20,335:INFO:compare_models() successfully completed......................................
2023-08-01 20:58:02,280:INFO:Initializing evaluate_model()
2023-08-01 20:58:02,280:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 20:58:02,299:INFO:Initializing plot_model()
2023-08-01 20:58:02,299:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, system=True)
2023-08-01 20:58:02,299:INFO:Checking exceptions
2023-08-01 20:58:02,302:INFO:Preloading libraries
2023-08-01 20:58:02,303:INFO:Copying training dataset
2023-08-01 20:58:02,303:INFO:Plot type: pipeline
2023-08-01 20:58:02,572:INFO:Visual Rendered Successfully
2023-08-01 20:58:02,764:INFO:plot_model() successfully completed......................................
2023-08-01 20:58:04,902:INFO:Initializing plot_model()
2023-08-01 20:58:04,902:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE6FA0>, system=True)
2023-08-01 20:58:04,902:INFO:Checking exceptions
2023-08-01 20:58:04,907:INFO:Preloading libraries
2023-08-01 20:58:04,908:INFO:Copying training dataset
2023-08-01 20:58:04,908:INFO:Plot type: confusion_matrix
2023-08-01 20:58:04,993:INFO:Fitting Model
2023-08-01 20:59:41,660:INFO:PyCaret ClassificationExperiment
2023-08-01 20:59:41,660:INFO:Logging name: clf-default-name
2023-08-01 20:59:41,661:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 20:59:41,661:INFO:version 3.0.4
2023-08-01 20:59:41,661:INFO:Initializing setup()
2023-08-01 20:59:41,661:INFO:self.USI: 5264
2023-08-01 20:59:41,661:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 20:59:41,661:INFO:Checking environment
2023-08-01 20:59:41,661:INFO:python_version: 3.9.13
2023-08-01 20:59:41,661:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 20:59:41,661:INFO:machine: AMD64
2023-08-01 20:59:41,661:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 20:59:41,665:INFO:Memory: svmem(total=17055166464, available=9296879616, percent=45.5, used=7758286848, free=9296879616)
2023-08-01 20:59:41,665:INFO:Physical Core: 4
2023-08-01 20:59:41,665:INFO:Logical Core: 8
2023-08-01 20:59:41,665:INFO:Checking libraries
2023-08-01 20:59:41,665:INFO:System:
2023-08-01 20:59:41,665:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 20:59:41,665:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 20:59:41,666:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 20:59:41,666:INFO:PyCaret required dependencies:
2023-08-01 20:59:41,666:INFO:                 pip: 22.0.4
2023-08-01 20:59:41,666:INFO:          setuptools: 58.1.0
2023-08-01 20:59:41,666:INFO:             pycaret: 3.0.4
2023-08-01 20:59:41,666:INFO:             IPython: 8.13.1
2023-08-01 20:59:41,666:INFO:          ipywidgets: 8.0.7
2023-08-01 20:59:41,666:INFO:                tqdm: 4.65.0
2023-08-01 20:59:41,666:INFO:               numpy: 1.23.0
2023-08-01 20:59:41,666:INFO:              pandas: 1.5.3
2023-08-01 20:59:41,666:INFO:              jinja2: 3.1.2
2023-08-01 20:59:41,666:INFO:               scipy: 1.10.1
2023-08-01 20:59:41,666:INFO:              joblib: 1.2.0
2023-08-01 20:59:41,666:INFO:             sklearn: 1.2.2
2023-08-01 20:59:41,666:INFO:                pyod: 1.1.0
2023-08-01 20:59:41,666:INFO:            imblearn: 0.11.0
2023-08-01 20:59:41,666:INFO:   category_encoders: 2.6.1
2023-08-01 20:59:41,666:INFO:            lightgbm: 3.3.5
2023-08-01 20:59:41,666:INFO:               numba: 0.57.1
2023-08-01 20:59:41,667:INFO:            requests: 2.31.0
2023-08-01 20:59:41,667:INFO:          matplotlib: 3.7.1
2023-08-01 20:59:41,667:INFO:          scikitplot: 0.3.7
2023-08-01 20:59:41,667:INFO:         yellowbrick: 1.5
2023-08-01 20:59:41,667:INFO:              plotly: 5.15.0
2023-08-01 20:59:41,667:INFO:    plotly-resampler: Not installed
2023-08-01 20:59:41,667:INFO:             kaleido: 0.2.1
2023-08-01 20:59:41,667:INFO:           schemdraw: 0.15
2023-08-01 20:59:41,667:INFO:         statsmodels: 0.14.0
2023-08-01 20:59:41,667:INFO:              sktime: 0.20.0
2023-08-01 20:59:41,667:INFO:               tbats: 1.1.3
2023-08-01 20:59:41,667:INFO:            pmdarima: 2.0.3
2023-08-01 20:59:41,667:INFO:              psutil: 5.9.5
2023-08-01 20:59:41,667:INFO:          markupsafe: 2.1.3
2023-08-01 20:59:41,667:INFO:             pickle5: Not installed
2023-08-01 20:59:41,667:INFO:         cloudpickle: 2.2.1
2023-08-01 20:59:41,667:INFO:         deprecation: 2.1.0
2023-08-01 20:59:41,667:INFO:              xxhash: 3.2.0
2023-08-01 20:59:41,667:INFO:           wurlitzer: Not installed
2023-08-01 20:59:41,667:INFO:PyCaret optional dependencies:
2023-08-01 20:59:41,668:INFO:                shap: Not installed
2023-08-01 20:59:41,668:INFO:           interpret: Not installed
2023-08-01 20:59:41,668:INFO:                umap: Not installed
2023-08-01 20:59:41,668:INFO:    pandas_profiling: 4.3.1
2023-08-01 20:59:41,668:INFO:  explainerdashboard: Not installed
2023-08-01 20:59:41,668:INFO:             autoviz: Not installed
2023-08-01 20:59:41,668:INFO:           fairlearn: Not installed
2023-08-01 20:59:41,668:INFO:          deepchecks: Not installed
2023-08-01 20:59:41,668:INFO:             xgboost: Not installed
2023-08-01 20:59:41,668:INFO:            catboost: Not installed
2023-08-01 20:59:41,668:INFO:              kmodes: Not installed
2023-08-01 20:59:41,668:INFO:             mlxtend: 0.22.0
2023-08-01 20:59:41,668:INFO:       statsforecast: Not installed
2023-08-01 20:59:41,668:INFO:        tune_sklearn: Not installed
2023-08-01 20:59:41,668:INFO:                 ray: Not installed
2023-08-01 20:59:41,668:INFO:            hyperopt: Not installed
2023-08-01 20:59:41,668:INFO:              optuna: Not installed
2023-08-01 20:59:41,668:INFO:               skopt: Not installed
2023-08-01 20:59:41,669:INFO:              mlflow: Not installed
2023-08-01 20:59:41,669:INFO:              gradio: Not installed
2023-08-01 20:59:41,669:INFO:             fastapi: Not installed
2023-08-01 20:59:41,669:INFO:             uvicorn: Not installed
2023-08-01 20:59:41,669:INFO:              m2cgen: Not installed
2023-08-01 20:59:41,669:INFO:           evidently: Not installed
2023-08-01 20:59:41,669:INFO:               fugue: Not installed
2023-08-01 20:59:41,669:INFO:           streamlit: Not installed
2023-08-01 20:59:41,669:INFO:             prophet: Not installed
2023-08-01 20:59:41,669:INFO:None
2023-08-01 20:59:41,669:INFO:Set up data.
2023-08-01 20:59:41,682:INFO:Set up train/test split.
2023-08-01 20:59:41,691:INFO:Set up index.
2023-08-01 20:59:41,692:INFO:Set up folding strategy.
2023-08-01 20:59:41,692:INFO:Assigning column types.
2023-08-01 20:59:41,698:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 20:59:41,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:59:41,763:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:59:41,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:41,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:41,856:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 20:59:41,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:59:41,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:41,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:41,907:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 20:59:42,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:59:42,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 20:59:42,192:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,193:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 20:59:42,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:42,384:INFO:Preparing preprocessing pipeline...
2023-08-01 20:59:42,385:INFO:Set up simple imputation.
2023-08-01 20:59:42,388:INFO:Set up encoding of categorical features.
2023-08-01 20:59:42,388:INFO:Set up removing multicollinearity.
2023-08-01 20:59:42,388:INFO:Set up feature normalization.
2023-08-01 20:59:42,539:INFO:Finished creating preprocessing pipeline.
2023-08-01 20:59:42,547:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 20:59:42,548:INFO:Creating final display dataframe.
2023-08-01 20:59:42,945:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              5264
2023-08-01 20:59:43,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:43,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:43,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:43,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 20:59:43,149:INFO:setup() successfully completed in 2.4s...............
2023-08-01 20:59:47,291:INFO:Initializing create_model()
2023-08-01 20:59:47,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A532370>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 20:59:47,291:INFO:Checking exceptions
2023-08-01 20:59:47,314:INFO:Importing libraries
2023-08-01 20:59:47,314:INFO:Copying training dataset
2023-08-01 20:59:47,324:INFO:Defining folds
2023-08-01 20:59:47,324:INFO:Declaring metric variables
2023-08-01 20:59:47,331:INFO:Importing untrained model
2023-08-01 20:59:47,337:INFO:K Neighbors Classifier Imported successfully
2023-08-01 20:59:47,349:INFO:Starting cross validation
2023-08-01 20:59:47,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:00:05,397:INFO:Calculating mean and std
2023-08-01 21:00:05,398:INFO:Creating metrics dataframe
2023-08-01 21:00:05,405:INFO:Finalizing model
2023-08-01 21:00:06,892:INFO:Uploading results into container
2023-08-01 21:00:06,894:INFO:Uploading model into container now
2023-08-01 21:00:06,907:INFO:_master_model_container: 1
2023-08-01 21:00:06,907:INFO:_display_container: 2
2023-08-01 21:00:06,908:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:00:06,908:INFO:create_model() successfully completed......................................
2023-08-01 21:00:12,867:INFO:Initializing evaluate_model()
2023-08-01 21:00:12,867:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A532370>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:00:12,881:INFO:Initializing plot_model()
2023-08-01 21:00:12,882:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A532370>, system=True)
2023-08-01 21:00:12,882:INFO:Checking exceptions
2023-08-01 21:00:12,886:INFO:Preloading libraries
2023-08-01 21:00:12,887:INFO:Copying training dataset
2023-08-01 21:00:12,887:INFO:Plot type: pipeline
2023-08-01 21:00:13,148:INFO:Visual Rendered Successfully
2023-08-01 21:00:13,328:INFO:plot_model() successfully completed......................................
2023-08-01 21:00:14,226:INFO:Initializing plot_model()
2023-08-01 21:00:14,226:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A532370>, system=True)
2023-08-01 21:00:14,226:INFO:Checking exceptions
2023-08-01 21:00:14,231:INFO:Preloading libraries
2023-08-01 21:00:14,232:INFO:Copying training dataset
2023-08-01 21:00:14,232:INFO:Plot type: confusion_matrix
2023-08-01 21:00:14,741:INFO:Fitting Model
2023-08-01 21:01:19,425:INFO:Initializing plot_model()
2023-08-01 21:01:19,425:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A532370>, system=True)
2023-08-01 21:01:19,425:INFO:Checking exceptions
2023-08-01 21:01:19,432:INFO:Preloading libraries
2023-08-01 21:01:19,434:INFO:Copying training dataset
2023-08-01 21:01:19,434:INFO:Plot type: threshold
2023-08-01 21:01:19,674:INFO:Fitting Model
2023-08-01 21:04:48,632:INFO:PyCaret ClassificationExperiment
2023-08-01 21:04:48,632:INFO:Logging name: clf-default-name
2023-08-01 21:04:48,632:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 21:04:48,632:INFO:version 3.0.4
2023-08-01 21:04:48,632:INFO:Initializing setup()
2023-08-01 21:04:48,632:INFO:self.USI: 55b8
2023-08-01 21:04:48,632:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 21:04:48,632:INFO:Checking environment
2023-08-01 21:04:48,632:INFO:python_version: 3.9.13
2023-08-01 21:04:48,633:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 21:04:48,633:INFO:machine: AMD64
2023-08-01 21:04:48,633:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 21:04:48,636:INFO:Memory: svmem(total=17055166464, available=8189390848, percent=52.0, used=8865775616, free=8189390848)
2023-08-01 21:04:48,636:INFO:Physical Core: 4
2023-08-01 21:04:48,636:INFO:Logical Core: 8
2023-08-01 21:04:48,636:INFO:Checking libraries
2023-08-01 21:04:48,636:INFO:System:
2023-08-01 21:04:48,636:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 21:04:48,636:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 21:04:48,636:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 21:04:48,636:INFO:PyCaret required dependencies:
2023-08-01 21:04:48,636:INFO:                 pip: 22.0.4
2023-08-01 21:04:48,636:INFO:          setuptools: 58.1.0
2023-08-01 21:04:48,636:INFO:             pycaret: 3.0.4
2023-08-01 21:04:48,636:INFO:             IPython: 8.13.1
2023-08-01 21:04:48,636:INFO:          ipywidgets: 8.0.7
2023-08-01 21:04:48,637:INFO:                tqdm: 4.65.0
2023-08-01 21:04:48,637:INFO:               numpy: 1.23.0
2023-08-01 21:04:48,637:INFO:              pandas: 1.5.3
2023-08-01 21:04:48,637:INFO:              jinja2: 3.1.2
2023-08-01 21:04:48,637:INFO:               scipy: 1.10.1
2023-08-01 21:04:48,637:INFO:              joblib: 1.2.0
2023-08-01 21:04:48,637:INFO:             sklearn: 1.2.2
2023-08-01 21:04:48,637:INFO:                pyod: 1.1.0
2023-08-01 21:04:48,637:INFO:            imblearn: 0.11.0
2023-08-01 21:04:48,637:INFO:   category_encoders: 2.6.1
2023-08-01 21:04:48,637:INFO:            lightgbm: 3.3.5
2023-08-01 21:04:48,637:INFO:               numba: 0.57.1
2023-08-01 21:04:48,637:INFO:            requests: 2.31.0
2023-08-01 21:04:48,637:INFO:          matplotlib: 3.7.1
2023-08-01 21:04:48,637:INFO:          scikitplot: 0.3.7
2023-08-01 21:04:48,637:INFO:         yellowbrick: 1.5
2023-08-01 21:04:48,637:INFO:              plotly: 5.15.0
2023-08-01 21:04:48,637:INFO:    plotly-resampler: Not installed
2023-08-01 21:04:48,637:INFO:             kaleido: 0.2.1
2023-08-01 21:04:48,637:INFO:           schemdraw: 0.15
2023-08-01 21:04:48,637:INFO:         statsmodels: 0.14.0
2023-08-01 21:04:48,637:INFO:              sktime: 0.20.0
2023-08-01 21:04:48,637:INFO:               tbats: 1.1.3
2023-08-01 21:04:48,638:INFO:            pmdarima: 2.0.3
2023-08-01 21:04:48,638:INFO:              psutil: 5.9.5
2023-08-01 21:04:48,638:INFO:          markupsafe: 2.1.3
2023-08-01 21:04:48,638:INFO:             pickle5: Not installed
2023-08-01 21:04:48,638:INFO:         cloudpickle: 2.2.1
2023-08-01 21:04:48,638:INFO:         deprecation: 2.1.0
2023-08-01 21:04:48,638:INFO:              xxhash: 3.2.0
2023-08-01 21:04:48,638:INFO:           wurlitzer: Not installed
2023-08-01 21:04:48,638:INFO:PyCaret optional dependencies:
2023-08-01 21:04:48,638:INFO:                shap: Not installed
2023-08-01 21:04:48,638:INFO:           interpret: Not installed
2023-08-01 21:04:48,638:INFO:                umap: Not installed
2023-08-01 21:04:48,638:INFO:    pandas_profiling: 4.3.1
2023-08-01 21:04:48,638:INFO:  explainerdashboard: Not installed
2023-08-01 21:04:48,638:INFO:             autoviz: Not installed
2023-08-01 21:04:48,638:INFO:           fairlearn: Not installed
2023-08-01 21:04:48,638:INFO:          deepchecks: Not installed
2023-08-01 21:04:48,638:INFO:             xgboost: Not installed
2023-08-01 21:04:48,638:INFO:            catboost: Not installed
2023-08-01 21:04:48,638:INFO:              kmodes: Not installed
2023-08-01 21:04:48,639:INFO:             mlxtend: 0.22.0
2023-08-01 21:04:48,639:INFO:       statsforecast: Not installed
2023-08-01 21:04:48,639:INFO:        tune_sklearn: Not installed
2023-08-01 21:04:48,639:INFO:                 ray: Not installed
2023-08-01 21:04:48,639:INFO:            hyperopt: Not installed
2023-08-01 21:04:48,639:INFO:              optuna: Not installed
2023-08-01 21:04:48,639:INFO:               skopt: Not installed
2023-08-01 21:04:48,639:INFO:              mlflow: Not installed
2023-08-01 21:04:48,639:INFO:              gradio: Not installed
2023-08-01 21:04:48,639:INFO:             fastapi: Not installed
2023-08-01 21:04:48,639:INFO:             uvicorn: Not installed
2023-08-01 21:04:48,639:INFO:              m2cgen: Not installed
2023-08-01 21:04:48,639:INFO:           evidently: Not installed
2023-08-01 21:04:48,639:INFO:               fugue: Not installed
2023-08-01 21:04:48,639:INFO:           streamlit: Not installed
2023-08-01 21:04:48,639:INFO:             prophet: Not installed
2023-08-01 21:04:48,639:INFO:None
2023-08-01 21:04:48,639:INFO:Set up data.
2023-08-01 21:04:48,652:INFO:Set up train/test split.
2023-08-01 21:04:48,662:INFO:Set up index.
2023-08-01 21:04:48,662:INFO:Set up folding strategy.
2023-08-01 21:04:48,662:INFO:Assigning column types.
2023-08-01 21:04:48,667:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 21:04:48,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:04:48,736:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:04:48,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:48,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:48,864:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:04:48,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:04:48,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:48,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:48,908:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 21:04:49,040:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:04:49,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,157:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:04:49,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,196:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 21:04:49,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,400:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:49,402:INFO:Preparing preprocessing pipeline...
2023-08-01 21:04:49,403:INFO:Set up simple imputation.
2023-08-01 21:04:49,407:INFO:Set up encoding of categorical features.
2023-08-01 21:04:49,407:INFO:Set up removing multicollinearity.
2023-08-01 21:04:49,407:INFO:Set up feature normalization.
2023-08-01 21:04:49,595:INFO:Finished creating preprocessing pipeline.
2023-08-01 21:04:49,604:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-01 21:04:49,604:INFO:Creating final display dataframe.
2023-08-01 21:04:49,869:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              55b8
2023-08-01 21:04:50,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:50,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:50,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:50,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:04:50,107:INFO:setup() successfully completed in 2.45s...............
2023-08-01 21:05:18,457:INFO:Initializing compare_models()
2023-08-01 21:05:18,457:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=Balanced, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Balanced', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:05:18,457:INFO:Checking exceptions
2023-08-01 21:05:26,587:INFO:Initializing compare_models()
2023-08-01 21:05:26,588:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:05:26,588:INFO:Checking exceptions
2023-08-01 21:05:26,597:INFO:Preparing display monitor
2023-08-01 21:05:26,645:INFO:Initializing Logistic Regression
2023-08-01 21:05:26,645:INFO:Total runtime is 0.0 minutes
2023-08-01 21:05:26,652:INFO:SubProcess create_model() called ==================================
2023-08-01 21:05:26,653:INFO:Initializing create_model()
2023-08-01 21:05:26,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70618F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:05:26,653:INFO:Checking exceptions
2023-08-01 21:05:26,653:INFO:Importing libraries
2023-08-01 21:05:26,653:INFO:Copying training dataset
2023-08-01 21:05:26,666:INFO:Defining folds
2023-08-01 21:05:26,667:INFO:Declaring metric variables
2023-08-01 21:05:26,674:INFO:Importing untrained model
2023-08-01 21:05:26,686:INFO:Logistic Regression Imported successfully
2023-08-01 21:05:26,704:INFO:Starting cross validation
2023-08-01 21:05:26,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:05:49,517:INFO:Calculating mean and std
2023-08-01 21:05:49,518:INFO:Creating metrics dataframe
2023-08-01 21:05:51,110:INFO:Uploading results into container
2023-08-01 21:05:51,112:INFO:Uploading model into container now
2023-08-01 21:05:51,113:INFO:_master_model_container: 1
2023-08-01 21:05:51,113:INFO:_display_container: 2
2023-08-01 21:05:51,114:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 21:05:51,114:INFO:create_model() successfully completed......................................
2023-08-01 21:05:51,385:INFO:SubProcess create_model() end ==================================
2023-08-01 21:05:51,385:INFO:Creating metrics dataframe
2023-08-01 21:05:51,402:INFO:Initializing K Neighbors Classifier
2023-08-01 21:05:51,402:INFO:Total runtime is 0.41262686252593994 minutes
2023-08-01 21:05:51,409:INFO:SubProcess create_model() called ==================================
2023-08-01 21:05:51,409:INFO:Initializing create_model()
2023-08-01 21:05:51,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70618F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:05:51,409:INFO:Checking exceptions
2023-08-01 21:05:51,410:INFO:Importing libraries
2023-08-01 21:05:51,411:INFO:Copying training dataset
2023-08-01 21:05:51,425:INFO:Defining folds
2023-08-01 21:05:51,425:INFO:Declaring metric variables
2023-08-01 21:05:51,434:INFO:Importing untrained model
2023-08-01 21:05:51,445:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:05:51,467:INFO:Starting cross validation
2023-08-01 21:05:51,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:06:02,954:INFO:Calculating mean and std
2023-08-01 21:06:02,956:INFO:Creating metrics dataframe
2023-08-01 21:06:04,460:INFO:Uploading results into container
2023-08-01 21:06:04,462:INFO:Uploading model into container now
2023-08-01 21:06:04,462:INFO:_master_model_container: 2
2023-08-01 21:06:04,463:INFO:_display_container: 2
2023-08-01 21:06:04,464:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:06:04,464:INFO:create_model() successfully completed......................................
2023-08-01 21:06:04,670:INFO:SubProcess create_model() end ==================================
2023-08-01 21:06:04,670:INFO:Creating metrics dataframe
2023-08-01 21:06:04,683:INFO:Initializing Decision Tree Classifier
2023-08-01 21:06:04,684:INFO:Total runtime is 0.6339934945106507 minutes
2023-08-01 21:06:04,688:INFO:SubProcess create_model() called ==================================
2023-08-01 21:06:04,688:INFO:Initializing create_model()
2023-08-01 21:06:04,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70618F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:06:04,689:INFO:Checking exceptions
2023-08-01 21:06:04,689:INFO:Importing libraries
2023-08-01 21:06:04,689:INFO:Copying training dataset
2023-08-01 21:06:04,703:INFO:Defining folds
2023-08-01 21:06:04,704:INFO:Declaring metric variables
2023-08-01 21:06:04,709:INFO:Importing untrained model
2023-08-01 21:06:04,738:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:06:04,764:INFO:Starting cross validation
2023-08-01 21:06:04,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:06:16,143:INFO:Calculating mean and std
2023-08-01 21:06:16,145:INFO:Creating metrics dataframe
2023-08-01 21:06:17,719:INFO:Uploading results into container
2023-08-01 21:06:17,720:INFO:Uploading model into container now
2023-08-01 21:06:17,721:INFO:_master_model_container: 3
2023-08-01 21:06:17,721:INFO:_display_container: 2
2023-08-01 21:06:17,722:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:06:17,722:INFO:create_model() successfully completed......................................
2023-08-01 21:06:17,939:INFO:SubProcess create_model() end ==================================
2023-08-01 21:06:17,939:INFO:Creating metrics dataframe
2023-08-01 21:06:17,970:INFO:Initializing create_model()
2023-08-01 21:06:17,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:06:17,970:INFO:Checking exceptions
2023-08-01 21:06:17,973:INFO:Importing libraries
2023-08-01 21:06:17,973:INFO:Copying training dataset
2023-08-01 21:06:17,982:INFO:Defining folds
2023-08-01 21:06:17,983:INFO:Declaring metric variables
2023-08-01 21:06:17,983:INFO:Importing untrained model
2023-08-01 21:06:17,983:INFO:Declaring custom model
2023-08-01 21:06:17,984:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:06:17,987:INFO:Cross validation set to False
2023-08-01 21:06:17,987:INFO:Fitting Model
2023-08-01 21:06:19,147:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:06:19,148:INFO:create_model() successfully completed......................................
2023-08-01 21:06:19,468:INFO:_master_model_container: 3
2023-08-01 21:06:19,468:INFO:_display_container: 2
2023-08-01 21:06:19,469:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:06:19,469:INFO:compare_models() successfully completed......................................
2023-08-01 21:06:28,671:INFO:Initializing create_model()
2023-08-01 21:06:28,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:06:28,671:INFO:Checking exceptions
2023-08-01 21:06:28,695:INFO:Importing libraries
2023-08-01 21:06:28,695:INFO:Copying training dataset
2023-08-01 21:06:28,708:INFO:Defining folds
2023-08-01 21:06:28,708:INFO:Declaring metric variables
2023-08-01 21:06:28,716:INFO:Importing untrained model
2023-08-01 21:06:28,722:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:06:28,735:INFO:Starting cross validation
2023-08-01 21:06:28,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:06:40,740:INFO:Calculating mean and std
2023-08-01 21:06:40,741:INFO:Creating metrics dataframe
2023-08-01 21:06:40,751:INFO:Finalizing model
2023-08-01 21:06:42,775:INFO:Uploading results into container
2023-08-01 21:06:42,777:INFO:Uploading model into container now
2023-08-01 21:06:42,793:INFO:_master_model_container: 4
2023-08-01 21:06:42,794:INFO:_display_container: 3
2023-08-01 21:06:42,795:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:06:42,795:INFO:create_model() successfully completed......................................
2023-08-01 21:06:47,737:INFO:Initializing evaluate_model()
2023-08-01 21:06:47,737:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:06:47,752:INFO:Initializing plot_model()
2023-08-01 21:06:47,752:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, system=True)
2023-08-01 21:06:47,752:INFO:Checking exceptions
2023-08-01 21:06:47,756:INFO:Preloading libraries
2023-08-01 21:06:47,757:INFO:Copying training dataset
2023-08-01 21:06:47,757:INFO:Plot type: pipeline
2023-08-01 21:06:48,026:INFO:Visual Rendered Successfully
2023-08-01 21:06:48,230:INFO:plot_model() successfully completed......................................
2023-08-01 21:06:50,860:INFO:Initializing plot_model()
2023-08-01 21:06:50,860:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, system=True)
2023-08-01 21:06:50,860:INFO:Checking exceptions
2023-08-01 21:06:50,865:INFO:Preloading libraries
2023-08-01 21:06:50,865:INFO:Copying training dataset
2023-08-01 21:06:50,865:INFO:Plot type: parameter
2023-08-01 21:06:50,870:INFO:Visual Rendered Successfully
2023-08-01 21:06:51,132:INFO:plot_model() successfully completed......................................
2023-08-01 21:06:53,117:INFO:Initializing plot_model()
2023-08-01 21:06:53,118:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, system=True)
2023-08-01 21:06:53,118:INFO:Checking exceptions
2023-08-01 21:07:04,239:INFO:Initializing plot_model()
2023-08-01 21:07:04,239:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, system=True)
2023-08-01 21:07:04,239:INFO:Checking exceptions
2023-08-01 21:07:17,475:INFO:Initializing plot_model()
2023-08-01 21:07:17,475:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C70A4017F0>, system=True)
2023-08-01 21:07:17,475:INFO:Checking exceptions
2023-08-01 21:07:17,480:INFO:Preloading libraries
2023-08-01 21:07:17,481:INFO:Copying training dataset
2023-08-01 21:07:17,482:INFO:Plot type: threshold
2023-08-01 21:07:17,665:INFO:Fitting Model
2023-08-01 21:13:58,634:INFO:PyCaret ClassificationExperiment
2023-08-01 21:13:58,634:INFO:Logging name: clf-default-name
2023-08-01 21:13:58,634:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 21:13:58,634:INFO:version 3.0.4
2023-08-01 21:13:58,634:INFO:Initializing setup()
2023-08-01 21:13:58,634:INFO:self.USI: 65ee
2023-08-01 21:13:58,634:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 21:13:58,634:INFO:Checking environment
2023-08-01 21:13:58,635:INFO:python_version: 3.9.13
2023-08-01 21:13:58,635:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 21:13:58,635:INFO:machine: AMD64
2023-08-01 21:13:58,635:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 21:13:58,638:INFO:Memory: svmem(total=17055166464, available=8079994880, percent=52.6, used=8975171584, free=8079994880)
2023-08-01 21:13:58,639:INFO:Physical Core: 4
2023-08-01 21:13:58,639:INFO:Logical Core: 8
2023-08-01 21:13:58,639:INFO:Checking libraries
2023-08-01 21:13:58,639:INFO:System:
2023-08-01 21:13:58,639:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 21:13:58,640:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 21:13:58,640:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 21:13:58,640:INFO:PyCaret required dependencies:
2023-08-01 21:13:58,640:INFO:                 pip: 22.0.4
2023-08-01 21:13:58,640:INFO:          setuptools: 58.1.0
2023-08-01 21:13:58,640:INFO:             pycaret: 3.0.4
2023-08-01 21:13:58,640:INFO:             IPython: 8.13.1
2023-08-01 21:13:58,640:INFO:          ipywidgets: 8.0.7
2023-08-01 21:13:58,640:INFO:                tqdm: 4.65.0
2023-08-01 21:13:58,640:INFO:               numpy: 1.23.0
2023-08-01 21:13:58,640:INFO:              pandas: 1.5.3
2023-08-01 21:13:58,640:INFO:              jinja2: 3.1.2
2023-08-01 21:13:58,640:INFO:               scipy: 1.10.1
2023-08-01 21:13:58,640:INFO:              joblib: 1.2.0
2023-08-01 21:13:58,640:INFO:             sklearn: 1.2.2
2023-08-01 21:13:58,640:INFO:                pyod: 1.1.0
2023-08-01 21:13:58,641:INFO:            imblearn: 0.11.0
2023-08-01 21:13:58,641:INFO:   category_encoders: 2.6.1
2023-08-01 21:13:58,641:INFO:            lightgbm: 3.3.5
2023-08-01 21:13:58,641:INFO:               numba: 0.57.1
2023-08-01 21:13:58,641:INFO:            requests: 2.31.0
2023-08-01 21:13:58,641:INFO:          matplotlib: 3.7.1
2023-08-01 21:13:58,641:INFO:          scikitplot: 0.3.7
2023-08-01 21:13:58,641:INFO:         yellowbrick: 1.5
2023-08-01 21:13:58,641:INFO:              plotly: 5.15.0
2023-08-01 21:13:58,641:INFO:    plotly-resampler: Not installed
2023-08-01 21:13:58,641:INFO:             kaleido: 0.2.1
2023-08-01 21:13:58,641:INFO:           schemdraw: 0.15
2023-08-01 21:13:58,641:INFO:         statsmodels: 0.14.0
2023-08-01 21:13:58,641:INFO:              sktime: 0.20.0
2023-08-01 21:13:58,641:INFO:               tbats: 1.1.3
2023-08-01 21:13:58,641:INFO:            pmdarima: 2.0.3
2023-08-01 21:13:58,641:INFO:              psutil: 5.9.5
2023-08-01 21:13:58,641:INFO:          markupsafe: 2.1.3
2023-08-01 21:13:58,641:INFO:             pickle5: Not installed
2023-08-01 21:13:58,642:INFO:         cloudpickle: 2.2.1
2023-08-01 21:13:58,642:INFO:         deprecation: 2.1.0
2023-08-01 21:13:58,642:INFO:              xxhash: 3.2.0
2023-08-01 21:13:58,642:INFO:           wurlitzer: Not installed
2023-08-01 21:13:58,642:INFO:PyCaret optional dependencies:
2023-08-01 21:13:58,642:INFO:                shap: Not installed
2023-08-01 21:13:58,642:INFO:           interpret: Not installed
2023-08-01 21:13:58,642:INFO:                umap: Not installed
2023-08-01 21:13:58,642:INFO:    pandas_profiling: 4.3.1
2023-08-01 21:13:58,642:INFO:  explainerdashboard: Not installed
2023-08-01 21:13:58,642:INFO:             autoviz: Not installed
2023-08-01 21:13:58,642:INFO:           fairlearn: Not installed
2023-08-01 21:13:58,642:INFO:          deepchecks: Not installed
2023-08-01 21:13:58,642:INFO:             xgboost: Not installed
2023-08-01 21:13:58,642:INFO:            catboost: Not installed
2023-08-01 21:13:58,642:INFO:              kmodes: Not installed
2023-08-01 21:13:58,642:INFO:             mlxtend: 0.22.0
2023-08-01 21:13:58,642:INFO:       statsforecast: Not installed
2023-08-01 21:13:58,643:INFO:        tune_sklearn: Not installed
2023-08-01 21:13:58,643:INFO:                 ray: Not installed
2023-08-01 21:13:58,643:INFO:            hyperopt: Not installed
2023-08-01 21:13:58,643:INFO:              optuna: Not installed
2023-08-01 21:13:58,643:INFO:               skopt: Not installed
2023-08-01 21:13:58,643:INFO:              mlflow: Not installed
2023-08-01 21:13:58,643:INFO:              gradio: Not installed
2023-08-01 21:13:58,643:INFO:             fastapi: Not installed
2023-08-01 21:13:58,643:INFO:             uvicorn: Not installed
2023-08-01 21:13:58,643:INFO:              m2cgen: Not installed
2023-08-01 21:13:58,643:INFO:           evidently: Not installed
2023-08-01 21:13:58,643:INFO:               fugue: Not installed
2023-08-01 21:13:58,643:INFO:           streamlit: Not installed
2023-08-01 21:13:58,643:INFO:             prophet: Not installed
2023-08-01 21:13:58,643:INFO:None
2023-08-01 21:13:58,643:INFO:Set up data.
2023-08-01 21:13:58,659:INFO:Set up train/test split.
2023-08-01 21:13:58,670:INFO:Set up index.
2023-08-01 21:13:58,671:INFO:Set up folding strategy.
2023-08-01 21:13:58,671:INFO:Assigning column types.
2023-08-01 21:13:58,678:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 21:13:58,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:13:58,798:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:13:58,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:58,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,085:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:13:59,087:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:13:59,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,163:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 21:13:59,237:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:13:59,285:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,349:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:13:59,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,388:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 21:13:59,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:13:59,639:INFO:Preparing preprocessing pipeline...
2023-08-01 21:13:59,641:INFO:Set up simple imputation.
2023-08-01 21:13:59,646:INFO:Set up encoding of categorical features.
2023-08-01 21:13:59,646:INFO:Set up removing multicollinearity.
2023-08-01 21:13:59,811:INFO:Finished creating preprocessing pipeline.
2023-08-01 21:13:59,819:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 21:13:59,820:INFO:Creating final display dataframe.
2023-08-01 21:14:00,202:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              65ee
2023-08-01 21:14:00,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:00,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:00,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:00,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:00,476:INFO:setup() successfully completed in 2.9s...............
2023-08-01 21:14:20,376:INFO:PyCaret ClassificationExperiment
2023-08-01 21:14:20,376:INFO:Logging name: clf-default-name
2023-08-01 21:14:20,376:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 21:14:20,376:INFO:version 3.0.4
2023-08-01 21:14:20,376:INFO:Initializing setup()
2023-08-01 21:14:20,377:INFO:self.USI: c77d
2023-08-01 21:14:20,377:INFO:self._variable_keys: {'fix_imbalance', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'X', '_ml_usecase', 'fold_groups_param', 'y_train', 'idx', 'logging_param', 'gpu_param', 'fold_generator', 'seed', 'html_param', 'target_param', 'fold_shuffle_param', 'USI', 'memory', 'X_test', 'log_plots_param', 'X_train', 'y', '_available_plots', 'y_test', 'exp_name_log', 'is_multiclass', 'data', 'pipeline'}
2023-08-01 21:14:20,377:INFO:Checking environment
2023-08-01 21:14:20,377:INFO:python_version: 3.9.13
2023-08-01 21:14:20,377:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 21:14:20,377:INFO:machine: AMD64
2023-08-01 21:14:20,377:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 21:14:20,381:INFO:Memory: svmem(total=17055166464, available=8070492160, percent=52.7, used=8984674304, free=8070492160)
2023-08-01 21:14:20,381:INFO:Physical Core: 4
2023-08-01 21:14:20,381:INFO:Logical Core: 8
2023-08-01 21:14:20,381:INFO:Checking libraries
2023-08-01 21:14:20,381:INFO:System:
2023-08-01 21:14:20,381:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 21:14:20,381:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 21:14:20,382:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 21:14:20,382:INFO:PyCaret required dependencies:
2023-08-01 21:14:20,382:INFO:                 pip: 22.0.4
2023-08-01 21:14:20,382:INFO:          setuptools: 58.1.0
2023-08-01 21:14:20,382:INFO:             pycaret: 3.0.4
2023-08-01 21:14:20,382:INFO:             IPython: 8.13.1
2023-08-01 21:14:20,382:INFO:          ipywidgets: 8.0.7
2023-08-01 21:14:20,382:INFO:                tqdm: 4.65.0
2023-08-01 21:14:20,382:INFO:               numpy: 1.23.0
2023-08-01 21:14:20,382:INFO:              pandas: 1.5.3
2023-08-01 21:14:20,382:INFO:              jinja2: 3.1.2
2023-08-01 21:14:20,383:INFO:               scipy: 1.10.1
2023-08-01 21:14:20,383:INFO:              joblib: 1.2.0
2023-08-01 21:14:20,383:INFO:             sklearn: 1.2.2
2023-08-01 21:14:20,383:INFO:                pyod: 1.1.0
2023-08-01 21:14:20,383:INFO:            imblearn: 0.11.0
2023-08-01 21:14:20,383:INFO:   category_encoders: 2.6.1
2023-08-01 21:14:20,383:INFO:            lightgbm: 3.3.5
2023-08-01 21:14:20,383:INFO:               numba: 0.57.1
2023-08-01 21:14:20,383:INFO:            requests: 2.31.0
2023-08-01 21:14:20,384:INFO:          matplotlib: 3.7.1
2023-08-01 21:14:20,384:INFO:          scikitplot: 0.3.7
2023-08-01 21:14:20,384:INFO:         yellowbrick: 1.5
2023-08-01 21:14:20,384:INFO:              plotly: 5.15.0
2023-08-01 21:14:20,384:INFO:    plotly-resampler: Not installed
2023-08-01 21:14:20,384:INFO:             kaleido: 0.2.1
2023-08-01 21:14:20,384:INFO:           schemdraw: 0.15
2023-08-01 21:14:20,385:INFO:         statsmodels: 0.14.0
2023-08-01 21:14:20,385:INFO:              sktime: 0.20.0
2023-08-01 21:14:20,385:INFO:               tbats: 1.1.3
2023-08-01 21:14:20,385:INFO:            pmdarima: 2.0.3
2023-08-01 21:14:20,385:INFO:              psutil: 5.9.5
2023-08-01 21:14:20,386:INFO:          markupsafe: 2.1.3
2023-08-01 21:14:20,386:INFO:             pickle5: Not installed
2023-08-01 21:14:20,386:INFO:         cloudpickle: 2.2.1
2023-08-01 21:14:20,386:INFO:         deprecation: 2.1.0
2023-08-01 21:14:20,386:INFO:              xxhash: 3.2.0
2023-08-01 21:14:20,386:INFO:           wurlitzer: Not installed
2023-08-01 21:14:20,386:INFO:PyCaret optional dependencies:
2023-08-01 21:14:20,387:INFO:                shap: Not installed
2023-08-01 21:14:20,387:INFO:           interpret: Not installed
2023-08-01 21:14:20,387:INFO:                umap: Not installed
2023-08-01 21:14:20,387:INFO:    pandas_profiling: 4.3.1
2023-08-01 21:14:20,387:INFO:  explainerdashboard: Not installed
2023-08-01 21:14:20,387:INFO:             autoviz: Not installed
2023-08-01 21:14:20,388:INFO:           fairlearn: Not installed
2023-08-01 21:14:20,388:INFO:          deepchecks: Not installed
2023-08-01 21:14:20,388:INFO:             xgboost: Not installed
2023-08-01 21:14:20,388:INFO:            catboost: Not installed
2023-08-01 21:14:20,388:INFO:              kmodes: Not installed
2023-08-01 21:14:20,388:INFO:             mlxtend: 0.22.0
2023-08-01 21:14:20,388:INFO:       statsforecast: Not installed
2023-08-01 21:14:20,388:INFO:        tune_sklearn: Not installed
2023-08-01 21:14:20,389:INFO:                 ray: Not installed
2023-08-01 21:14:20,389:INFO:            hyperopt: Not installed
2023-08-01 21:14:20,389:INFO:              optuna: Not installed
2023-08-01 21:14:20,389:INFO:               skopt: Not installed
2023-08-01 21:14:20,389:INFO:              mlflow: Not installed
2023-08-01 21:14:20,389:INFO:              gradio: Not installed
2023-08-01 21:14:20,389:INFO:             fastapi: Not installed
2023-08-01 21:14:20,389:INFO:             uvicorn: Not installed
2023-08-01 21:14:20,389:INFO:              m2cgen: Not installed
2023-08-01 21:14:20,389:INFO:           evidently: Not installed
2023-08-01 21:14:20,389:INFO:               fugue: Not installed
2023-08-01 21:14:20,389:INFO:           streamlit: Not installed
2023-08-01 21:14:20,389:INFO:             prophet: Not installed
2023-08-01 21:14:20,389:INFO:None
2023-08-01 21:14:20,390:INFO:Set up data.
2023-08-01 21:14:20,407:INFO:Set up train/test split.
2023-08-01 21:14:20,420:INFO:Set up index.
2023-08-01 21:14:20,421:INFO:Set up folding strategy.
2023-08-01 21:14:20,421:INFO:Assigning column types.
2023-08-01 21:14:20,428:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 21:14:20,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,694:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 21:14:20,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,897:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:14:20,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:20,946:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 21:14:21,058:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:21,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:21,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:21,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:21,164:INFO:Preparing preprocessing pipeline...
2023-08-01 21:14:21,166:INFO:Set up simple imputation.
2023-08-01 21:14:21,172:INFO:Set up encoding of categorical features.
2023-08-01 21:14:21,172:INFO:Set up removing multicollinearity.
2023-08-01 21:14:21,380:INFO:Finished creating preprocessing pipeline.
2023-08-01 21:14:21,395:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 21:14:21,395:INFO:Creating final display dataframe.
2023-08-01 21:14:21,901:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              c77d
2023-08-01 21:14:22,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:22,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:22,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:22,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:14:22,144:INFO:setup() successfully completed in 3.29s...............
2023-08-01 21:14:27,168:INFO:Initializing compare_models()
2023-08-01 21:14:27,168:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:14:27,169:INFO:Checking exceptions
2023-08-01 21:14:27,177:INFO:Preparing display monitor
2023-08-01 21:14:27,213:INFO:Initializing Logistic Regression
2023-08-01 21:14:27,214:INFO:Total runtime is 1.66932741800944e-05 minutes
2023-08-01 21:14:27,220:INFO:SubProcess create_model() called ==================================
2023-08-01 21:14:27,221:INFO:Initializing create_model()
2023-08-01 21:14:27,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70A206340>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:14:27,221:INFO:Checking exceptions
2023-08-01 21:14:27,221:INFO:Importing libraries
2023-08-01 21:14:27,221:INFO:Copying training dataset
2023-08-01 21:14:27,231:INFO:Defining folds
2023-08-01 21:14:27,232:INFO:Declaring metric variables
2023-08-01 21:14:27,238:INFO:Importing untrained model
2023-08-01 21:14:27,244:INFO:Logistic Regression Imported successfully
2023-08-01 21:14:27,257:INFO:Starting cross validation
2023-08-01 21:14:27,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:15:01,048:INFO:Initializing compare_models()
2023-08-01 21:15:01,049:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:15:01,049:INFO:Checking exceptions
2023-08-01 21:15:01,057:INFO:Preparing display monitor
2023-08-01 21:15:01,101:INFO:Initializing Logistic Regression
2023-08-01 21:15:01,102:INFO:Total runtime is 1.668532689412435e-05 minutes
2023-08-01 21:15:01,110:INFO:SubProcess create_model() called ==================================
2023-08-01 21:15:01,111:INFO:Initializing create_model()
2023-08-01 21:15:01,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70985D0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:15:01,112:INFO:Checking exceptions
2023-08-01 21:15:01,112:INFO:Importing libraries
2023-08-01 21:15:01,112:INFO:Copying training dataset
2023-08-01 21:15:01,124:INFO:Defining folds
2023-08-01 21:15:01,124:INFO:Declaring metric variables
2023-08-01 21:15:01,131:INFO:Importing untrained model
2023-08-01 21:15:01,140:INFO:Logistic Regression Imported successfully
2023-08-01 21:15:01,158:INFO:Starting cross validation
2023-08-01 21:15:01,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:15:27,394:INFO:Calculating mean and std
2023-08-01 21:15:27,396:INFO:Creating metrics dataframe
2023-08-01 21:15:29,175:INFO:Uploading results into container
2023-08-01 21:15:29,176:INFO:Uploading model into container now
2023-08-01 21:15:29,177:INFO:_master_model_container: 1
2023-08-01 21:15:29,177:INFO:_display_container: 2
2023-08-01 21:15:29,178:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 21:15:29,178:INFO:create_model() successfully completed......................................
2023-08-01 21:15:29,444:INFO:SubProcess create_model() end ==================================
2023-08-01 21:15:29,445:INFO:Creating metrics dataframe
2023-08-01 21:15:29,458:INFO:Initializing K Neighbors Classifier
2023-08-01 21:15:29,459:INFO:Total runtime is 0.47263332207997644 minutes
2023-08-01 21:15:29,466:INFO:SubProcess create_model() called ==================================
2023-08-01 21:15:29,466:INFO:Initializing create_model()
2023-08-01 21:15:29,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70985D0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:15:29,466:INFO:Checking exceptions
2023-08-01 21:15:29,466:INFO:Importing libraries
2023-08-01 21:15:29,466:INFO:Copying training dataset
2023-08-01 21:15:29,480:INFO:Defining folds
2023-08-01 21:15:29,481:INFO:Declaring metric variables
2023-08-01 21:15:29,488:INFO:Importing untrained model
2023-08-01 21:15:29,499:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:15:29,522:INFO:Starting cross validation
2023-08-01 21:15:29,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:15:43,162:INFO:Calculating mean and std
2023-08-01 21:15:43,164:INFO:Creating metrics dataframe
2023-08-01 21:15:44,931:INFO:Uploading results into container
2023-08-01 21:15:44,932:INFO:Uploading model into container now
2023-08-01 21:15:44,933:INFO:_master_model_container: 2
2023-08-01 21:15:44,933:INFO:_display_container: 2
2023-08-01 21:15:44,933:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:15:44,933:INFO:create_model() successfully completed......................................
2023-08-01 21:15:45,175:INFO:SubProcess create_model() end ==================================
2023-08-01 21:15:45,175:INFO:Creating metrics dataframe
2023-08-01 21:15:45,192:INFO:Initializing Decision Tree Classifier
2023-08-01 21:15:45,193:INFO:Total runtime is 0.7348666310310363 minutes
2023-08-01 21:15:45,198:INFO:SubProcess create_model() called ==================================
2023-08-01 21:15:45,199:INFO:Initializing create_model()
2023-08-01 21:15:45,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C70985D0A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:15:45,199:INFO:Checking exceptions
2023-08-01 21:15:45,199:INFO:Importing libraries
2023-08-01 21:15:45,199:INFO:Copying training dataset
2023-08-01 21:15:45,214:INFO:Defining folds
2023-08-01 21:15:45,214:INFO:Declaring metric variables
2023-08-01 21:15:45,223:INFO:Importing untrained model
2023-08-01 21:15:45,232:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:15:45,256:INFO:Starting cross validation
2023-08-01 21:15:45,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:15:58,485:INFO:Calculating mean and std
2023-08-01 21:15:58,487:INFO:Creating metrics dataframe
2023-08-01 21:16:00,348:INFO:Uploading results into container
2023-08-01 21:16:00,350:INFO:Uploading model into container now
2023-08-01 21:16:00,350:INFO:_master_model_container: 3
2023-08-01 21:16:00,351:INFO:_display_container: 2
2023-08-01 21:16:00,351:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:16:00,351:INFO:create_model() successfully completed......................................
2023-08-01 21:16:00,591:INFO:SubProcess create_model() end ==================================
2023-08-01 21:16:00,591:INFO:Creating metrics dataframe
2023-08-01 21:16:00,630:INFO:Initializing create_model()
2023-08-01 21:16:00,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:16:00,630:INFO:Checking exceptions
2023-08-01 21:16:00,634:INFO:Importing libraries
2023-08-01 21:16:00,634:INFO:Copying training dataset
2023-08-01 21:16:00,649:INFO:Defining folds
2023-08-01 21:16:00,649:INFO:Declaring metric variables
2023-08-01 21:16:00,649:INFO:Importing untrained model
2023-08-01 21:16:00,649:INFO:Declaring custom model
2023-08-01 21:16:00,650:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:16:00,652:INFO:Cross validation set to False
2023-08-01 21:16:00,653:INFO:Fitting Model
2023-08-01 21:16:02,066:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:16:02,067:INFO:create_model() successfully completed......................................
2023-08-01 21:16:02,328:INFO:_master_model_container: 3
2023-08-01 21:16:02,328:INFO:_display_container: 2
2023-08-01 21:16:02,328:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:16:02,329:INFO:compare_models() successfully completed......................................
2023-08-01 21:16:09,837:INFO:Initializing evaluate_model()
2023-08-01 21:16:09,837:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:16:09,858:INFO:Initializing plot_model()
2023-08-01 21:16:09,858:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, system=True)
2023-08-01 21:16:09,858:INFO:Checking exceptions
2023-08-01 21:16:09,863:INFO:Preloading libraries
2023-08-01 21:16:09,863:INFO:Copying training dataset
2023-08-01 21:16:09,864:INFO:Plot type: pipeline
2023-08-01 21:16:10,208:INFO:Visual Rendered Successfully
2023-08-01 21:16:10,427:INFO:plot_model() successfully completed......................................
2023-08-01 21:16:12,917:INFO:Initializing plot_model()
2023-08-01 21:16:12,917:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, system=True)
2023-08-01 21:16:12,917:INFO:Checking exceptions
2023-08-01 21:16:12,924:INFO:Preloading libraries
2023-08-01 21:16:12,924:INFO:Copying training dataset
2023-08-01 21:16:12,925:INFO:Plot type: confusion_matrix
2023-08-01 21:16:13,045:INFO:Fitting Model
2023-08-01 21:17:04,733:INFO:Initializing get_config()
2023-08-01 21:17:04,733:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=None)
2023-08-01 21:19:48,966:INFO:Initializing get_config()
2023-08-01 21:19:48,966:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=None)
2023-08-01 21:19:55,108:INFO:Initializing get_config()
2023-08-01 21:19:55,108:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=X_train_transformed)
2023-08-01 21:19:55,173:INFO:Variable: X_train returned as       market_segment_Online TA  market_segment_Direct  market_segment_Groups  \
3760                       1.0                    0.0                    0.0   
9297                       0.0                    1.0                    0.0   
5694                       1.0                    0.0                    0.0   
1232                       0.0                    0.0                    1.0   
3919                       1.0                    0.0                    0.0   
...                        ...                    ...                    ...   
9238                       0.0                    0.0                    0.0   
7745                       0.0                    0.0                    1.0   
5901                       0.0                    0.0                    0.0   
5894                       0.0                    0.0                    0.0   
4545                       1.0                    0.0                    0.0   

      market_segment_Offline TA/TO  market_segment_Complementary  \
3760                           0.0                           0.0   
9297                           0.0                           0.0   
5694                           0.0                           0.0   
1232                           0.0                           0.0   
3919                           0.0                           0.0   
...                            ...                           ...   
9238                           0.0                           0.0   
7745                           0.0                           0.0   
5901                           1.0                           0.0   
5894                           1.0                           0.0   
4545                           0.0                           0.0   

      market_segment_Corporate  market_segment_Aviation  \
3760                       0.0                      0.0   
9297                       0.0                      0.0   
5694                       0.0                      0.0   
1232                       0.0                      0.0   
3919                       0.0                      0.0   
...                        ...                      ...   
9238                       1.0                      0.0   
7745                       0.0                      0.0   
5901                       0.0                      0.0   
5894                       0.0                      0.0   
4545                       0.0                      0.0   

      previous_cancellations  booking_changes  deposit_type_No Deposit  ...  \
3760                     0.0              0.0                      1.0  ...   
9297                     0.0              0.0                      1.0  ...   
5694                     0.0              0.0                      1.0  ...   
1232                     0.0              5.0                      1.0  ...   
3919                     0.0              4.0                      1.0  ...   
...                      ...              ...                      ...  ...   
9238                     0.0              0.0                      1.0  ...   
7745                     0.0              1.0                      1.0  ...   
5901                     0.0              0.0                      1.0  ...   
5894                     0.0              0.0                      1.0  ...   
4545                     0.0              1.0                      1.0  ...   

      reserved_room_type_A  reserved_room_type_D  reserved_room_type_C  \
3760                   0.0                   0.0                   0.0   
9297                   0.0                   0.0                   0.0   
5694                   0.0                   0.0                   0.0   
1232                   1.0                   0.0                   0.0   
3919                   1.0                   0.0                   0.0   
...                    ...                   ...                   ...   
9238                   0.0                   0.0                   0.0   
7745                   1.0                   0.0                   0.0   
5901                   0.0                   1.0                   0.0   
5894                   0.0                   0.0                   0.0   
4545                   1.0                   0.0                   0.0   

      reserved_room_type_H  reserved_room_type_B  reserved_room_type_G  \
3760                   0.0                   0.0                   0.0   
9297                   0.0                   0.0                   0.0   
5694                   0.0                   0.0                   0.0   
1232                   0.0                   0.0                   0.0   
3919                   0.0                   0.0                   0.0   
...                    ...                   ...                   ...   
9238                   0.0                   0.0                   0.0   
7745                   0.0                   0.0                   0.0   
5901                   0.0                   0.0                   0.0   
5894                   0.0                   0.0                   0.0   
4545                   0.0                   0.0                   0.0   

      reserved_room_type_P  reserved_room_type_L  required_car_parking_spaces  \
3760                   0.0                   0.0                          0.0   
9297                   0.0                   0.0                          0.0   
5694                   0.0                   0.0                          0.0   
1232                   0.0                   0.0                          0.0   
3919                   0.0                   0.0                          0.0   
...                    ...                   ...                          ...   
9238                   0.0                   0.0                          0.0   
7745                   0.0                   0.0                          1.0   
5901                   0.0                   0.0                          0.0   
5894                   0.0                   0.0                          0.0   
4545                   0.0                   0.0                          0.0   

      total_of_special_requests  
3760                        2.0  
9297                        0.0  
5694                        3.0  
1232                        1.0  
3919                        1.0  
...                         ...  
9238                        0.0  
7745                        0.0  
5901                        4.0  
5894                        0.0  
4545                        0.0  

[6508 rows x 29 columns]
2023-08-01 21:19:55,173:INFO:get_config() successfully completed......................................
2023-08-01 21:20:08,686:INFO:Initializing get_config()
2023-08-01 21:20:08,687:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=X_test_transformed)
2023-08-01 21:20:08,768:INFO:Variable: X_test returned as        market_segment_Online TA  market_segment_Direct  market_segment_Groups  \
8591                        0.0                    0.0                    1.0   
9326                        0.0                    0.0                    0.0   
4411                        1.0                    0.0                    0.0   
2665                        1.0                    0.0                    0.0   
7981                        1.0                    0.0                    0.0   
...                         ...                    ...                    ...   
7514                        0.0                    0.0                    0.0   
10122                       0.0                    0.0                    0.0   
4969                        0.0                    0.0                    0.0   
8205                        1.0                    0.0                    0.0   
2936                        0.0                    1.0                    0.0   

       market_segment_Offline TA/TO  market_segment_Complementary  \
8591                            0.0                           0.0   
9326                            1.0                           0.0   
4411                            0.0                           0.0   
2665                            0.0                           0.0   
7981                            0.0                           0.0   
...                             ...                           ...   
7514                            1.0                           0.0   
10122                           1.0                           0.0   
4969                            0.0                           0.0   
8205                            0.0                           0.0   
2936                            0.0                           0.0   

       market_segment_Corporate  market_segment_Aviation  \
8591                        0.0                      0.0   
9326                        0.0                      0.0   
4411                        0.0                      0.0   
2665                        0.0                      0.0   
7981                        0.0                      0.0   
...                         ...                      ...   
7514                        0.0                      0.0   
10122                       0.0                      0.0   
4969                        0.0                      1.0   
8205                        0.0                      0.0   
2936                        0.0                      0.0   

       previous_cancellations  booking_changes  deposit_type_No Deposit  ...  \
8591                      0.0              1.0                      1.0  ...   
9326                      0.0              2.0                      1.0  ...   
4411                      0.0              0.0                      0.0  ...   
2665                      0.0              0.0                      1.0  ...   
7981                      0.0              0.0                      1.0  ...   
...                       ...              ...                      ...  ...   
7514                      0.0              1.0                      1.0  ...   
10122                     0.0              0.0                      1.0  ...   
4969                      0.0              0.0                      1.0  ...   
8205                      0.0              1.0                      1.0  ...   
2936                      0.0              0.0                      1.0  ...   

       reserved_room_type_A  reserved_room_type_D  reserved_room_type_C  \
8591                    1.0                   0.0                   0.0   
9326                    0.0                   0.0                   0.0   
4411                    0.0                   0.0                   0.0   
2665                    1.0                   0.0                   0.0   
7981                    0.0                   1.0                   0.0   
...                     ...                   ...                   ...   
7514                    1.0                   0.0                   0.0   
10122                   1.0                   0.0                   0.0   
4969                    1.0                   0.0                   0.0   
8205                    1.0                   0.0                   0.0   
2936                    1.0                   0.0                   0.0   

       reserved_room_type_H  reserved_room_type_B  reserved_room_type_G  \
8591                    0.0                   0.0                   0.0   
9326                    0.0                   0.0                   0.0   
4411                    0.0                   0.0                   0.0   
2665                    0.0                   0.0                   0.0   
7981                    0.0                   0.0                   0.0   
...                     ...                   ...                   ...   
7514                    0.0                   0.0                   0.0   
10122                   0.0                   0.0                   0.0   
4969                    0.0                   0.0                   0.0   
8205                    0.0                   0.0                   0.0   
2936                    0.0                   0.0                   0.0   

       reserved_room_type_P  reserved_room_type_L  \
8591                    0.0                   0.0   
9326                    0.0                   0.0   
4411                    0.0                   0.0   
2665                    0.0                   0.0   
7981                    0.0                   0.0   
...                     ...                   ...   
7514                    0.0                   0.0   
10122                   0.0                   0.0   
4969                    0.0                   0.0   
8205                    0.0                   0.0   
2936                    0.0                   0.0   

       required_car_parking_spaces  total_of_special_requests  
8591                           0.0                        0.0  
9326                           0.0                        1.0  
4411                           0.0                        0.0  
2665                           1.0                        0.0  
7981                           0.0                        2.0  
...                            ...                        ...  
7514                           0.0                        0.0  
10122                          1.0                        0.0  
4969                           1.0                        0.0  
8205                           0.0                        1.0  
2936                           0.0                        0.0  

[1628 rows x 29 columns]
2023-08-01 21:20:08,769:INFO:get_config() successfully completed......................................
2023-08-01 21:20:15,542:INFO:Initializing get_config()
2023-08-01 21:20:15,542:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=X_transformed)
2023-08-01 21:20:15,635:INFO:Variable: X returned as        market_segment_Online TA  market_segment_Direct  market_segment_Groups  \
3760                        1.0                    0.0                    0.0   
9297                        0.0                    1.0                    0.0   
5694                        1.0                    0.0                    0.0   
1232                        0.0                    0.0                    1.0   
3919                        1.0                    0.0                    0.0   
...                         ...                    ...                    ...   
7514                        0.0                    0.0                    0.0   
10122                       0.0                    0.0                    0.0   
4969                        0.0                    0.0                    0.0   
8205                        1.0                    0.0                    0.0   
2936                        0.0                    1.0                    0.0   

       market_segment_Offline TA/TO  market_segment_Complementary  \
3760                            0.0                           0.0   
9297                            0.0                           0.0   
5694                            0.0                           0.0   
1232                            0.0                           0.0   
3919                            0.0                           0.0   
...                             ...                           ...   
7514                            1.0                           0.0   
10122                           1.0                           0.0   
4969                            0.0                           0.0   
8205                            0.0                           0.0   
2936                            0.0                           0.0   

       market_segment_Corporate  market_segment_Aviation  \
3760                        0.0                      0.0   
9297                        0.0                      0.0   
5694                        0.0                      0.0   
1232                        0.0                      0.0   
3919                        0.0                      0.0   
...                         ...                      ...   
7514                        0.0                      0.0   
10122                       0.0                      0.0   
4969                        0.0                      1.0   
8205                        0.0                      0.0   
2936                        0.0                      0.0   

       previous_cancellations  booking_changes  deposit_type_No Deposit  ...  \
3760                      0.0              0.0                      1.0  ...   
9297                      0.0              0.0                      1.0  ...   
5694                      0.0              0.0                      1.0  ...   
1232                      0.0              5.0                      1.0  ...   
3919                      0.0              4.0                      1.0  ...   
...                       ...              ...                      ...  ...   
7514                      0.0              1.0                      1.0  ...   
10122                     0.0              0.0                      1.0  ...   
4969                      0.0              0.0                      1.0  ...   
8205                      0.0              1.0                      1.0  ...   
2936                      0.0              0.0                      1.0  ...   

       reserved_room_type_A  reserved_room_type_D  reserved_room_type_C  \
3760                    0.0                   0.0                   0.0   
9297                    0.0                   0.0                   0.0   
5694                    0.0                   0.0                   0.0   
1232                    1.0                   0.0                   0.0   
3919                    1.0                   0.0                   0.0   
...                     ...                   ...                   ...   
7514                    1.0                   0.0                   0.0   
10122                   1.0                   0.0                   0.0   
4969                    1.0                   0.0                   0.0   
8205                    1.0                   0.0                   0.0   
2936                    1.0                   0.0                   0.0   

       reserved_room_type_H  reserved_room_type_B  reserved_room_type_G  \
3760                    0.0                   0.0                   0.0   
9297                    0.0                   0.0                   0.0   
5694                    0.0                   0.0                   0.0   
1232                    0.0                   0.0                   0.0   
3919                    0.0                   0.0                   0.0   
...                     ...                   ...                   ...   
7514                    0.0                   0.0                   0.0   
10122                   0.0                   0.0                   0.0   
4969                    0.0                   0.0                   0.0   
8205                    0.0                   0.0                   0.0   
2936                    0.0                   0.0                   0.0   

       reserved_room_type_P  reserved_room_type_L  \
3760                    0.0                   0.0   
9297                    0.0                   0.0   
5694                    0.0                   0.0   
1232                    0.0                   0.0   
3919                    0.0                   0.0   
...                     ...                   ...   
7514                    0.0                   0.0   
10122                   0.0                   0.0   
4969                    0.0                   0.0   
8205                    0.0                   0.0   
2936                    0.0                   0.0   

       required_car_parking_spaces  total_of_special_requests  
3760                           0.0                        2.0  
9297                           0.0                        0.0  
5694                           0.0                        3.0  
1232                           0.0                        1.0  
3919                           0.0                        1.0  
...                            ...                        ...  
7514                           0.0                        0.0  
10122                          1.0                        0.0  
4969                           1.0                        0.0  
8205                           0.0                        1.0  
2936                           0.0                        0.0  

[8136 rows x 29 columns]
2023-08-01 21:20:15,636:INFO:get_config() successfully completed......................................
2023-08-01 21:20:22,821:INFO:Initializing get_config()
2023-08-01 21:20:22,821:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=y_transformed)
2023-08-01 21:20:22,892:INFO:Variable: y returned as 3760     0
9297     1
5694     1
1232     0
3919     1
        ..
7514     0
10122    0
4969     0
8205     0
2936     0
Name: is_canceled, Length: 8136, dtype: int8
2023-08-01 21:20:22,893:INFO:get_config() successfully completed......................................
2023-08-01 21:20:29,491:INFO:Initializing get_config()
2023-08-01 21:20:29,491:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, variable=X)
2023-08-01 21:20:29,504:INFO:Variable:  returned as       market_segment  previous_cancellations  booking_changes deposit_type  \
3760       Online TA                       0                0   No Deposit   
9297          Direct                       0                0   No Deposit   
5694       Online TA                       0                0   No Deposit   
1232          Groups                       0                5   No Deposit   
3919       Online TA                       0                4   No Deposit   
...              ...                     ...              ...          ...   
7514   Offline TA/TO                       0                1   No Deposit   
10122  Offline TA/TO                       0                0   No Deposit   
4969        Aviation                       0                0   No Deposit   
8205       Online TA                       0                1   No Deposit   
2936          Direct                       0                0   No Deposit   

       days_in_waiting_list    customer_type reserved_room_type  \
3760                      0        Transient                  E   
9297                      0  Transient-Party                  F   
5694                      0  Transient-Party                  E   
1232                      0  Transient-Party                  A   
3919                      0  Transient-Party                  A   
...                     ...              ...                ...   
7514                      0  Transient-Party                  A   
10122                     0        Transient                  A   
4969                      0        Transient                  A   
8205                      0        Transient                  A   
2936                      0        Transient                  A   

       required_car_parking_spaces  total_of_special_requests  
3760                             0                          2  
9297                             0                          0  
5694                             0                          3  
1232                             0                          1  
3919                             0                          1  
...                            ...                        ...  
7514                             0                          0  
10122                            1                          0  
4969                             1                          0  
8205                             0                          1  
2936                             0                          0  

[8136 rows x 9 columns]
2023-08-01 21:20:29,505:INFO:get_config() successfully completed......................................
2023-08-01 21:21:26,114:INFO:Initializing plot_model()
2023-08-01 21:21:26,114:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, system=True)
2023-08-01 21:21:26,115:INFO:Checking exceptions
2023-08-01 21:21:26,119:INFO:Preloading libraries
2023-08-01 21:21:26,120:INFO:Copying training dataset
2023-08-01 21:21:26,120:INFO:Plot type: parameter
2023-08-01 21:21:26,125:INFO:Visual Rendered Successfully
2023-08-01 21:21:27,294:INFO:plot_model() successfully completed......................................
2023-08-01 21:21:27,467:INFO:Initializing plot_model()
2023-08-01 21:21:27,468:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C709AE66A0>, system=True)
2023-08-01 21:21:27,468:INFO:Checking exceptions
2023-08-01 21:21:27,474:INFO:Preloading libraries
2023-08-01 21:21:27,474:INFO:Copying training dataset
2023-08-01 21:21:27,474:INFO:Plot type: auc
2023-08-01 21:21:27,564:INFO:Fitting Model
2023-08-01 21:24:23,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 21:24:23,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 21:24:23,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 21:24:23,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 21:24:24,962:INFO:PyCaret ClassificationExperiment
2023-08-01 21:24:24,962:INFO:Logging name: clf-default-name
2023-08-01 21:24:24,962:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 21:24:24,962:INFO:version 3.0.4
2023-08-01 21:24:24,962:INFO:Initializing setup()
2023-08-01 21:24:24,963:INFO:self.USI: 69dd
2023-08-01 21:24:24,963:INFO:self._variable_keys: {'fix_imbalance', 'html_param', 'exp_id', 'fold_generator', 'log_plots_param', 'gpu_param', 'logging_param', 'fold_groups_param', 'USI', 'X_train', 'X', 'X_test', 'memory', 'target_param', 'y_train', 'n_jobs_param', 'fold_shuffle_param', 'is_multiclass', 'pipeline', 'exp_name_log', 'gpu_n_jobs_param', 'y_test', 'idx', 'seed', '_ml_usecase', 'y', 'data', '_available_plots'}
2023-08-01 21:24:24,963:INFO:Checking environment
2023-08-01 21:24:24,963:INFO:python_version: 3.9.13
2023-08-01 21:24:24,963:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 21:24:24,963:INFO:machine: AMD64
2023-08-01 21:24:24,963:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 21:24:24,966:INFO:Memory: svmem(total=17055166464, available=9357373440, percent=45.1, used=7697793024, free=9357373440)
2023-08-01 21:24:24,967:INFO:Physical Core: 4
2023-08-01 21:24:24,967:INFO:Logical Core: 8
2023-08-01 21:24:24,967:INFO:Checking libraries
2023-08-01 21:24:24,967:INFO:System:
2023-08-01 21:24:24,967:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 21:24:24,967:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 21:24:24,967:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 21:24:24,967:INFO:PyCaret required dependencies:
2023-08-01 21:24:24,970:INFO:                 pip: 22.0.4
2023-08-01 21:24:24,970:INFO:          setuptools: 58.1.0
2023-08-01 21:24:24,970:INFO:             pycaret: 3.0.4
2023-08-01 21:24:24,970:INFO:             IPython: 8.13.1
2023-08-01 21:24:24,970:INFO:          ipywidgets: 8.0.7
2023-08-01 21:24:24,970:INFO:                tqdm: 4.65.0
2023-08-01 21:24:24,970:INFO:               numpy: 1.23.0
2023-08-01 21:24:24,970:INFO:              pandas: 1.5.3
2023-08-01 21:24:24,970:INFO:              jinja2: 3.1.2
2023-08-01 21:24:24,970:INFO:               scipy: 1.10.1
2023-08-01 21:24:24,970:INFO:              joblib: 1.2.0
2023-08-01 21:24:24,970:INFO:             sklearn: 1.2.2
2023-08-01 21:24:24,970:INFO:                pyod: 1.1.0
2023-08-01 21:24:24,971:INFO:            imblearn: 0.11.0
2023-08-01 21:24:24,971:INFO:   category_encoders: 2.6.1
2023-08-01 21:24:24,971:INFO:            lightgbm: 3.3.5
2023-08-01 21:24:24,971:INFO:               numba: 0.57.1
2023-08-01 21:24:24,971:INFO:            requests: 2.31.0
2023-08-01 21:24:24,971:INFO:          matplotlib: 3.7.1
2023-08-01 21:24:24,971:INFO:          scikitplot: 0.3.7
2023-08-01 21:24:24,971:INFO:         yellowbrick: 1.5
2023-08-01 21:24:24,971:INFO:              plotly: 5.15.0
2023-08-01 21:24:24,971:INFO:    plotly-resampler: Not installed
2023-08-01 21:24:24,971:INFO:             kaleido: 0.2.1
2023-08-01 21:24:24,971:INFO:           schemdraw: 0.15
2023-08-01 21:24:24,971:INFO:         statsmodels: 0.14.0
2023-08-01 21:24:24,971:INFO:              sktime: 0.20.0
2023-08-01 21:24:24,971:INFO:               tbats: 1.1.3
2023-08-01 21:24:24,971:INFO:            pmdarima: 2.0.3
2023-08-01 21:24:24,971:INFO:              psutil: 5.9.5
2023-08-01 21:24:24,971:INFO:          markupsafe: 2.1.3
2023-08-01 21:24:24,972:INFO:             pickle5: Not installed
2023-08-01 21:24:24,972:INFO:         cloudpickle: 2.2.1
2023-08-01 21:24:24,972:INFO:         deprecation: 2.1.0
2023-08-01 21:24:24,972:INFO:              xxhash: 3.2.0
2023-08-01 21:24:24,972:INFO:           wurlitzer: Not installed
2023-08-01 21:24:24,972:INFO:PyCaret optional dependencies:
2023-08-01 21:24:24,991:INFO:                shap: Not installed
2023-08-01 21:24:24,991:INFO:           interpret: Not installed
2023-08-01 21:24:24,992:INFO:                umap: Not installed
2023-08-01 21:24:24,992:INFO:    pandas_profiling: 4.3.1
2023-08-01 21:24:24,992:INFO:  explainerdashboard: Not installed
2023-08-01 21:24:24,992:INFO:             autoviz: Not installed
2023-08-01 21:24:24,992:INFO:           fairlearn: Not installed
2023-08-01 21:24:24,992:INFO:          deepchecks: Not installed
2023-08-01 21:24:24,992:INFO:             xgboost: Not installed
2023-08-01 21:24:24,992:INFO:            catboost: Not installed
2023-08-01 21:24:24,992:INFO:              kmodes: Not installed
2023-08-01 21:24:24,992:INFO:             mlxtend: 0.22.0
2023-08-01 21:24:24,992:INFO:       statsforecast: Not installed
2023-08-01 21:24:24,992:INFO:        tune_sklearn: Not installed
2023-08-01 21:24:24,992:INFO:                 ray: Not installed
2023-08-01 21:24:24,992:INFO:            hyperopt: Not installed
2023-08-01 21:24:24,992:INFO:              optuna: Not installed
2023-08-01 21:24:24,992:INFO:               skopt: Not installed
2023-08-01 21:24:24,992:INFO:              mlflow: Not installed
2023-08-01 21:24:24,992:INFO:              gradio: Not installed
2023-08-01 21:24:24,992:INFO:             fastapi: Not installed
2023-08-01 21:24:24,993:INFO:             uvicorn: Not installed
2023-08-01 21:24:24,993:INFO:              m2cgen: Not installed
2023-08-01 21:24:24,993:INFO:           evidently: Not installed
2023-08-01 21:24:24,993:INFO:               fugue: Not installed
2023-08-01 21:24:24,993:INFO:           streamlit: Not installed
2023-08-01 21:24:24,993:INFO:             prophet: Not installed
2023-08-01 21:24:24,993:INFO:None
2023-08-01 21:24:24,993:INFO:Set up data.
2023-08-01 21:24:25,006:INFO:Set up train/test split.
2023-08-01 21:24:25,017:INFO:Set up index.
2023-08-01 21:24:25,017:INFO:Set up folding strategy.
2023-08-01 21:24:25,017:INFO:Assigning column types.
2023-08-01 21:24:25,023:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 21:24:25,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,250:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,298:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 21:24:25,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:24:25,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,556:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 21:24:25,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,676:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:25,785:INFO:Preparing preprocessing pipeline...
2023-08-01 21:24:25,786:INFO:Set up simple imputation.
2023-08-01 21:24:25,792:INFO:Set up encoding of categorical features.
2023-08-01 21:24:25,792:INFO:Set up removing multicollinearity.
2023-08-01 21:24:26,066:INFO:Finished creating preprocessing pipeline.
2023-08-01 21:24:26,076:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 21:24:26,076:INFO:Creating final display dataframe.
2023-08-01 21:24:26,177:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (6508, 30)
6    Transformed test set shape        (1628, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              69dd
2023-08-01 21:24:26,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:26,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:26,464:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:26,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:24:26,466:INFO:setup() successfully completed in 2.68s...............
2023-08-01 21:24:38,102:INFO:Initializing compare_models()
2023-08-01 21:24:38,102:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:24:38,102:INFO:Checking exceptions
2023-08-01 21:24:38,109:INFO:Preparing display monitor
2023-08-01 21:24:38,145:INFO:Initializing Logistic Regression
2023-08-01 21:24:38,145:INFO:Total runtime is 0.0 minutes
2023-08-01 21:24:38,151:INFO:SubProcess create_model() called ==================================
2023-08-01 21:24:38,152:INFO:Initializing create_model()
2023-08-01 21:24:38,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF891B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:24:38,152:INFO:Checking exceptions
2023-08-01 21:24:38,152:INFO:Importing libraries
2023-08-01 21:24:38,152:INFO:Copying training dataset
2023-08-01 21:24:38,160:INFO:Defining folds
2023-08-01 21:24:38,160:INFO:Declaring metric variables
2023-08-01 21:24:38,166:INFO:Importing untrained model
2023-08-01 21:24:38,173:INFO:Logistic Regression Imported successfully
2023-08-01 21:24:38,190:INFO:Starting cross validation
2023-08-01 21:24:38,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:25:02,551:INFO:Calculating mean and std
2023-08-01 21:25:02,552:INFO:Creating metrics dataframe
2023-08-01 21:25:04,370:INFO:Uploading results into container
2023-08-01 21:25:04,371:INFO:Uploading model into container now
2023-08-01 21:25:04,372:INFO:_master_model_container: 1
2023-08-01 21:25:04,372:INFO:_display_container: 2
2023-08-01 21:25:04,373:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 21:25:04,373:INFO:create_model() successfully completed......................................
2023-08-01 21:25:04,446:INFO:SubProcess create_model() end ==================================
2023-08-01 21:25:04,447:INFO:Creating metrics dataframe
2023-08-01 21:25:04,460:INFO:Initializing K Neighbors Classifier
2023-08-01 21:25:04,460:INFO:Total runtime is 0.43858470519383747 minutes
2023-08-01 21:25:04,467:INFO:SubProcess create_model() called ==================================
2023-08-01 21:25:04,467:INFO:Initializing create_model()
2023-08-01 21:25:04,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF891B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:25:04,467:INFO:Checking exceptions
2023-08-01 21:25:04,467:INFO:Importing libraries
2023-08-01 21:25:04,468:INFO:Copying training dataset
2023-08-01 21:25:04,480:INFO:Defining folds
2023-08-01 21:25:04,480:INFO:Declaring metric variables
2023-08-01 21:25:04,486:INFO:Importing untrained model
2023-08-01 21:25:04,494:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:25:04,512:INFO:Starting cross validation
2023-08-01 21:25:04,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:25:17,893:INFO:Calculating mean and std
2023-08-01 21:25:17,895:INFO:Creating metrics dataframe
2023-08-01 21:25:19,615:INFO:Uploading results into container
2023-08-01 21:25:19,617:INFO:Uploading model into container now
2023-08-01 21:25:19,618:INFO:_master_model_container: 2
2023-08-01 21:25:19,618:INFO:_display_container: 2
2023-08-01 21:25:19,619:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:25:19,619:INFO:create_model() successfully completed......................................
2023-08-01 21:25:19,693:INFO:SubProcess create_model() end ==================================
2023-08-01 21:25:19,694:INFO:Creating metrics dataframe
2023-08-01 21:25:19,707:INFO:Initializing Decision Tree Classifier
2023-08-01 21:25:19,707:INFO:Total runtime is 0.6927013397216797 minutes
2023-08-01 21:25:19,711:INFO:SubProcess create_model() called ==================================
2023-08-01 21:25:19,711:INFO:Initializing create_model()
2023-08-01 21:25:19,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF891B20>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:25:19,712:INFO:Checking exceptions
2023-08-01 21:25:19,712:INFO:Importing libraries
2023-08-01 21:25:19,712:INFO:Copying training dataset
2023-08-01 21:25:19,723:INFO:Defining folds
2023-08-01 21:25:19,724:INFO:Declaring metric variables
2023-08-01 21:25:19,731:INFO:Importing untrained model
2023-08-01 21:25:19,739:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:25:19,757:INFO:Starting cross validation
2023-08-01 21:25:19,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:25:31,617:INFO:Calculating mean and std
2023-08-01 21:25:31,618:INFO:Creating metrics dataframe
2023-08-01 21:25:33,344:INFO:Uploading results into container
2023-08-01 21:25:33,346:INFO:Uploading model into container now
2023-08-01 21:25:33,348:INFO:_master_model_container: 3
2023-08-01 21:25:33,348:INFO:_display_container: 2
2023-08-01 21:25:33,349:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:25:33,349:INFO:create_model() successfully completed......................................
2023-08-01 21:25:33,427:INFO:SubProcess create_model() end ==================================
2023-08-01 21:25:33,427:INFO:Creating metrics dataframe
2023-08-01 21:25:33,466:INFO:Initializing create_model()
2023-08-01 21:25:33,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:25:33,467:INFO:Checking exceptions
2023-08-01 21:25:33,471:INFO:Importing libraries
2023-08-01 21:25:33,471:INFO:Copying training dataset
2023-08-01 21:25:33,483:INFO:Defining folds
2023-08-01 21:25:33,484:INFO:Declaring metric variables
2023-08-01 21:25:33,484:INFO:Importing untrained model
2023-08-01 21:25:33,484:INFO:Declaring custom model
2023-08-01 21:25:33,485:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:25:33,488:INFO:Cross validation set to False
2023-08-01 21:25:33,489:INFO:Fitting Model
2023-08-01 21:25:34,873:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:25:34,873:INFO:create_model() successfully completed......................................
2023-08-01 21:25:34,982:INFO:_master_model_container: 3
2023-08-01 21:25:34,983:INFO:_display_container: 2
2023-08-01 21:25:34,984:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:25:34,984:INFO:compare_models() successfully completed......................................
2023-08-01 21:25:37,163:INFO:Initializing get_config()
2023-08-01 21:25:37,164:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, variable=pipeline)
2023-08-01 21:25:37,174:INFO:Variable:  returned as Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'customer_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 21:25:37,174:INFO:get_config() successfully completed......................................
2023-08-01 21:26:18,349:INFO:Initializing evaluate_model()
2023-08-01 21:26:18,350:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:26:18,367:INFO:Initializing plot_model()
2023-08-01 21:26:18,368:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:18,368:INFO:Checking exceptions
2023-08-01 21:26:18,372:INFO:Preloading libraries
2023-08-01 21:26:18,372:INFO:Copying training dataset
2023-08-01 21:26:18,372:INFO:Plot type: pipeline
2023-08-01 21:26:18,727:INFO:Visual Rendered Successfully
2023-08-01 21:26:18,797:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:21,336:INFO:Initializing plot_model()
2023-08-01 21:26:21,337:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:21,337:INFO:Checking exceptions
2023-08-01 21:26:21,341:INFO:Preloading libraries
2023-08-01 21:26:21,341:INFO:Copying training dataset
2023-08-01 21:26:21,341:INFO:Plot type: parameter
2023-08-01 21:26:21,348:INFO:Visual Rendered Successfully
2023-08-01 21:26:21,417:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:22,316:INFO:Initializing plot_model()
2023-08-01 21:26:22,316:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:22,316:INFO:Checking exceptions
2023-08-01 21:26:22,320:INFO:Preloading libraries
2023-08-01 21:26:22,321:INFO:Copying training dataset
2023-08-01 21:26:22,321:INFO:Plot type: confusion_matrix
2023-08-01 21:26:22,425:INFO:Fitting Model
2023-08-01 21:26:22,426:INFO:Scoring test/hold-out set
2023-08-01 21:26:22,613:INFO:Visual Rendered Successfully
2023-08-01 21:26:22,707:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:26,901:INFO:Initializing plot_model()
2023-08-01 21:26:26,901:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:26,901:INFO:Checking exceptions
2023-08-01 21:26:26,906:INFO:Preloading libraries
2023-08-01 21:26:26,907:INFO:Copying training dataset
2023-08-01 21:26:26,907:INFO:Plot type: threshold
2023-08-01 21:26:26,992:INFO:Fitting Model
2023-08-01 21:26:28,076:INFO:Scoring test/hold-out set
2023-08-01 21:26:28,662:INFO:Visual Rendered Successfully
2023-08-01 21:26:28,726:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:35,665:INFO:Initializing plot_model()
2023-08-01 21:26:35,665:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:35,666:INFO:Checking exceptions
2023-08-01 21:26:35,670:INFO:Preloading libraries
2023-08-01 21:26:35,670:INFO:Copying training dataset
2023-08-01 21:26:35,670:INFO:Plot type: feature
2023-08-01 21:26:35,671:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 21:26:36,032:INFO:Visual Rendered Successfully
2023-08-01 21:26:36,125:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:46,437:INFO:Initializing plot_model()
2023-08-01 21:26:46,437:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:26:46,437:INFO:Checking exceptions
2023-08-01 21:26:46,441:INFO:Preloading libraries
2023-08-01 21:26:46,442:INFO:Copying training dataset
2023-08-01 21:26:46,442:INFO:Plot type: threshold
2023-08-01 21:26:46,529:INFO:Fitting Model
2023-08-01 21:26:47,613:INFO:Scoring test/hold-out set
2023-08-01 21:26:47,881:INFO:Visual Rendered Successfully
2023-08-01 21:26:47,976:INFO:plot_model() successfully completed......................................
2023-08-01 21:26:58,260:INFO:Initializing compare_models()
2023-08-01 21:26:58,261:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=0.26, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': 0.26, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:26:58,262:INFO:Checking exceptions
2023-08-01 21:26:58,269:INFO:Preparing display monitor
2023-08-01 21:26:58,339:INFO:Initializing Logistic Regression
2023-08-01 21:26:58,339:INFO:Total runtime is 0.0 minutes
2023-08-01 21:26:58,349:INFO:SubProcess create_model() called ==================================
2023-08-01 21:26:58,350:INFO:Initializing create_model()
2023-08-01 21:26:58,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF76AAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:26:58,351:INFO:Checking exceptions
2023-08-01 21:26:58,351:INFO:Importing libraries
2023-08-01 21:26:58,351:INFO:Copying training dataset
2023-08-01 21:26:58,366:INFO:Defining folds
2023-08-01 21:26:58,366:INFO:Declaring metric variables
2023-08-01 21:26:58,374:INFO:Importing untrained model
2023-08-01 21:26:58,385:INFO:Logistic Regression Imported successfully
2023-08-01 21:26:58,409:INFO:Starting cross validation
2023-08-01 21:26:58,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:27:00,408:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 21:27:12,655:INFO:Calculating mean and std
2023-08-01 21:27:12,657:INFO:Creating metrics dataframe
2023-08-01 21:27:14,433:INFO:Uploading results into container
2023-08-01 21:27:14,436:INFO:Uploading model into container now
2023-08-01 21:27:14,439:INFO:_master_model_container: 4
2023-08-01 21:27:14,440:INFO:_display_container: 3
2023-08-01 21:27:14,444:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:27:14,444:INFO:create_model() successfully completed......................................
2023-08-01 21:27:14,530:INFO:SubProcess create_model() end ==================================
2023-08-01 21:27:14,530:INFO:Creating metrics dataframe
2023-08-01 21:27:14,543:INFO:Initializing K Neighbors Classifier
2023-08-01 21:27:14,544:INFO:Total runtime is 0.2700687646865845 minutes
2023-08-01 21:27:14,549:INFO:SubProcess create_model() called ==================================
2023-08-01 21:27:14,549:INFO:Initializing create_model()
2023-08-01 21:27:14,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF76AAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:27:14,550:INFO:Checking exceptions
2023-08-01 21:27:14,550:INFO:Importing libraries
2023-08-01 21:27:14,551:INFO:Copying training dataset
2023-08-01 21:27:14,563:INFO:Defining folds
2023-08-01 21:27:14,563:INFO:Declaring metric variables
2023-08-01 21:27:14,572:INFO:Importing untrained model
2023-08-01 21:27:14,578:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:27:14,596:INFO:Starting cross validation
2023-08-01 21:27:14,598:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:27:27,250:INFO:Calculating mean and std
2023-08-01 21:27:27,252:INFO:Creating metrics dataframe
2023-08-01 21:27:28,949:INFO:Uploading results into container
2023-08-01 21:27:28,950:INFO:Uploading model into container now
2023-08-01 21:27:28,952:INFO:_master_model_container: 5
2023-08-01 21:27:28,952:INFO:_display_container: 3
2023-08-01 21:27:28,954:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.26,
                                     weights='uniform')
2023-08-01 21:27:28,954:INFO:create_model() successfully completed......................................
2023-08-01 21:27:29,034:INFO:SubProcess create_model() end ==================================
2023-08-01 21:27:29,035:INFO:Creating metrics dataframe
2023-08-01 21:27:29,052:INFO:Initializing Decision Tree Classifier
2023-08-01 21:27:29,053:INFO:Total runtime is 0.511885424455007 minutes
2023-08-01 21:27:29,060:INFO:SubProcess create_model() called ==================================
2023-08-01 21:27:29,060:INFO:Initializing create_model()
2023-08-01 21:27:29,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF76AAC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:27:29,060:INFO:Checking exceptions
2023-08-01 21:27:29,060:INFO:Importing libraries
2023-08-01 21:27:29,061:INFO:Copying training dataset
2023-08-01 21:27:29,073:INFO:Defining folds
2023-08-01 21:27:29,073:INFO:Declaring metric variables
2023-08-01 21:27:29,081:INFO:Importing untrained model
2023-08-01 21:27:29,090:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:27:29,105:INFO:Starting cross validation
2023-08-01 21:27:29,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:27:41,728:INFO:Calculating mean and std
2023-08-01 21:27:41,729:INFO:Creating metrics dataframe
2023-08-01 21:27:43,493:INFO:Uploading results into container
2023-08-01 21:27:43,494:INFO:Uploading model into container now
2023-08-01 21:27:43,495:INFO:_master_model_container: 6
2023-08-01 21:27:43,495:INFO:_display_container: 3
2023-08-01 21:27:43,497:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:27:43,497:INFO:create_model() successfully completed......................................
2023-08-01 21:27:43,574:INFO:SubProcess create_model() end ==================================
2023-08-01 21:27:43,575:INFO:Creating metrics dataframe
2023-08-01 21:27:43,614:INFO:Initializing create_model()
2023-08-01 21:27:43,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:27:43,614:INFO:Checking exceptions
2023-08-01 21:27:43,617:INFO:Importing libraries
2023-08-01 21:27:43,617:INFO:Copying training dataset
2023-08-01 21:27:43,629:INFO:Defining folds
2023-08-01 21:27:43,629:INFO:Declaring metric variables
2023-08-01 21:27:43,630:INFO:Importing untrained model
2023-08-01 21:27:43,630:INFO:Declaring custom model
2023-08-01 21:27:43,632:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:27:43,634:INFO:Cross validation set to False
2023-08-01 21:27:43,635:INFO:Fitting Model
2023-08-01 21:27:45,764:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:27:45,765:INFO:create_model() successfully completed......................................
2023-08-01 21:27:45,867:INFO:_master_model_container: 6
2023-08-01 21:27:45,867:INFO:_display_container: 3
2023-08-01 21:27:45,870:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:27:45,870:INFO:compare_models() successfully completed......................................
2023-08-01 21:29:58,765:INFO:Initializing evaluate_model()
2023-08-01 21:29:58,765:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:29:58,782:INFO:Initializing plot_model()
2023-08-01 21:29:58,782:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:29:58,782:INFO:Checking exceptions
2023-08-01 21:29:58,785:INFO:Preloading libraries
2023-08-01 21:29:58,786:INFO:Copying training dataset
2023-08-01 21:29:58,786:INFO:Plot type: pipeline
2023-08-01 21:29:59,009:INFO:Visual Rendered Successfully
2023-08-01 21:29:59,088:INFO:plot_model() successfully completed......................................
2023-08-01 21:30:00,497:INFO:Initializing plot_model()
2023-08-01 21:30:00,497:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:30:00,498:INFO:Checking exceptions
2023-08-01 21:30:00,503:INFO:Preloading libraries
2023-08-01 21:30:00,503:INFO:Copying training dataset
2023-08-01 21:30:00,503:INFO:Plot type: confusion_matrix
2023-08-01 21:30:00,606:INFO:Fitting Model
2023-08-01 21:30:00,607:INFO:Scoring test/hold-out set
2023-08-01 21:30:00,765:INFO:Visual Rendered Successfully
2023-08-01 21:30:00,845:INFO:plot_model() successfully completed......................................
2023-08-01 21:30:31,544:INFO:Initializing plot_model()
2023-08-01 21:30:31,544:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:30:31,544:INFO:Checking exceptions
2023-08-01 21:30:31,548:INFO:Preloading libraries
2023-08-01 21:30:31,549:INFO:Copying training dataset
2023-08-01 21:30:31,549:INFO:Plot type: threshold
2023-08-01 21:30:31,625:INFO:Fitting Model
2023-08-01 21:30:49,719:INFO:Scoring test/hold-out set
2023-08-01 21:30:49,956:INFO:Visual Rendered Successfully
2023-08-01 21:30:50,021:INFO:plot_model() successfully completed......................................
2023-08-01 21:30:54,923:INFO:Initializing plot_model()
2023-08-01 21:30:54,923:INFO:plot_model(plot=boundary, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:30:54,923:INFO:Checking exceptions
2023-08-01 21:30:54,928:INFO:Preloading libraries
2023-08-01 21:30:54,928:INFO:Copying training dataset
2023-08-01 21:30:54,928:INFO:Plot type: boundary
2023-08-01 21:30:55,031:INFO:Fitting StandardScaler()
2023-08-01 21:30:55,041:INFO:Fitting PCA()
2023-08-01 21:30:55,145:INFO:Fitting Model
2023-08-01 21:30:56,414:INFO:Visual Rendered Successfully
2023-08-01 21:30:56,577:INFO:plot_model() successfully completed......................................
2023-08-01 21:31:16,201:INFO:Initializing plot_model()
2023-08-01 21:31:16,202:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:31:16,202:INFO:Checking exceptions
2023-08-01 21:31:16,206:INFO:Preloading libraries
2023-08-01 21:31:16,206:INFO:Copying training dataset
2023-08-01 21:31:16,206:INFO:Plot type: feature
2023-08-01 21:31:16,469:INFO:Visual Rendered Successfully
2023-08-01 21:31:16,536:INFO:plot_model() successfully completed......................................
2023-08-01 21:31:18,871:INFO:Initializing plot_model()
2023-08-01 21:31:18,872:INFO:plot_model(plot=class_report, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:31:18,872:INFO:Checking exceptions
2023-08-01 21:31:18,876:INFO:Preloading libraries
2023-08-01 21:31:18,877:INFO:Copying training dataset
2023-08-01 21:31:18,877:INFO:Plot type: class_report
2023-08-01 21:31:18,950:INFO:Fitting Model
2023-08-01 21:31:18,951:INFO:Scoring test/hold-out set
2023-08-01 21:31:19,222:INFO:Visual Rendered Successfully
2023-08-01 21:31:19,311:INFO:plot_model() successfully completed......................................
2023-08-01 21:31:36,959:INFO:Initializing plot_model()
2023-08-01 21:31:36,959:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:31:36,960:INFO:Checking exceptions
2023-08-01 21:31:36,963:INFO:Preloading libraries
2023-08-01 21:31:36,964:INFO:Copying training dataset
2023-08-01 21:31:36,964:INFO:Plot type: feature
2023-08-01 21:31:37,185:INFO:Visual Rendered Successfully
2023-08-01 21:31:37,248:INFO:plot_model() successfully completed......................................
2023-08-01 21:31:42,868:INFO:Initializing plot_model()
2023-08-01 21:31:42,869:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:31:42,869:INFO:Checking exceptions
2023-08-01 21:31:42,874:INFO:Preloading libraries
2023-08-01 21:31:42,874:INFO:Copying training dataset
2023-08-01 21:31:42,874:INFO:Plot type: parameter
2023-08-01 21:31:42,878:INFO:Visual Rendered Successfully
2023-08-01 21:31:42,937:INFO:plot_model() successfully completed......................................
2023-08-01 21:33:18,875:INFO:Initializing tune_model()
2023-08-01 21:33:18,875:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>)
2023-08-01 21:33:18,876:INFO:Checking exceptions
2023-08-01 21:33:18,916:INFO:Copying training dataset
2023-08-01 21:33:18,928:INFO:Checking base model
2023-08-01 21:33:18,928:INFO:Base model : Logistic Regression
2023-08-01 21:33:18,939:INFO:Declaring metric variables
2023-08-01 21:33:18,948:INFO:Defining Hyperparameters
2023-08-01 21:33:19,065:INFO:Tuning with n_jobs=-1
2023-08-01 21:33:19,066:INFO:Initializing RandomizedSearchCV
2023-08-01 21:36:10,345:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.831}
2023-08-01 21:36:10,347:INFO:Hyperparameter search completed
2023-08-01 21:36:10,347:INFO:SubProcess create_model() called ==================================
2023-08-01 21:36:10,351:INFO:Initializing create_model()
2023-08-01 21:36:10,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF05BAD90>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.831})
2023-08-01 21:36:10,352:INFO:Checking exceptions
2023-08-01 21:36:10,352:INFO:Importing libraries
2023-08-01 21:36:10,352:INFO:Copying training dataset
2023-08-01 21:36:10,368:INFO:Defining folds
2023-08-01 21:36:10,368:INFO:Declaring metric variables
2023-08-01 21:36:10,376:INFO:Importing untrained model
2023-08-01 21:36:10,376:INFO:Declaring custom model
2023-08-01 21:36:10,385:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:36:10,400:INFO:Starting cross validation
2023-08-01 21:36:10,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:36:25,432:INFO:Calculating mean and std
2023-08-01 21:36:25,434:INFO:Creating metrics dataframe
2023-08-01 21:36:25,444:INFO:Finalizing model
2023-08-01 21:36:28,163:INFO:Uploading results into container
2023-08-01 21:36:28,165:INFO:Uploading model into container now
2023-08-01 21:36:28,165:INFO:_master_model_container: 7
2023-08-01 21:36:28,166:INFO:_display_container: 4
2023-08-01 21:36:28,170:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:36:28,170:INFO:create_model() successfully completed......................................
2023-08-01 21:36:28,273:INFO:SubProcess create_model() end ==================================
2023-08-01 21:36:28,274:INFO:choose_better activated
2023-08-01 21:36:28,281:INFO:SubProcess create_model() called ==================================
2023-08-01 21:36:28,283:INFO:Initializing create_model()
2023-08-01 21:36:28,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:36:28,283:INFO:Checking exceptions
2023-08-01 21:36:28,286:INFO:Importing libraries
2023-08-01 21:36:28,286:INFO:Copying training dataset
2023-08-01 21:36:28,297:INFO:Defining folds
2023-08-01 21:36:28,297:INFO:Declaring metric variables
2023-08-01 21:36:28,297:INFO:Importing untrained model
2023-08-01 21:36:28,297:INFO:Declaring custom model
2023-08-01 21:36:28,299:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:36:28,299:INFO:Starting cross validation
2023-08-01 21:36:28,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:36:43,580:INFO:Calculating mean and std
2023-08-01 21:36:43,581:INFO:Creating metrics dataframe
2023-08-01 21:36:43,584:INFO:Finalizing model
2023-08-01 21:36:45,892:INFO:Uploading results into container
2023-08-01 21:36:45,894:INFO:Uploading model into container now
2023-08-01 21:36:45,895:INFO:_master_model_container: 8
2023-08-01 21:36:45,895:INFO:_display_container: 5
2023-08-01 21:36:45,897:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:36:45,897:INFO:create_model() successfully completed......................................
2023-08-01 21:36:45,974:INFO:SubProcess create_model() end ==================================
2023-08-01 21:36:45,978:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) result for MCC is 0.3821
2023-08-01 21:36:45,980:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) result for MCC is 0.3827
2023-08-01 21:36:45,981:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) is best model
2023-08-01 21:36:45,981:INFO:choose_better completed
2023-08-01 21:36:45,995:INFO:_master_model_container: 8
2023-08-01 21:36:45,996:INFO:_display_container: 4
2023-08-01 21:36:45,998:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:36:45,998:INFO:tune_model() successfully completed......................................
2023-08-01 21:37:34,027:INFO:Initializing tune_model()
2023-08-01 21:37:34,028:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=None, round=4, n_iter=15, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>)
2023-08-01 21:37:34,028:INFO:Checking exceptions
2023-08-01 21:37:34,062:INFO:Copying training dataset
2023-08-01 21:37:34,073:INFO:Checking base model
2023-08-01 21:37:34,073:INFO:Base model : Logistic Regression
2023-08-01 21:37:34,109:INFO:Declaring metric variables
2023-08-01 21:37:34,153:INFO:Defining Hyperparameters
2023-08-01 21:37:34,300:INFO:Tuning with n_jobs=-1
2023-08-01 21:37:34,300:INFO:Initializing RandomizedSearchCV
2023-08-01 21:41:37,600:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.831}
2023-08-01 21:41:37,602:INFO:Hyperparameter search completed
2023-08-01 21:41:37,602:INFO:SubProcess create_model() called ==================================
2023-08-01 21:41:37,606:INFO:Initializing create_model()
2023-08-01 21:41:37,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AABF775DC0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.831})
2023-08-01 21:41:37,606:INFO:Checking exceptions
2023-08-01 21:41:37,606:INFO:Importing libraries
2023-08-01 21:41:37,607:INFO:Copying training dataset
2023-08-01 21:41:37,621:INFO:Defining folds
2023-08-01 21:41:37,622:INFO:Declaring metric variables
2023-08-01 21:41:37,630:INFO:Importing untrained model
2023-08-01 21:41:37,630:INFO:Declaring custom model
2023-08-01 21:41:37,640:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:41:37,657:INFO:Starting cross validation
2023-08-01 21:41:37,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:41:53,471:INFO:Calculating mean and std
2023-08-01 21:41:53,473:INFO:Creating metrics dataframe
2023-08-01 21:41:53,482:INFO:Finalizing model
2023-08-01 21:41:55,970:INFO:Uploading results into container
2023-08-01 21:41:55,971:INFO:Uploading model into container now
2023-08-01 21:41:55,973:INFO:_master_model_container: 9
2023-08-01 21:41:55,973:INFO:_display_container: 5
2023-08-01 21:41:55,975:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:41:55,975:INFO:create_model() successfully completed......................................
2023-08-01 21:41:56,083:INFO:SubProcess create_model() end ==================================
2023-08-01 21:41:56,083:INFO:choose_better activated
2023-08-01 21:41:56,089:INFO:SubProcess create_model() called ==================================
2023-08-01 21:41:56,092:INFO:Initializing create_model()
2023-08-01 21:41:56,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:41:56,092:INFO:Checking exceptions
2023-08-01 21:41:56,096:INFO:Importing libraries
2023-08-01 21:41:56,096:INFO:Copying training dataset
2023-08-01 21:41:56,104:INFO:Defining folds
2023-08-01 21:41:56,105:INFO:Declaring metric variables
2023-08-01 21:41:56,105:INFO:Importing untrained model
2023-08-01 21:41:56,105:INFO:Declaring custom model
2023-08-01 21:41:56,108:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:41:56,108:INFO:Starting cross validation
2023-08-01 21:41:56,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:42:10,912:INFO:Calculating mean and std
2023-08-01 21:42:10,912:INFO:Creating metrics dataframe
2023-08-01 21:42:10,915:INFO:Finalizing model
2023-08-01 21:42:13,297:INFO:Uploading results into container
2023-08-01 21:42:13,298:INFO:Uploading model into container now
2023-08-01 21:42:13,299:INFO:_master_model_container: 10
2023-08-01 21:42:13,299:INFO:_display_container: 6
2023-08-01 21:42:13,300:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:42:13,300:INFO:create_model() successfully completed......................................
2023-08-01 21:42:13,379:INFO:SubProcess create_model() end ==================================
2023-08-01 21:42:13,381:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) result for MCC is 0.3821
2023-08-01 21:42:13,383:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) result for MCC is 0.3827
2023-08-01 21:42:13,385:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False) is best model
2023-08-01 21:42:13,385:INFO:choose_better completed
2023-08-01 21:42:13,398:INFO:_master_model_container: 10
2023-08-01 21:42:13,398:INFO:_display_container: 5
2023-08-01 21:42:13,399:INFO:CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:42:13,399:INFO:tune_model() successfully completed......................................
2023-08-01 21:42:57,892:INFO:Initializing evaluate_model()
2023-08-01 21:42:57,892:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, estimator=CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:42:57,921:INFO:Initializing plot_model()
2023-08-01 21:42:57,921:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:42:57,922:INFO:Checking exceptions
2023-08-01 21:42:57,930:INFO:Preloading libraries
2023-08-01 21:42:57,931:INFO:Copying training dataset
2023-08-01 21:42:57,931:INFO:Plot type: pipeline
2023-08-01 21:42:58,401:INFO:Visual Rendered Successfully
2023-08-01 21:42:58,597:INFO:plot_model() successfully completed......................................
2023-08-01 21:43:00,457:INFO:Initializing plot_model()
2023-08-01 21:43:00,457:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:43:00,457:INFO:Checking exceptions
2023-08-01 21:43:00,460:INFO:Preloading libraries
2023-08-01 21:43:00,461:INFO:Copying training dataset
2023-08-01 21:43:00,461:INFO:Plot type: confusion_matrix
2023-08-01 21:43:00,577:INFO:Fitting Model
2023-08-01 21:43:00,578:INFO:Scoring test/hold-out set
2023-08-01 21:43:00,794:INFO:Visual Rendered Successfully
2023-08-01 21:43:00,868:INFO:plot_model() successfully completed......................................
2023-08-01 21:43:04,323:INFO:Initializing plot_model()
2023-08-01 21:43:04,324:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:43:04,324:INFO:Checking exceptions
2023-08-01 21:43:04,327:INFO:Preloading libraries
2023-08-01 21:43:04,327:INFO:Copying training dataset
2023-08-01 21:43:04,327:INFO:Plot type: threshold
2023-08-01 21:43:04,423:INFO:Fitting Model
2023-08-01 21:43:26,368:INFO:Scoring test/hold-out set
2023-08-01 21:43:26,670:INFO:Visual Rendered Successfully
2023-08-01 21:43:26,761:INFO:plot_model() successfully completed......................................
2023-08-01 21:43:55,279:INFO:Initializing plot_model()
2023-08-01 21:43:55,279:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(C=0.831, class_weight={},
                                     classifier=LogisticRegression(C=0.831,
                                                                   class_weight={},
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AABF9E8A30>, system=True)
2023-08-01 21:43:55,279:INFO:Checking exceptions
2023-08-01 21:43:55,282:INFO:Preloading libraries
2023-08-01 21:43:55,283:INFO:Copying training dataset
2023-08-01 21:43:55,283:INFO:Plot type: feature
2023-08-01 21:43:55,642:INFO:Visual Rendered Successfully
2023-08-01 21:43:55,715:INFO:plot_model() successfully completed......................................
2023-08-01 21:46:39,459:INFO:PyCaret ClassificationExperiment
2023-08-01 21:46:39,459:INFO:Logging name: clf-default-name
2023-08-01 21:46:39,459:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 21:46:39,459:INFO:version 3.0.4
2023-08-01 21:46:39,460:INFO:Initializing setup()
2023-08-01 21:46:39,460:INFO:self.USI: bc93
2023-08-01 21:46:39,460:INFO:self._variable_keys: {'fix_imbalance', 'html_param', 'exp_id', 'fold_generator', 'log_plots_param', 'gpu_param', 'logging_param', 'fold_groups_param', 'USI', 'X_train', 'X', 'X_test', 'memory', 'target_param', 'y_train', 'n_jobs_param', 'fold_shuffle_param', 'is_multiclass', 'pipeline', 'exp_name_log', 'gpu_n_jobs_param', 'y_test', 'idx', 'seed', '_ml_usecase', 'y', 'data', '_available_plots'}
2023-08-01 21:46:39,460:INFO:Checking environment
2023-08-01 21:46:39,460:INFO:python_version: 3.9.13
2023-08-01 21:46:39,461:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 21:46:39,461:INFO:machine: AMD64
2023-08-01 21:46:39,461:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 21:46:39,466:INFO:Memory: svmem(total=17055166464, available=8239251456, percent=51.7, used=8815915008, free=8239251456)
2023-08-01 21:46:39,466:INFO:Physical Core: 4
2023-08-01 21:46:39,466:INFO:Logical Core: 8
2023-08-01 21:46:39,466:INFO:Checking libraries
2023-08-01 21:46:39,466:INFO:System:
2023-08-01 21:46:39,466:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 21:46:39,466:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 21:46:39,467:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 21:46:39,467:INFO:PyCaret required dependencies:
2023-08-01 21:46:39,467:INFO:                 pip: 22.0.4
2023-08-01 21:46:39,467:INFO:          setuptools: 58.1.0
2023-08-01 21:46:39,467:INFO:             pycaret: 3.0.4
2023-08-01 21:46:39,467:INFO:             IPython: 8.13.1
2023-08-01 21:46:39,467:INFO:          ipywidgets: 8.0.7
2023-08-01 21:46:39,467:INFO:                tqdm: 4.65.0
2023-08-01 21:46:39,467:INFO:               numpy: 1.23.0
2023-08-01 21:46:39,467:INFO:              pandas: 1.5.3
2023-08-01 21:46:39,467:INFO:              jinja2: 3.1.2
2023-08-01 21:46:39,468:INFO:               scipy: 1.10.1
2023-08-01 21:46:39,468:INFO:              joblib: 1.2.0
2023-08-01 21:46:39,468:INFO:             sklearn: 1.2.2
2023-08-01 21:46:39,468:INFO:                pyod: 1.1.0
2023-08-01 21:46:39,468:INFO:            imblearn: 0.11.0
2023-08-01 21:46:39,468:INFO:   category_encoders: 2.6.1
2023-08-01 21:46:39,468:INFO:            lightgbm: 3.3.5
2023-08-01 21:46:39,469:INFO:               numba: 0.57.1
2023-08-01 21:46:39,469:INFO:            requests: 2.31.0
2023-08-01 21:46:39,469:INFO:          matplotlib: 3.7.1
2023-08-01 21:46:39,469:INFO:          scikitplot: 0.3.7
2023-08-01 21:46:39,469:INFO:         yellowbrick: 1.5
2023-08-01 21:46:39,469:INFO:              plotly: 5.15.0
2023-08-01 21:46:39,469:INFO:    plotly-resampler: Not installed
2023-08-01 21:46:39,469:INFO:             kaleido: 0.2.1
2023-08-01 21:46:39,470:INFO:           schemdraw: 0.15
2023-08-01 21:46:39,470:INFO:         statsmodels: 0.14.0
2023-08-01 21:46:39,470:INFO:              sktime: 0.20.0
2023-08-01 21:46:39,470:INFO:               tbats: 1.1.3
2023-08-01 21:46:39,470:INFO:            pmdarima: 2.0.3
2023-08-01 21:46:39,470:INFO:              psutil: 5.9.5
2023-08-01 21:46:39,470:INFO:          markupsafe: 2.1.3
2023-08-01 21:46:39,470:INFO:             pickle5: Not installed
2023-08-01 21:46:39,470:INFO:         cloudpickle: 2.2.1
2023-08-01 21:46:39,470:INFO:         deprecation: 2.1.0
2023-08-01 21:46:39,470:INFO:              xxhash: 3.2.0
2023-08-01 21:46:39,471:INFO:           wurlitzer: Not installed
2023-08-01 21:46:39,471:INFO:PyCaret optional dependencies:
2023-08-01 21:46:39,471:INFO:                shap: Not installed
2023-08-01 21:46:39,471:INFO:           interpret: Not installed
2023-08-01 21:46:39,471:INFO:                umap: Not installed
2023-08-01 21:46:39,471:INFO:    pandas_profiling: 4.3.1
2023-08-01 21:46:39,471:INFO:  explainerdashboard: Not installed
2023-08-01 21:46:39,471:INFO:             autoviz: Not installed
2023-08-01 21:46:39,471:INFO:           fairlearn: Not installed
2023-08-01 21:46:39,472:INFO:          deepchecks: Not installed
2023-08-01 21:46:39,472:INFO:             xgboost: Not installed
2023-08-01 21:46:39,472:INFO:            catboost: Not installed
2023-08-01 21:46:39,472:INFO:              kmodes: Not installed
2023-08-01 21:46:39,472:INFO:             mlxtend: 0.22.0
2023-08-01 21:46:39,472:INFO:       statsforecast: Not installed
2023-08-01 21:46:39,472:INFO:        tune_sklearn: Not installed
2023-08-01 21:46:39,472:INFO:                 ray: Not installed
2023-08-01 21:46:39,473:INFO:            hyperopt: Not installed
2023-08-01 21:46:39,473:INFO:              optuna: Not installed
2023-08-01 21:46:39,473:INFO:               skopt: Not installed
2023-08-01 21:46:39,473:INFO:              mlflow: Not installed
2023-08-01 21:46:39,473:INFO:              gradio: Not installed
2023-08-01 21:46:39,473:INFO:             fastapi: Not installed
2023-08-01 21:46:39,473:INFO:             uvicorn: Not installed
2023-08-01 21:46:39,473:INFO:              m2cgen: Not installed
2023-08-01 21:46:39,473:INFO:           evidently: Not installed
2023-08-01 21:46:39,473:INFO:               fugue: Not installed
2023-08-01 21:46:39,473:INFO:           streamlit: Not installed
2023-08-01 21:46:39,473:INFO:             prophet: Not installed
2023-08-01 21:46:39,473:INFO:None
2023-08-01 21:46:39,474:INFO:Set up data.
2023-08-01 21:46:39,490:INFO:Set up train/test split.
2023-08-01 21:46:39,501:INFO:Set up index.
2023-08-01 21:46:39,501:INFO:Set up folding strategy.
2023-08-01 21:46:39,501:INFO:Assigning column types.
2023-08-01 21:46:39,508:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 21:46:39,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,733:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,778:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,779:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 21:46:39,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,928:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 21:46:39,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:39,964:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 21:46:40,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:40,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:40,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:40,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:40,154:INFO:Preparing preprocessing pipeline...
2023-08-01 21:46:40,156:INFO:Set up simple imputation.
2023-08-01 21:46:40,159:INFO:Set up encoding of categorical features.
2023-08-01 21:46:40,159:INFO:Set up removing multicollinearity.
2023-08-01 21:46:40,344:INFO:Finished creating preprocessing pipeline.
2023-08-01 21:46:40,352:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 21:46:40,353:INFO:Creating final display dataframe.
2023-08-01 21:46:40,725:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 24)
5   Transformed train set shape        (6508, 24)
6    Transformed test set shape        (1628, 24)
7               Ignore features                 3
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              bc93
2023-08-01 21:46:40,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:40,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:41,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:41,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 21:46:41,014:INFO:setup() successfully completed in 3.27s...............
2023-08-01 21:46:51,761:INFO:Initializing compare_models()
2023-08-01 21:46:51,761:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:46:51,762:INFO:Checking exceptions
2023-08-01 21:46:51,771:INFO:Preparing display monitor
2023-08-01 21:46:51,828:INFO:Initializing Logistic Regression
2023-08-01 21:46:51,829:INFO:Total runtime is 1.6701221466064452e-05 minutes
2023-08-01 21:46:51,838:INFO:SubProcess create_model() called ==================================
2023-08-01 21:46:51,839:INFO:Initializing create_model()
2023-08-01 21:46:51,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0997BE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:46:51,840:INFO:Checking exceptions
2023-08-01 21:46:51,840:INFO:Importing libraries
2023-08-01 21:46:51,840:INFO:Copying training dataset
2023-08-01 21:46:51,850:INFO:Defining folds
2023-08-01 21:46:51,851:INFO:Declaring metric variables
2023-08-01 21:46:51,860:INFO:Importing untrained model
2023-08-01 21:46:51,868:INFO:Logistic Regression Imported successfully
2023-08-01 21:46:51,890:INFO:Starting cross validation
2023-08-01 21:46:51,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:47:08,919:INFO:Calculating mean and std
2023-08-01 21:47:08,923:INFO:Creating metrics dataframe
2023-08-01 21:47:11,023:INFO:Uploading results into container
2023-08-01 21:47:11,024:INFO:Uploading model into container now
2023-08-01 21:47:11,025:INFO:_master_model_container: 1
2023-08-01 21:47:11,026:INFO:_display_container: 2
2023-08-01 21:47:11,026:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 21:47:11,027:INFO:create_model() successfully completed......................................
2023-08-01 21:47:11,117:INFO:SubProcess create_model() end ==================================
2023-08-01 21:47:11,117:INFO:Creating metrics dataframe
2023-08-01 21:47:11,132:INFO:Initializing K Neighbors Classifier
2023-08-01 21:47:11,133:INFO:Total runtime is 0.3217499375343323 minutes
2023-08-01 21:47:11,138:INFO:SubProcess create_model() called ==================================
2023-08-01 21:47:11,139:INFO:Initializing create_model()
2023-08-01 21:47:11,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0997BE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:47:11,139:INFO:Checking exceptions
2023-08-01 21:47:11,139:INFO:Importing libraries
2023-08-01 21:47:11,139:INFO:Copying training dataset
2023-08-01 21:47:11,151:INFO:Defining folds
2023-08-01 21:47:11,151:INFO:Declaring metric variables
2023-08-01 21:47:11,159:INFO:Importing untrained model
2023-08-01 21:47:11,165:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:47:11,181:INFO:Starting cross validation
2023-08-01 21:47:11,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:47:27,341:INFO:Calculating mean and std
2023-08-01 21:47:27,343:INFO:Creating metrics dataframe
2023-08-01 21:47:29,455:INFO:Uploading results into container
2023-08-01 21:47:29,457:INFO:Uploading model into container now
2023-08-01 21:47:29,459:INFO:_master_model_container: 2
2023-08-01 21:47:29,459:INFO:_display_container: 2
2023-08-01 21:47:29,460:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 21:47:29,460:INFO:create_model() successfully completed......................................
2023-08-01 21:47:29,545:INFO:SubProcess create_model() end ==================================
2023-08-01 21:47:29,545:INFO:Creating metrics dataframe
2023-08-01 21:47:29,561:INFO:Initializing Decision Tree Classifier
2023-08-01 21:47:29,561:INFO:Total runtime is 0.6288832823435466 minutes
2023-08-01 21:47:29,567:INFO:SubProcess create_model() called ==================================
2023-08-01 21:47:29,568:INFO:Initializing create_model()
2023-08-01 21:47:29,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0997BE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:47:29,568:INFO:Checking exceptions
2023-08-01 21:47:29,568:INFO:Importing libraries
2023-08-01 21:47:29,569:INFO:Copying training dataset
2023-08-01 21:47:29,581:INFO:Defining folds
2023-08-01 21:47:29,582:INFO:Declaring metric variables
2023-08-01 21:47:29,588:INFO:Importing untrained model
2023-08-01 21:47:29,595:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:47:29,609:INFO:Starting cross validation
2023-08-01 21:47:29,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:47:45,258:INFO:Calculating mean and std
2023-08-01 21:47:45,261:INFO:Creating metrics dataframe
2023-08-01 21:47:47,514:INFO:Uploading results into container
2023-08-01 21:47:47,515:INFO:Uploading model into container now
2023-08-01 21:47:47,516:INFO:_master_model_container: 3
2023-08-01 21:47:47,516:INFO:_display_container: 2
2023-08-01 21:47:47,517:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:47:47,517:INFO:create_model() successfully completed......................................
2023-08-01 21:47:47,598:INFO:SubProcess create_model() end ==================================
2023-08-01 21:47:47,598:INFO:Creating metrics dataframe
2023-08-01 21:47:47,638:INFO:Initializing create_model()
2023-08-01 21:47:47,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:47:47,638:INFO:Checking exceptions
2023-08-01 21:47:47,643:INFO:Importing libraries
2023-08-01 21:47:47,643:INFO:Copying training dataset
2023-08-01 21:47:47,656:INFO:Defining folds
2023-08-01 21:47:47,657:INFO:Declaring metric variables
2023-08-01 21:47:47,657:INFO:Importing untrained model
2023-08-01 21:47:47,657:INFO:Declaring custom model
2023-08-01 21:47:47,659:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:47:47,662:INFO:Cross validation set to False
2023-08-01 21:47:47,662:INFO:Fitting Model
2023-08-01 21:47:49,240:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:47:49,240:INFO:create_model() successfully completed......................................
2023-08-01 21:47:49,343:INFO:_master_model_container: 3
2023-08-01 21:47:49,343:INFO:_display_container: 2
2023-08-01 21:47:49,344:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 21:47:49,344:INFO:compare_models() successfully completed......................................
2023-08-01 21:47:54,412:INFO:Initializing evaluate_model()
2023-08-01 21:47:54,413:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:47:54,443:INFO:Initializing plot_model()
2023-08-01 21:47:54,443:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:47:54,443:INFO:Checking exceptions
2023-08-01 21:47:54,449:INFO:Preloading libraries
2023-08-01 21:47:54,450:INFO:Copying training dataset
2023-08-01 21:47:54,450:INFO:Plot type: pipeline
2023-08-01 21:47:54,762:INFO:Visual Rendered Successfully
2023-08-01 21:47:54,872:INFO:plot_model() successfully completed......................................
2023-08-01 21:47:56,701:INFO:Initializing plot_model()
2023-08-01 21:47:56,702:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:47:56,702:INFO:Checking exceptions
2023-08-01 21:47:56,707:INFO:Preloading libraries
2023-08-01 21:47:56,707:INFO:Copying training dataset
2023-08-01 21:47:56,707:INFO:Plot type: confusion_matrix
2023-08-01 21:47:57,295:INFO:Fitting Model
2023-08-01 21:47:57,295:INFO:Scoring test/hold-out set
2023-08-01 21:47:57,529:INFO:Visual Rendered Successfully
2023-08-01 21:47:57,627:INFO:plot_model() successfully completed......................................
2023-08-01 21:48:15,497:INFO:Initializing plot_model()
2023-08-01 21:48:15,498:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:48:15,498:INFO:Checking exceptions
2023-08-01 21:48:15,503:INFO:Preloading libraries
2023-08-01 21:48:15,503:INFO:Copying training dataset
2023-08-01 21:48:15,503:INFO:Plot type: threshold
2023-08-01 21:48:15,744:INFO:Fitting Model
2023-08-01 21:48:16,604:INFO:Scoring test/hold-out set
2023-08-01 21:48:16,901:INFO:Visual Rendered Successfully
2023-08-01 21:48:17,060:INFO:plot_model() successfully completed......................................
2023-08-01 21:48:28,471:INFO:Initializing plot_model()
2023-08-01 21:48:28,472:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:48:28,472:INFO:Checking exceptions
2023-08-01 21:48:28,479:INFO:Preloading libraries
2023-08-01 21:48:28,480:INFO:Copying training dataset
2023-08-01 21:48:28,480:INFO:Plot type: feature
2023-08-01 21:48:28,481:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 21:48:28,964:INFO:Visual Rendered Successfully
2023-08-01 21:48:29,053:INFO:plot_model() successfully completed......................................
2023-08-01 21:48:47,795:INFO:Initializing plot_model()
2023-08-01 21:48:47,795:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:48:47,795:INFO:Checking exceptions
2023-08-01 21:48:47,800:INFO:Preloading libraries
2023-08-01 21:48:47,801:INFO:Copying training dataset
2023-08-01 21:48:47,801:INFO:Plot type: feature_all
2023-08-01 21:48:47,822:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 21:48:48,253:INFO:Visual Rendered Successfully
2023-08-01 21:48:48,323:INFO:plot_model() successfully completed......................................
2023-08-01 21:49:06,027:INFO:Initializing compare_models()
2023-08-01 21:49:06,028:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, include=['lr', 'knn', 'dt'], fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=0.26, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, 'include': ['lr', 'knn', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': 0.26, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 21:49:06,028:INFO:Checking exceptions
2023-08-01 21:49:06,032:INFO:Preparing display monitor
2023-08-01 21:49:06,065:INFO:Initializing Logistic Regression
2023-08-01 21:49:06,066:INFO:Total runtime is 1.6868114471435547e-05 minutes
2023-08-01 21:49:06,071:INFO:SubProcess create_model() called ==================================
2023-08-01 21:49:06,072:INFO:Initializing create_model()
2023-08-01 21:49:06,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0DA0EB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:49:06,072:INFO:Checking exceptions
2023-08-01 21:49:06,072:INFO:Importing libraries
2023-08-01 21:49:06,072:INFO:Copying training dataset
2023-08-01 21:49:06,083:INFO:Defining folds
2023-08-01 21:49:06,084:INFO:Declaring metric variables
2023-08-01 21:49:06,092:INFO:Importing untrained model
2023-08-01 21:49:06,101:INFO:Logistic Regression Imported successfully
2023-08-01 21:49:06,116:INFO:Starting cross validation
2023-08-01 21:49:06,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:49:21,767:INFO:Calculating mean and std
2023-08-01 21:49:21,770:INFO:Creating metrics dataframe
2023-08-01 21:49:23,791:INFO:Uploading results into container
2023-08-01 21:49:23,792:INFO:Uploading model into container now
2023-08-01 21:49:23,794:INFO:_master_model_container: 4
2023-08-01 21:49:23,794:INFO:_display_container: 3
2023-08-01 21:49:23,797:INFO:CustomProbabilityThresholdClassifier(C=1.0, class_weight=None,
                                     classifier=LogisticRegression(C=1.0,
                                                                   class_weight=None,
                                                                   dual=False,
                                                                   fit_intercept=True,
                                                                   intercept_scaling=1,
                                                                   l1_ratio=None,
                                                                   max_iter=1000,
                                                                   multi_class='auto',
                                                                   n_jobs=None,
                                                                   penalty='l2',
                                                                   random_state=2020,
                                                                   solver='lbfgs',
                                                                   tol=0.0001,
                                                                   verbose=0,
                                                                   warm_start=False),
                                     dual=False, fit_intercept=True,
                                     intercept_scaling=1, l1_ratio=None,
                                     max_iter=1000, multi_class='auto',
                                     n_jobs=None, penalty='l2',
                                     probability_threshold=0.26,
                                     random_state=2020, solver='lbfgs',
                                     tol=0.0001, verbose=0, warm_start=False)
2023-08-01 21:49:23,798:INFO:create_model() successfully completed......................................
2023-08-01 21:49:23,878:INFO:SubProcess create_model() end ==================================
2023-08-01 21:49:23,878:INFO:Creating metrics dataframe
2023-08-01 21:49:23,889:INFO:Initializing K Neighbors Classifier
2023-08-01 21:49:23,889:INFO:Total runtime is 0.29706663290659585 minutes
2023-08-01 21:49:23,895:INFO:SubProcess create_model() called ==================================
2023-08-01 21:49:23,896:INFO:Initializing create_model()
2023-08-01 21:49:23,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0DA0EB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:49:23,896:INFO:Checking exceptions
2023-08-01 21:49:23,896:INFO:Importing libraries
2023-08-01 21:49:23,897:INFO:Copying training dataset
2023-08-01 21:49:23,908:INFO:Defining folds
2023-08-01 21:49:23,908:INFO:Declaring metric variables
2023-08-01 21:49:23,915:INFO:Importing untrained model
2023-08-01 21:49:23,921:INFO:K Neighbors Classifier Imported successfully
2023-08-01 21:49:23,938:INFO:Starting cross validation
2023-08-01 21:49:23,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:49:38,118:INFO:Calculating mean and std
2023-08-01 21:49:38,121:INFO:Creating metrics dataframe
2023-08-01 21:49:40,760:INFO:Uploading results into container
2023-08-01 21:49:40,761:INFO:Uploading model into container now
2023-08-01 21:49:40,763:INFO:_master_model_container: 5
2023-08-01 21:49:40,763:INFO:_display_container: 3
2023-08-01 21:49:40,764:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.26,
                                     weights='uniform')
2023-08-01 21:49:40,765:INFO:create_model() successfully completed......................................
2023-08-01 21:49:40,844:INFO:SubProcess create_model() end ==================================
2023-08-01 21:49:40,845:INFO:Creating metrics dataframe
2023-08-01 21:49:40,862:INFO:Initializing Decision Tree Classifier
2023-08-01 21:49:40,862:INFO:Total runtime is 0.5799500306447347 minutes
2023-08-01 21:49:40,870:INFO:SubProcess create_model() called ==================================
2023-08-01 21:49:40,871:INFO:Initializing create_model()
2023-08-01 21:49:40,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0DA0EB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:49:40,872:INFO:Checking exceptions
2023-08-01 21:49:40,872:INFO:Importing libraries
2023-08-01 21:49:40,872:INFO:Copying training dataset
2023-08-01 21:49:40,885:INFO:Defining folds
2023-08-01 21:49:40,885:INFO:Declaring metric variables
2023-08-01 21:49:40,895:INFO:Importing untrained model
2023-08-01 21:49:40,904:INFO:Decision Tree Classifier Imported successfully
2023-08-01 21:49:40,925:INFO:Starting cross validation
2023-08-01 21:49:40,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:50:00,188:INFO:Calculating mean and std
2023-08-01 21:50:00,189:INFO:Creating metrics dataframe
2023-08-01 21:50:02,421:INFO:Uploading results into container
2023-08-01 21:50:02,423:INFO:Uploading model into container now
2023-08-01 21:50:02,424:INFO:_master_model_container: 6
2023-08-01 21:50:02,424:INFO:_display_container: 3
2023-08-01 21:50:02,426:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:50:02,426:INFO:create_model() successfully completed......................................
2023-08-01 21:50:02,516:INFO:SubProcess create_model() end ==================================
2023-08-01 21:50:02,517:INFO:Creating metrics dataframe
2023-08-01 21:50:02,556:INFO:Initializing create_model()
2023-08-01 21:50:02,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=0.26, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:50:02,556:INFO:Checking exceptions
2023-08-01 21:50:02,559:INFO:Importing libraries
2023-08-01 21:50:02,559:INFO:Copying training dataset
2023-08-01 21:50:02,572:INFO:Defining folds
2023-08-01 21:50:02,573:INFO:Declaring metric variables
2023-08-01 21:50:02,573:INFO:Importing untrained model
2023-08-01 21:50:02,573:INFO:Declaring custom model
2023-08-01 21:50:02,576:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:50:02,580:INFO:Cross validation set to False
2023-08-01 21:50:02,580:INFO:Fitting Model
2023-08-01 21:50:04,312:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:50:04,312:INFO:create_model() successfully completed......................................
2023-08-01 21:50:04,417:INFO:_master_model_container: 6
2023-08-01 21:50:04,417:INFO:_display_container: 3
2023-08-01 21:50:04,418:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:50:04,419:INFO:compare_models() successfully completed......................................
2023-08-01 21:50:11,530:INFO:Initializing evaluate_model()
2023-08-01 21:50:11,531:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 21:50:11,549:INFO:Initializing plot_model()
2023-08-01 21:50:11,549:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:50:11,550:INFO:Checking exceptions
2023-08-01 21:50:11,553:INFO:Preloading libraries
2023-08-01 21:50:11,554:INFO:Copying training dataset
2023-08-01 21:50:11,554:INFO:Plot type: pipeline
2023-08-01 21:50:11,839:INFO:Visual Rendered Successfully
2023-08-01 21:50:11,968:INFO:plot_model() successfully completed......................................
2023-08-01 21:50:16,507:INFO:Initializing plot_model()
2023-08-01 21:50:16,507:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:50:16,507:INFO:Checking exceptions
2023-08-01 21:50:16,511:INFO:Preloading libraries
2023-08-01 21:50:16,511:INFO:Copying training dataset
2023-08-01 21:50:16,511:INFO:Plot type: confusion_matrix
2023-08-01 21:50:16,693:INFO:Fitting Model
2023-08-01 21:50:16,693:INFO:Scoring test/hold-out set
2023-08-01 21:50:16,915:INFO:Visual Rendered Successfully
2023-08-01 21:50:17,006:INFO:plot_model() successfully completed......................................
2023-08-01 21:50:29,416:INFO:Initializing plot_model()
2023-08-01 21:50:29,416:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:50:29,416:INFO:Checking exceptions
2023-08-01 21:50:29,420:INFO:Preloading libraries
2023-08-01 21:50:29,421:INFO:Copying training dataset
2023-08-01 21:50:29,421:INFO:Plot type: threshold
2023-08-01 21:50:29,615:INFO:Fitting Model
2023-08-01 21:50:30,595:INFO:Scoring test/hold-out set
2023-08-01 21:50:30,904:INFO:Visual Rendered Successfully
2023-08-01 21:50:30,974:INFO:plot_model() successfully completed......................................
2023-08-01 21:50:33,711:INFO:Initializing plot_model()
2023-08-01 21:50:33,711:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:50:33,711:INFO:Checking exceptions
2023-08-01 21:50:33,715:INFO:Preloading libraries
2023-08-01 21:50:33,716:INFO:Copying training dataset
2023-08-01 21:50:33,716:INFO:Plot type: feature
2023-08-01 21:50:33,716:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 21:50:34,033:INFO:Visual Rendered Successfully
2023-08-01 21:50:34,124:INFO:plot_model() successfully completed......................................
2023-08-01 21:50:44,839:INFO:Initializing plot_model()
2023-08-01 21:50:44,840:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 21:50:44,840:INFO:Checking exceptions
2023-08-01 21:50:44,844:INFO:Preloading libraries
2023-08-01 21:50:44,844:INFO:Copying training dataset
2023-08-01 21:50:44,844:INFO:Plot type: parameter
2023-08-01 21:50:44,849:INFO:Visual Rendered Successfully
2023-08-01 21:50:44,921:INFO:plot_model() successfully completed......................................
2023-08-01 21:53:59,356:INFO:Initializing tune_model()
2023-08-01 21:53:59,356:INFO:tune_model(estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), fold=None, round=4, n_iter=15, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>)
2023-08-01 21:53:59,357:INFO:Checking exceptions
2023-08-01 21:53:59,386:INFO:Copying training dataset
2023-08-01 21:53:59,394:INFO:Checking base model
2023-08-01 21:53:59,394:INFO:Base model : Decision Tree Classifier
2023-08-01 21:53:59,399:INFO:Declaring metric variables
2023-08-01 21:53:59,405:INFO:Defining Hyperparameters
2023-08-01 21:53:59,519:INFO:Tuning with n_jobs=-1
2023-08-01 21:53:59,520:INFO:Initializing RandomizedSearchCV
2023-08-01 21:58:58,257:INFO:best_params: {'actual_estimator__min_samples_split': 7, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'gini'}
2023-08-01 21:58:58,259:INFO:Hyperparameter search completed
2023-08-01 21:58:58,259:INFO:SubProcess create_model() called ==================================
2023-08-01 21:58:58,261:INFO:Initializing create_model()
2023-08-01 21:58:58,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF10A5B50>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 7, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0002, 'max_features': 1.0, 'max_depth': 9, 'criterion': 'gini'})
2023-08-01 21:58:58,262:INFO:Checking exceptions
2023-08-01 21:58:58,262:INFO:Importing libraries
2023-08-01 21:58:58,262:INFO:Copying training dataset
2023-08-01 21:58:58,278:INFO:Defining folds
2023-08-01 21:58:58,278:INFO:Declaring metric variables
2023-08-01 21:58:58,285:INFO:Importing untrained model
2023-08-01 21:58:58,286:INFO:Declaring custom model
2023-08-01 21:58:58,296:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:58:58,313:INFO:Starting cross validation
2023-08-01 21:58:58,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:59:15,412:INFO:Calculating mean and std
2023-08-01 21:59:15,414:INFO:Creating metrics dataframe
2023-08-01 21:59:15,425:INFO:Finalizing model
2023-08-01 21:59:18,298:INFO:Uploading results into container
2023-08-01 21:59:18,300:INFO:Uploading model into container now
2023-08-01 21:59:18,301:INFO:_master_model_container: 7
2023-08-01 21:59:18,301:INFO:_display_container: 4
2023-08-01 21:59:18,304:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=9,
                                                                       max_features=1.0,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0002,
                                                                       min_samples_leaf=4,
                                                                       min_samples_split=7,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=9,
                                     max_features=1.0, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0002,
                                     min_samples_leaf=4, min_samples_split=7,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:59:18,305:INFO:create_model() successfully completed......................................
2023-08-01 21:59:18,436:INFO:SubProcess create_model() end ==================================
2023-08-01 21:59:18,437:INFO:choose_better activated
2023-08-01 21:59:18,445:INFO:SubProcess create_model() called ==================================
2023-08-01 21:59:18,448:INFO:Initializing create_model()
2023-08-01 21:59:18,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 21:59:18,449:INFO:Checking exceptions
2023-08-01 21:59:18,452:INFO:Importing libraries
2023-08-01 21:59:18,452:INFO:Copying training dataset
2023-08-01 21:59:18,465:INFO:Defining folds
2023-08-01 21:59:18,466:INFO:Declaring metric variables
2023-08-01 21:59:18,466:INFO:Importing untrained model
2023-08-01 21:59:18,466:INFO:Declaring custom model
2023-08-01 21:59:18,469:INFO:CustomProbabilityThresholdClassifier Imported successfully
2023-08-01 21:59:18,470:INFO:Starting cross validation
2023-08-01 21:59:18,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 21:59:37,141:INFO:Calculating mean and std
2023-08-01 21:59:37,142:INFO:Creating metrics dataframe
2023-08-01 21:59:37,146:INFO:Finalizing model
2023-08-01 21:59:40,038:INFO:Uploading results into container
2023-08-01 21:59:40,039:INFO:Uploading model into container now
2023-08-01 21:59:40,040:INFO:_master_model_container: 8
2023-08-01 21:59:40,040:INFO:_display_container: 5
2023-08-01 21:59:40,042:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:59:40,042:INFO:create_model() successfully completed......................................
2023-08-01 21:59:40,135:INFO:SubProcess create_model() end ==================================
2023-08-01 21:59:40,138:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best') result for MCC is 0.331
2023-08-01 21:59:40,141:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=9,
                                                                       max_features=1.0,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0002,
                                                                       min_samples_leaf=4,
                                                                       min_samples_split=7,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=9,
                                     max_features=1.0, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0002,
                                     min_samples_leaf=4, min_samples_split=7,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best') result for MCC is 0.3337
2023-08-01 21:59:40,143:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=9,
                                                                       max_features=1.0,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0002,
                                                                       min_samples_leaf=4,
                                                                       min_samples_split=7,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=9,
                                     max_features=1.0, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0002,
                                     min_samples_leaf=4, min_samples_split=7,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best') is best model
2023-08-01 21:59:40,143:INFO:choose_better completed
2023-08-01 21:59:40,162:INFO:_master_model_container: 8
2023-08-01 21:59:40,162:INFO:_display_container: 4
2023-08-01 21:59:40,164:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=9,
                                                                       max_features=1.0,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0002,
                                                                       min_samples_leaf=4,
                                                                       min_samples_split=7,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=9,
                                     max_features=1.0, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0002,
                                     min_samples_leaf=4, min_samples_split=7,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best')
2023-08-01 21:59:40,164:INFO:tune_model() successfully completed......................................
2023-08-01 22:02:37,033:INFO:Initializing plot_model()
2023-08-01 22:02:37,033:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=CustomProbabilityThresholdClassifier(ccp_alpha=0.0, class_weight=None,
                                     classifier=DecisionTreeClassifier(ccp_alpha=0.0,
                                                                       class_weight=None,
                                                                       criterion='gini',
                                                                       max_depth=None,
                                                                       max_features=None,
                                                                       max_leaf_nodes=None,
                                                                       min_impurity_decrease=0.0,
                                                                       min_samples_leaf=1,
                                                                       min_samples_split=2,
                                                                       min_weight_fraction_leaf=0.0,
                                                                       random_state=2020,
                                                                       splitter='best'),
                                     criterion='gini', max_depth=None,
                                     max_features=None, max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     probability_threshold=0.26,
                                     random_state=2020, splitter='best'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BD6F10>, system=True)
2023-08-01 22:02:37,033:INFO:Checking exceptions
2023-08-01 22:02:37,035:INFO:Preloading libraries
2023-08-01 22:02:37,036:INFO:Copying training dataset
2023-08-01 22:02:37,036:INFO:Plot type: feature
2023-08-01 22:02:37,036:WARNING:No coef_ found. Trying feature_importances_
2023-08-01 22:02:37,315:INFO:Visual Rendered Successfully
2023-08-01 22:02:37,393:INFO:plot_model() successfully completed......................................
2023-08-01 22:02:48,308:INFO:PyCaret ClassificationExperiment
2023-08-01 22:02:48,308:INFO:Logging name: clf-default-name
2023-08-01 22:02:48,308:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 22:02:48,308:INFO:version 3.0.4
2023-08-01 22:02:48,308:INFO:Initializing setup()
2023-08-01 22:02:48,308:INFO:self.USI: 712f
2023-08-01 22:02:48,308:INFO:self._variable_keys: {'fix_imbalance', 'html_param', 'exp_id', 'fold_generator', 'log_plots_param', 'gpu_param', 'logging_param', 'fold_groups_param', 'USI', 'X_train', 'X', 'X_test', 'memory', 'target_param', 'y_train', 'n_jobs_param', 'fold_shuffle_param', 'is_multiclass', 'pipeline', 'exp_name_log', 'gpu_n_jobs_param', 'y_test', 'idx', 'seed', '_ml_usecase', 'y', 'data', '_available_plots'}
2023-08-01 22:02:48,308:INFO:Checking environment
2023-08-01 22:02:48,308:INFO:python_version: 3.9.13
2023-08-01 22:02:48,308:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 22:02:48,308:INFO:machine: AMD64
2023-08-01 22:02:48,309:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 22:02:48,313:INFO:Memory: svmem(total=17055166464, available=8371482624, percent=50.9, used=8683683840, free=8371482624)
2023-08-01 22:02:48,313:INFO:Physical Core: 4
2023-08-01 22:02:48,313:INFO:Logical Core: 8
2023-08-01 22:02:48,313:INFO:Checking libraries
2023-08-01 22:02:48,313:INFO:System:
2023-08-01 22:02:48,313:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 22:02:48,313:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 22:02:48,313:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 22:02:48,314:INFO:PyCaret required dependencies:
2023-08-01 22:02:48,314:INFO:                 pip: 22.0.4
2023-08-01 22:02:48,314:INFO:          setuptools: 58.1.0
2023-08-01 22:02:48,314:INFO:             pycaret: 3.0.4
2023-08-01 22:02:48,314:INFO:             IPython: 8.13.1
2023-08-01 22:02:48,314:INFO:          ipywidgets: 8.0.7
2023-08-01 22:02:48,314:INFO:                tqdm: 4.65.0
2023-08-01 22:02:48,314:INFO:               numpy: 1.23.0
2023-08-01 22:02:48,314:INFO:              pandas: 1.5.3
2023-08-01 22:02:48,314:INFO:              jinja2: 3.1.2
2023-08-01 22:02:48,314:INFO:               scipy: 1.10.1
2023-08-01 22:02:48,314:INFO:              joblib: 1.2.0
2023-08-01 22:02:48,314:INFO:             sklearn: 1.2.2
2023-08-01 22:02:48,314:INFO:                pyod: 1.1.0
2023-08-01 22:02:48,314:INFO:            imblearn: 0.11.0
2023-08-01 22:02:48,314:INFO:   category_encoders: 2.6.1
2023-08-01 22:02:48,315:INFO:            lightgbm: 3.3.5
2023-08-01 22:02:48,315:INFO:               numba: 0.57.1
2023-08-01 22:02:48,315:INFO:            requests: 2.31.0
2023-08-01 22:02:48,315:INFO:          matplotlib: 3.7.1
2023-08-01 22:02:48,315:INFO:          scikitplot: 0.3.7
2023-08-01 22:02:48,315:INFO:         yellowbrick: 1.5
2023-08-01 22:02:48,315:INFO:              plotly: 5.15.0
2023-08-01 22:02:48,315:INFO:    plotly-resampler: Not installed
2023-08-01 22:02:48,315:INFO:             kaleido: 0.2.1
2023-08-01 22:02:48,315:INFO:           schemdraw: 0.15
2023-08-01 22:02:48,315:INFO:         statsmodels: 0.14.0
2023-08-01 22:02:48,315:INFO:              sktime: 0.20.0
2023-08-01 22:02:48,315:INFO:               tbats: 1.1.3
2023-08-01 22:02:48,315:INFO:            pmdarima: 2.0.3
2023-08-01 22:02:48,315:INFO:              psutil: 5.9.5
2023-08-01 22:02:48,315:INFO:          markupsafe: 2.1.3
2023-08-01 22:02:48,315:INFO:             pickle5: Not installed
2023-08-01 22:02:48,315:INFO:         cloudpickle: 2.2.1
2023-08-01 22:02:48,316:INFO:         deprecation: 2.1.0
2023-08-01 22:02:48,316:INFO:              xxhash: 3.2.0
2023-08-01 22:02:48,316:INFO:           wurlitzer: Not installed
2023-08-01 22:02:48,316:INFO:PyCaret optional dependencies:
2023-08-01 22:02:48,316:INFO:                shap: Not installed
2023-08-01 22:02:48,316:INFO:           interpret: Not installed
2023-08-01 22:02:48,316:INFO:                umap: Not installed
2023-08-01 22:02:48,316:INFO:    pandas_profiling: 4.3.1
2023-08-01 22:02:48,316:INFO:  explainerdashboard: Not installed
2023-08-01 22:02:48,316:INFO:             autoviz: Not installed
2023-08-01 22:02:48,316:INFO:           fairlearn: Not installed
2023-08-01 22:02:48,316:INFO:          deepchecks: Not installed
2023-08-01 22:02:48,316:INFO:             xgboost: Not installed
2023-08-01 22:02:48,316:INFO:            catboost: Not installed
2023-08-01 22:02:48,316:INFO:              kmodes: Not installed
2023-08-01 22:02:48,317:INFO:             mlxtend: 0.22.0
2023-08-01 22:02:48,317:INFO:       statsforecast: Not installed
2023-08-01 22:02:48,317:INFO:        tune_sklearn: Not installed
2023-08-01 22:02:48,317:INFO:                 ray: Not installed
2023-08-01 22:02:48,317:INFO:            hyperopt: Not installed
2023-08-01 22:02:48,317:INFO:              optuna: Not installed
2023-08-01 22:02:48,317:INFO:               skopt: Not installed
2023-08-01 22:02:48,317:INFO:              mlflow: Not installed
2023-08-01 22:02:48,317:INFO:              gradio: Not installed
2023-08-01 22:02:48,317:INFO:             fastapi: Not installed
2023-08-01 22:02:48,317:INFO:             uvicorn: Not installed
2023-08-01 22:02:48,317:INFO:              m2cgen: Not installed
2023-08-01 22:02:48,317:INFO:           evidently: Not installed
2023-08-01 22:02:48,317:INFO:               fugue: Not installed
2023-08-01 22:02:48,317:INFO:           streamlit: Not installed
2023-08-01 22:02:48,317:INFO:             prophet: Not installed
2023-08-01 22:02:48,317:INFO:None
2023-08-01 22:02:48,317:INFO:Set up data.
2023-08-01 22:02:48,330:INFO:Set up train/test split.
2023-08-01 22:02:48,338:INFO:Set up index.
2023-08-01 22:02:48,339:INFO:Set up folding strategy.
2023-08-01 22:02:48,339:INFO:Assigning column types.
2023-08-01 22:02:48,344:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 22:02:48,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,446:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,517:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,562:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 22:02:48,634:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,755:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:02:48,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,800:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 22:02:48,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:48,932:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,036:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,036:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,037:INFO:Preparing preprocessing pipeline...
2023-08-01 22:02:49,038:INFO:Set up simple imputation.
2023-08-01 22:02:49,041:INFO:Set up encoding of categorical features.
2023-08-01 22:02:49,041:INFO:Set up removing multicollinearity.
2023-08-01 22:02:49,185:INFO:Finished creating preprocessing pipeline.
2023-08-01 22:02:49,192:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 22:02:49,192:INFO:Creating final display dataframe.
2023-08-01 22:02:49,397:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 24)
5   Transformed train set shape        (6508, 24)
6    Transformed test set shape        (1628, 24)
7               Ignore features                 3
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              712f
2023-08-01 22:02:49,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:02:49,637:INFO:setup() successfully completed in 2.88s...............
2023-08-01 22:02:55,143:INFO:Initializing compare_models()
2023-08-01 22:02:55,143:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 22:02:55,143:INFO:Checking exceptions
2023-08-01 22:02:55,151:INFO:Preparing display monitor
2023-08-01 22:02:55,189:INFO:Initializing Logistic Regression
2023-08-01 22:02:55,189:INFO:Total runtime is 0.0 minutes
2023-08-01 22:02:55,195:INFO:SubProcess create_model() called ==================================
2023-08-01 22:02:55,196:INFO:Initializing create_model()
2023-08-01 22:02:55,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:02:55,196:INFO:Checking exceptions
2023-08-01 22:02:55,197:INFO:Importing libraries
2023-08-01 22:02:55,197:INFO:Copying training dataset
2023-08-01 22:02:55,204:INFO:Defining folds
2023-08-01 22:02:55,204:INFO:Declaring metric variables
2023-08-01 22:02:55,210:INFO:Importing untrained model
2023-08-01 22:02:55,216:INFO:Logistic Regression Imported successfully
2023-08-01 22:02:55,231:INFO:Starting cross validation
2023-08-01 22:02:55,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:03:11,438:INFO:Calculating mean and std
2023-08-01 22:03:11,439:INFO:Creating metrics dataframe
2023-08-01 22:03:13,816:INFO:Uploading results into container
2023-08-01 22:03:13,818:INFO:Uploading model into container now
2023-08-01 22:03:13,819:INFO:_master_model_container: 1
2023-08-01 22:03:13,820:INFO:_display_container: 2
2023-08-01 22:03:13,821:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 22:03:13,821:INFO:create_model() successfully completed......................................
2023-08-01 22:03:13,908:INFO:SubProcess create_model() end ==================================
2023-08-01 22:03:13,908:INFO:Creating metrics dataframe
2023-08-01 22:03:13,923:INFO:Initializing K Neighbors Classifier
2023-08-01 22:03:13,923:INFO:Total runtime is 0.3122332771619161 minutes
2023-08-01 22:03:13,928:INFO:SubProcess create_model() called ==================================
2023-08-01 22:03:13,930:INFO:Initializing create_model()
2023-08-01 22:03:13,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:03:13,931:INFO:Checking exceptions
2023-08-01 22:03:13,932:INFO:Importing libraries
2023-08-01 22:03:13,932:INFO:Copying training dataset
2023-08-01 22:03:13,944:INFO:Defining folds
2023-08-01 22:03:13,944:INFO:Declaring metric variables
2023-08-01 22:03:13,954:INFO:Importing untrained model
2023-08-01 22:03:13,961:INFO:K Neighbors Classifier Imported successfully
2023-08-01 22:03:13,983:INFO:Starting cross validation
2023-08-01 22:03:13,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:03:31,066:INFO:Calculating mean and std
2023-08-01 22:03:31,069:INFO:Creating metrics dataframe
2023-08-01 22:03:33,295:INFO:Uploading results into container
2023-08-01 22:03:33,296:INFO:Uploading model into container now
2023-08-01 22:03:33,298:INFO:_master_model_container: 2
2023-08-01 22:03:33,298:INFO:_display_container: 2
2023-08-01 22:03:33,299:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 22:03:33,299:INFO:create_model() successfully completed......................................
2023-08-01 22:03:33,384:INFO:SubProcess create_model() end ==================================
2023-08-01 22:03:33,385:INFO:Creating metrics dataframe
2023-08-01 22:03:33,401:INFO:Initializing Naive Bayes
2023-08-01 22:03:33,402:INFO:Total runtime is 0.6368832906087241 minutes
2023-08-01 22:03:33,407:INFO:SubProcess create_model() called ==================================
2023-08-01 22:03:33,408:INFO:Initializing create_model()
2023-08-01 22:03:33,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:03:33,409:INFO:Checking exceptions
2023-08-01 22:03:33,409:INFO:Importing libraries
2023-08-01 22:03:33,409:INFO:Copying training dataset
2023-08-01 22:03:33,422:INFO:Defining folds
2023-08-01 22:03:33,423:INFO:Declaring metric variables
2023-08-01 22:03:33,429:INFO:Importing untrained model
2023-08-01 22:03:33,439:INFO:Naive Bayes Imported successfully
2023-08-01 22:03:33,456:INFO:Starting cross validation
2023-08-01 22:03:33,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:03:49,860:INFO:Calculating mean and std
2023-08-01 22:03:49,861:INFO:Creating metrics dataframe
2023-08-01 22:03:52,264:INFO:Uploading results into container
2023-08-01 22:03:52,266:INFO:Uploading model into container now
2023-08-01 22:03:52,267:INFO:_master_model_container: 3
2023-08-01 22:03:52,267:INFO:_display_container: 2
2023-08-01 22:03:52,268:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 22:03:52,268:INFO:create_model() successfully completed......................................
2023-08-01 22:03:52,357:INFO:SubProcess create_model() end ==================================
2023-08-01 22:03:52,358:INFO:Creating metrics dataframe
2023-08-01 22:03:52,374:INFO:Initializing Decision Tree Classifier
2023-08-01 22:03:52,374:INFO:Total runtime is 0.9530770540237428 minutes
2023-08-01 22:03:52,379:INFO:SubProcess create_model() called ==================================
2023-08-01 22:03:52,380:INFO:Initializing create_model()
2023-08-01 22:03:52,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:03:52,381:INFO:Checking exceptions
2023-08-01 22:03:52,381:INFO:Importing libraries
2023-08-01 22:03:52,382:INFO:Copying training dataset
2023-08-01 22:03:52,392:INFO:Defining folds
2023-08-01 22:03:52,392:INFO:Declaring metric variables
2023-08-01 22:03:52,399:INFO:Importing untrained model
2023-08-01 22:03:52,405:INFO:Decision Tree Classifier Imported successfully
2023-08-01 22:03:52,422:INFO:Starting cross validation
2023-08-01 22:03:52,425:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:04:09,089:INFO:Calculating mean and std
2023-08-01 22:04:09,092:INFO:Creating metrics dataframe
2023-08-01 22:04:12,300:INFO:Uploading results into container
2023-08-01 22:04:12,302:INFO:Uploading model into container now
2023-08-01 22:04:12,303:INFO:_master_model_container: 4
2023-08-01 22:04:12,303:INFO:_display_container: 2
2023-08-01 22:04:12,305:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 22:04:12,306:INFO:create_model() successfully completed......................................
2023-08-01 22:04:12,437:INFO:SubProcess create_model() end ==================================
2023-08-01 22:04:12,437:INFO:Creating metrics dataframe
2023-08-01 22:04:12,460:INFO:Initializing SVM - Linear Kernel
2023-08-01 22:04:12,461:INFO:Total runtime is 1.2878603974978131 minutes
2023-08-01 22:04:12,472:INFO:SubProcess create_model() called ==================================
2023-08-01 22:04:12,472:INFO:Initializing create_model()
2023-08-01 22:04:12,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:04:12,473:INFO:Checking exceptions
2023-08-01 22:04:12,473:INFO:Importing libraries
2023-08-01 22:04:12,473:INFO:Copying training dataset
2023-08-01 22:04:12,488:INFO:Defining folds
2023-08-01 22:04:12,489:INFO:Declaring metric variables
2023-08-01 22:04:12,503:INFO:Importing untrained model
2023-08-01 22:04:12,515:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 22:04:12,542:INFO:Starting cross validation
2023-08-01 22:04:12,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:04:13,479:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:13,695:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:13,706:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:13,862:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:13,924:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:14,263:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:14,297:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:14,408:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:20,738:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:20,761:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:04:33,713:INFO:Calculating mean and std
2023-08-01 22:04:33,715:INFO:Creating metrics dataframe
2023-08-01 22:04:36,313:INFO:Uploading results into container
2023-08-01 22:04:36,314:INFO:Uploading model into container now
2023-08-01 22:04:36,315:INFO:_master_model_container: 5
2023-08-01 22:04:36,316:INFO:_display_container: 2
2023-08-01 22:04:36,317:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 22:04:36,317:INFO:create_model() successfully completed......................................
2023-08-01 22:04:36,397:INFO:SubProcess create_model() end ==================================
2023-08-01 22:04:36,399:INFO:Creating metrics dataframe
2023-08-01 22:04:36,415:INFO:Initializing Ridge Classifier
2023-08-01 22:04:36,415:INFO:Total runtime is 1.6870847622553509 minutes
2023-08-01 22:04:36,424:INFO:SubProcess create_model() called ==================================
2023-08-01 22:04:36,424:INFO:Initializing create_model()
2023-08-01 22:04:36,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:04:36,425:INFO:Checking exceptions
2023-08-01 22:04:36,425:INFO:Importing libraries
2023-08-01 22:04:36,425:INFO:Copying training dataset
2023-08-01 22:04:36,434:INFO:Defining folds
2023-08-01 22:04:36,435:INFO:Declaring metric variables
2023-08-01 22:04:36,443:INFO:Importing untrained model
2023-08-01 22:04:36,452:INFO:Ridge Classifier Imported successfully
2023-08-01 22:04:36,469:INFO:Starting cross validation
2023-08-01 22:04:36,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:04:37,218:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,257:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,385:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,388:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,462:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,518:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,596:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:37,704:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:43,608:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:43,661:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:04:59,587:INFO:Calculating mean and std
2023-08-01 22:04:59,588:INFO:Creating metrics dataframe
2023-08-01 22:05:02,035:INFO:Uploading results into container
2023-08-01 22:05:02,036:INFO:Uploading model into container now
2023-08-01 22:05:02,038:INFO:_master_model_container: 6
2023-08-01 22:05:02,039:INFO:_display_container: 2
2023-08-01 22:05:02,040:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 22:05:02,040:INFO:create_model() successfully completed......................................
2023-08-01 22:05:02,141:INFO:SubProcess create_model() end ==================================
2023-08-01 22:05:02,142:INFO:Creating metrics dataframe
2023-08-01 22:05:02,161:INFO:Initializing Random Forest Classifier
2023-08-01 22:05:02,161:INFO:Total runtime is 2.1162010431289673 minutes
2023-08-01 22:05:02,169:INFO:SubProcess create_model() called ==================================
2023-08-01 22:05:02,170:INFO:Initializing create_model()
2023-08-01 22:05:02,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:05:02,171:INFO:Checking exceptions
2023-08-01 22:05:02,171:INFO:Importing libraries
2023-08-01 22:05:02,172:INFO:Copying training dataset
2023-08-01 22:05:02,184:INFO:Defining folds
2023-08-01 22:05:02,185:INFO:Declaring metric variables
2023-08-01 22:05:02,194:INFO:Importing untrained model
2023-08-01 22:05:02,206:INFO:Random Forest Classifier Imported successfully
2023-08-01 22:05:02,224:INFO:Starting cross validation
2023-08-01 22:05:02,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:05:03,427:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-01 22:05:05,359:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:05,417:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:05,427:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:05,502:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:05,510:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:05,518:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:05:06,900:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:05:06,901:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:05:06,910:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:05:07,580:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:05:07,855:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:05:26,411:INFO:Calculating mean and std
2023-08-01 22:05:26,413:INFO:Creating metrics dataframe
2023-08-01 22:05:29,005:INFO:Uploading results into container
2023-08-01 22:05:29,006:INFO:Uploading model into container now
2023-08-01 22:05:29,007:INFO:_master_model_container: 7
2023-08-01 22:05:29,007:INFO:_display_container: 2
2023-08-01 22:05:29,008:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 22:05:29,008:INFO:create_model() successfully completed......................................
2023-08-01 22:05:29,101:INFO:SubProcess create_model() end ==================================
2023-08-01 22:05:29,101:INFO:Creating metrics dataframe
2023-08-01 22:05:29,122:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 22:05:29,122:INFO:Total runtime is 2.5655344247817995 minutes
2023-08-01 22:05:29,131:INFO:SubProcess create_model() called ==================================
2023-08-01 22:05:29,131:INFO:Initializing create_model()
2023-08-01 22:05:29,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:05:29,132:INFO:Checking exceptions
2023-08-01 22:05:29,132:INFO:Importing libraries
2023-08-01 22:05:29,132:INFO:Copying training dataset
2023-08-01 22:05:29,147:INFO:Defining folds
2023-08-01 22:05:29,147:INFO:Declaring metric variables
2023-08-01 22:05:29,156:INFO:Importing untrained model
2023-08-01 22:05:29,166:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 22:05:29,184:INFO:Starting cross validation
2023-08-01 22:05:29,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:05:29,590:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,607:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,611:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,623:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,632:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,654:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,713:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:29,714:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:30,043:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,044:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,044:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,045:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,046:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,048:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,063:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,063:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,064:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,102:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,103:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,104:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,108:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,109:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,109:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,126:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,127:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,128:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,160:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,161:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,162:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,184:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,185:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,186:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,200:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,217:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,219:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,222:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,228:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,229:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,229:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,235:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,243:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,243:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,244:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,245:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,261:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,262:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,263:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,267:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,268:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,273:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,275:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,275:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,276:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,277:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,284:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,291:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,313:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,314:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,320:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:05:30,326:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,345:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:30,375:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,375:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:30,376:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:30,381:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:05:30,386:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:36,391:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:36,414:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:05:36,533:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,533:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,534:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:36,649:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,649:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,650:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:36,659:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,659:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,659:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:36,661:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:36,699:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,699:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:05:36,699:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:05:36,701:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:05:48,235:INFO:Calculating mean and std
2023-08-01 22:05:48,237:INFO:Creating metrics dataframe
2023-08-01 22:05:50,574:INFO:Uploading results into container
2023-08-01 22:05:50,575:INFO:Uploading model into container now
2023-08-01 22:05:50,576:INFO:_master_model_container: 8
2023-08-01 22:05:50,576:INFO:_display_container: 2
2023-08-01 22:05:50,577:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 22:05:50,578:INFO:create_model() successfully completed......................................
2023-08-01 22:05:50,668:INFO:SubProcess create_model() end ==================================
2023-08-01 22:05:50,669:INFO:Creating metrics dataframe
2023-08-01 22:05:50,684:INFO:Initializing Ada Boost Classifier
2023-08-01 22:05:50,684:INFO:Total runtime is 2.9249177058537805 minutes
2023-08-01 22:05:50,690:INFO:SubProcess create_model() called ==================================
2023-08-01 22:05:50,690:INFO:Initializing create_model()
2023-08-01 22:05:50,690:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:05:50,690:INFO:Checking exceptions
2023-08-01 22:05:50,690:INFO:Importing libraries
2023-08-01 22:05:50,692:INFO:Copying training dataset
2023-08-01 22:05:50,701:INFO:Defining folds
2023-08-01 22:05:50,701:INFO:Declaring metric variables
2023-08-01 22:05:50,709:INFO:Importing untrained model
2023-08-01 22:05:50,713:INFO:Ada Boost Classifier Imported successfully
2023-08-01 22:05:50,727:INFO:Starting cross validation
2023-08-01 22:05:50,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:06:12,305:INFO:Calculating mean and std
2023-08-01 22:06:12,306:INFO:Creating metrics dataframe
2023-08-01 22:06:14,762:INFO:Uploading results into container
2023-08-01 22:06:14,763:INFO:Uploading model into container now
2023-08-01 22:06:14,764:INFO:_master_model_container: 9
2023-08-01 22:06:14,764:INFO:_display_container: 2
2023-08-01 22:06:14,764:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 22:06:14,765:INFO:create_model() successfully completed......................................
2023-08-01 22:06:14,857:INFO:SubProcess create_model() end ==================================
2023-08-01 22:06:14,858:INFO:Creating metrics dataframe
2023-08-01 22:06:14,877:INFO:Initializing Gradient Boosting Classifier
2023-08-01 22:06:14,877:INFO:Total runtime is 3.3281198898951216 minutes
2023-08-01 22:06:14,884:INFO:SubProcess create_model() called ==================================
2023-08-01 22:06:14,885:INFO:Initializing create_model()
2023-08-01 22:06:14,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:06:14,885:INFO:Checking exceptions
2023-08-01 22:06:14,885:INFO:Importing libraries
2023-08-01 22:06:14,886:INFO:Copying training dataset
2023-08-01 22:06:14,901:INFO:Defining folds
2023-08-01 22:06:14,901:INFO:Declaring metric variables
2023-08-01 22:06:14,911:INFO:Importing untrained model
2023-08-01 22:06:14,920:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:06:14,942:INFO:Starting cross validation
2023-08-01 22:06:14,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:06:17,984:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:06:18,093:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:06:18,279:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:06:18,823:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:18,965:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:18,990:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:19,230:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:19,458:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:19,735:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:06:27,981:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:06:28,016:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:06:42,528:INFO:Calculating mean and std
2023-08-01 22:06:42,530:INFO:Creating metrics dataframe
2023-08-01 22:06:45,186:INFO:Uploading results into container
2023-08-01 22:06:45,188:INFO:Uploading model into container now
2023-08-01 22:06:45,189:INFO:_master_model_container: 10
2023-08-01 22:06:45,189:INFO:_display_container: 2
2023-08-01 22:06:45,190:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:06:45,190:INFO:create_model() successfully completed......................................
2023-08-01 22:06:45,283:INFO:SubProcess create_model() end ==================================
2023-08-01 22:06:45,283:INFO:Creating metrics dataframe
2023-08-01 22:06:45,307:INFO:Initializing Linear Discriminant Analysis
2023-08-01 22:06:45,308:INFO:Total runtime is 3.8353170911471053 minutes
2023-08-01 22:06:45,318:INFO:SubProcess create_model() called ==================================
2023-08-01 22:06:45,319:INFO:Initializing create_model()
2023-08-01 22:06:45,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:06:45,320:INFO:Checking exceptions
2023-08-01 22:06:45,320:INFO:Importing libraries
2023-08-01 22:06:45,320:INFO:Copying training dataset
2023-08-01 22:06:45,343:INFO:Defining folds
2023-08-01 22:06:45,343:INFO:Declaring metric variables
2023-08-01 22:06:45,354:INFO:Importing untrained model
2023-08-01 22:06:45,370:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 22:06:45,459:INFO:Starting cross validation
2023-08-01 22:06:45,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:07:04,810:INFO:Calculating mean and std
2023-08-01 22:07:04,811:INFO:Creating metrics dataframe
2023-08-01 22:07:07,379:INFO:Uploading results into container
2023-08-01 22:07:07,380:INFO:Uploading model into container now
2023-08-01 22:07:07,381:INFO:_master_model_container: 11
2023-08-01 22:07:07,382:INFO:_display_container: 2
2023-08-01 22:07:07,382:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 22:07:07,383:INFO:create_model() successfully completed......................................
2023-08-01 22:07:07,475:INFO:SubProcess create_model() end ==================================
2023-08-01 22:07:07,475:INFO:Creating metrics dataframe
2023-08-01 22:07:07,496:INFO:Initializing Extra Trees Classifier
2023-08-01 22:07:07,496:INFO:Total runtime is 4.205117042859396 minutes
2023-08-01 22:07:07,504:INFO:SubProcess create_model() called ==================================
2023-08-01 22:07:07,505:INFO:Initializing create_model()
2023-08-01 22:07:07,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:07:07,505:INFO:Checking exceptions
2023-08-01 22:07:07,505:INFO:Importing libraries
2023-08-01 22:07:07,505:INFO:Copying training dataset
2023-08-01 22:07:07,518:INFO:Defining folds
2023-08-01 22:07:07,518:INFO:Declaring metric variables
2023-08-01 22:07:07,527:INFO:Importing untrained model
2023-08-01 22:07:07,534:INFO:Extra Trees Classifier Imported successfully
2023-08-01 22:07:07,558:INFO:Starting cross validation
2023-08-01 22:07:07,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:07:10,473:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:10,510:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:10,579:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:10,763:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:10,792:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:10,889:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:07:11,567:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:07:11,768:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:07:11,847:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:07:11,977:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:07:12,015:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:07:31,068:INFO:Calculating mean and std
2023-08-01 22:07:31,069:INFO:Creating metrics dataframe
2023-08-01 22:07:33,731:INFO:Uploading results into container
2023-08-01 22:07:33,733:INFO:Uploading model into container now
2023-08-01 22:07:33,733:INFO:_master_model_container: 12
2023-08-01 22:07:33,733:INFO:_display_container: 2
2023-08-01 22:07:33,734:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 22:07:33,734:INFO:create_model() successfully completed......................................
2023-08-01 22:07:33,816:INFO:SubProcess create_model() end ==================================
2023-08-01 22:07:33,817:INFO:Creating metrics dataframe
2023-08-01 22:07:33,843:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 22:07:33,843:INFO:Total runtime is 4.644233906269074 minutes
2023-08-01 22:07:33,851:INFO:SubProcess create_model() called ==================================
2023-08-01 22:07:33,852:INFO:Initializing create_model()
2023-08-01 22:07:33,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:07:33,852:INFO:Checking exceptions
2023-08-01 22:07:33,852:INFO:Importing libraries
2023-08-01 22:07:33,853:INFO:Copying training dataset
2023-08-01 22:07:33,864:INFO:Defining folds
2023-08-01 22:07:33,865:INFO:Declaring metric variables
2023-08-01 22:07:33,872:INFO:Importing untrained model
2023-08-01 22:07:33,881:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 22:07:33,908:INFO:Starting cross validation
2023-08-01 22:07:33,914:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:08:00,188:INFO:Calculating mean and std
2023-08-01 22:08:00,190:INFO:Creating metrics dataframe
2023-08-01 22:08:02,840:INFO:Uploading results into container
2023-08-01 22:08:02,842:INFO:Uploading model into container now
2023-08-01 22:08:02,844:INFO:_master_model_container: 13
2023-08-01 22:08:02,844:INFO:_display_container: 2
2023-08-01 22:08:02,845:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 22:08:02,845:INFO:create_model() successfully completed......................................
2023-08-01 22:08:02,962:INFO:SubProcess create_model() end ==================================
2023-08-01 22:08:02,963:INFO:Creating metrics dataframe
2023-08-01 22:08:02,990:INFO:Initializing Dummy Classifier
2023-08-01 22:08:02,990:INFO:Total runtime is 5.130009353160858 minutes
2023-08-01 22:08:03,002:INFO:SubProcess create_model() called ==================================
2023-08-01 22:08:03,003:INFO:Initializing create_model()
2023-08-01 22:08:03,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAF0B94190>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:08:03,003:INFO:Checking exceptions
2023-08-01 22:08:03,003:INFO:Importing libraries
2023-08-01 22:08:03,003:INFO:Copying training dataset
2023-08-01 22:08:03,025:INFO:Defining folds
2023-08-01 22:08:03,025:INFO:Declaring metric variables
2023-08-01 22:08:03,037:INFO:Importing untrained model
2023-08-01 22:08:03,052:INFO:Dummy Classifier Imported successfully
2023-08-01 22:08:03,086:INFO:Starting cross validation
2023-08-01 22:08:03,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:08:04,139:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,172:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,319:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,372:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,426:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,516:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,536:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:04,988:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:12,190:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:12,305:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:08:26,997:INFO:Calculating mean and std
2023-08-01 22:08:26,999:INFO:Creating metrics dataframe
2023-08-01 22:08:30,059:INFO:Uploading results into container
2023-08-01 22:08:30,060:INFO:Uploading model into container now
2023-08-01 22:08:30,062:INFO:_master_model_container: 14
2023-08-01 22:08:30,062:INFO:_display_container: 2
2023-08-01 22:08:30,062:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 22:08:30,062:INFO:create_model() successfully completed......................................
2023-08-01 22:08:30,155:INFO:SubProcess create_model() end ==================================
2023-08-01 22:08:30,155:INFO:Creating metrics dataframe
2023-08-01 22:08:30,196:INFO:Initializing create_model()
2023-08-01 22:08:30,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:08:30,196:INFO:Checking exceptions
2023-08-01 22:08:30,200:INFO:Importing libraries
2023-08-01 22:08:30,200:INFO:Copying training dataset
2023-08-01 22:08:30,210:INFO:Defining folds
2023-08-01 22:08:30,210:INFO:Declaring metric variables
2023-08-01 22:08:30,211:INFO:Importing untrained model
2023-08-01 22:08:30,211:INFO:Declaring custom model
2023-08-01 22:08:30,212:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:08:30,214:INFO:Cross validation set to False
2023-08-01 22:08:30,214:INFO:Fitting Model
2023-08-01 22:08:33,036:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:08:33,036:INFO:create_model() successfully completed......................................
2023-08-01 22:08:33,183:INFO:_master_model_container: 14
2023-08-01 22:08:33,183:INFO:_display_container: 2
2023-08-01 22:08:33,184:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:08:33,184:INFO:compare_models() successfully completed......................................
2023-08-01 22:11:32,042:INFO:Initializing evaluate_model()
2023-08-01 22:11:32,042:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 22:11:32,058:INFO:Initializing plot_model()
2023-08-01 22:11:32,059:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, system=True)
2023-08-01 22:11:32,059:INFO:Checking exceptions
2023-08-01 22:11:32,063:INFO:Preloading libraries
2023-08-01 22:11:32,074:INFO:Copying training dataset
2023-08-01 22:11:32,074:INFO:Plot type: pipeline
2023-08-01 22:11:32,467:INFO:Visual Rendered Successfully
2023-08-01 22:11:32,565:INFO:plot_model() successfully completed......................................
2023-08-01 22:11:34,199:INFO:Initializing plot_model()
2023-08-01 22:11:34,200:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, system=True)
2023-08-01 22:11:34,201:INFO:Checking exceptions
2023-08-01 22:11:34,205:INFO:Preloading libraries
2023-08-01 22:11:34,215:INFO:Copying training dataset
2023-08-01 22:11:34,215:INFO:Plot type: threshold
2023-08-01 22:11:34,452:INFO:Fitting Model
2023-08-01 22:11:59,510:INFO:Scoring test/hold-out set
2023-08-01 22:11:59,842:INFO:Visual Rendered Successfully
2023-08-01 22:11:59,928:INFO:plot_model() successfully completed......................................
2023-08-01 22:13:07,440:INFO:Initializing create_model()
2023-08-01 22:13:07,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.31, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:13:07,440:INFO:Checking exceptions
2023-08-01 22:13:07,480:INFO:Importing libraries
2023-08-01 22:13:07,480:INFO:Copying training dataset
2023-08-01 22:13:07,496:INFO:Defining folds
2023-08-01 22:13:07,496:INFO:Declaring metric variables
2023-08-01 22:13:07,507:INFO:Importing untrained model
2023-08-01 22:13:07,516:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:13:07,536:INFO:Starting cross validation
2023-08-01 22:13:07,541:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:13:27,512:INFO:Calculating mean and std
2023-08-01 22:13:27,514:INFO:Creating metrics dataframe
2023-08-01 22:13:27,523:INFO:Finalizing model
2023-08-01 22:13:30,808:INFO:Uploading results into container
2023-08-01 22:13:30,809:INFO:Uploading model into container now
2023-08-01 22:13:30,824:INFO:_master_model_container: 15
2023-08-01 22:13:30,824:INFO:_display_container: 3
2023-08-01 22:13:30,826:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0,
                                     classifier=GradientBoostingClassifier(ccp_alpha=0.0,
                                                                           criterion='friedman_mse',
                                                                           init=None,
                                                                           learning_rate=0.1,
                                                                           loss='log_loss',
                                                                           max_depth=3,
                                                                           max_features=None,
                                                                           max_leaf_nodes=None,
                                                                           min_impurity_decrease=0.0,
                                                                           min_samples_leaf=1,
                                                                           min_samples_split=2,
                                                                           min_weight_fraction_leaf=0.0,
                                                                           n_estimators=100,
                                                                           n_iter_no_change=...
                                     criterion='friedman_mse', init=None,
                                     learning_rate=0.1, loss='log_loss',
                                     max_depth=3, max_features=None,
                                     max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     n_estimators=100, n_iter_no_change=None,
                                     probability_threshold=0.31,
                                     random_state=2020, subsample=1.0,
                                     tol=0.0001, validation_fraction=0.1,
                                     verbose=0, warm_start=False)
2023-08-01 22:13:30,826:INFO:create_model() successfully completed......................................
2023-08-01 22:15:25,638:INFO:Initializing tune_model()
2023-08-01 22:15:25,638:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=15, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>)
2023-08-01 22:15:25,638:INFO:Checking exceptions
2023-08-01 22:15:25,677:INFO:Copying training dataset
2023-08-01 22:15:25,687:INFO:Checking base model
2023-08-01 22:15:25,687:INFO:Base model : Gradient Boosting Classifier
2023-08-01 22:15:25,696:INFO:Declaring metric variables
2023-08-01 22:15:25,703:INFO:Defining Hyperparameters
2023-08-01 22:15:25,845:INFO:Tuning with n_jobs=-1
2023-08-01 22:15:25,846:INFO:Initializing RandomizedSearchCV
2023-08-01 22:15:30,155:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:31,041:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:40,223:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:40,834:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:41,242:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:41,364:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:42,549:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:42,551:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

 X, None, with_final=False)

2023-08-01 22:15:42,553:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:43,363:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:43,555:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:43,645:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:44,228:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:44,233:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:44,607:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:45,052:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:50,908:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:52,143:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:52,993:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:53,363:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:53,844:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:15:54,461:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:54,833:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:55,230:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:15:57,509:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:16:02,302:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:18:39,599:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:19:51,271:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-01 22:21:30,066:INFO:best_params: {'actual_estimator__subsample': 0.95, 'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.5, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 10, 'actual_estimator__learning_rate': 0.5}
2023-08-01 22:21:30,067:INFO:Hyperparameter search completed
2023-08-01 22:21:30,067:INFO:SubProcess create_model() called ==================================
2023-08-01 22:21:30,068:INFO:Initializing create_model()
2023-08-01 22:21:30,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001AAFBA8D070>, model_only=True, return_train_score=False, kwargs={'subsample': 0.95, 'n_estimators': 130, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.5, 'max_features': 1.0, 'max_depth': 10, 'learning_rate': 0.5})
2023-08-01 22:21:30,069:INFO:Checking exceptions
2023-08-01 22:21:30,069:INFO:Importing libraries
2023-08-01 22:21:30,069:INFO:Copying training dataset
2023-08-01 22:21:30,084:INFO:Defining folds
2023-08-01 22:21:30,085:INFO:Declaring metric variables
2023-08-01 22:21:30,092:INFO:Importing untrained model
2023-08-01 22:21:30,092:INFO:Declaring custom model
2023-08-01 22:21:30,102:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:21:30,121:INFO:Starting cross validation
2023-08-01 22:21:30,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:21:31,592:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:31,693:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:31,705:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:31,743:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:31,790:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:31,929:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:50,691:INFO:Calculating mean and std
2023-08-01 22:21:50,693:INFO:Creating metrics dataframe
2023-08-01 22:21:50,704:INFO:Finalizing model
2023-08-01 22:21:54,797:INFO:Uploading results into container
2023-08-01 22:21:54,799:INFO:Uploading model into container now
2023-08-01 22:21:54,800:INFO:_master_model_container: 16
2023-08-01 22:21:54,800:INFO:_display_container: 4
2023-08-01 22:21:54,801:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.5, loss='log_loss', max_depth=10,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=2020, subsample=0.95, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:21:54,801:INFO:create_model() successfully completed......................................
2023-08-01 22:21:54,911:INFO:SubProcess create_model() end ==================================
2023-08-01 22:21:54,911:INFO:choose_better activated
2023-08-01 22:21:54,920:INFO:SubProcess create_model() called ==================================
2023-08-01 22:21:54,921:INFO:Initializing create_model()
2023-08-01 22:21:54,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:21:54,922:INFO:Checking exceptions
2023-08-01 22:21:54,925:INFO:Importing libraries
2023-08-01 22:21:54,926:INFO:Copying training dataset
2023-08-01 22:21:54,941:INFO:Defining folds
2023-08-01 22:21:54,941:INFO:Declaring metric variables
2023-08-01 22:21:54,941:INFO:Importing untrained model
2023-08-01 22:21:54,942:INFO:Declaring custom model
2023-08-01 22:21:54,943:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:21:54,944:INFO:Starting cross validation
2023-08-01 22:21:54,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:21:56,515:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:56,523:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:56,534:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:21:56,842:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:22:16,968:INFO:Calculating mean and std
2023-08-01 22:22:16,968:INFO:Creating metrics dataframe
2023-08-01 22:22:16,971:INFO:Finalizing model
2023-08-01 22:22:20,393:INFO:Uploading results into container
2023-08-01 22:22:20,395:INFO:Uploading model into container now
2023-08-01 22:22:20,395:INFO:_master_model_container: 17
2023-08-01 22:22:20,396:INFO:_display_container: 5
2023-08-01 22:22:20,397:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:22:20,398:INFO:create_model() successfully completed......................................
2023-08-01 22:22:20,527:INFO:SubProcess create_model() end ==================================
2023-08-01 22:22:20,528:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for MCC is 0.3014
2023-08-01 22:22:20,529:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.5, loss='log_loss', max_depth=10,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.5, min_samples_leaf=4,
                           min_samples_split=9, min_weight_fraction_leaf=0.0,
                           n_estimators=130, n_iter_no_change=None,
                           random_state=2020, subsample=0.95, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for MCC is 0.2996
2023-08-01 22:22:20,531:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-01 22:22:20,531:INFO:choose_better completed
2023-08-01 22:22:20,532:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-01 22:22:20,558:INFO:_master_model_container: 17
2023-08-01 22:22:20,559:INFO:_display_container: 4
2023-08-01 22:22:20,560:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:22:20,560:INFO:tune_model() successfully completed......................................
2023-08-01 22:24:49,322:INFO:Initializing tune_model()
2023-08-01 22:24:49,323:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=5, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001AAF0BE5D90>)
2023-08-01 22:24:49,324:INFO:Checking exceptions
2023-08-01 22:24:49,324:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-08-01 22:26:17,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 22:26:17,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 22:26:17,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 22:26:17,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-01 22:26:20,055:INFO:PyCaret ClassificationExperiment
2023-08-01 22:26:20,055:INFO:Logging name: clf-default-name
2023-08-01 22:26:20,055:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-01 22:26:20,055:INFO:version 3.0.4
2023-08-01 22:26:20,055:INFO:Initializing setup()
2023-08-01 22:26:20,055:INFO:self.USI: baff
2023-08-01 22:26:20,055:INFO:self._variable_keys: {'gpu_param', 'X', '_ml_usecase', 'logging_param', 'USI', 'fix_imbalance', 'seed', 'exp_name_log', 'idx', 'gpu_n_jobs_param', 'pipeline', 'n_jobs_param', 'fold_generator', 'X_test', 'y_train', 'log_plots_param', '_available_plots', 'html_param', 'fold_shuffle_param', 'fold_groups_param', 'memory', 'y_test', 'X_train', 'data', 'y', 'is_multiclass', 'target_param', 'exp_id'}
2023-08-01 22:26:20,055:INFO:Checking environment
2023-08-01 22:26:20,056:INFO:python_version: 3.9.13
2023-08-01 22:26:20,056:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-01 22:26:20,056:INFO:machine: AMD64
2023-08-01 22:26:20,056:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-01 22:26:20,061:INFO:Memory: svmem(total=17055166464, available=9449938944, percent=44.6, used=7605227520, free=9449938944)
2023-08-01 22:26:20,061:INFO:Physical Core: 4
2023-08-01 22:26:20,061:INFO:Logical Core: 8
2023-08-01 22:26:20,061:INFO:Checking libraries
2023-08-01 22:26:20,061:INFO:System:
2023-08-01 22:26:20,062:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-01 22:26:20,062:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-01 22:26:20,062:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-01 22:26:20,062:INFO:PyCaret required dependencies:
2023-08-01 22:26:20,065:INFO:                 pip: 22.0.4
2023-08-01 22:26:20,065:INFO:          setuptools: 58.1.0
2023-08-01 22:26:20,065:INFO:             pycaret: 3.0.4
2023-08-01 22:26:20,066:INFO:             IPython: 8.13.1
2023-08-01 22:26:20,066:INFO:          ipywidgets: 8.0.7
2023-08-01 22:26:20,066:INFO:                tqdm: 4.65.0
2023-08-01 22:26:20,066:INFO:               numpy: 1.23.0
2023-08-01 22:26:20,066:INFO:              pandas: 1.5.3
2023-08-01 22:26:20,066:INFO:              jinja2: 3.1.2
2023-08-01 22:26:20,066:INFO:               scipy: 1.10.1
2023-08-01 22:26:20,066:INFO:              joblib: 1.2.0
2023-08-01 22:26:20,066:INFO:             sklearn: 1.2.2
2023-08-01 22:26:20,066:INFO:                pyod: 1.1.0
2023-08-01 22:26:20,067:INFO:            imblearn: 0.11.0
2023-08-01 22:26:20,067:INFO:   category_encoders: 2.6.1
2023-08-01 22:26:20,067:INFO:            lightgbm: 3.3.5
2023-08-01 22:26:20,067:INFO:               numba: 0.57.1
2023-08-01 22:26:20,067:INFO:            requests: 2.31.0
2023-08-01 22:26:20,067:INFO:          matplotlib: 3.7.1
2023-08-01 22:26:20,067:INFO:          scikitplot: 0.3.7
2023-08-01 22:26:20,067:INFO:         yellowbrick: 1.5
2023-08-01 22:26:20,067:INFO:              plotly: 5.15.0
2023-08-01 22:26:20,067:INFO:    plotly-resampler: Not installed
2023-08-01 22:26:20,067:INFO:             kaleido: 0.2.1
2023-08-01 22:26:20,067:INFO:           schemdraw: 0.15
2023-08-01 22:26:20,068:INFO:         statsmodels: 0.14.0
2023-08-01 22:26:20,068:INFO:              sktime: 0.20.0
2023-08-01 22:26:20,068:INFO:               tbats: 1.1.3
2023-08-01 22:26:20,068:INFO:            pmdarima: 2.0.3
2023-08-01 22:26:20,068:INFO:              psutil: 5.9.5
2023-08-01 22:26:20,068:INFO:          markupsafe: 2.1.3
2023-08-01 22:26:20,068:INFO:             pickle5: Not installed
2023-08-01 22:26:20,068:INFO:         cloudpickle: 2.2.1
2023-08-01 22:26:20,068:INFO:         deprecation: 2.1.0
2023-08-01 22:26:20,068:INFO:              xxhash: 3.2.0
2023-08-01 22:26:20,068:INFO:           wurlitzer: Not installed
2023-08-01 22:26:20,068:INFO:PyCaret optional dependencies:
2023-08-01 22:26:20,097:INFO:                shap: Not installed
2023-08-01 22:26:20,098:INFO:           interpret: Not installed
2023-08-01 22:26:20,098:INFO:                umap: Not installed
2023-08-01 22:26:20,098:INFO:    pandas_profiling: 4.3.1
2023-08-01 22:26:20,098:INFO:  explainerdashboard: Not installed
2023-08-01 22:26:20,098:INFO:             autoviz: Not installed
2023-08-01 22:26:20,098:INFO:           fairlearn: Not installed
2023-08-01 22:26:20,098:INFO:          deepchecks: Not installed
2023-08-01 22:26:20,098:INFO:             xgboost: Not installed
2023-08-01 22:26:20,099:INFO:            catboost: Not installed
2023-08-01 22:26:20,099:INFO:              kmodes: Not installed
2023-08-01 22:26:20,099:INFO:             mlxtend: 0.22.0
2023-08-01 22:26:20,099:INFO:       statsforecast: Not installed
2023-08-01 22:26:20,099:INFO:        tune_sklearn: Not installed
2023-08-01 22:26:20,099:INFO:                 ray: Not installed
2023-08-01 22:26:20,099:INFO:            hyperopt: Not installed
2023-08-01 22:26:20,099:INFO:              optuna: 3.2.0
2023-08-01 22:26:20,099:INFO:               skopt: Not installed
2023-08-01 22:26:20,099:INFO:              mlflow: Not installed
2023-08-01 22:26:20,099:INFO:              gradio: Not installed
2023-08-01 22:26:20,100:INFO:             fastapi: Not installed
2023-08-01 22:26:20,100:INFO:             uvicorn: Not installed
2023-08-01 22:26:20,100:INFO:              m2cgen: Not installed
2023-08-01 22:26:20,100:INFO:           evidently: Not installed
2023-08-01 22:26:20,100:INFO:               fugue: Not installed
2023-08-01 22:26:20,100:INFO:           streamlit: Not installed
2023-08-01 22:26:20,100:INFO:             prophet: Not installed
2023-08-01 22:26:20,100:INFO:None
2023-08-01 22:26:20,100:INFO:Set up data.
2023-08-01 22:26:20,115:INFO:Set up train/test split.
2023-08-01 22:26:20,126:INFO:Set up index.
2023-08-01 22:26:20,127:INFO:Set up folding strategy.
2023-08-01 22:26:20,127:INFO:Assigning column types.
2023-08-01 22:26:20,133:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-01 22:26:20,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,398:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,399:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,443:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-01 22:26:20,520:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,654:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-01 22:26:20,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,710:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-01 22:26:20,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,971:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:20,975:INFO:Preparing preprocessing pipeline...
2023-08-01 22:26:20,977:INFO:Set up simple imputation.
2023-08-01 22:26:20,982:INFO:Set up encoding of categorical features.
2023-08-01 22:26:20,982:INFO:Set up removing multicollinearity.
2023-08-01 22:26:21,232:INFO:Finished creating preprocessing pipeline.
2023-08-01 22:26:21,250:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strateg...
                                             'reserved_room_type'],
                                    transformer=OneHotEncoder(cols=['market_segment',
                                                                    'deposit_type',
                                                                    'reserved_room_type'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8)))],
         verbose=False)
2023-08-01 22:26:21,250:INFO:Creating final display dataframe.
2023-08-01 22:26:21,512:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 24)
5   Transformed train set shape        (6508, 24)
6    Transformed test set shape        (1628, 24)
7               Ignore features                 3
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16     Remove multicollinearity              True
17  Multicollinearity threshold               0.8
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              baff
2023-08-01 22:26:21,698:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:21,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:21,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:21,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-01 22:26:21,820:INFO:setup() successfully completed in 3.72s...............
2023-08-01 22:26:32,600:INFO:Initializing compare_models()
2023-08-01 22:26:32,601:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-01 22:26:32,601:INFO:Checking exceptions
2023-08-01 22:26:32,612:INFO:Preparing display monitor
2023-08-01 22:26:32,682:INFO:Initializing Logistic Regression
2023-08-01 22:26:32,682:INFO:Total runtime is 0.0 minutes
2023-08-01 22:26:32,691:INFO:SubProcess create_model() called ==================================
2023-08-01 22:26:32,692:INFO:Initializing create_model()
2023-08-01 22:26:32,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:26:32,693:INFO:Checking exceptions
2023-08-01 22:26:32,694:INFO:Importing libraries
2023-08-01 22:26:32,694:INFO:Copying training dataset
2023-08-01 22:26:32,712:INFO:Defining folds
2023-08-01 22:26:32,712:INFO:Declaring metric variables
2023-08-01 22:26:32,723:INFO:Importing untrained model
2023-08-01 22:26:32,737:INFO:Logistic Regression Imported successfully
2023-08-01 22:26:32,763:INFO:Starting cross validation
2023-08-01 22:26:32,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:27:03,185:INFO:Calculating mean and std
2023-08-01 22:27:03,187:INFO:Creating metrics dataframe
2023-08-01 22:27:05,908:INFO:Uploading results into container
2023-08-01 22:27:05,909:INFO:Uploading model into container now
2023-08-01 22:27:05,911:INFO:_master_model_container: 1
2023-08-01 22:27:05,912:INFO:_display_container: 2
2023-08-01 22:27:05,912:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-01 22:27:05,913:INFO:create_model() successfully completed......................................
2023-08-01 22:27:05,998:INFO:SubProcess create_model() end ==================================
2023-08-01 22:27:05,998:INFO:Creating metrics dataframe
2023-08-01 22:27:06,013:INFO:Initializing K Neighbors Classifier
2023-08-01 22:27:06,014:INFO:Total runtime is 0.5555335481961569 minutes
2023-08-01 22:27:06,020:INFO:SubProcess create_model() called ==================================
2023-08-01 22:27:06,020:INFO:Initializing create_model()
2023-08-01 22:27:06,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:27:06,021:INFO:Checking exceptions
2023-08-01 22:27:06,021:INFO:Importing libraries
2023-08-01 22:27:06,021:INFO:Copying training dataset
2023-08-01 22:27:06,034:INFO:Defining folds
2023-08-01 22:27:06,034:INFO:Declaring metric variables
2023-08-01 22:27:06,041:INFO:Importing untrained model
2023-08-01 22:27:06,048:INFO:K Neighbors Classifier Imported successfully
2023-08-01 22:27:06,079:INFO:Starting cross validation
2023-08-01 22:27:06,097:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:27:25,855:INFO:Calculating mean and std
2023-08-01 22:27:25,857:INFO:Creating metrics dataframe
2023-08-01 22:27:28,591:INFO:Uploading results into container
2023-08-01 22:27:28,593:INFO:Uploading model into container now
2023-08-01 22:27:28,593:INFO:_master_model_container: 2
2023-08-01 22:27:28,594:INFO:_display_container: 2
2023-08-01 22:27:28,596:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-01 22:27:28,596:INFO:create_model() successfully completed......................................
2023-08-01 22:27:28,671:INFO:SubProcess create_model() end ==================================
2023-08-01 22:27:28,672:INFO:Creating metrics dataframe
2023-08-01 22:27:28,689:INFO:Initializing Naive Bayes
2023-08-01 22:27:28,690:INFO:Total runtime is 0.9334668914477031 minutes
2023-08-01 22:27:28,698:INFO:SubProcess create_model() called ==================================
2023-08-01 22:27:28,698:INFO:Initializing create_model()
2023-08-01 22:27:28,699:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:27:28,699:INFO:Checking exceptions
2023-08-01 22:27:28,699:INFO:Importing libraries
2023-08-01 22:27:28,699:INFO:Copying training dataset
2023-08-01 22:27:28,713:INFO:Defining folds
2023-08-01 22:27:28,713:INFO:Declaring metric variables
2023-08-01 22:27:28,723:INFO:Importing untrained model
2023-08-01 22:27:28,735:INFO:Naive Bayes Imported successfully
2023-08-01 22:27:28,756:INFO:Starting cross validation
2023-08-01 22:27:28,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:27:47,708:INFO:Calculating mean and std
2023-08-01 22:27:47,709:INFO:Creating metrics dataframe
2023-08-01 22:27:50,552:INFO:Uploading results into container
2023-08-01 22:27:50,553:INFO:Uploading model into container now
2023-08-01 22:27:50,554:INFO:_master_model_container: 3
2023-08-01 22:27:50,554:INFO:_display_container: 2
2023-08-01 22:27:50,554:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-01 22:27:50,555:INFO:create_model() successfully completed......................................
2023-08-01 22:27:50,642:INFO:SubProcess create_model() end ==================================
2023-08-01 22:27:50,642:INFO:Creating metrics dataframe
2023-08-01 22:27:50,665:INFO:Initializing Decision Tree Classifier
2023-08-01 22:27:50,666:INFO:Total runtime is 1.2997436364491781 minutes
2023-08-01 22:27:50,675:INFO:SubProcess create_model() called ==================================
2023-08-01 22:27:50,675:INFO:Initializing create_model()
2023-08-01 22:27:50,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:27:50,676:INFO:Checking exceptions
2023-08-01 22:27:50,676:INFO:Importing libraries
2023-08-01 22:27:50,676:INFO:Copying training dataset
2023-08-01 22:27:50,691:INFO:Defining folds
2023-08-01 22:27:50,691:INFO:Declaring metric variables
2023-08-01 22:27:50,701:INFO:Importing untrained model
2023-08-01 22:27:50,713:INFO:Decision Tree Classifier Imported successfully
2023-08-01 22:27:50,737:INFO:Starting cross validation
2023-08-01 22:27:50,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:28:10,027:INFO:Calculating mean and std
2023-08-01 22:28:10,029:INFO:Creating metrics dataframe
2023-08-01 22:28:12,857:INFO:Uploading results into container
2023-08-01 22:28:12,858:INFO:Uploading model into container now
2023-08-01 22:28:12,859:INFO:_master_model_container: 4
2023-08-01 22:28:12,859:INFO:_display_container: 2
2023-08-01 22:28:12,860:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-01 22:28:12,860:INFO:create_model() successfully completed......................................
2023-08-01 22:28:12,942:INFO:SubProcess create_model() end ==================================
2023-08-01 22:28:12,942:INFO:Creating metrics dataframe
2023-08-01 22:28:12,973:INFO:Initializing SVM - Linear Kernel
2023-08-01 22:28:12,973:INFO:Total runtime is 1.6715266187985738 minutes
2023-08-01 22:28:12,982:INFO:SubProcess create_model() called ==================================
2023-08-01 22:28:12,983:INFO:Initializing create_model()
2023-08-01 22:28:12,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:28:12,983:INFO:Checking exceptions
2023-08-01 22:28:12,983:INFO:Importing libraries
2023-08-01 22:28:12,983:INFO:Copying training dataset
2023-08-01 22:28:12,999:INFO:Defining folds
2023-08-01 22:28:12,999:INFO:Declaring metric variables
2023-08-01 22:28:13,007:INFO:Importing untrained model
2023-08-01 22:28:13,018:INFO:SVM - Linear Kernel Imported successfully
2023-08-01 22:28:13,042:INFO:Starting cross validation
2023-08-01 22:28:13,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:28:13,530:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,532:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,555:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,584:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,616:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,618:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,623:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:13,687:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:19,902:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:19,908:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-01 22:28:33,227:INFO:Calculating mean and std
2023-08-01 22:28:33,228:INFO:Creating metrics dataframe
2023-08-01 22:28:36,070:INFO:Uploading results into container
2023-08-01 22:28:36,072:INFO:Uploading model into container now
2023-08-01 22:28:36,073:INFO:_master_model_container: 5
2023-08-01 22:28:36,074:INFO:_display_container: 2
2023-08-01 22:28:36,075:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-01 22:28:36,076:INFO:create_model() successfully completed......................................
2023-08-01 22:28:36,157:INFO:SubProcess create_model() end ==================================
2023-08-01 22:28:36,157:INFO:Creating metrics dataframe
2023-08-01 22:28:36,175:INFO:Initializing Ridge Classifier
2023-08-01 22:28:36,175:INFO:Total runtime is 2.0582269549369814 minutes
2023-08-01 22:28:36,183:INFO:SubProcess create_model() called ==================================
2023-08-01 22:28:36,184:INFO:Initializing create_model()
2023-08-01 22:28:36,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:28:36,184:INFO:Checking exceptions
2023-08-01 22:28:36,184:INFO:Importing libraries
2023-08-01 22:28:36,184:INFO:Copying training dataset
2023-08-01 22:28:36,198:INFO:Defining folds
2023-08-01 22:28:36,198:INFO:Declaring metric variables
2023-08-01 22:28:36,206:INFO:Importing untrained model
2023-08-01 22:28:36,218:INFO:Ridge Classifier Imported successfully
2023-08-01 22:28:36,240:INFO:Starting cross validation
2023-08-01 22:28:36,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:28:36,699:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,734:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,740:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,757:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,757:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,783:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,809:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:36,838:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:42,952:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:42,953:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-01 22:28:56,250:INFO:Calculating mean and std
2023-08-01 22:28:56,252:INFO:Creating metrics dataframe
2023-08-01 22:28:59,087:INFO:Uploading results into container
2023-08-01 22:28:59,088:INFO:Uploading model into container now
2023-08-01 22:28:59,089:INFO:_master_model_container: 6
2023-08-01 22:28:59,089:INFO:_display_container: 2
2023-08-01 22:28:59,089:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-01 22:28:59,090:INFO:create_model() successfully completed......................................
2023-08-01 22:28:59,179:INFO:SubProcess create_model() end ==================================
2023-08-01 22:28:59,179:INFO:Creating metrics dataframe
2023-08-01 22:28:59,206:INFO:Initializing Random Forest Classifier
2023-08-01 22:28:59,206:INFO:Total runtime is 2.44206885099411 minutes
2023-08-01 22:28:59,214:INFO:SubProcess create_model() called ==================================
2023-08-01 22:28:59,215:INFO:Initializing create_model()
2023-08-01 22:28:59,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:28:59,216:INFO:Checking exceptions
2023-08-01 22:28:59,217:INFO:Importing libraries
2023-08-01 22:28:59,217:INFO:Copying training dataset
2023-08-01 22:28:59,234:INFO:Defining folds
2023-08-01 22:28:59,234:INFO:Declaring metric variables
2023-08-01 22:28:59,244:INFO:Importing untrained model
2023-08-01 22:28:59,256:INFO:Random Forest Classifier Imported successfully
2023-08-01 22:28:59,276:INFO:Starting cross validation
2023-08-01 22:28:59,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:29:19,526:INFO:Calculating mean and std
2023-08-01 22:29:19,528:INFO:Creating metrics dataframe
2023-08-01 22:29:22,358:INFO:Uploading results into container
2023-08-01 22:29:22,360:INFO:Uploading model into container now
2023-08-01 22:29:22,361:INFO:_master_model_container: 7
2023-08-01 22:29:22,361:INFO:_display_container: 2
2023-08-01 22:29:22,362:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-01 22:29:22,362:INFO:create_model() successfully completed......................................
2023-08-01 22:29:22,448:INFO:SubProcess create_model() end ==================================
2023-08-01 22:29:22,449:INFO:Creating metrics dataframe
2023-08-01 22:29:22,466:INFO:Initializing Quadratic Discriminant Analysis
2023-08-01 22:29:22,466:INFO:Total runtime is 2.8297356883684794 minutes
2023-08-01 22:29:22,472:INFO:SubProcess create_model() called ==================================
2023-08-01 22:29:22,473:INFO:Initializing create_model()
2023-08-01 22:29:22,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:29:22,473:INFO:Checking exceptions
2023-08-01 22:29:22,473:INFO:Importing libraries
2023-08-01 22:29:22,473:INFO:Copying training dataset
2023-08-01 22:29:22,482:INFO:Defining folds
2023-08-01 22:29:22,483:INFO:Declaring metric variables
2023-08-01 22:29:22,490:INFO:Importing untrained model
2023-08-01 22:29:22,496:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-01 22:29:22,514:INFO:Starting cross validation
2023-08-01 22:29:22,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:29:22,877:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,877:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,898:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,930:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,934:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,955:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,956:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,956:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,957:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:22,963:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,964:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,967:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:22,976:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:22,988:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,989:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:22,990:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,001:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,002:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,003:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,008:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,009:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,011:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,028:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,029:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,029:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,031:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,031:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,032:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,035:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:23,038:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,039:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,040:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,043:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,050:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,056:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,056:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,057:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,065:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,067:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,068:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,071:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:29:23,075:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,075:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,076:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,078:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,090:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,101:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,102:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,103:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,109:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,109:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,110:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,112:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,121:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,126:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,127:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,128:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,162:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,163:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,164:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,175:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,204:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,205:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:23,206:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:23,218:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:23,245:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:29:29,065:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:29,101:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-01 22:29:29,142:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,142:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,142:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:29,188:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,189:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,189:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:29,192:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:29,324:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,325:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,325:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:29,366:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,367:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-08-01 22:29:29,367:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-08-01 22:29:29,370:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-08-01 22:29:41,668:INFO:Calculating mean and std
2023-08-01 22:29:41,669:INFO:Creating metrics dataframe
2023-08-01 22:29:44,479:INFO:Uploading results into container
2023-08-01 22:29:44,481:INFO:Uploading model into container now
2023-08-01 22:29:44,482:INFO:_master_model_container: 8
2023-08-01 22:29:44,482:INFO:_display_container: 2
2023-08-01 22:29:44,482:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-01 22:29:44,482:INFO:create_model() successfully completed......................................
2023-08-01 22:29:44,560:INFO:SubProcess create_model() end ==================================
2023-08-01 22:29:44,560:INFO:Creating metrics dataframe
2023-08-01 22:29:44,580:INFO:Initializing Ada Boost Classifier
2023-08-01 22:29:44,581:INFO:Total runtime is 3.1983117341995237 minutes
2023-08-01 22:29:44,589:INFO:SubProcess create_model() called ==================================
2023-08-01 22:29:44,590:INFO:Initializing create_model()
2023-08-01 22:29:44,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:29:44,590:INFO:Checking exceptions
2023-08-01 22:29:44,591:INFO:Importing libraries
2023-08-01 22:29:44,591:INFO:Copying training dataset
2023-08-01 22:29:44,604:INFO:Defining folds
2023-08-01 22:29:44,604:INFO:Declaring metric variables
2023-08-01 22:29:44,612:INFO:Importing untrained model
2023-08-01 22:29:44,649:INFO:Ada Boost Classifier Imported successfully
2023-08-01 22:29:44,695:INFO:Starting cross validation
2023-08-01 22:29:44,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:30:04,048:INFO:Calculating mean and std
2023-08-01 22:30:04,051:INFO:Creating metrics dataframe
2023-08-01 22:30:06,872:INFO:Uploading results into container
2023-08-01 22:30:06,874:INFO:Uploading model into container now
2023-08-01 22:30:06,874:INFO:_master_model_container: 9
2023-08-01 22:30:06,874:INFO:_display_container: 2
2023-08-01 22:30:06,875:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-01 22:30:06,875:INFO:create_model() successfully completed......................................
2023-08-01 22:30:06,962:INFO:SubProcess create_model() end ==================================
2023-08-01 22:30:06,963:INFO:Creating metrics dataframe
2023-08-01 22:30:06,991:INFO:Initializing Gradient Boosting Classifier
2023-08-01 22:30:06,991:INFO:Total runtime is 3.571811759471893 minutes
2023-08-01 22:30:06,999:INFO:SubProcess create_model() called ==================================
2023-08-01 22:30:07,000:INFO:Initializing create_model()
2023-08-01 22:30:07,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:30:07,000:INFO:Checking exceptions
2023-08-01 22:30:07,000:INFO:Importing libraries
2023-08-01 22:30:07,000:INFO:Copying training dataset
2023-08-01 22:30:07,016:INFO:Defining folds
2023-08-01 22:30:07,016:INFO:Declaring metric variables
2023-08-01 22:30:07,026:INFO:Importing untrained model
2023-08-01 22:30:07,036:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:30:07,058:INFO:Starting cross validation
2023-08-01 22:30:07,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:30:27,364:INFO:Calculating mean and std
2023-08-01 22:30:27,366:INFO:Creating metrics dataframe
2023-08-01 22:30:30,243:INFO:Uploading results into container
2023-08-01 22:30:30,244:INFO:Uploading model into container now
2023-08-01 22:30:30,245:INFO:_master_model_container: 10
2023-08-01 22:30:30,245:INFO:_display_container: 2
2023-08-01 22:30:30,246:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:30:30,247:INFO:create_model() successfully completed......................................
2023-08-01 22:30:30,338:INFO:SubProcess create_model() end ==================================
2023-08-01 22:30:30,339:INFO:Creating metrics dataframe
2023-08-01 22:30:30,366:INFO:Initializing Linear Discriminant Analysis
2023-08-01 22:30:30,366:INFO:Total runtime is 3.961395053068797 minutes
2023-08-01 22:30:30,377:INFO:SubProcess create_model() called ==================================
2023-08-01 22:30:30,378:INFO:Initializing create_model()
2023-08-01 22:30:30,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:30:30,378:INFO:Checking exceptions
2023-08-01 22:30:30,378:INFO:Importing libraries
2023-08-01 22:30:30,378:INFO:Copying training dataset
2023-08-01 22:30:30,392:INFO:Defining folds
2023-08-01 22:30:30,392:INFO:Declaring metric variables
2023-08-01 22:30:30,401:INFO:Importing untrained model
2023-08-01 22:30:30,412:INFO:Linear Discriminant Analysis Imported successfully
2023-08-01 22:30:30,429:INFO:Starting cross validation
2023-08-01 22:30:30,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:30:52,502:INFO:Calculating mean and std
2023-08-01 22:30:52,504:INFO:Creating metrics dataframe
2023-08-01 22:30:55,496:INFO:Uploading results into container
2023-08-01 22:30:55,497:INFO:Uploading model into container now
2023-08-01 22:30:55,498:INFO:_master_model_container: 11
2023-08-01 22:30:55,498:INFO:_display_container: 2
2023-08-01 22:30:55,499:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-01 22:30:55,499:INFO:create_model() successfully completed......................................
2023-08-01 22:30:55,587:INFO:SubProcess create_model() end ==================================
2023-08-01 22:30:55,588:INFO:Creating metrics dataframe
2023-08-01 22:30:55,612:INFO:Initializing Extra Trees Classifier
2023-08-01 22:30:55,612:INFO:Total runtime is 4.382172024250031 minutes
2023-08-01 22:30:55,621:INFO:SubProcess create_model() called ==================================
2023-08-01 22:30:55,622:INFO:Initializing create_model()
2023-08-01 22:30:55,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:30:55,622:INFO:Checking exceptions
2023-08-01 22:30:55,622:INFO:Importing libraries
2023-08-01 22:30:55,622:INFO:Copying training dataset
2023-08-01 22:30:55,641:INFO:Defining folds
2023-08-01 22:30:55,641:INFO:Declaring metric variables
2023-08-01 22:30:55,649:INFO:Importing untrained model
2023-08-01 22:30:55,661:INFO:Extra Trees Classifier Imported successfully
2023-08-01 22:30:55,683:INFO:Starting cross validation
2023-08-01 22:30:55,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:31:19,404:INFO:Calculating mean and std
2023-08-01 22:31:19,407:INFO:Creating metrics dataframe
2023-08-01 22:31:22,277:INFO:Uploading results into container
2023-08-01 22:31:22,278:INFO:Uploading model into container now
2023-08-01 22:31:22,279:INFO:_master_model_container: 12
2023-08-01 22:31:22,279:INFO:_display_container: 2
2023-08-01 22:31:22,280:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-01 22:31:22,281:INFO:create_model() successfully completed......................................
2023-08-01 22:31:22,366:INFO:SubProcess create_model() end ==================================
2023-08-01 22:31:22,366:INFO:Creating metrics dataframe
2023-08-01 22:31:22,396:INFO:Initializing Light Gradient Boosting Machine
2023-08-01 22:31:22,396:INFO:Total runtime is 4.828572042783102 minutes
2023-08-01 22:31:22,406:INFO:SubProcess create_model() called ==================================
2023-08-01 22:31:22,406:INFO:Initializing create_model()
2023-08-01 22:31:22,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:31:22,407:INFO:Checking exceptions
2023-08-01 22:31:22,408:INFO:Importing libraries
2023-08-01 22:31:22,408:INFO:Copying training dataset
2023-08-01 22:31:22,418:INFO:Defining folds
2023-08-01 22:31:22,418:INFO:Declaring metric variables
2023-08-01 22:31:22,426:INFO:Importing untrained model
2023-08-01 22:31:22,434:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-01 22:31:22,451:INFO:Starting cross validation
2023-08-01 22:31:22,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:31:42,319:INFO:Calculating mean and std
2023-08-01 22:31:42,320:INFO:Creating metrics dataframe
2023-08-01 22:31:45,071:INFO:Uploading results into container
2023-08-01 22:31:45,073:INFO:Uploading model into container now
2023-08-01 22:31:45,074:INFO:_master_model_container: 13
2023-08-01 22:31:45,074:INFO:_display_container: 2
2023-08-01 22:31:45,076:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-01 22:31:45,076:INFO:create_model() successfully completed......................................
2023-08-01 22:31:45,163:INFO:SubProcess create_model() end ==================================
2023-08-01 22:31:45,163:INFO:Creating metrics dataframe
2023-08-01 22:31:45,191:INFO:Initializing Dummy Classifier
2023-08-01 22:31:45,191:INFO:Total runtime is 5.208488468329112 minutes
2023-08-01 22:31:45,200:INFO:SubProcess create_model() called ==================================
2023-08-01 22:31:45,201:INFO:Initializing create_model()
2023-08-01 22:31:45,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BD5FABB0>, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:31:45,201:INFO:Checking exceptions
2023-08-01 22:31:45,201:INFO:Importing libraries
2023-08-01 22:31:45,201:INFO:Copying training dataset
2023-08-01 22:31:45,217:INFO:Defining folds
2023-08-01 22:31:45,218:INFO:Declaring metric variables
2023-08-01 22:31:45,227:INFO:Importing untrained model
2023-08-01 22:31:45,236:INFO:Dummy Classifier Imported successfully
2023-08-01 22:31:45,251:INFO:Starting cross validation
2023-08-01 22:31:45,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:31:45,773:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,800:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,831:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,842:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,868:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,875:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,920:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:45,943:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:52,068:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:31:52,151:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-01 22:32:05,180:INFO:Calculating mean and std
2023-08-01 22:32:05,182:INFO:Creating metrics dataframe
2023-08-01 22:32:08,049:INFO:Uploading results into container
2023-08-01 22:32:08,050:INFO:Uploading model into container now
2023-08-01 22:32:08,051:INFO:_master_model_container: 14
2023-08-01 22:32:08,051:INFO:_display_container: 2
2023-08-01 22:32:08,052:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-01 22:32:08,052:INFO:create_model() successfully completed......................................
2023-08-01 22:32:08,137:INFO:SubProcess create_model() end ==================================
2023-08-01 22:32:08,137:INFO:Creating metrics dataframe
2023-08-01 22:32:08,184:INFO:Initializing create_model()
2023-08-01 22:32:08,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:32:08,185:INFO:Checking exceptions
2023-08-01 22:32:08,188:INFO:Importing libraries
2023-08-01 22:32:08,188:INFO:Copying training dataset
2023-08-01 22:32:08,198:INFO:Defining folds
2023-08-01 22:32:08,198:INFO:Declaring metric variables
2023-08-01 22:32:08,198:INFO:Importing untrained model
2023-08-01 22:32:08,199:INFO:Declaring custom model
2023-08-01 22:32:08,200:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:32:08,203:INFO:Cross validation set to False
2023-08-01 22:32:08,203:INFO:Fitting Model
2023-08-01 22:32:10,480:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:32:10,480:INFO:create_model() successfully completed......................................
2023-08-01 22:32:10,611:INFO:_master_model_container: 14
2023-08-01 22:32:10,612:INFO:_display_container: 2
2023-08-01 22:32:10,612:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:32:10,613:INFO:compare_models() successfully completed......................................
2023-08-01 22:32:14,285:INFO:Initializing evaluate_model()
2023-08-01 22:32:14,285:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-01 22:32:14,316:INFO:Initializing plot_model()
2023-08-01 22:32:14,317:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, system=True)
2023-08-01 22:32:14,317:INFO:Checking exceptions
2023-08-01 22:32:14,323:INFO:Preloading libraries
2023-08-01 22:32:14,353:INFO:Copying training dataset
2023-08-01 22:32:14,353:INFO:Plot type: pipeline
2023-08-01 22:32:14,714:INFO:Visual Rendered Successfully
2023-08-01 22:32:14,796:INFO:plot_model() successfully completed......................................
2023-08-01 22:32:16,123:INFO:Initializing plot_model()
2023-08-01 22:32:16,124:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, system=True)
2023-08-01 22:32:16,124:INFO:Checking exceptions
2023-08-01 22:32:16,129:INFO:Preloading libraries
2023-08-01 22:32:16,142:INFO:Copying training dataset
2023-08-01 22:32:16,142:INFO:Plot type: threshold
2023-08-01 22:32:16,323:INFO:Fitting Model
2023-08-01 22:32:41,838:INFO:Scoring test/hold-out set
2023-08-01 22:32:42,618:INFO:Visual Rendered Successfully
2023-08-01 22:32:42,750:INFO:plot_model() successfully completed......................................
2023-08-01 22:32:55,130:INFO:Initializing create_model()
2023-08-01 22:32:55,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.31, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:32:55,131:INFO:Checking exceptions
2023-08-01 22:32:55,156:INFO:Importing libraries
2023-08-01 22:32:55,156:INFO:Copying training dataset
2023-08-01 22:32:55,168:INFO:Defining folds
2023-08-01 22:32:55,168:INFO:Declaring metric variables
2023-08-01 22:32:55,175:INFO:Importing untrained model
2023-08-01 22:32:55,182:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:32:55,198:INFO:Starting cross validation
2023-08-01 22:32:55,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:32:56,741:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:56,820:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:56,854:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:56,952:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:57,015:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:57,096:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:32:57,187:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:33:15,519:INFO:Calculating mean and std
2023-08-01 22:33:15,521:INFO:Creating metrics dataframe
2023-08-01 22:33:15,533:INFO:Finalizing model
2023-08-01 22:33:18,545:INFO:Uploading results into container
2023-08-01 22:33:18,547:INFO:Uploading model into container now
2023-08-01 22:33:18,565:INFO:_master_model_container: 15
2023-08-01 22:33:18,566:INFO:_display_container: 3
2023-08-01 22:33:18,568:INFO:CustomProbabilityThresholdClassifier(ccp_alpha=0.0,
                                     classifier=GradientBoostingClassifier(ccp_alpha=0.0,
                                                                           criterion='friedman_mse',
                                                                           init=None,
                                                                           learning_rate=0.1,
                                                                           loss='log_loss',
                                                                           max_depth=3,
                                                                           max_features=None,
                                                                           max_leaf_nodes=None,
                                                                           min_impurity_decrease=0.0,
                                                                           min_samples_leaf=1,
                                                                           min_samples_split=2,
                                                                           min_weight_fraction_leaf=0.0,
                                                                           n_estimators=100,
                                                                           n_iter_no_change=...
                                     criterion='friedman_mse', init=None,
                                     learning_rate=0.1, loss='log_loss',
                                     max_depth=3, max_features=None,
                                     max_leaf_nodes=None,
                                     min_impurity_decrease=0.0,
                                     min_samples_leaf=1, min_samples_split=2,
                                     min_weight_fraction_leaf=0.0,
                                     n_estimators=100, n_iter_no_change=None,
                                     probability_threshold=0.31,
                                     random_state=2020, subsample=1.0,
                                     tol=0.0001, validation_fraction=0.1,
                                     verbose=0, warm_start=False)
2023-08-01 22:33:18,568:INFO:create_model() successfully completed......................................
2023-08-01 22:33:31,674:INFO:Initializing tune_model()
2023-08-01 22:33:31,674:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=5, custom_grid=None, optimize=MCC, custom_scorer=None, search_library=optuna, search_algorithm=tpe, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>)
2023-08-01 22:33:31,674:INFO:Checking exceptions
2023-08-01 22:33:31,675:INFO:Soft dependency imported: optuna: 3.2.0
2023-08-01 22:33:32,513:INFO:Copying training dataset
2023-08-01 22:33:32,523:INFO:Checking base model
2023-08-01 22:33:32,524:INFO:Base model : Gradient Boosting Classifier
2023-08-01 22:33:32,535:INFO:Declaring metric variables
2023-08-01 22:33:32,546:INFO:Defining Hyperparameters
2023-08-01 22:33:32,735:INFO:Tuning with n_jobs=-1
2023-08-01 22:33:32,737:INFO:Initializing optuna.integration.OptunaSearchCV
2023-08-01 22:36:34,088:INFO:best_params: {'actual_estimator__n_estimators': 138, 'actual_estimator__learning_rate': 0.1435730096602507, 'actual_estimator__subsample': 0.657994763593881, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__max_depth': 7, 'actual_estimator__min_impurity_decrease': 2.022564124790628e-05, 'actual_estimator__max_features': 0.7331100775527036}
2023-08-01 22:36:34,088:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-08-01 22:36:34,091:WARNING:Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2668, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-08-01 22:36:34,092:INFO:Hyperparameter search completed
2023-08-01 22:36:34,092:INFO:SubProcess create_model() called ==================================
2023-08-01 22:36:34,093:INFO:Initializing create_model()
2023-08-01 22:36:34,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000275BE03FD00>, model_only=True, return_train_score=False, kwargs={'n_estimators': 138, 'learning_rate': 0.1435730096602507, 'subsample': 0.657994763593881, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 7, 'min_impurity_decrease': 2.022564124790628e-05, 'max_features': 0.7331100775527036})
2023-08-01 22:36:34,094:INFO:Checking exceptions
2023-08-01 22:36:34,094:INFO:Importing libraries
2023-08-01 22:36:34,094:INFO:Copying training dataset
2023-08-01 22:36:34,108:INFO:Defining folds
2023-08-01 22:36:34,108:INFO:Declaring metric variables
2023-08-01 22:36:34,115:INFO:Importing untrained model
2023-08-01 22:36:34,115:INFO:Declaring custom model
2023-08-01 22:36:34,125:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:36:34,143:INFO:Starting cross validation
2023-08-01 22:36:34,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:36:36,487:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:36,511:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:36,641:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:36,762:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:36,799:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:37,002:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:37,125:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:37,299:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:36:49,511:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-01 22:37:09,998:INFO:Calculating mean and std
2023-08-01 22:37:10,000:INFO:Creating metrics dataframe
2023-08-01 22:37:10,016:INFO:Finalizing model
2023-08-01 22:37:16,825:INFO:Uploading results into container
2023-08-01 22:37:16,827:INFO:Uploading model into container now
2023-08-01 22:37:16,830:INFO:_master_model_container: 16
2023-08-01 22:37:16,831:INFO:_display_container: 4
2023-08-01 22:37:16,833:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1435730096602507, loss='log_loss',
                           max_depth=7, max_features=0.7331100775527036,
                           max_leaf_nodes=None,
                           min_impurity_decrease=2.022564124790628e-05,
                           min_samples_leaf=5, min_samples_split=3,
                           min_weight_fraction_leaf=0.0, n_estimators=138,
                           n_iter_no_change=None, random_state=2020,
                           subsample=0.657994763593881, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:37:16,834:INFO:create_model() successfully completed......................................
2023-08-01 22:37:17,108:INFO:SubProcess create_model() end ==================================
2023-08-01 22:37:17,109:INFO:choose_better activated
2023-08-01 22:37:17,127:INFO:SubProcess create_model() called ==================================
2023-08-01 22:37:17,129:INFO:Initializing create_model()
2023-08-01 22:37:17,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002758CA85610>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-01 22:37:17,130:INFO:Checking exceptions
2023-08-01 22:37:17,139:INFO:Importing libraries
2023-08-01 22:37:17,139:INFO:Copying training dataset
2023-08-01 22:37:17,159:INFO:Defining folds
2023-08-01 22:37:17,159:INFO:Declaring metric variables
2023-08-01 22:37:17,160:INFO:Importing untrained model
2023-08-01 22:37:17,160:INFO:Declaring custom model
2023-08-01 22:37:17,163:INFO:Gradient Boosting Classifier Imported successfully
2023-08-01 22:37:17,163:INFO:Starting cross validation
2023-08-01 22:37:17,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-01 22:38:10,244:INFO:Calculating mean and std
2023-08-01 22:38:10,249:INFO:Creating metrics dataframe
2023-08-01 22:38:10,266:INFO:Finalizing model
2023-08-01 22:38:15,485:INFO:Uploading results into container
2023-08-01 22:38:15,486:INFO:Uploading model into container now
2023-08-01 22:38:15,487:INFO:_master_model_container: 17
2023-08-01 22:38:15,487:INFO:_display_container: 5
2023-08-01 22:38:15,488:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:38:15,488:INFO:create_model() successfully completed......................................
2023-08-01 22:38:15,624:INFO:SubProcess create_model() end ==================================
2023-08-01 22:38:15,626:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for MCC is 0.3014
2023-08-01 22:38:15,628:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1435730096602507, loss='log_loss',
                           max_depth=7, max_features=0.7331100775527036,
                           max_leaf_nodes=None,
                           min_impurity_decrease=2.022564124790628e-05,
                           min_samples_leaf=5, min_samples_split=3,
                           min_weight_fraction_leaf=0.0, n_estimators=138,
                           n_iter_no_change=None, random_state=2020,
                           subsample=0.657994763593881, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for MCC is 0.29
2023-08-01 22:38:15,629:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-01 22:38:15,629:INFO:choose_better completed
2023-08-01 22:38:15,630:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-01 22:38:15,677:INFO:_master_model_container: 17
2023-08-01 22:38:15,678:INFO:_display_container: 4
2023-08-01 22:38:15,679:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-01 22:38:15,680:INFO:tune_model() successfully completed......................................
2023-08-02 18:21:19,646:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-02 18:21:19,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-02 18:21:19,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-02 18:21:19,662:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-02 18:21:38,219:INFO:PyCaret ClassificationExperiment
2023-08-02 18:21:38,220:INFO:Logging name: clf-default-name
2023-08-02 18:21:38,220:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-02 18:21:38,220:INFO:version 3.0.4
2023-08-02 18:21:38,220:INFO:Initializing setup()
2023-08-02 18:21:38,220:INFO:self.USI: be95
2023-08-02 18:21:38,220:INFO:self._variable_keys: {'target_param', 'fold_shuffle_param', 'is_multiclass', 'data', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'seed', 'exp_id', 'pipeline', 'fix_imbalance', 'y', 'X', '_available_plots', 'X_train', 'memory', 'n_jobs_param', 'X_test', 'fold_groups_param', 'idx', '_ml_usecase', 'fold_generator', 'logging_param', 'html_param', 'log_plots_param', 'y_train', 'y_test', 'exp_name_log'}
2023-08-02 18:21:38,220:INFO:Checking environment
2023-08-02 18:21:38,220:INFO:python_version: 3.9.13
2023-08-02 18:21:38,220:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-02 18:21:38,220:INFO:machine: AMD64
2023-08-02 18:21:38,220:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-02 18:21:38,237:INFO:Memory: svmem(total=17055166464, available=9009491968, percent=47.2, used=8045674496, free=9009491968)
2023-08-02 18:21:38,237:INFO:Physical Core: 4
2023-08-02 18:21:38,237:INFO:Logical Core: 8
2023-08-02 18:21:38,237:INFO:Checking libraries
2023-08-02 18:21:38,237:INFO:System:
2023-08-02 18:21:38,237:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-02 18:21:38,238:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-02 18:21:38,238:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-02 18:21:38,238:INFO:PyCaret required dependencies:
2023-08-02 18:21:38,241:INFO:                 pip: 22.0.4
2023-08-02 18:21:38,241:INFO:          setuptools: 58.1.0
2023-08-02 18:21:38,241:INFO:             pycaret: 3.0.4
2023-08-02 18:21:38,241:INFO:             IPython: 8.13.1
2023-08-02 18:21:38,241:INFO:          ipywidgets: 7.8.0
2023-08-02 18:21:38,241:INFO:                tqdm: 4.65.0
2023-08-02 18:21:38,241:INFO:               numpy: 1.23.0
2023-08-02 18:21:38,241:INFO:              pandas: 1.5.3
2023-08-02 18:21:38,241:INFO:              jinja2: 3.1.2
2023-08-02 18:21:38,241:INFO:               scipy: 1.10.1
2023-08-02 18:21:38,241:INFO:              joblib: 1.2.0
2023-08-02 18:21:38,241:INFO:             sklearn: 1.2.2
2023-08-02 18:21:38,241:INFO:                pyod: 1.1.0
2023-08-02 18:21:38,241:INFO:            imblearn: 0.11.0
2023-08-02 18:21:38,242:INFO:   category_encoders: 2.6.1
2023-08-02 18:21:38,242:INFO:            lightgbm: 3.3.5
2023-08-02 18:21:38,242:INFO:               numba: 0.57.1
2023-08-02 18:21:38,242:INFO:            requests: 2.31.0
2023-08-02 18:21:38,242:INFO:          matplotlib: 3.7.1
2023-08-02 18:21:38,242:INFO:          scikitplot: 0.3.7
2023-08-02 18:21:38,242:INFO:         yellowbrick: 1.5
2023-08-02 18:21:38,242:INFO:              plotly: 5.15.0
2023-08-02 18:21:38,242:INFO:    plotly-resampler: Not installed
2023-08-02 18:21:38,242:INFO:             kaleido: 0.2.1
2023-08-02 18:21:38,242:INFO:           schemdraw: 0.15
2023-08-02 18:21:38,242:INFO:         statsmodels: 0.14.0
2023-08-02 18:21:38,242:INFO:              sktime: 0.20.0
2023-08-02 18:21:38,242:INFO:               tbats: 1.1.3
2023-08-02 18:21:38,242:INFO:            pmdarima: 2.0.3
2023-08-02 18:21:38,242:INFO:              psutil: 5.9.5
2023-08-02 18:21:38,242:INFO:          markupsafe: 2.1.3
2023-08-02 18:21:38,242:INFO:             pickle5: Not installed
2023-08-02 18:21:38,243:INFO:         cloudpickle: 2.2.1
2023-08-02 18:21:38,243:INFO:         deprecation: 2.1.0
2023-08-02 18:21:38,243:INFO:              xxhash: 3.2.0
2023-08-02 18:21:38,243:INFO:           wurlitzer: Not installed
2023-08-02 18:21:38,243:INFO:PyCaret optional dependencies:
2023-08-02 18:21:38,259:INFO:                shap: Not installed
2023-08-02 18:21:38,259:INFO:           interpret: Not installed
2023-08-02 18:21:38,259:INFO:                umap: 0.5.3
2023-08-02 18:21:38,259:INFO:    pandas_profiling: 4.3.1
2023-08-02 18:21:38,259:INFO:  explainerdashboard: Not installed
2023-08-02 18:21:38,259:INFO:             autoviz: Not installed
2023-08-02 18:21:38,260:INFO:           fairlearn: Not installed
2023-08-02 18:21:38,260:INFO:          deepchecks: Not installed
2023-08-02 18:21:38,260:INFO:             xgboost: Not installed
2023-08-02 18:21:38,260:INFO:            catboost: Not installed
2023-08-02 18:21:38,260:INFO:              kmodes: Not installed
2023-08-02 18:21:38,260:INFO:             mlxtend: 0.22.0
2023-08-02 18:21:38,260:INFO:       statsforecast: Not installed
2023-08-02 18:21:38,260:INFO:        tune_sklearn: Not installed
2023-08-02 18:21:38,260:INFO:                 ray: Not installed
2023-08-02 18:21:38,260:INFO:            hyperopt: Not installed
2023-08-02 18:21:38,260:INFO:              optuna: 3.2.0
2023-08-02 18:21:38,260:INFO:               skopt: Not installed
2023-08-02 18:21:38,260:INFO:              mlflow: 2.5.0
2023-08-02 18:21:38,260:INFO:              gradio: Not installed
2023-08-02 18:21:38,260:INFO:             fastapi: Not installed
2023-08-02 18:21:38,260:INFO:             uvicorn: Not installed
2023-08-02 18:21:38,260:INFO:              m2cgen: Not installed
2023-08-02 18:21:38,260:INFO:           evidently: Not installed
2023-08-02 18:21:38,260:INFO:               fugue: Not installed
2023-08-02 18:21:38,260:INFO:           streamlit: 1.25.0
2023-08-02 18:21:38,261:INFO:             prophet: Not installed
2023-08-02 18:21:38,261:INFO:None
2023-08-02 18:21:38,261:INFO:Set up data.
2023-08-02 18:21:38,272:INFO:Set up train/test split.
2023-08-02 18:21:38,280:INFO:Set up index.
2023-08-02 18:21:38,280:INFO:Set up folding strategy.
2023-08-02 18:21:38,280:INFO:Assigning column types.
2023-08-02 18:21:38,284:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-02 18:21:38,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,704:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,745:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-02 18:21:38,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:21:38,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:38,981:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-02 18:21:39,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:39,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:39,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:39,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:39,231:INFO:Preparing preprocessing pipeline...
2023-08-02 18:21:39,257:INFO:Set up simple imputation.
2023-08-02 18:21:39,261:INFO:Set up encoding of categorical features.
2023-08-02 18:21:39,261:INFO:Set up removing multicollinearity.
2023-08-02 18:21:39,261:INFO:Set up feature normalization.
2023-08-02 18:21:39,507:INFO:Finished creating preprocessing pipeline.
2023-08-02 18:21:39,533:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                                handle_missing='value',
                                                                handle_unknown='value',
                                                                random_state=None,
                                                                return_df=True,
                                                                sigma=None,
                                                                verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-02 18:21:39,533:INFO:Creating final display dataframe.
2023-08-02 18:21:40,051:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 10)  
5                                          (6508, 10)  
6                                          (1628, 10)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  CatBoostEncoder(a=1, cols=None, drop_invariant...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             zscore  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               be95  
2023-08-02 18:21:40,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:40,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:40,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:40,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:21:40,409:INFO:setup() successfully completed in 4.58s...............
2023-08-02 18:22:01,986:INFO:Initializing compare_models()
2023-08-02 18:22:01,986:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-02 18:22:01,986:INFO:Checking exceptions
2023-08-02 18:22:01,994:INFO:Preparing display monitor
2023-08-02 18:22:02,040:INFO:Initializing Logistic Regression
2023-08-02 18:22:02,040:INFO:Total runtime is 0.0 minutes
2023-08-02 18:22:02,050:INFO:SubProcess create_model() called ==================================
2023-08-02 18:22:02,050:INFO:Initializing create_model()
2023-08-02 18:22:02,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:22:02,051:INFO:Checking exceptions
2023-08-02 18:22:02,051:INFO:Importing libraries
2023-08-02 18:22:02,051:INFO:Copying training dataset
2023-08-02 18:22:02,065:INFO:Defining folds
2023-08-02 18:22:02,066:INFO:Declaring metric variables
2023-08-02 18:22:02,072:INFO:Importing untrained model
2023-08-02 18:22:02,082:INFO:Logistic Regression Imported successfully
2023-08-02 18:22:02,103:INFO:Starting cross validation
2023-08-02 18:22:02,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:22:38,640:INFO:Calculating mean and std
2023-08-02 18:22:38,642:INFO:Creating metrics dataframe
2023-08-02 18:22:41,813:INFO:Uploading results into container
2023-08-02 18:22:41,814:INFO:Uploading model into container now
2023-08-02 18:22:41,815:INFO:_master_model_container: 1
2023-08-02 18:22:41,815:INFO:_display_container: 2
2023-08-02 18:22:41,816:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-02 18:22:41,816:INFO:create_model() successfully completed......................................
2023-08-02 18:22:41,917:INFO:SubProcess create_model() end ==================================
2023-08-02 18:22:41,917:INFO:Creating metrics dataframe
2023-08-02 18:22:41,937:INFO:Initializing K Neighbors Classifier
2023-08-02 18:22:41,938:INFO:Total runtime is 0.6649683078130086 minutes
2023-08-02 18:22:41,945:INFO:SubProcess create_model() called ==================================
2023-08-02 18:22:41,945:INFO:Initializing create_model()
2023-08-02 18:22:41,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:22:41,946:INFO:Checking exceptions
2023-08-02 18:22:41,946:INFO:Importing libraries
2023-08-02 18:22:41,946:INFO:Copying training dataset
2023-08-02 18:22:41,962:INFO:Defining folds
2023-08-02 18:22:41,962:INFO:Declaring metric variables
2023-08-02 18:22:41,970:INFO:Importing untrained model
2023-08-02 18:22:41,980:INFO:K Neighbors Classifier Imported successfully
2023-08-02 18:22:42,002:INFO:Starting cross validation
2023-08-02 18:22:42,008:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:23:07,888:INFO:Calculating mean and std
2023-08-02 18:23:07,890:INFO:Creating metrics dataframe
2023-08-02 18:23:11,279:INFO:Uploading results into container
2023-08-02 18:23:11,281:INFO:Uploading model into container now
2023-08-02 18:23:11,282:INFO:_master_model_container: 2
2023-08-02 18:23:11,282:INFO:_display_container: 2
2023-08-02 18:23:11,283:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 18:23:11,283:INFO:create_model() successfully completed......................................
2023-08-02 18:23:11,383:INFO:SubProcess create_model() end ==================================
2023-08-02 18:23:11,383:INFO:Creating metrics dataframe
2023-08-02 18:23:11,408:INFO:Initializing Naive Bayes
2023-08-02 18:23:11,408:INFO:Total runtime is 1.1561384201049805 minutes
2023-08-02 18:23:11,417:INFO:SubProcess create_model() called ==================================
2023-08-02 18:23:11,419:INFO:Initializing create_model()
2023-08-02 18:23:11,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:23:11,419:INFO:Checking exceptions
2023-08-02 18:23:11,419:INFO:Importing libraries
2023-08-02 18:23:11,419:INFO:Copying training dataset
2023-08-02 18:23:11,436:INFO:Defining folds
2023-08-02 18:23:11,436:INFO:Declaring metric variables
2023-08-02 18:23:11,449:INFO:Importing untrained model
2023-08-02 18:23:11,461:INFO:Naive Bayes Imported successfully
2023-08-02 18:23:11,484:INFO:Starting cross validation
2023-08-02 18:23:11,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:23:36,936:INFO:Calculating mean and std
2023-08-02 18:23:36,937:INFO:Creating metrics dataframe
2023-08-02 18:23:40,571:INFO:Uploading results into container
2023-08-02 18:23:40,572:INFO:Uploading model into container now
2023-08-02 18:23:40,573:INFO:_master_model_container: 3
2023-08-02 18:23:40,573:INFO:_display_container: 2
2023-08-02 18:23:40,574:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-02 18:23:40,574:INFO:create_model() successfully completed......................................
2023-08-02 18:23:40,683:INFO:SubProcess create_model() end ==================================
2023-08-02 18:23:40,683:INFO:Creating metrics dataframe
2023-08-02 18:23:40,703:INFO:Initializing Decision Tree Classifier
2023-08-02 18:23:40,703:INFO:Total runtime is 1.6443814794222513 minutes
2023-08-02 18:23:40,710:INFO:SubProcess create_model() called ==================================
2023-08-02 18:23:40,710:INFO:Initializing create_model()
2023-08-02 18:23:40,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:23:40,711:INFO:Checking exceptions
2023-08-02 18:23:40,711:INFO:Importing libraries
2023-08-02 18:23:40,712:INFO:Copying training dataset
2023-08-02 18:23:40,730:INFO:Defining folds
2023-08-02 18:23:40,731:INFO:Declaring metric variables
2023-08-02 18:23:40,741:INFO:Importing untrained model
2023-08-02 18:23:40,753:INFO:Decision Tree Classifier Imported successfully
2023-08-02 18:23:40,780:INFO:Starting cross validation
2023-08-02 18:23:40,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:24:07,883:INFO:Calculating mean and std
2023-08-02 18:24:07,884:INFO:Creating metrics dataframe
2023-08-02 18:24:11,556:INFO:Uploading results into container
2023-08-02 18:24:11,557:INFO:Uploading model into container now
2023-08-02 18:24:11,558:INFO:_master_model_container: 4
2023-08-02 18:24:11,558:INFO:_display_container: 2
2023-08-02 18:24:11,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-02 18:24:11,560:INFO:create_model() successfully completed......................................
2023-08-02 18:24:11,674:INFO:SubProcess create_model() end ==================================
2023-08-02 18:24:11,674:INFO:Creating metrics dataframe
2023-08-02 18:24:11,703:INFO:Initializing SVM - Linear Kernel
2023-08-02 18:24:11,703:INFO:Total runtime is 2.1610582669576006 minutes
2023-08-02 18:24:11,713:INFO:SubProcess create_model() called ==================================
2023-08-02 18:24:11,715:INFO:Initializing create_model()
2023-08-02 18:24:11,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:24:11,715:INFO:Checking exceptions
2023-08-02 18:24:11,715:INFO:Importing libraries
2023-08-02 18:24:11,715:INFO:Copying training dataset
2023-08-02 18:24:11,734:INFO:Defining folds
2023-08-02 18:24:11,734:INFO:Declaring metric variables
2023-08-02 18:24:11,747:INFO:Importing untrained model
2023-08-02 18:24:11,757:INFO:SVM - Linear Kernel Imported successfully
2023-08-02 18:24:11,782:INFO:Starting cross validation
2023-08-02 18:24:11,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:24:13,761:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,765:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,769:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,786:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:24:13,798:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,800:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,803:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,805:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:13,801:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:22,477:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:22,758:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:24:39,944:INFO:Calculating mean and std
2023-08-02 18:24:39,945:INFO:Creating metrics dataframe
2023-08-02 18:24:43,994:INFO:Uploading results into container
2023-08-02 18:24:43,996:INFO:Uploading model into container now
2023-08-02 18:24:43,997:INFO:_master_model_container: 5
2023-08-02 18:24:43,998:INFO:_display_container: 2
2023-08-02 18:24:44,000:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-02 18:24:44,002:INFO:create_model() successfully completed......................................
2023-08-02 18:24:44,106:INFO:SubProcess create_model() end ==================================
2023-08-02 18:24:44,106:INFO:Creating metrics dataframe
2023-08-02 18:24:44,128:INFO:Initializing Ridge Classifier
2023-08-02 18:24:44,128:INFO:Total runtime is 2.7014683961868284 minutes
2023-08-02 18:24:44,137:INFO:SubProcess create_model() called ==================================
2023-08-02 18:24:44,138:INFO:Initializing create_model()
2023-08-02 18:24:44,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:24:44,139:INFO:Checking exceptions
2023-08-02 18:24:44,139:INFO:Importing libraries
2023-08-02 18:24:44,139:INFO:Copying training dataset
2023-08-02 18:24:44,156:INFO:Defining folds
2023-08-02 18:24:44,156:INFO:Declaring metric variables
2023-08-02 18:24:44,167:INFO:Importing untrained model
2023-08-02 18:24:44,179:INFO:Ridge Classifier Imported successfully
2023-08-02 18:24:44,210:INFO:Starting cross validation
2023-08-02 18:24:44,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:24:45,594:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:45,681:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:45,775:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:45,894:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:24:45,918:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:46,162:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:24:46,176:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:46,205:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:24:46,219:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:46,292:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:46,504:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:54,717:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:24:54,887:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:25:11,206:INFO:Calculating mean and std
2023-08-02 18:25:11,208:INFO:Creating metrics dataframe
2023-08-02 18:25:15,114:INFO:Uploading results into container
2023-08-02 18:25:15,116:INFO:Uploading model into container now
2023-08-02 18:25:15,118:INFO:_master_model_container: 6
2023-08-02 18:25:15,118:INFO:_display_container: 2
2023-08-02 18:25:15,119:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-02 18:25:15,119:INFO:create_model() successfully completed......................................
2023-08-02 18:25:15,235:INFO:SubProcess create_model() end ==================================
2023-08-02 18:25:15,235:INFO:Creating metrics dataframe
2023-08-02 18:25:15,259:INFO:Initializing Random Forest Classifier
2023-08-02 18:25:15,259:INFO:Total runtime is 3.220327488581339 minutes
2023-08-02 18:25:15,268:INFO:SubProcess create_model() called ==================================
2023-08-02 18:25:15,269:INFO:Initializing create_model()
2023-08-02 18:25:15,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:25:15,269:INFO:Checking exceptions
2023-08-02 18:25:15,270:INFO:Importing libraries
2023-08-02 18:25:15,270:INFO:Copying training dataset
2023-08-02 18:25:15,285:INFO:Defining folds
2023-08-02 18:25:15,285:INFO:Declaring metric variables
2023-08-02 18:25:15,294:INFO:Importing untrained model
2023-08-02 18:25:15,304:INFO:Random Forest Classifier Imported successfully
2023-08-02 18:25:15,328:INFO:Starting cross validation
2023-08-02 18:25:15,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:25:24,511:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:24,709:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:24,745:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:24,962:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:25,170:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:25,291:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:25,812:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:25,972:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:25:26,003:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:26,160:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:26,402:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:26,569:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:26,758:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:26,961:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:27,513:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:27,572:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:25:56,524:INFO:Calculating mean and std
2023-08-02 18:25:56,525:INFO:Creating metrics dataframe
2023-08-02 18:26:00,695:INFO:Uploading results into container
2023-08-02 18:26:00,697:INFO:Uploading model into container now
2023-08-02 18:26:00,698:INFO:_master_model_container: 7
2023-08-02 18:26:00,699:INFO:_display_container: 2
2023-08-02 18:26:00,702:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-02 18:26:00,702:INFO:create_model() successfully completed......................................
2023-08-02 18:26:00,844:INFO:SubProcess create_model() end ==================================
2023-08-02 18:26:00,845:INFO:Creating metrics dataframe
2023-08-02 18:26:00,880:INFO:Initializing Quadratic Discriminant Analysis
2023-08-02 18:26:00,881:INFO:Total runtime is 3.9806792775789894 minutes
2023-08-02 18:26:00,895:INFO:SubProcess create_model() called ==================================
2023-08-02 18:26:00,896:INFO:Initializing create_model()
2023-08-02 18:26:00,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:26:00,897:INFO:Checking exceptions
2023-08-02 18:26:00,897:INFO:Importing libraries
2023-08-02 18:26:00,898:INFO:Copying training dataset
2023-08-02 18:26:00,924:INFO:Defining folds
2023-08-02 18:26:00,925:INFO:Declaring metric variables
2023-08-02 18:26:00,941:INFO:Importing untrained model
2023-08-02 18:26:00,955:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-02 18:26:00,989:INFO:Starting cross validation
2023-08-02 18:26:00,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:26:01,775:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,775:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,775:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,776:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,776:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,777:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:01,812:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:03,114:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:03,132:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:03,154:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:03,199:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:12,831:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:12,849:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 18:26:31,691:INFO:Calculating mean and std
2023-08-02 18:26:31,693:INFO:Creating metrics dataframe
2023-08-02 18:26:35,633:INFO:Uploading results into container
2023-08-02 18:26:35,635:INFO:Uploading model into container now
2023-08-02 18:26:35,636:INFO:_master_model_container: 8
2023-08-02 18:26:35,637:INFO:_display_container: 2
2023-08-02 18:26:35,638:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-02 18:26:35,638:INFO:create_model() successfully completed......................................
2023-08-02 18:26:35,746:INFO:SubProcess create_model() end ==================================
2023-08-02 18:26:35,747:INFO:Creating metrics dataframe
2023-08-02 18:26:35,774:INFO:Initializing Ada Boost Classifier
2023-08-02 18:26:35,774:INFO:Total runtime is 4.562229820092519 minutes
2023-08-02 18:26:35,782:INFO:SubProcess create_model() called ==================================
2023-08-02 18:26:35,783:INFO:Initializing create_model()
2023-08-02 18:26:35,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:26:35,783:INFO:Checking exceptions
2023-08-02 18:26:35,783:INFO:Importing libraries
2023-08-02 18:26:35,783:INFO:Copying training dataset
2023-08-02 18:26:35,799:INFO:Defining folds
2023-08-02 18:26:35,800:INFO:Declaring metric variables
2023-08-02 18:26:35,812:INFO:Importing untrained model
2023-08-02 18:26:35,825:INFO:Ada Boost Classifier Imported successfully
2023-08-02 18:26:35,847:INFO:Starting cross validation
2023-08-02 18:26:35,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:26:40,429:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:40,444:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:40,724:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:40,727:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:40,783:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:26:40,801:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:10,943:INFO:Calculating mean and std
2023-08-02 18:27:10,945:INFO:Creating metrics dataframe
2023-08-02 18:27:15,153:INFO:Uploading results into container
2023-08-02 18:27:15,154:INFO:Uploading model into container now
2023-08-02 18:27:15,156:INFO:_master_model_container: 9
2023-08-02 18:27:15,157:INFO:_display_container: 2
2023-08-02 18:27:15,158:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-02 18:27:15,159:INFO:create_model() successfully completed......................................
2023-08-02 18:27:15,279:INFO:SubProcess create_model() end ==================================
2023-08-02 18:27:15,279:INFO:Creating metrics dataframe
2023-08-02 18:27:15,306:INFO:Initializing Gradient Boosting Classifier
2023-08-02 18:27:15,306:INFO:Total runtime is 5.221102913220723 minutes
2023-08-02 18:27:15,317:INFO:SubProcess create_model() called ==================================
2023-08-02 18:27:15,317:INFO:Initializing create_model()
2023-08-02 18:27:15,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:27:15,318:INFO:Checking exceptions
2023-08-02 18:27:15,318:INFO:Importing libraries
2023-08-02 18:27:15,318:INFO:Copying training dataset
2023-08-02 18:27:15,337:INFO:Defining folds
2023-08-02 18:27:15,338:INFO:Declaring metric variables
2023-08-02 18:27:15,349:INFO:Importing untrained model
2023-08-02 18:27:15,364:INFO:Gradient Boosting Classifier Imported successfully
2023-08-02 18:27:15,395:INFO:Starting cross validation
2023-08-02 18:27:15,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:27:24,604:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:27:25,478:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,499:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,648:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,786:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,832:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,869:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:25,992:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:27:58,672:INFO:Calculating mean and std
2023-08-02 18:27:58,676:INFO:Creating metrics dataframe
2023-08-02 18:28:03,019:INFO:Uploading results into container
2023-08-02 18:28:03,021:INFO:Uploading model into container now
2023-08-02 18:28:03,022:INFO:_master_model_container: 10
2023-08-02 18:28:03,022:INFO:_display_container: 2
2023-08-02 18:28:03,025:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-02 18:28:03,025:INFO:create_model() successfully completed......................................
2023-08-02 18:28:03,146:INFO:SubProcess create_model() end ==================================
2023-08-02 18:28:03,147:INFO:Creating metrics dataframe
2023-08-02 18:28:03,178:INFO:Initializing Linear Discriminant Analysis
2023-08-02 18:28:03,178:INFO:Total runtime is 6.018971975644429 minutes
2023-08-02 18:28:03,187:INFO:SubProcess create_model() called ==================================
2023-08-02 18:28:03,188:INFO:Initializing create_model()
2023-08-02 18:28:03,188:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:28:03,188:INFO:Checking exceptions
2023-08-02 18:28:03,188:INFO:Importing libraries
2023-08-02 18:28:03,188:INFO:Copying training dataset
2023-08-02 18:28:03,209:INFO:Defining folds
2023-08-02 18:28:03,210:INFO:Declaring metric variables
2023-08-02 18:28:03,221:INFO:Importing untrained model
2023-08-02 18:28:03,234:INFO:Linear Discriminant Analysis Imported successfully
2023-08-02 18:28:03,265:INFO:Starting cross validation
2023-08-02 18:28:03,271:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:28:05,045:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:05,134:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:34,589:INFO:Calculating mean and std
2023-08-02 18:28:34,591:INFO:Creating metrics dataframe
2023-08-02 18:28:39,036:INFO:Uploading results into container
2023-08-02 18:28:39,037:INFO:Uploading model into container now
2023-08-02 18:28:39,041:INFO:_master_model_container: 11
2023-08-02 18:28:39,042:INFO:_display_container: 2
2023-08-02 18:28:39,043:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-02 18:28:39,044:INFO:create_model() successfully completed......................................
2023-08-02 18:28:39,171:INFO:SubProcess create_model() end ==================================
2023-08-02 18:28:39,171:INFO:Creating metrics dataframe
2023-08-02 18:28:39,208:INFO:Initializing Extra Trees Classifier
2023-08-02 18:28:39,208:INFO:Total runtime is 6.619465724627176 minutes
2023-08-02 18:28:39,220:INFO:SubProcess create_model() called ==================================
2023-08-02 18:28:39,220:INFO:Initializing create_model()
2023-08-02 18:28:39,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:28:39,221:INFO:Checking exceptions
2023-08-02 18:28:39,221:INFO:Importing libraries
2023-08-02 18:28:39,221:INFO:Copying training dataset
2023-08-02 18:28:39,239:INFO:Defining folds
2023-08-02 18:28:39,240:INFO:Declaring metric variables
2023-08-02 18:28:39,251:INFO:Importing untrained model
2023-08-02 18:28:39,263:INFO:Extra Trees Classifier Imported successfully
2023-08-02 18:28:39,299:INFO:Starting cross validation
2023-08-02 18:28:39,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:28:45,214:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,244:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,449:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,461:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,508:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,618:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:45,859:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:46,082:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:28:46,699:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:46,707:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,015:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,052:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,054:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,265:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,487:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:28:47,858:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:29:18,312:INFO:Calculating mean and std
2023-08-02 18:29:18,315:INFO:Creating metrics dataframe
2023-08-02 18:29:22,859:INFO:Uploading results into container
2023-08-02 18:29:22,862:INFO:Uploading model into container now
2023-08-02 18:29:22,864:INFO:_master_model_container: 12
2023-08-02 18:29:22,864:INFO:_display_container: 2
2023-08-02 18:29:22,865:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-02 18:29:22,866:INFO:create_model() successfully completed......................................
2023-08-02 18:29:23,014:INFO:SubProcess create_model() end ==================================
2023-08-02 18:29:23,014:INFO:Creating metrics dataframe
2023-08-02 18:29:23,058:INFO:Initializing Light Gradient Boosting Machine
2023-08-02 18:29:23,059:INFO:Total runtime is 7.350315709908802 minutes
2023-08-02 18:29:23,069:INFO:SubProcess create_model() called ==================================
2023-08-02 18:29:23,071:INFO:Initializing create_model()
2023-08-02 18:29:23,071:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:29:23,071:INFO:Checking exceptions
2023-08-02 18:29:23,071:INFO:Importing libraries
2023-08-02 18:29:23,072:INFO:Copying training dataset
2023-08-02 18:29:23,092:INFO:Defining folds
2023-08-02 18:29:23,094:INFO:Declaring metric variables
2023-08-02 18:29:23,112:INFO:Importing untrained model
2023-08-02 18:29:23,126:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-02 18:29:23,166:INFO:Starting cross validation
2023-08-02 18:29:23,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:29:25,224:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:29:25,274:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:29:26,077:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:29:26,249:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:29:26,493:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:29:26,495:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:29:57,550:INFO:Calculating mean and std
2023-08-02 18:29:57,553:INFO:Creating metrics dataframe
2023-08-02 18:30:01,977:INFO:Uploading results into container
2023-08-02 18:30:01,978:INFO:Uploading model into container now
2023-08-02 18:30:01,981:INFO:_master_model_container: 13
2023-08-02 18:30:01,981:INFO:_display_container: 2
2023-08-02 18:30:01,982:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-02 18:30:01,982:INFO:create_model() successfully completed......................................
2023-08-02 18:30:02,093:INFO:SubProcess create_model() end ==================================
2023-08-02 18:30:02,094:INFO:Creating metrics dataframe
2023-08-02 18:30:02,125:INFO:Initializing Dummy Classifier
2023-08-02 18:30:02,125:INFO:Total runtime is 8.00141657590866 minutes
2023-08-02 18:30:02,133:INFO:SubProcess create_model() called ==================================
2023-08-02 18:30:02,135:INFO:Initializing create_model()
2023-08-02 18:30:02,135:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07B50>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:30:02,135:INFO:Checking exceptions
2023-08-02 18:30:02,135:INFO:Importing libraries
2023-08-02 18:30:02,135:INFO:Copying training dataset
2023-08-02 18:30:02,150:INFO:Defining folds
2023-08-02 18:30:02,150:INFO:Declaring metric variables
2023-08-02 18:30:02,158:INFO:Importing untrained model
2023-08-02 18:30:02,169:INFO:Dummy Classifier Imported successfully
2023-08-02 18:30:02,198:INFO:Starting cross validation
2023-08-02 18:30:02,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:30:03,687:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:03,688:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:03,725:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:30:03,806:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:30:03,873:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:03,926:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:04,001:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:04,019:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:04,043:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:04,060:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:14,252:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:14,301:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 18:30:34,613:INFO:Calculating mean and std
2023-08-02 18:30:34,617:INFO:Creating metrics dataframe
2023-08-02 18:30:39,168:INFO:Uploading results into container
2023-08-02 18:30:39,170:INFO:Uploading model into container now
2023-08-02 18:30:39,171:INFO:_master_model_container: 14
2023-08-02 18:30:39,171:INFO:_display_container: 2
2023-08-02 18:30:39,171:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-02 18:30:39,171:INFO:create_model() successfully completed......................................
2023-08-02 18:30:39,286:INFO:SubProcess create_model() end ==================================
2023-08-02 18:30:39,286:INFO:Creating metrics dataframe
2023-08-02 18:30:39,361:INFO:Initializing create_model()
2023-08-02 18:30:39,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024750E31910>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:30:39,363:INFO:Checking exceptions
2023-08-02 18:30:39,370:INFO:Importing libraries
2023-08-02 18:30:39,370:INFO:Copying training dataset
2023-08-02 18:30:39,391:INFO:Defining folds
2023-08-02 18:30:39,391:INFO:Declaring metric variables
2023-08-02 18:30:39,392:INFO:Importing untrained model
2023-08-02 18:30:39,392:INFO:Declaring custom model
2023-08-02 18:30:39,401:INFO:Ada Boost Classifier Imported successfully
2023-08-02 18:30:39,407:INFO:Cross validation set to False
2023-08-02 18:30:39,408:INFO:Fitting Model
2023-08-02 18:30:43,255:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-02 18:30:43,255:INFO:create_model() successfully completed......................................
2023-08-02 18:30:43,487:INFO:_master_model_container: 14
2023-08-02 18:30:43,488:INFO:_display_container: 2
2023-08-02 18:30:43,489:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-02 18:30:43,489:INFO:compare_models() successfully completed......................................
2023-08-02 18:31:12,456:INFO:PyCaret ClassificationExperiment
2023-08-02 18:31:12,457:INFO:Logging name: clf-default-name
2023-08-02 18:31:12,457:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-02 18:31:12,457:INFO:version 3.0.4
2023-08-02 18:31:12,457:INFO:Initializing setup()
2023-08-02 18:31:12,457:INFO:self.USI: d7c7
2023-08-02 18:31:12,457:INFO:self._variable_keys: {'target_param', 'fold_shuffle_param', 'is_multiclass', 'data', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'seed', 'exp_id', 'pipeline', 'fix_imbalance', 'y', 'X', '_available_plots', 'X_train', 'memory', 'n_jobs_param', 'X_test', 'fold_groups_param', 'idx', '_ml_usecase', 'fold_generator', 'logging_param', 'html_param', 'log_plots_param', 'y_train', 'y_test', 'exp_name_log'}
2023-08-02 18:31:12,458:INFO:Checking environment
2023-08-02 18:31:12,458:INFO:python_version: 3.9.13
2023-08-02 18:31:12,458:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-02 18:31:12,458:INFO:machine: AMD64
2023-08-02 18:31:12,458:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-02 18:31:12,463:INFO:Memory: svmem(total=17055166464, available=8551096320, percent=49.9, used=8504070144, free=8551096320)
2023-08-02 18:31:12,463:INFO:Physical Core: 4
2023-08-02 18:31:12,463:INFO:Logical Core: 8
2023-08-02 18:31:12,463:INFO:Checking libraries
2023-08-02 18:31:12,463:INFO:System:
2023-08-02 18:31:12,464:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-02 18:31:12,464:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-02 18:31:12,464:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-02 18:31:12,464:INFO:PyCaret required dependencies:
2023-08-02 18:31:12,464:INFO:                 pip: 22.0.4
2023-08-02 18:31:12,464:INFO:          setuptools: 58.1.0
2023-08-02 18:31:12,464:INFO:             pycaret: 3.0.4
2023-08-02 18:31:12,464:INFO:             IPython: 8.13.1
2023-08-02 18:31:12,464:INFO:          ipywidgets: 7.8.0
2023-08-02 18:31:12,464:INFO:                tqdm: 4.65.0
2023-08-02 18:31:12,464:INFO:               numpy: 1.23.0
2023-08-02 18:31:12,464:INFO:              pandas: 1.5.3
2023-08-02 18:31:12,465:INFO:              jinja2: 3.1.2
2023-08-02 18:31:12,465:INFO:               scipy: 1.10.1
2023-08-02 18:31:12,465:INFO:              joblib: 1.2.0
2023-08-02 18:31:12,465:INFO:             sklearn: 1.2.2
2023-08-02 18:31:12,466:INFO:                pyod: 1.1.0
2023-08-02 18:31:12,466:INFO:            imblearn: 0.11.0
2023-08-02 18:31:12,466:INFO:   category_encoders: 2.6.1
2023-08-02 18:31:12,466:INFO:            lightgbm: 3.3.5
2023-08-02 18:31:12,466:INFO:               numba: 0.57.1
2023-08-02 18:31:12,466:INFO:            requests: 2.31.0
2023-08-02 18:31:12,466:INFO:          matplotlib: 3.7.1
2023-08-02 18:31:12,466:INFO:          scikitplot: 0.3.7
2023-08-02 18:31:12,466:INFO:         yellowbrick: 1.5
2023-08-02 18:31:12,466:INFO:              plotly: 5.15.0
2023-08-02 18:31:12,466:INFO:    plotly-resampler: Not installed
2023-08-02 18:31:12,466:INFO:             kaleido: 0.2.1
2023-08-02 18:31:12,466:INFO:           schemdraw: 0.15
2023-08-02 18:31:12,466:INFO:         statsmodels: 0.14.0
2023-08-02 18:31:12,466:INFO:              sktime: 0.20.0
2023-08-02 18:31:12,466:INFO:               tbats: 1.1.3
2023-08-02 18:31:12,466:INFO:            pmdarima: 2.0.3
2023-08-02 18:31:12,467:INFO:              psutil: 5.9.5
2023-08-02 18:31:12,467:INFO:          markupsafe: 2.1.3
2023-08-02 18:31:12,467:INFO:             pickle5: Not installed
2023-08-02 18:31:12,467:INFO:         cloudpickle: 2.2.1
2023-08-02 18:31:12,467:INFO:         deprecation: 2.1.0
2023-08-02 18:31:12,467:INFO:              xxhash: 3.2.0
2023-08-02 18:31:12,467:INFO:           wurlitzer: Not installed
2023-08-02 18:31:12,467:INFO:PyCaret optional dependencies:
2023-08-02 18:31:12,467:INFO:                shap: Not installed
2023-08-02 18:31:12,467:INFO:           interpret: Not installed
2023-08-02 18:31:12,469:INFO:                umap: 0.5.3
2023-08-02 18:31:12,469:INFO:    pandas_profiling: 4.3.1
2023-08-02 18:31:12,469:INFO:  explainerdashboard: Not installed
2023-08-02 18:31:12,469:INFO:             autoviz: Not installed
2023-08-02 18:31:12,469:INFO:           fairlearn: Not installed
2023-08-02 18:31:12,469:INFO:          deepchecks: Not installed
2023-08-02 18:31:12,469:INFO:             xgboost: Not installed
2023-08-02 18:31:12,469:INFO:            catboost: Not installed
2023-08-02 18:31:12,469:INFO:              kmodes: Not installed
2023-08-02 18:31:12,469:INFO:             mlxtend: 0.22.0
2023-08-02 18:31:12,469:INFO:       statsforecast: Not installed
2023-08-02 18:31:12,470:INFO:        tune_sklearn: Not installed
2023-08-02 18:31:12,470:INFO:                 ray: Not installed
2023-08-02 18:31:12,470:INFO:            hyperopt: Not installed
2023-08-02 18:31:12,470:INFO:              optuna: 3.2.0
2023-08-02 18:31:12,470:INFO:               skopt: Not installed
2023-08-02 18:31:12,470:INFO:              mlflow: 2.5.0
2023-08-02 18:31:12,470:INFO:              gradio: Not installed
2023-08-02 18:31:12,470:INFO:             fastapi: Not installed
2023-08-02 18:31:12,470:INFO:             uvicorn: Not installed
2023-08-02 18:31:12,470:INFO:              m2cgen: Not installed
2023-08-02 18:31:12,470:INFO:           evidently: Not installed
2023-08-02 18:31:12,470:INFO:               fugue: Not installed
2023-08-02 18:31:12,471:INFO:           streamlit: 1.25.0
2023-08-02 18:31:12,471:INFO:             prophet: Not installed
2023-08-02 18:31:12,471:INFO:None
2023-08-02 18:31:12,471:INFO:Set up data.
2023-08-02 18:31:12,487:INFO:Set up train/test split.
2023-08-02 18:31:12,500:INFO:Set up index.
2023-08-02 18:31:12,500:INFO:Set up folding strategy.
2023-08-02 18:31:12,501:INFO:Assigning column types.
2023-08-02 18:31:12,510:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-02 18:31:12,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:31:12,606:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:31:12,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:12,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:12,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:31:12,733:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:31:12,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:12,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:12,793:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-02 18:31:12,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:31:12,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:12,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:31:13,084:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,086:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-02 18:31:13,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:13,398:INFO:Preparing preprocessing pipeline...
2023-08-02 18:31:13,400:INFO:Set up simple imputation.
2023-08-02 18:31:13,405:INFO:Set up encoding of categorical features.
2023-08-02 18:31:13,405:INFO:Set up removing multicollinearity.
2023-08-02 18:31:13,405:INFO:Set up feature normalization.
2023-08-02 18:31:13,607:INFO:Finished creating preprocessing pipeline.
2023-08-02 18:31:13,620:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                                return_df=True,
                                                                sigma=None,
                                                                verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=RobustScaler(copy=True,
                                                             quantile_range=(25.0,
                                                                             75.0),
                                                             unit_variance=False,
                                                             with_centering=True,
                                                             with_scaling=True)))],
         verbose=False)
2023-08-02 18:31:13,621:INFO:Creating final display dataframe.
2023-08-02 18:31:14,081:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3           Original data shape   
4        Transformed data shape   
5   Transformed train set shape   
6    Transformed test set shape   
7              Numeric features   
8          Categorical features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13     Maximum one-hot encoding   
14              Encoding method   
15     Remove multicollinearity   
16  Multicollinearity threshold   
17                    Normalize   
18             Normalize method   
19               Fold Generator   
20                  Fold Number   
21                     CPU Jobs   
22                      Use GPU   
23               Log Experiment   
24              Experiment Name   
25                          USI   

                                                Value  
0                                                2020  
1                                         is_canceled  
2                                              Binary  
3                                          (8136, 10)  
4                                          (8136, 10)  
5                                          (5695, 10)  
6                                          (2441, 10)  
7                                                   5  
8                                                   4  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                                  0  
14  CatBoostEncoder(a=1, cols=None, drop_invariant...  
15                                               True  
16                                                0.8  
17                                               True  
18                                             robust  
19                                    StratifiedKFold  
20                                                 10  
21                                                 -1  
22                                              False  
23                                              False  
24                                   clf-default-name  
25                                               d7c7  
2023-08-02 18:31:14,294:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:14,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:14,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:14,446:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:31:14,447:INFO:setup() successfully completed in 4.93s...............
2023-08-02 18:31:27,980:INFO:Initializing compare_models()
2023-08-02 18:31:27,980:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-02 18:31:27,980:INFO:Checking exceptions
2023-08-02 18:31:27,989:INFO:Preparing display monitor
2023-08-02 18:31:28,042:INFO:Initializing Logistic Regression
2023-08-02 18:31:28,042:INFO:Total runtime is 0.0 minutes
2023-08-02 18:31:28,053:INFO:SubProcess create_model() called ==================================
2023-08-02 18:31:28,054:INFO:Initializing create_model()
2023-08-02 18:31:28,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:31:28,055:INFO:Checking exceptions
2023-08-02 18:31:28,055:INFO:Importing libraries
2023-08-02 18:31:28,056:INFO:Copying training dataset
2023-08-02 18:31:28,071:INFO:Defining folds
2023-08-02 18:31:28,072:INFO:Declaring metric variables
2023-08-02 18:31:28,083:INFO:Importing untrained model
2023-08-02 18:31:28,095:INFO:Logistic Regression Imported successfully
2023-08-02 18:31:28,123:INFO:Starting cross validation
2023-08-02 18:31:28,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:32:00,916:INFO:Calculating mean and std
2023-08-02 18:32:00,920:INFO:Creating metrics dataframe
2023-08-02 18:32:05,282:INFO:Uploading results into container
2023-08-02 18:32:05,285:INFO:Uploading model into container now
2023-08-02 18:32:05,287:INFO:_master_model_container: 1
2023-08-02 18:32:05,287:INFO:_display_container: 2
2023-08-02 18:32:05,288:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-02 18:32:05,289:INFO:create_model() successfully completed......................................
2023-08-02 18:32:05,409:INFO:SubProcess create_model() end ==================================
2023-08-02 18:32:05,409:INFO:Creating metrics dataframe
2023-08-02 18:32:05,427:INFO:Initializing K Neighbors Classifier
2023-08-02 18:32:05,427:INFO:Total runtime is 0.6230842510859171 minutes
2023-08-02 18:32:05,436:INFO:SubProcess create_model() called ==================================
2023-08-02 18:32:05,437:INFO:Initializing create_model()
2023-08-02 18:32:05,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:32:05,438:INFO:Checking exceptions
2023-08-02 18:32:05,438:INFO:Importing libraries
2023-08-02 18:32:05,438:INFO:Copying training dataset
2023-08-02 18:32:05,452:INFO:Defining folds
2023-08-02 18:32:05,453:INFO:Declaring metric variables
2023-08-02 18:32:05,461:INFO:Importing untrained model
2023-08-02 18:32:05,474:INFO:K Neighbors Classifier Imported successfully
2023-08-02 18:32:05,497:INFO:Starting cross validation
2023-08-02 18:32:05,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:32:06,662:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 18:32:40,032:INFO:Calculating mean and std
2023-08-02 18:32:40,034:INFO:Creating metrics dataframe
2023-08-02 18:32:44,634:INFO:Uploading results into container
2023-08-02 18:32:44,637:INFO:Uploading model into container now
2023-08-02 18:32:44,639:INFO:_master_model_container: 2
2023-08-02 18:32:44,639:INFO:_display_container: 2
2023-08-02 18:32:44,640:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 18:32:44,640:INFO:create_model() successfully completed......................................
2023-08-02 18:32:44,769:INFO:SubProcess create_model() end ==================================
2023-08-02 18:32:44,769:INFO:Creating metrics dataframe
2023-08-02 18:32:44,796:INFO:Initializing Naive Bayes
2023-08-02 18:32:44,796:INFO:Total runtime is 1.2792327602704368 minutes
2023-08-02 18:32:44,806:INFO:SubProcess create_model() called ==================================
2023-08-02 18:32:44,808:INFO:Initializing create_model()
2023-08-02 18:32:44,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:32:44,809:INFO:Checking exceptions
2023-08-02 18:32:44,809:INFO:Importing libraries
2023-08-02 18:32:44,810:INFO:Copying training dataset
2023-08-02 18:32:44,827:INFO:Defining folds
2023-08-02 18:32:44,827:INFO:Declaring metric variables
2023-08-02 18:32:44,838:INFO:Importing untrained model
2023-08-02 18:32:44,851:INFO:Naive Bayes Imported successfully
2023-08-02 18:32:44,885:INFO:Starting cross validation
2023-08-02 18:32:44,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:32:46,493:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:33:18,217:INFO:Calculating mean and std
2023-08-02 18:33:18,219:INFO:Creating metrics dataframe
2023-08-02 18:33:22,897:INFO:Uploading results into container
2023-08-02 18:33:22,898:INFO:Uploading model into container now
2023-08-02 18:33:22,899:INFO:_master_model_container: 3
2023-08-02 18:33:22,899:INFO:_display_container: 2
2023-08-02 18:33:22,900:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-02 18:33:22,900:INFO:create_model() successfully completed......................................
2023-08-02 18:33:23,004:INFO:SubProcess create_model() end ==================================
2023-08-02 18:33:23,004:INFO:Creating metrics dataframe
2023-08-02 18:33:23,033:INFO:Initializing Decision Tree Classifier
2023-08-02 18:33:23,033:INFO:Total runtime is 1.916512151559194 minutes
2023-08-02 18:33:23,042:INFO:SubProcess create_model() called ==================================
2023-08-02 18:33:23,042:INFO:Initializing create_model()
2023-08-02 18:33:23,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:33:23,043:INFO:Checking exceptions
2023-08-02 18:33:23,043:INFO:Importing libraries
2023-08-02 18:33:23,044:INFO:Copying training dataset
2023-08-02 18:33:23,060:INFO:Defining folds
2023-08-02 18:33:23,061:INFO:Declaring metric variables
2023-08-02 18:33:23,071:INFO:Importing untrained model
2023-08-02 18:33:23,086:INFO:Decision Tree Classifier Imported successfully
2023-08-02 18:33:23,118:INFO:Starting cross validation
2023-08-02 18:33:23,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:33:57,899:INFO:Calculating mean and std
2023-08-02 18:33:57,901:INFO:Creating metrics dataframe
2023-08-02 18:34:02,762:INFO:Uploading results into container
2023-08-02 18:34:02,764:INFO:Uploading model into container now
2023-08-02 18:34:02,765:INFO:_master_model_container: 4
2023-08-02 18:34:02,765:INFO:_display_container: 2
2023-08-02 18:34:02,766:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-02 18:34:02,766:INFO:create_model() successfully completed......................................
2023-08-02 18:34:02,882:INFO:SubProcess create_model() end ==================================
2023-08-02 18:34:02,883:INFO:Creating metrics dataframe
2023-08-02 18:34:02,910:INFO:Initializing SVM - Linear Kernel
2023-08-02 18:34:02,910:INFO:Total runtime is 2.5811376492182414 minutes
2023-08-02 18:34:02,918:INFO:SubProcess create_model() called ==================================
2023-08-02 18:34:02,919:INFO:Initializing create_model()
2023-08-02 18:34:02,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:34:02,920:INFO:Checking exceptions
2023-08-02 18:34:02,920:INFO:Importing libraries
2023-08-02 18:34:02,920:INFO:Copying training dataset
2023-08-02 18:34:02,935:INFO:Defining folds
2023-08-02 18:34:02,935:INFO:Declaring metric variables
2023-08-02 18:34:02,945:INFO:Importing untrained model
2023-08-02 18:34:02,959:INFO:SVM - Linear Kernel Imported successfully
2023-08-02 18:34:02,981:INFO:Starting cross validation
2023-08-02 18:34:02,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:34:04,691:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:04,710:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:04,780:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:04,826:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:04,934:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:04,936:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:05,083:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:05,214:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:05,228:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:05,237:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:05,394:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:15,671:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:15,704:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:34:35,563:INFO:Calculating mean and std
2023-08-02 18:34:35,565:INFO:Creating metrics dataframe
2023-08-02 18:34:40,138:INFO:Uploading results into container
2023-08-02 18:34:40,139:INFO:Uploading model into container now
2023-08-02 18:34:40,142:INFO:_master_model_container: 5
2023-08-02 18:34:40,142:INFO:_display_container: 2
2023-08-02 18:34:40,143:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-02 18:34:40,144:INFO:create_model() successfully completed......................................
2023-08-02 18:34:40,255:INFO:SubProcess create_model() end ==================================
2023-08-02 18:34:40,256:INFO:Creating metrics dataframe
2023-08-02 18:34:40,277:INFO:Initializing Ridge Classifier
2023-08-02 18:34:40,277:INFO:Total runtime is 3.203920515378316 minutes
2023-08-02 18:34:40,283:INFO:SubProcess create_model() called ==================================
2023-08-02 18:34:40,284:INFO:Initializing create_model()
2023-08-02 18:34:40,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024777CA30D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024750E07C10>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:34:40,284:INFO:Checking exceptions
2023-08-02 18:34:40,284:INFO:Importing libraries
2023-08-02 18:34:40,284:INFO:Copying training dataset
2023-08-02 18:34:40,299:INFO:Defining folds
2023-08-02 18:34:40,300:INFO:Declaring metric variables
2023-08-02 18:34:40,309:INFO:Importing untrained model
2023-08-02 18:34:40,322:INFO:Ridge Classifier Imported successfully
2023-08-02 18:34:40,346:INFO:Starting cross validation
2023-08-02 18:34:40,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:34:41,798:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:41,883:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:41,982:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:42,119:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:42,171:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:42,211:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:42,231:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:42,251:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:42,282:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:42,380:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:34:42,397:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:42,541:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:55,092:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:34:55,148:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 18:49:16,597:INFO:PyCaret ClassificationExperiment
2023-08-02 18:49:16,597:INFO:Logging name: clf-default-name
2023-08-02 18:49:16,597:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-02 18:49:16,598:INFO:version 3.0.4
2023-08-02 18:49:16,598:INFO:Initializing setup()
2023-08-02 18:49:16,598:INFO:self.USI: f471
2023-08-02 18:49:16,599:INFO:self._variable_keys: {'target_param', 'fold_shuffle_param', 'is_multiclass', 'data', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'seed', 'exp_id', 'pipeline', 'fix_imbalance', 'y', 'X', '_available_plots', 'X_train', 'memory', 'n_jobs_param', 'X_test', 'fold_groups_param', 'idx', '_ml_usecase', 'fold_generator', 'logging_param', 'html_param', 'log_plots_param', 'y_train', 'y_test', 'exp_name_log'}
2023-08-02 18:49:16,599:INFO:Checking environment
2023-08-02 18:49:16,599:INFO:python_version: 3.9.13
2023-08-02 18:49:16,599:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-02 18:49:16,599:INFO:machine: AMD64
2023-08-02 18:49:16,599:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-02 18:49:16,604:INFO:Memory: svmem(total=17055166464, available=9073643520, percent=46.8, used=7981522944, free=9073643520)
2023-08-02 18:49:16,604:INFO:Physical Core: 4
2023-08-02 18:49:16,605:INFO:Logical Core: 8
2023-08-02 18:49:16,605:INFO:Checking libraries
2023-08-02 18:49:16,605:INFO:System:
2023-08-02 18:49:16,605:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-02 18:49:16,605:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-02 18:49:16,605:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-02 18:49:16,605:INFO:PyCaret required dependencies:
2023-08-02 18:49:16,605:INFO:                 pip: 22.0.4
2023-08-02 18:49:16,606:INFO:          setuptools: 58.1.0
2023-08-02 18:49:16,606:INFO:             pycaret: 3.0.4
2023-08-02 18:49:16,606:INFO:             IPython: 8.13.1
2023-08-02 18:49:16,606:INFO:          ipywidgets: 7.8.0
2023-08-02 18:49:16,606:INFO:                tqdm: 4.65.0
2023-08-02 18:49:16,606:INFO:               numpy: 1.23.0
2023-08-02 18:49:16,606:INFO:              pandas: 1.5.3
2023-08-02 18:49:16,606:INFO:              jinja2: 3.1.2
2023-08-02 18:49:16,606:INFO:               scipy: 1.10.1
2023-08-02 18:49:16,606:INFO:              joblib: 1.2.0
2023-08-02 18:49:16,606:INFO:             sklearn: 1.2.2
2023-08-02 18:49:16,607:INFO:                pyod: 1.1.0
2023-08-02 18:49:16,607:INFO:            imblearn: 0.11.0
2023-08-02 18:49:16,607:INFO:   category_encoders: 2.6.1
2023-08-02 18:49:16,607:INFO:            lightgbm: 3.3.5
2023-08-02 18:49:16,607:INFO:               numba: 0.57.1
2023-08-02 18:49:16,607:INFO:            requests: 2.31.0
2023-08-02 18:49:16,607:INFO:          matplotlib: 3.7.1
2023-08-02 18:49:16,607:INFO:          scikitplot: 0.3.7
2023-08-02 18:49:16,607:INFO:         yellowbrick: 1.5
2023-08-02 18:49:16,607:INFO:              plotly: 5.15.0
2023-08-02 18:49:16,607:INFO:    plotly-resampler: Not installed
2023-08-02 18:49:16,608:INFO:             kaleido: 0.2.1
2023-08-02 18:49:16,608:INFO:           schemdraw: 0.15
2023-08-02 18:49:16,608:INFO:         statsmodels: 0.14.0
2023-08-02 18:49:16,608:INFO:              sktime: 0.20.0
2023-08-02 18:49:16,608:INFO:               tbats: 1.1.3
2023-08-02 18:49:16,608:INFO:            pmdarima: 2.0.3
2023-08-02 18:49:16,608:INFO:              psutil: 5.9.5
2023-08-02 18:49:16,608:INFO:          markupsafe: 2.1.3
2023-08-02 18:49:16,608:INFO:             pickle5: Not installed
2023-08-02 18:49:16,608:INFO:         cloudpickle: 2.2.1
2023-08-02 18:49:16,608:INFO:         deprecation: 2.1.0
2023-08-02 18:49:16,609:INFO:              xxhash: 3.2.0
2023-08-02 18:49:16,609:INFO:           wurlitzer: Not installed
2023-08-02 18:49:16,609:INFO:PyCaret optional dependencies:
2023-08-02 18:49:16,609:INFO:                shap: Not installed
2023-08-02 18:49:16,609:INFO:           interpret: Not installed
2023-08-02 18:49:16,609:INFO:                umap: 0.5.3
2023-08-02 18:49:16,609:INFO:    pandas_profiling: 4.3.1
2023-08-02 18:49:16,609:INFO:  explainerdashboard: Not installed
2023-08-02 18:49:16,609:INFO:             autoviz: Not installed
2023-08-02 18:49:16,609:INFO:           fairlearn: Not installed
2023-08-02 18:49:16,610:INFO:          deepchecks: Not installed
2023-08-02 18:49:16,610:INFO:             xgboost: Not installed
2023-08-02 18:49:16,610:INFO:            catboost: Not installed
2023-08-02 18:49:16,610:INFO:              kmodes: Not installed
2023-08-02 18:49:16,610:INFO:             mlxtend: 0.22.0
2023-08-02 18:49:16,610:INFO:       statsforecast: Not installed
2023-08-02 18:49:16,610:INFO:        tune_sklearn: Not installed
2023-08-02 18:49:16,610:INFO:                 ray: Not installed
2023-08-02 18:49:16,610:INFO:            hyperopt: Not installed
2023-08-02 18:49:16,610:INFO:              optuna: 3.2.0
2023-08-02 18:49:16,610:INFO:               skopt: Not installed
2023-08-02 18:49:16,611:INFO:              mlflow: 2.5.0
2023-08-02 18:49:16,611:INFO:              gradio: Not installed
2023-08-02 18:49:16,611:INFO:             fastapi: Not installed
2023-08-02 18:49:16,611:INFO:             uvicorn: Not installed
2023-08-02 18:49:16,611:INFO:              m2cgen: Not installed
2023-08-02 18:49:16,611:INFO:           evidently: Not installed
2023-08-02 18:49:16,611:INFO:               fugue: Not installed
2023-08-02 18:49:16,611:INFO:           streamlit: 1.25.0
2023-08-02 18:49:16,611:INFO:             prophet: Not installed
2023-08-02 18:49:16,611:INFO:None
2023-08-02 18:49:16,611:INFO:Set up data.
2023-08-02 18:49:16,635:INFO:Set up train/test split.
2023-08-02 18:49:16,649:INFO:Set up index.
2023-08-02 18:49:16,649:INFO:Set up folding strategy.
2023-08-02 18:49:16,650:INFO:Assigning column types.
2023-08-02 18:49:16,657:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-02 18:49:16,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:49:16,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:49:16,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:16,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:16,925:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 18:49:16,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:49:16,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:16,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:16,988:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-02 18:49:17,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:49:17,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 18:49:17,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,249:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-02 18:49:17,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:17,508:INFO:Preparing preprocessing pipeline...
2023-08-02 18:49:17,510:INFO:Set up simple imputation.
2023-08-02 18:49:17,515:INFO:Set up encoding of categorical features.
2023-08-02 18:49:17,516:INFO:Set up removing multicollinearity.
2023-08-02 18:49:17,516:INFO:Set up feature normalization.
2023-08-02 18:49:17,824:INFO:Finished creating preprocessing pipeline.
2023-08-02 18:49:17,836:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-08-02 18:49:17,836:INFO:Creating final display dataframe.
2023-08-02 18:49:18,424:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8128, 10)
4        Transformed data shape        (8128, 30)
5   Transformed train set shape        (5689, 30)
6    Transformed test set shape        (2439, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            minmax
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              f471
2023-08-02 18:49:18,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:18,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:18,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:18,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 18:49:18,821:INFO:setup() successfully completed in 4.83s...............
2023-08-02 18:49:27,299:INFO:Initializing compare_models()
2023-08-02 18:49:27,300:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-02 18:49:27,300:INFO:Checking exceptions
2023-08-02 18:49:27,312:INFO:Preparing display monitor
2023-08-02 18:49:27,397:INFO:Initializing Logistic Regression
2023-08-02 18:49:27,398:INFO:Total runtime is 1.6697247823079427e-05 minutes
2023-08-02 18:49:27,410:INFO:SubProcess create_model() called ==================================
2023-08-02 18:49:27,411:INFO:Initializing create_model()
2023-08-02 18:49:27,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247778B3130>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:49:27,412:INFO:Checking exceptions
2023-08-02 18:49:27,412:INFO:Importing libraries
2023-08-02 18:49:27,413:INFO:Copying training dataset
2023-08-02 18:49:27,433:INFO:Defining folds
2023-08-02 18:49:27,434:INFO:Declaring metric variables
2023-08-02 18:49:27,445:INFO:Importing untrained model
2023-08-02 18:49:27,455:INFO:Logistic Regression Imported successfully
2023-08-02 18:49:27,480:INFO:Starting cross validation
2023-08-02 18:49:27,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:50:20,335:INFO:Calculating mean and std
2023-08-02 18:50:20,338:INFO:Creating metrics dataframe
2023-08-02 18:50:24,970:INFO:Uploading results into container
2023-08-02 18:50:24,972:INFO:Uploading model into container now
2023-08-02 18:50:24,974:INFO:_master_model_container: 1
2023-08-02 18:50:24,974:INFO:_display_container: 2
2023-08-02 18:50:24,976:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-02 18:50:24,976:INFO:create_model() successfully completed......................................
2023-08-02 18:50:25,200:INFO:SubProcess create_model() end ==================================
2023-08-02 18:50:25,202:INFO:Creating metrics dataframe
2023-08-02 18:50:25,235:INFO:Initializing K Neighbors Classifier
2023-08-02 18:50:25,235:INFO:Total runtime is 0.9639678319295247 minutes
2023-08-02 18:50:25,246:INFO:SubProcess create_model() called ==================================
2023-08-02 18:50:25,246:INFO:Initializing create_model()
2023-08-02 18:50:25,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247778B3130>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:50:25,247:INFO:Checking exceptions
2023-08-02 18:50:25,247:INFO:Importing libraries
2023-08-02 18:50:25,247:INFO:Copying training dataset
2023-08-02 18:50:25,269:INFO:Defining folds
2023-08-02 18:50:25,269:INFO:Declaring metric variables
2023-08-02 18:50:25,281:INFO:Importing untrained model
2023-08-02 18:50:25,293:INFO:K Neighbors Classifier Imported successfully
2023-08-02 18:50:25,324:INFO:Starting cross validation
2023-08-02 18:50:25,333:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:51:00,755:INFO:Calculating mean and std
2023-08-02 18:51:00,759:INFO:Creating metrics dataframe
2023-08-02 18:51:06,606:INFO:Uploading results into container
2023-08-02 18:51:06,609:INFO:Uploading model into container now
2023-08-02 18:51:06,610:INFO:_master_model_container: 2
2023-08-02 18:51:06,610:INFO:_display_container: 2
2023-08-02 18:51:06,611:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 18:51:06,612:INFO:create_model() successfully completed......................................
2023-08-02 18:51:06,862:INFO:SubProcess create_model() end ==================================
2023-08-02 18:51:06,863:INFO:Creating metrics dataframe
2023-08-02 18:51:06,903:INFO:Initializing Naive Bayes
2023-08-02 18:51:06,904:INFO:Total runtime is 1.6584435145060221 minutes
2023-08-02 18:51:06,917:INFO:SubProcess create_model() called ==================================
2023-08-02 18:51:06,918:INFO:Initializing create_model()
2023-08-02 18:51:06,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247778B3130>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:51:06,919:INFO:Checking exceptions
2023-08-02 18:51:06,920:INFO:Importing libraries
2023-08-02 18:51:06,920:INFO:Copying training dataset
2023-08-02 18:51:06,949:INFO:Defining folds
2023-08-02 18:51:06,950:INFO:Declaring metric variables
2023-08-02 18:51:06,972:INFO:Importing untrained model
2023-08-02 18:51:06,989:INFO:Naive Bayes Imported successfully
2023-08-02 18:51:07,037:INFO:Starting cross validation
2023-08-02 18:51:07,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:51:40,694:INFO:Calculating mean and std
2023-08-02 18:51:40,696:INFO:Creating metrics dataframe
2023-08-02 18:51:45,684:INFO:Uploading results into container
2023-08-02 18:51:45,686:INFO:Uploading model into container now
2023-08-02 18:51:45,688:INFO:_master_model_container: 3
2023-08-02 18:51:45,689:INFO:_display_container: 2
2023-08-02 18:51:45,689:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-02 18:51:45,690:INFO:create_model() successfully completed......................................
2023-08-02 18:51:45,867:INFO:SubProcess create_model() end ==================================
2023-08-02 18:51:45,868:INFO:Creating metrics dataframe
2023-08-02 18:51:45,886:INFO:Initializing Decision Tree Classifier
2023-08-02 18:51:45,887:INFO:Total runtime is 2.3081601738929747 minutes
2023-08-02 18:51:45,895:INFO:SubProcess create_model() called ==================================
2023-08-02 18:51:45,896:INFO:Initializing create_model()
2023-08-02 18:51:45,896:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247778B3130>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:51:45,896:INFO:Checking exceptions
2023-08-02 18:51:45,897:INFO:Importing libraries
2023-08-02 18:51:45,897:INFO:Copying training dataset
2023-08-02 18:51:45,913:INFO:Defining folds
2023-08-02 18:51:45,913:INFO:Declaring metric variables
2023-08-02 18:51:45,926:INFO:Importing untrained model
2023-08-02 18:51:45,943:INFO:Decision Tree Classifier Imported successfully
2023-08-02 18:51:45,977:INFO:Starting cross validation
2023-08-02 18:51:45,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:51:47,922:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:51:48,018:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:51:48,042:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:52:20,079:INFO:Calculating mean and std
2023-08-02 18:52:20,081:INFO:Creating metrics dataframe
2023-08-02 18:52:25,127:INFO:Uploading results into container
2023-08-02 18:52:25,130:INFO:Uploading model into container now
2023-08-02 18:52:25,131:INFO:_master_model_container: 4
2023-08-02 18:52:25,131:INFO:_display_container: 2
2023-08-02 18:52:25,133:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-02 18:52:25,133:INFO:create_model() successfully completed......................................
2023-08-02 18:52:25,336:INFO:SubProcess create_model() end ==================================
2023-08-02 18:52:25,336:INFO:Creating metrics dataframe
2023-08-02 18:52:25,367:INFO:Initializing SVM - Linear Kernel
2023-08-02 18:52:25,367:INFO:Total runtime is 2.9661711812019345 minutes
2023-08-02 18:52:25,378:INFO:SubProcess create_model() called ==================================
2023-08-02 18:52:25,379:INFO:Initializing create_model()
2023-08-02 18:52:25,379:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000247778B3130>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 18:52:25,380:INFO:Checking exceptions
2023-08-02 18:52:25,380:INFO:Importing libraries
2023-08-02 18:52:25,381:INFO:Copying training dataset
2023-08-02 18:52:25,399:INFO:Defining folds
2023-08-02 18:52:25,400:INFO:Declaring metric variables
2023-08-02 18:52:25,413:INFO:Importing untrained model
2023-08-02 18:52:25,434:INFO:SVM - Linear Kernel Imported successfully
2023-08-02 18:52:25,494:INFO:Starting cross validation
2023-08-02 18:52:25,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 18:52:27,117:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:52:27,245:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:52:27,546:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:52:27,552:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 18:52:28,082:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,118:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,234:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 18:52:28,280:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,304:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,312:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,373:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,653:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:28,701:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:40,763:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:52:40,857:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 18:54:43,985:INFO:Initializing get_config()
2023-08-02 18:54:43,986:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, variable=None)
2023-08-02 18:54:56,074:INFO:Initializing get_config()
2023-08-02 18:54:56,074:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002477E063B50>, variable=X_train_transformed)
2023-08-02 18:54:56,228:INFO:Variable: X_train returned as       market_segment_Complementary  market_segment_Aviation  \
270                            1.0                      0.0   
4442                           0.0                      1.0   
2757                           0.0                      0.0   
2411                           0.0                      0.0   
3819                           0.0                      0.0   
...                            ...                      ...   
569                            0.0                      0.0   
2865                           0.0                      0.0   
7091                           0.0                      0.0   
4431                           0.0                      0.0   
6026                           0.0                      0.0   

      market_segment_Online TA  market_segment_Direct  \
270                        0.0                    0.0   
4442                       0.0                    0.0   
2757                       1.0                    0.0   
2411                       1.0                    0.0   
3819                       0.0                    1.0   
...                        ...                    ...   
569                        0.0                    0.0   
2865                       1.0                    0.0   
7091                       0.0                    0.0   
4431                       0.0                    0.0   
6026                       1.0                    0.0   

      market_segment_Offline TA/TO  market_segment_Corporate  \
270                            0.0                       0.0   
4442                           0.0                       0.0   
2757                           0.0                       0.0   
2411                           0.0                       0.0   
3819                           0.0                       0.0   
...                            ...                       ...   
569                            0.0                       1.0   
2865                           0.0                       0.0   
7091                           1.0                       0.0   
4431                           0.0                       0.0   
6026                           0.0                       0.0   

      market_segment_Groups  market_segment_Undefined  previous_cancellations  \
270                     0.0                       0.0                0.000000   
4442                    0.0                       0.0                0.000000   
2757                    0.0                       0.0                0.000000   
2411                    0.0                       0.0                0.000000   
3819                    0.0                       0.0                0.166667   
...                     ...                       ...                     ...   
569                     0.0                       0.0                0.166667   
2865                    0.0                       0.0                0.000000   
7091                    0.0                       0.0                0.000000   
4431                    1.0                       0.0                0.000000   
6026                    0.0                       0.0                0.000000   

      booking_changes  deposit_type_No Deposit  deposit_type_Non Refund  \
270          0.066667                      1.0                      0.0   
4442         0.000000                      1.0                      0.0   
2757         0.000000                      1.0                      0.0   
2411         0.000000                      1.0                      0.0   
3819         0.000000                      1.0                      0.0   
...               ...                      ...                      ...   
569          0.066667                      1.0                      0.0   
2865         0.066667                      1.0                      0.0   
7091         0.000000                      1.0                      0.0   
4431         0.000000                      1.0                      0.0   
6026         0.133333                      1.0                      0.0   

      deposit_type_Refundable  days_in_waiting_list  customer_type_Transient  \
270                       0.0                   0.0                      1.0   
4442                      0.0                   0.0                      0.0   
2757                      0.0                   0.0                      1.0   
2411                      0.0                   0.0                      1.0   
3819                      0.0                   0.0                      1.0   
...                       ...                   ...                      ...   
569                       0.0                   0.0                      0.0   
2865                      0.0                   0.0                      1.0   
7091                      0.0                   0.0                      1.0   
4431                      0.0                   0.0                      0.0   
6026                      0.0                   0.0                      1.0   

      customer_type_Transient-Party  customer_type_Group  \
270                             0.0                  0.0   
4442                            1.0                  0.0   
2757                            0.0                  0.0   
2411                            0.0                  0.0   
3819                            0.0                  0.0   
...                             ...                  ...   
569                             1.0                  0.0   
2865                            0.0                  0.0   
7091                            0.0                  0.0   
4431                            1.0                  0.0   
6026                            0.0                  0.0   

      customer_type_Contract  reserved_room_type_D  reserved_room_type_E  \
270                      0.0                   1.0                   0.0   
4442                     0.0                   1.0                   0.0   
2757                     0.0                   0.0                   1.0   
2411                     0.0                   0.0                   1.0   
3819                     0.0                   0.0                   0.0   
...                      ...                   ...                   ...   
569                      0.0                   0.0                   1.0   
2865                     0.0                   1.0                   0.0   
7091                     0.0                   0.0                   0.0   
4431                     0.0                   0.0                   1.0   
6026                     0.0                   0.0                   0.0   

      reserved_room_type_A  reserved_room_type_G  reserved_room_type_C  \
270                    0.0                   0.0                   0.0   
4442                   0.0                   0.0                   0.0   
2757                   0.0                   0.0                   0.0   
2411                   0.0                   0.0                   0.0   
3819                   1.0                   0.0                   0.0   
...                    ...                   ...                   ...   
569                    0.0                   0.0                   0.0   
2865                   0.0                   0.0                   0.0   
7091                   0.0                   0.0                   0.0   
4431                   0.0                   0.0                   0.0   
6026                   0.0                   0.0                   0.0   

      reserved_room_type_F  reserved_room_type_H  reserved_room_type_B  \
270                    0.0                   0.0                   0.0   
4442                   0.0                   0.0                   0.0   
2757                   0.0                   0.0                   0.0   
2411                   0.0                   0.0                   0.0   
3819                   0.0                   0.0                   0.0   
...                    ...                   ...                   ...   
569                    0.0                   0.0                   0.0   
2865                   0.0                   0.0                   0.0   
7091                   1.0                   0.0                   0.0   
4431                   0.0                   0.0                   0.0   
6026                   1.0                   0.0                   0.0   

      reserved_room_type_P  required_car_parking_spaces  \
270                    0.0                     0.333333   
4442                   0.0                     0.000000   
2757                   0.0                     0.000000   
2411                   0.0                     0.000000   
3819                   0.0                     0.000000   
...                    ...                          ...   
569                    0.0                     0.333333   
2865                   0.0                     0.000000   
7091                   0.0                     0.000000   
4431                   0.0                     0.000000   
6026                   0.0                     0.000000   

      total_of_special_requests  
270                         0.2  
4442                        0.0  
2757                        0.8  
2411                        0.2  
3819                        0.2  
...                         ...  
569                         0.6  
2865                        0.0  
7091                        0.0  
4431                        0.2  
6026                        0.2  

[5689 rows x 29 columns]
2023-08-02 18:54:56,229:INFO:get_config() successfully completed......................................
2023-08-02 20:51:38,982:INFO:PyCaret ClassificationExperiment
2023-08-02 20:51:38,982:INFO:Logging name: clf-default-name
2023-08-02 20:51:38,983:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-02 20:51:38,983:INFO:version 3.0.4
2023-08-02 20:51:38,983:INFO:Initializing setup()
2023-08-02 20:51:38,983:INFO:self.USI: c2c0
2023-08-02 20:51:38,983:INFO:self._variable_keys: {'target_param', 'fold_shuffle_param', 'is_multiclass', 'data', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'seed', 'exp_id', 'pipeline', 'fix_imbalance', 'y', 'X', '_available_plots', 'X_train', 'memory', 'n_jobs_param', 'X_test', 'fold_groups_param', 'idx', '_ml_usecase', 'fold_generator', 'logging_param', 'html_param', 'log_plots_param', 'y_train', 'y_test', 'exp_name_log'}
2023-08-02 20:51:38,983:INFO:Checking environment
2023-08-02 20:51:38,983:INFO:python_version: 3.9.13
2023-08-02 20:51:38,984:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-02 20:51:38,984:INFO:machine: AMD64
2023-08-02 20:51:38,984:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-02 20:51:38,991:INFO:Memory: svmem(total=17055166464, available=8412774400, percent=50.7, used=8642392064, free=8412774400)
2023-08-02 20:51:38,992:INFO:Physical Core: 4
2023-08-02 20:51:38,993:INFO:Logical Core: 8
2023-08-02 20:51:38,993:INFO:Checking libraries
2023-08-02 20:51:38,993:INFO:System:
2023-08-02 20:51:38,994:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-02 20:51:38,994:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-02 20:51:38,994:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-02 20:51:38,994:INFO:PyCaret required dependencies:
2023-08-02 20:51:38,995:INFO:                 pip: 22.0.4
2023-08-02 20:51:38,995:INFO:          setuptools: 58.1.0
2023-08-02 20:51:38,996:INFO:             pycaret: 3.0.4
2023-08-02 20:51:38,996:INFO:             IPython: 8.13.1
2023-08-02 20:51:38,996:INFO:          ipywidgets: 7.8.0
2023-08-02 20:51:38,997:INFO:                tqdm: 4.65.0
2023-08-02 20:51:38,997:INFO:               numpy: 1.23.0
2023-08-02 20:51:38,997:INFO:              pandas: 1.5.3
2023-08-02 20:51:38,997:INFO:              jinja2: 3.1.2
2023-08-02 20:51:38,997:INFO:               scipy: 1.10.1
2023-08-02 20:51:38,997:INFO:              joblib: 1.2.0
2023-08-02 20:51:38,997:INFO:             sklearn: 1.2.2
2023-08-02 20:51:38,997:INFO:                pyod: 1.1.0
2023-08-02 20:51:38,997:INFO:            imblearn: 0.11.0
2023-08-02 20:51:38,998:INFO:   category_encoders: 2.6.1
2023-08-02 20:51:38,998:INFO:            lightgbm: 3.3.5
2023-08-02 20:51:38,998:INFO:               numba: 0.57.1
2023-08-02 20:51:38,998:INFO:            requests: 2.31.0
2023-08-02 20:51:38,998:INFO:          matplotlib: 3.7.1
2023-08-02 20:51:38,998:INFO:          scikitplot: 0.3.7
2023-08-02 20:51:38,998:INFO:         yellowbrick: 1.5
2023-08-02 20:51:38,998:INFO:              plotly: 5.15.0
2023-08-02 20:51:38,998:INFO:    plotly-resampler: Not installed
2023-08-02 20:51:38,999:INFO:             kaleido: 0.2.1
2023-08-02 20:51:38,999:INFO:           schemdraw: 0.15
2023-08-02 20:51:38,999:INFO:         statsmodels: 0.14.0
2023-08-02 20:51:38,999:INFO:              sktime: 0.20.0
2023-08-02 20:51:38,999:INFO:               tbats: 1.1.3
2023-08-02 20:51:38,999:INFO:            pmdarima: 2.0.3
2023-08-02 20:51:38,999:INFO:              psutil: 5.9.5
2023-08-02 20:51:38,999:INFO:          markupsafe: 2.1.3
2023-08-02 20:51:39,000:INFO:             pickle5: Not installed
2023-08-02 20:51:39,000:INFO:         cloudpickle: 2.2.1
2023-08-02 20:51:39,000:INFO:         deprecation: 2.1.0
2023-08-02 20:51:39,000:INFO:              xxhash: 3.2.0
2023-08-02 20:51:39,000:INFO:           wurlitzer: Not installed
2023-08-02 20:51:39,000:INFO:PyCaret optional dependencies:
2023-08-02 20:51:39,001:INFO:                shap: Not installed
2023-08-02 20:51:39,001:INFO:           interpret: Not installed
2023-08-02 20:51:39,001:INFO:                umap: 0.5.3
2023-08-02 20:51:39,001:INFO:    pandas_profiling: 4.3.1
2023-08-02 20:51:39,002:INFO:  explainerdashboard: Not installed
2023-08-02 20:51:39,002:INFO:             autoviz: Not installed
2023-08-02 20:51:39,002:INFO:           fairlearn: Not installed
2023-08-02 20:51:39,002:INFO:          deepchecks: Not installed
2023-08-02 20:51:39,002:INFO:             xgboost: Not installed
2023-08-02 20:51:39,003:INFO:            catboost: Not installed
2023-08-02 20:51:39,003:INFO:              kmodes: Not installed
2023-08-02 20:51:39,003:INFO:             mlxtend: 0.22.0
2023-08-02 20:51:39,003:INFO:       statsforecast: Not installed
2023-08-02 20:51:39,003:INFO:        tune_sklearn: Not installed
2023-08-02 20:51:39,003:INFO:                 ray: Not installed
2023-08-02 20:51:39,004:INFO:            hyperopt: Not installed
2023-08-02 20:51:39,004:INFO:              optuna: 3.2.0
2023-08-02 20:51:39,004:INFO:               skopt: Not installed
2023-08-02 20:51:39,004:INFO:              mlflow: 2.5.0
2023-08-02 20:51:39,004:INFO:              gradio: Not installed
2023-08-02 20:51:39,004:INFO:             fastapi: Not installed
2023-08-02 20:51:39,004:INFO:             uvicorn: Not installed
2023-08-02 20:51:39,004:INFO:              m2cgen: Not installed
2023-08-02 20:51:39,005:INFO:           evidently: Not installed
2023-08-02 20:51:39,005:INFO:               fugue: Not installed
2023-08-02 20:51:39,005:INFO:           streamlit: 1.25.0
2023-08-02 20:51:39,005:INFO:             prophet: Not installed
2023-08-02 20:51:39,005:INFO:None
2023-08-02 20:51:39,005:INFO:Set up data.
2023-08-02 20:51:39,046:INFO:Set up train/test split.
2023-08-02 20:51:39,072:INFO:Set up index.
2023-08-02 20:51:39,073:INFO:Set up folding strategy.
2023-08-02 20:51:39,073:INFO:Assigning column types.
2023-08-02 20:51:39,087:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-02 20:51:39,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,553:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-02 20:51:39,694:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 20:51:39,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:39,893:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-02 20:51:40,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:40,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:40,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:40,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:40,349:INFO:Preparing preprocessing pipeline...
2023-08-02 20:51:40,351:INFO:Set up simple imputation.
2023-08-02 20:51:40,360:INFO:Set up encoding of categorical features.
2023-08-02 20:51:40,361:INFO:Set up removing multicollinearity.
2023-08-02 20:51:40,361:INFO:Set up feature normalization.
2023-08-02 20:51:41,086:INFO:Finished creating preprocessing pipeline.
2023-08-02 20:51:41,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-02 20:51:41,116:INFO:Creating final display dataframe.
2023-08-02 20:51:42,082:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape        (8136, 30)
5   Transformed train set shape        (5695, 30)
6    Transformed test set shape        (2441, 30)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15     Remove multicollinearity              True
16  Multicollinearity threshold               0.8
17                    Normalize              True
18             Normalize method            zscore
19               Fold Generator   StratifiedKFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  clf-default-name
25                          USI              c2c0
2023-08-02 20:51:42,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:42,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:42,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:42,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 20:51:42,735:INFO:setup() successfully completed in 8.54s...............
2023-08-02 20:51:49,433:INFO:Initializing compare_models()
2023-08-02 20:51:49,434:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-02 20:51:49,434:INFO:Checking exceptions
2023-08-02 20:51:49,446:INFO:Preparing display monitor
2023-08-02 20:51:49,552:INFO:Initializing Logistic Regression
2023-08-02 20:51:49,553:INFO:Total runtime is 1.6701221466064452e-05 minutes
2023-08-02 20:51:49,570:INFO:SubProcess create_model() called ==================================
2023-08-02 20:51:49,571:INFO:Initializing create_model()
2023-08-02 20:51:49,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:51:49,572:INFO:Checking exceptions
2023-08-02 20:51:49,572:INFO:Importing libraries
2023-08-02 20:51:49,573:INFO:Copying training dataset
2023-08-02 20:51:49,593:INFO:Defining folds
2023-08-02 20:51:49,593:INFO:Declaring metric variables
2023-08-02 20:51:49,604:INFO:Importing untrained model
2023-08-02 20:51:49,620:INFO:Logistic Regression Imported successfully
2023-08-02 20:51:49,653:INFO:Starting cross validation
2023-08-02 20:51:49,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:52:40,843:INFO:Calculating mean and std
2023-08-02 20:52:40,845:INFO:Creating metrics dataframe
2023-08-02 20:52:45,344:INFO:Uploading results into container
2023-08-02 20:52:45,346:INFO:Uploading model into container now
2023-08-02 20:52:45,347:INFO:_master_model_container: 1
2023-08-02 20:52:45,347:INFO:_display_container: 2
2023-08-02 20:52:45,348:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-02 20:52:45,348:INFO:create_model() successfully completed......................................
2023-08-02 20:52:50,364:INFO:SubProcess create_model() end ==================================
2023-08-02 20:52:50,365:INFO:Creating metrics dataframe
2023-08-02 20:52:50,382:INFO:Initializing K Neighbors Classifier
2023-08-02 20:52:50,383:INFO:Total runtime is 1.013852588335673 minutes
2023-08-02 20:52:50,389:INFO:SubProcess create_model() called ==================================
2023-08-02 20:52:50,390:INFO:Initializing create_model()
2023-08-02 20:52:50,390:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:52:50,390:INFO:Checking exceptions
2023-08-02 20:52:50,391:INFO:Importing libraries
2023-08-02 20:52:50,391:INFO:Copying training dataset
2023-08-02 20:52:50,403:INFO:Defining folds
2023-08-02 20:52:50,404:INFO:Declaring metric variables
2023-08-02 20:52:50,412:INFO:Importing untrained model
2023-08-02 20:52:50,421:INFO:K Neighbors Classifier Imported successfully
2023-08-02 20:52:50,445:INFO:Starting cross validation
2023-08-02 20:52:50,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:53:24,968:INFO:Calculating mean and std
2023-08-02 20:53:24,971:INFO:Creating metrics dataframe
2023-08-02 20:53:30,031:INFO:Uploading results into container
2023-08-02 20:53:30,034:INFO:Uploading model into container now
2023-08-02 20:53:30,035:INFO:_master_model_container: 2
2023-08-02 20:53:30,035:INFO:_display_container: 2
2023-08-02 20:53:30,036:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 20:53:30,036:INFO:create_model() successfully completed......................................
2023-08-02 20:53:30,279:INFO:SubProcess create_model() end ==================================
2023-08-02 20:53:30,280:INFO:Creating metrics dataframe
2023-08-02 20:53:30,306:INFO:Initializing Naive Bayes
2023-08-02 20:53:30,306:INFO:Total runtime is 1.6792362173398336 minutes
2023-08-02 20:53:30,318:INFO:SubProcess create_model() called ==================================
2023-08-02 20:53:30,318:INFO:Initializing create_model()
2023-08-02 20:53:30,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:53:30,319:INFO:Checking exceptions
2023-08-02 20:53:30,319:INFO:Importing libraries
2023-08-02 20:53:30,319:INFO:Copying training dataset
2023-08-02 20:53:30,337:INFO:Defining folds
2023-08-02 20:53:30,337:INFO:Declaring metric variables
2023-08-02 20:53:30,349:INFO:Importing untrained model
2023-08-02 20:53:30,361:INFO:Naive Bayes Imported successfully
2023-08-02 20:53:30,390:INFO:Starting cross validation
2023-08-02 20:53:30,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:53:32,288:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:53:32,350:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:53:32,424:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:04,884:INFO:Calculating mean and std
2023-08-02 20:54:04,886:INFO:Creating metrics dataframe
2023-08-02 20:54:10,159:INFO:Uploading results into container
2023-08-02 20:54:10,161:INFO:Uploading model into container now
2023-08-02 20:54:10,162:INFO:_master_model_container: 3
2023-08-02 20:54:10,162:INFO:_display_container: 2
2023-08-02 20:54:10,163:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-02 20:54:10,163:INFO:create_model() successfully completed......................................
2023-08-02 20:54:10,379:INFO:SubProcess create_model() end ==================================
2023-08-02 20:54:10,380:INFO:Creating metrics dataframe
2023-08-02 20:54:10,407:INFO:Initializing Decision Tree Classifier
2023-08-02 20:54:10,408:INFO:Total runtime is 2.347602693239848 minutes
2023-08-02 20:54:10,418:INFO:SubProcess create_model() called ==================================
2023-08-02 20:54:10,419:INFO:Initializing create_model()
2023-08-02 20:54:10,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:54:10,419:INFO:Checking exceptions
2023-08-02 20:54:10,419:INFO:Importing libraries
2023-08-02 20:54:10,419:INFO:Copying training dataset
2023-08-02 20:54:10,437:INFO:Defining folds
2023-08-02 20:54:10,437:INFO:Declaring metric variables
2023-08-02 20:54:10,455:INFO:Importing untrained model
2023-08-02 20:54:10,469:INFO:Decision Tree Classifier Imported successfully
2023-08-02 20:54:10,505:INFO:Starting cross validation
2023-08-02 20:54:10,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:54:12,434:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:12,570:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:12,606:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:12,621:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:12,778:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:54:45,009:INFO:Calculating mean and std
2023-08-02 20:54:45,011:INFO:Creating metrics dataframe
2023-08-02 20:54:50,204:INFO:Uploading results into container
2023-08-02 20:54:50,207:INFO:Uploading model into container now
2023-08-02 20:54:50,208:INFO:_master_model_container: 4
2023-08-02 20:54:50,208:INFO:_display_container: 2
2023-08-02 20:54:50,210:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-02 20:54:50,211:INFO:create_model() successfully completed......................................
2023-08-02 20:54:50,418:INFO:SubProcess create_model() end ==================================
2023-08-02 20:54:50,418:INFO:Creating metrics dataframe
2023-08-02 20:54:50,439:INFO:Initializing SVM - Linear Kernel
2023-08-02 20:54:50,439:INFO:Total runtime is 3.014785957336426 minutes
2023-08-02 20:54:50,449:INFO:SubProcess create_model() called ==================================
2023-08-02 20:54:50,450:INFO:Initializing create_model()
2023-08-02 20:54:50,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:54:50,450:INFO:Checking exceptions
2023-08-02 20:54:50,451:INFO:Importing libraries
2023-08-02 20:54:50,451:INFO:Copying training dataset
2023-08-02 20:54:50,470:INFO:Defining folds
2023-08-02 20:54:50,470:INFO:Declaring metric variables
2023-08-02 20:54:50,494:INFO:Importing untrained model
2023-08-02 20:54:50,540:INFO:SVM - Linear Kernel Imported successfully
2023-08-02 20:54:50,595:INFO:Starting cross validation
2023-08-02 20:54:50,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:54:52,068:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:54:52,265:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:54:52,267:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:54:52,980:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,104:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,170:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,194:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,208:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,341:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,348:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:54:53,356:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:55:05,237:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:55:05,263:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 20:55:24,276:INFO:Calculating mean and std
2023-08-02 20:55:24,278:INFO:Creating metrics dataframe
2023-08-02 20:55:29,254:INFO:Uploading results into container
2023-08-02 20:55:29,256:INFO:Uploading model into container now
2023-08-02 20:55:29,257:INFO:_master_model_container: 5
2023-08-02 20:55:29,257:INFO:_display_container: 2
2023-08-02 20:55:29,259:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-02 20:55:29,259:INFO:create_model() successfully completed......................................
2023-08-02 20:55:29,488:INFO:SubProcess create_model() end ==================================
2023-08-02 20:55:29,489:INFO:Creating metrics dataframe
2023-08-02 20:55:29,526:INFO:Initializing Ridge Classifier
2023-08-02 20:55:29,527:INFO:Total runtime is 3.666252605120341 minutes
2023-08-02 20:55:29,539:INFO:SubProcess create_model() called ==================================
2023-08-02 20:55:29,540:INFO:Initializing create_model()
2023-08-02 20:55:29,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:55:29,541:INFO:Checking exceptions
2023-08-02 20:55:29,541:INFO:Importing libraries
2023-08-02 20:55:29,541:INFO:Copying training dataset
2023-08-02 20:55:29,562:INFO:Defining folds
2023-08-02 20:55:29,563:INFO:Declaring metric variables
2023-08-02 20:55:29,579:INFO:Importing untrained model
2023-08-02 20:55:29,604:INFO:Ridge Classifier Imported successfully
2023-08-02 20:55:29,644:INFO:Starting cross validation
2023-08-02 20:55:29,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:55:31,371:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,428:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:55:31,431:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,431:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,445:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,456:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:55:31,507:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,509:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,533:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:31,533:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:55:31,572:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:43,485:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:55:43,487:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 20:56:03,841:INFO:Calculating mean and std
2023-08-02 20:56:03,844:INFO:Creating metrics dataframe
2023-08-02 20:56:08,966:INFO:Uploading results into container
2023-08-02 20:56:08,967:INFO:Uploading model into container now
2023-08-02 20:56:08,969:INFO:_master_model_container: 6
2023-08-02 20:56:08,969:INFO:_display_container: 2
2023-08-02 20:56:08,971:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-02 20:56:08,971:INFO:create_model() successfully completed......................................
2023-08-02 20:56:09,163:INFO:SubProcess create_model() end ==================================
2023-08-02 20:56:09,163:INFO:Creating metrics dataframe
2023-08-02 20:56:09,189:INFO:Initializing Random Forest Classifier
2023-08-02 20:56:09,189:INFO:Total runtime is 4.327295887470245 minutes
2023-08-02 20:56:09,197:INFO:SubProcess create_model() called ==================================
2023-08-02 20:56:09,198:INFO:Initializing create_model()
2023-08-02 20:56:09,198:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:56:09,198:INFO:Checking exceptions
2023-08-02 20:56:09,199:INFO:Importing libraries
2023-08-02 20:56:09,199:INFO:Copying training dataset
2023-08-02 20:56:09,216:INFO:Defining folds
2023-08-02 20:56:09,217:INFO:Declaring metric variables
2023-08-02 20:56:09,227:INFO:Importing untrained model
2023-08-02 20:56:09,242:INFO:Random Forest Classifier Imported successfully
2023-08-02 20:56:09,279:INFO:Starting cross validation
2023-08-02 20:56:09,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:56:14,450:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:14,506:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:14,727:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:14,727:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:14,732:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:14,918:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:15,092:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:15,149:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:16,237:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,298:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,497:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,518:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,529:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,827:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:16,896:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:17,058:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:31,714:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:31,765:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:56:33,090:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:33,323:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:56:54,513:INFO:Calculating mean and std
2023-08-02 20:56:54,516:INFO:Creating metrics dataframe
2023-08-02 20:56:59,829:INFO:Uploading results into container
2023-08-02 20:56:59,831:INFO:Uploading model into container now
2023-08-02 20:56:59,832:INFO:_master_model_container: 7
2023-08-02 20:56:59,832:INFO:_display_container: 2
2023-08-02 20:56:59,834:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-02 20:56:59,834:INFO:create_model() successfully completed......................................
2023-08-02 20:57:00,110:INFO:SubProcess create_model() end ==================================
2023-08-02 20:57:00,110:INFO:Creating metrics dataframe
2023-08-02 20:57:00,149:INFO:Initializing Quadratic Discriminant Analysis
2023-08-02 20:57:00,150:INFO:Total runtime is 5.176645890871684 minutes
2023-08-02 20:57:00,163:INFO:SubProcess create_model() called ==================================
2023-08-02 20:57:00,164:INFO:Initializing create_model()
2023-08-02 20:57:00,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:57:00,165:INFO:Checking exceptions
2023-08-02 20:57:00,165:INFO:Importing libraries
2023-08-02 20:57:00,165:INFO:Copying training dataset
2023-08-02 20:57:00,185:INFO:Defining folds
2023-08-02 20:57:00,187:INFO:Declaring metric variables
2023-08-02 20:57:00,204:INFO:Importing untrained model
2023-08-02 20:57:00,221:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-02 20:57:00,254:INFO:Starting cross validation
2023-08-02 20:57:00,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:57:00,997:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,030:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,032:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,066:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,078:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,111:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,124:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:01,124:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:02,082:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:02,154:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:02,220:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:02,264:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:02,288:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:02,403:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-02 20:57:15,161:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:15,221:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 20:57:37,907:INFO:Calculating mean and std
2023-08-02 20:57:37,910:INFO:Creating metrics dataframe
2023-08-02 20:57:43,505:INFO:Uploading results into container
2023-08-02 20:57:43,509:INFO:Uploading model into container now
2023-08-02 20:57:43,512:INFO:_master_model_container: 8
2023-08-02 20:57:43,512:INFO:_display_container: 2
2023-08-02 20:57:43,514:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-02 20:57:43,515:INFO:create_model() successfully completed......................................
2023-08-02 20:57:43,876:INFO:SubProcess create_model() end ==================================
2023-08-02 20:57:43,877:INFO:Creating metrics dataframe
2023-08-02 20:57:43,950:INFO:Initializing Ada Boost Classifier
2023-08-02 20:57:43,951:INFO:Total runtime is 5.906654997666677 minutes
2023-08-02 20:57:43,966:INFO:SubProcess create_model() called ==================================
2023-08-02 20:57:43,967:INFO:Initializing create_model()
2023-08-02 20:57:43,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:57:43,968:INFO:Checking exceptions
2023-08-02 20:57:43,968:INFO:Importing libraries
2023-08-02 20:57:43,968:INFO:Copying training dataset
2023-08-02 20:57:44,002:INFO:Defining folds
2023-08-02 20:57:44,003:INFO:Declaring metric variables
2023-08-02 20:57:44,042:INFO:Importing untrained model
2023-08-02 20:57:44,070:INFO:Ada Boost Classifier Imported successfully
2023-08-02 20:57:44,137:INFO:Starting cross validation
2023-08-02 20:57:44,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:57:47,372:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:47,717:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:47,860:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:48,041:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:48,068:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:48,298:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:48,486:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:57:48,984:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,354:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,356:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,661:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,692:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,920:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:57:49,935:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:27,699:INFO:Calculating mean and std
2023-08-02 20:58:27,702:INFO:Creating metrics dataframe
2023-08-02 20:58:32,844:INFO:Uploading results into container
2023-08-02 20:58:32,846:INFO:Uploading model into container now
2023-08-02 20:58:32,848:INFO:_master_model_container: 9
2023-08-02 20:58:32,849:INFO:_display_container: 2
2023-08-02 20:58:32,850:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-02 20:58:32,851:INFO:create_model() successfully completed......................................
2023-08-02 20:58:33,082:INFO:SubProcess create_model() end ==================================
2023-08-02 20:58:33,083:INFO:Creating metrics dataframe
2023-08-02 20:58:33,108:INFO:Initializing Gradient Boosting Classifier
2023-08-02 20:58:33,108:INFO:Total runtime is 6.72593191464742 minutes
2023-08-02 20:58:33,117:INFO:SubProcess create_model() called ==================================
2023-08-02 20:58:33,118:INFO:Initializing create_model()
2023-08-02 20:58:33,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:58:33,118:INFO:Checking exceptions
2023-08-02 20:58:33,119:INFO:Importing libraries
2023-08-02 20:58:33,119:INFO:Copying training dataset
2023-08-02 20:58:33,136:INFO:Defining folds
2023-08-02 20:58:33,136:INFO:Declaring metric variables
2023-08-02 20:58:33,147:INFO:Importing untrained model
2023-08-02 20:58:33,163:INFO:Gradient Boosting Classifier Imported successfully
2023-08-02 20:58:33,203:INFO:Starting cross validation
2023-08-02 20:58:33,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:58:37,624:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,702:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,732:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,742:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,785:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,875:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,902:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:37,944:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 20:58:39,117:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,123:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,124:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,252:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,274:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,277:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,347:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:58:39,350:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 20:59:16,501:INFO:Calculating mean and std
2023-08-02 20:59:16,504:INFO:Creating metrics dataframe
2023-08-02 20:59:21,689:INFO:Uploading results into container
2023-08-02 20:59:21,693:INFO:Uploading model into container now
2023-08-02 20:59:21,697:INFO:_master_model_container: 10
2023-08-02 20:59:21,697:INFO:_display_container: 2
2023-08-02 20:59:21,698:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-02 20:59:21,699:INFO:create_model() successfully completed......................................
2023-08-02 20:59:21,942:INFO:SubProcess create_model() end ==================================
2023-08-02 20:59:21,942:INFO:Creating metrics dataframe
2023-08-02 20:59:21,971:INFO:Initializing Linear Discriminant Analysis
2023-08-02 20:59:21,971:INFO:Total runtime is 7.540324425697326 minutes
2023-08-02 20:59:21,980:INFO:SubProcess create_model() called ==================================
2023-08-02 20:59:21,981:INFO:Initializing create_model()
2023-08-02 20:59:21,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 20:59:21,981:INFO:Checking exceptions
2023-08-02 20:59:21,981:INFO:Importing libraries
2023-08-02 20:59:21,982:INFO:Copying training dataset
2023-08-02 20:59:21,994:INFO:Defining folds
2023-08-02 20:59:21,996:INFO:Declaring metric variables
2023-08-02 20:59:22,008:INFO:Importing untrained model
2023-08-02 20:59:22,022:INFO:Linear Discriminant Analysis Imported successfully
2023-08-02 20:59:22,053:INFO:Starting cross validation
2023-08-02 20:59:22,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 20:59:24,519:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:01,206:INFO:Calculating mean and std
2023-08-02 21:00:01,208:INFO:Creating metrics dataframe
2023-08-02 21:00:06,674:INFO:Uploading results into container
2023-08-02 21:00:06,675:INFO:Uploading model into container now
2023-08-02 21:00:06,677:INFO:_master_model_container: 11
2023-08-02 21:00:06,677:INFO:_display_container: 2
2023-08-02 21:00:06,678:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-02 21:00:06,678:INFO:create_model() successfully completed......................................
2023-08-02 21:00:06,925:INFO:SubProcess create_model() end ==================================
2023-08-02 21:00:06,925:INFO:Creating metrics dataframe
2023-08-02 21:00:06,962:INFO:Initializing Extra Trees Classifier
2023-08-02 21:00:06,962:INFO:Total runtime is 8.29016805489858 minutes
2023-08-02 21:00:06,975:INFO:SubProcess create_model() called ==================================
2023-08-02 21:00:06,976:INFO:Initializing create_model()
2023-08-02 21:00:06,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:00:06,976:INFO:Checking exceptions
2023-08-02 21:00:06,977:INFO:Importing libraries
2023-08-02 21:00:06,977:INFO:Copying training dataset
2023-08-02 21:00:06,993:INFO:Defining folds
2023-08-02 21:00:06,993:INFO:Declaring metric variables
2023-08-02 21:00:07,008:INFO:Importing untrained model
2023-08-02 21:00:07,022:INFO:Extra Trees Classifier Imported successfully
2023-08-02 21:00:07,058:INFO:Starting cross validation
2023-08-02 21:00:07,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:00:12,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:12,461:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:12,565:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:12,616:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:13,027:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:13,027:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:13,052:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:13,055:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:00:14,239:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,244:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,410:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,483:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,836:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,988:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:14,999:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:15,110:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:00:52,697:INFO:Calculating mean and std
2023-08-02 21:00:52,700:INFO:Creating metrics dataframe
2023-08-02 21:00:58,046:INFO:Uploading results into container
2023-08-02 21:00:58,049:INFO:Uploading model into container now
2023-08-02 21:00:58,051:INFO:_master_model_container: 12
2023-08-02 21:00:58,051:INFO:_display_container: 2
2023-08-02 21:00:58,053:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-02 21:00:58,053:INFO:create_model() successfully completed......................................
2023-08-02 21:00:58,295:INFO:SubProcess create_model() end ==================================
2023-08-02 21:00:58,295:INFO:Creating metrics dataframe
2023-08-02 21:00:58,326:INFO:Initializing Light Gradient Boosting Machine
2023-08-02 21:00:58,327:INFO:Total runtime is 9.146234130859375 minutes
2023-08-02 21:00:58,336:INFO:SubProcess create_model() called ==================================
2023-08-02 21:00:58,337:INFO:Initializing create_model()
2023-08-02 21:00:58,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:00:58,339:INFO:Checking exceptions
2023-08-02 21:00:58,339:INFO:Importing libraries
2023-08-02 21:00:58,339:INFO:Copying training dataset
2023-08-02 21:00:58,356:INFO:Defining folds
2023-08-02 21:00:58,357:INFO:Declaring metric variables
2023-08-02 21:00:58,366:INFO:Importing untrained model
2023-08-02 21:00:58,377:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-02 21:00:58,410:INFO:Starting cross validation
2023-08-02 21:00:58,420:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:01:00,655:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:00,759:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:00,844:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:00,948:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:01,015:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:01,066:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:01,115:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:01,320:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:01:01,874:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:01:01,915:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:01:02,150:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:01:37,755:INFO:Calculating mean and std
2023-08-02 21:01:37,757:INFO:Creating metrics dataframe
2023-08-02 21:01:42,692:INFO:Uploading results into container
2023-08-02 21:01:42,693:INFO:Uploading model into container now
2023-08-02 21:01:42,694:INFO:_master_model_container: 13
2023-08-02 21:01:42,694:INFO:_display_container: 2
2023-08-02 21:01:42,696:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-02 21:01:42,696:INFO:create_model() successfully completed......................................
2023-08-02 21:01:42,917:INFO:SubProcess create_model() end ==================================
2023-08-02 21:01:42,917:INFO:Creating metrics dataframe
2023-08-02 21:01:42,948:INFO:Initializing Dummy Classifier
2023-08-02 21:01:42,948:INFO:Total runtime is 9.889934047063191 minutes
2023-08-02 21:01:42,959:INFO:SubProcess create_model() called ==================================
2023-08-02 21:01:42,959:INFO:Initializing create_model()
2023-08-02 21:01:42,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024788077D90>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:01:42,960:INFO:Checking exceptions
2023-08-02 21:01:42,960:INFO:Importing libraries
2023-08-02 21:01:42,960:INFO:Copying training dataset
2023-08-02 21:01:42,978:INFO:Defining folds
2023-08-02 21:01:42,978:INFO:Declaring metric variables
2023-08-02 21:01:42,989:INFO:Importing untrained model
2023-08-02 21:01:43,000:INFO:Dummy Classifier Imported successfully
2023-08-02 21:01:43,031:INFO:Starting cross validation
2023-08-02 21:01:43,040:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:01:45,246:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:01:45,247:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,292:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,374:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,375:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:01:45,388:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,413:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,565:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,607:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:45,863:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:58,195:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:01:58,229:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:02:19,429:INFO:Calculating mean and std
2023-08-02 21:02:19,431:INFO:Creating metrics dataframe
2023-08-02 21:02:24,436:INFO:Uploading results into container
2023-08-02 21:02:24,438:INFO:Uploading model into container now
2023-08-02 21:02:24,439:INFO:_master_model_container: 14
2023-08-02 21:02:24,439:INFO:_display_container: 2
2023-08-02 21:02:24,440:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-02 21:02:24,440:INFO:create_model() successfully completed......................................
2023-08-02 21:02:24,635:INFO:SubProcess create_model() end ==================================
2023-08-02 21:02:24,635:INFO:Creating metrics dataframe
2023-08-02 21:02:24,684:INFO:Initializing create_model()
2023-08-02 21:02:24,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:02:24,685:INFO:Checking exceptions
2023-08-02 21:02:24,690:INFO:Importing libraries
2023-08-02 21:02:24,690:INFO:Copying training dataset
2023-08-02 21:02:24,704:INFO:Defining folds
2023-08-02 21:02:24,704:INFO:Declaring metric variables
2023-08-02 21:02:24,705:INFO:Importing untrained model
2023-08-02 21:02:24,705:INFO:Declaring custom model
2023-08-02 21:02:24,706:INFO:Gradient Boosting Classifier Imported successfully
2023-08-02 21:02:24,709:INFO:Cross validation set to False
2023-08-02 21:02:24,710:INFO:Fitting Model
2023-08-02 21:02:29,251:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-02 21:02:29,252:INFO:create_model() successfully completed......................................
2023-08-02 21:02:29,655:INFO:_master_model_container: 14
2023-08-02 21:02:29,655:INFO:_display_container: 2
2023-08-02 21:02:29,657:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-02 21:02:29,658:INFO:compare_models() successfully completed......................................
2023-08-02 21:03:27,066:INFO:Initializing create_model()
2023-08-02 21:03:27,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:03:27,067:INFO:Checking exceptions
2023-08-02 21:03:27,133:INFO:Importing libraries
2023-08-02 21:03:27,134:INFO:Copying training dataset
2023-08-02 21:03:27,154:INFO:Defining folds
2023-08-02 21:03:27,155:INFO:Declaring metric variables
2023-08-02 21:03:27,168:INFO:Importing untrained model
2023-08-02 21:03:27,183:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:03:27,219:INFO:Starting cross validation
2023-08-02 21:03:27,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:03:28,841:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:04:10,290:INFO:Calculating mean and std
2023-08-02 21:04:10,294:INFO:Creating metrics dataframe
2023-08-02 21:04:10,309:INFO:Finalizing model
2023-08-02 21:04:19,405:INFO:Uploading results into container
2023-08-02 21:04:19,408:INFO:Uploading model into container now
2023-08-02 21:04:19,482:INFO:_master_model_container: 15
2023-08-02 21:04:19,483:INFO:_display_container: 3
2023-08-02 21:04:19,485:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 21:04:19,487:INFO:create_model() successfully completed......................................
2023-08-02 21:05:21,764:INFO:Initializing evaluate_model()
2023-08-02 21:05:21,765:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-02 21:05:21,865:INFO:Initializing plot_model()
2023-08-02 21:05:21,865:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, system=True)
2023-08-02 21:05:21,866:INFO:Checking exceptions
2023-08-02 21:05:21,873:INFO:Preloading libraries
2023-08-02 21:05:21,874:INFO:Copying training dataset
2023-08-02 21:05:21,875:INFO:Plot type: pipeline
2023-08-02 21:05:23,120:INFO:Visual Rendered Successfully
2023-08-02 21:05:23,887:INFO:plot_model() successfully completed......................................
2023-08-02 21:05:25,694:INFO:Initializing plot_model()
2023-08-02 21:05:25,695:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, system=True)
2023-08-02 21:05:25,695:INFO:Checking exceptions
2023-08-02 21:05:25,703:INFO:Preloading libraries
2023-08-02 21:05:25,705:INFO:Copying training dataset
2023-08-02 21:05:25,705:INFO:Plot type: confusion_matrix
2023-08-02 21:05:25,944:INFO:Fitting Model
2023-08-02 21:05:25,946:INFO:Scoring test/hold-out set
2023-08-02 21:05:27,210:INFO:Visual Rendered Successfully
2023-08-02 21:05:27,373:INFO:plot_model() successfully completed......................................
2023-08-02 21:07:55,674:INFO:Initializing plot_model()
2023-08-02 21:07:55,674:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, system=True)
2023-08-02 21:07:55,674:INFO:Checking exceptions
2023-08-02 21:07:55,678:INFO:Preloading libraries
2023-08-02 21:07:55,679:INFO:Copying training dataset
2023-08-02 21:07:55,679:INFO:Plot type: threshold
2023-08-02 21:07:55,789:INFO:Fitting Model
2023-08-02 21:07:58,125:INFO:Scoring test/hold-out set
2023-08-02 21:07:59,249:INFO:Visual Rendered Successfully
2023-08-02 21:07:59,472:INFO:plot_model() successfully completed......................................
2023-08-02 21:08:13,755:INFO:Initializing create_model()
2023-08-02 21:08:13,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.33, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:08:13,756:INFO:Checking exceptions
2023-08-02 21:08:13,791:INFO:Importing libraries
2023-08-02 21:08:13,791:INFO:Copying training dataset
2023-08-02 21:08:13,806:INFO:Defining folds
2023-08-02 21:08:13,807:INFO:Declaring metric variables
2023-08-02 21:08:13,819:INFO:Importing untrained model
2023-08-02 21:08:13,835:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:08:13,861:INFO:Starting cross validation
2023-08-02 21:08:13,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:08:43,534:INFO:Calculating mean and std
2023-08-02 21:08:43,536:INFO:Creating metrics dataframe
2023-08-02 21:08:43,547:INFO:Finalizing model
2023-08-02 21:08:48,392:INFO:Uploading results into container
2023-08-02 21:08:48,395:INFO:Uploading model into container now
2023-08-02 21:08:48,423:INFO:_master_model_container: 16
2023-08-02 21:08:48,423:INFO:_display_container: 4
2023-08-02 21:08:48,426:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.33,
                                     weights='uniform')
2023-08-02 21:08:48,426:INFO:create_model() successfully completed......................................
2023-08-02 21:09:06,701:INFO:Initializing create_model()
2023-08-02 21:09:06,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.6, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:09:06,702:INFO:Checking exceptions
2023-08-02 21:09:06,762:INFO:Importing libraries
2023-08-02 21:09:06,763:INFO:Copying training dataset
2023-08-02 21:09:06,786:INFO:Defining folds
2023-08-02 21:09:06,788:INFO:Declaring metric variables
2023-08-02 21:09:06,804:INFO:Importing untrained model
2023-08-02 21:09:06,819:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:09:06,848:INFO:Starting cross validation
2023-08-02 21:09:06,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:09:08,877:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:09:08,882:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:09:09,011:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:09:37,714:INFO:Calculating mean and std
2023-08-02 21:09:37,716:INFO:Creating metrics dataframe
2023-08-02 21:09:37,726:INFO:Finalizing model
2023-08-02 21:09:42,357:INFO:Uploading results into container
2023-08-02 21:09:42,360:INFO:Uploading model into container now
2023-08-02 21:09:42,397:INFO:_master_model_container: 17
2023-08-02 21:09:42,398:INFO:_display_container: 5
2023-08-02 21:09:42,400:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.6,
                                     weights='uniform')
2023-08-02 21:09:42,400:INFO:create_model() successfully completed......................................
2023-08-02 21:09:53,931:INFO:Initializing create_model()
2023-08-02 21:09:53,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.7, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:09:53,933:INFO:Checking exceptions
2023-08-02 21:09:53,968:INFO:Importing libraries
2023-08-02 21:09:53,969:INFO:Copying training dataset
2023-08-02 21:09:53,983:INFO:Defining folds
2023-08-02 21:09:53,984:INFO:Declaring metric variables
2023-08-02 21:09:53,994:INFO:Importing untrained model
2023-08-02 21:09:54,005:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:09:54,031:INFO:Starting cross validation
2023-08-02 21:09:54,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:09:55,644:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:09:55,961:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:09:56,265:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:10:27,702:INFO:Calculating mean and std
2023-08-02 21:10:27,705:INFO:Creating metrics dataframe
2023-08-02 21:10:27,719:INFO:Finalizing model
2023-08-02 21:10:33,321:INFO:Uploading results into container
2023-08-02 21:10:33,328:INFO:Uploading model into container now
2023-08-02 21:10:33,372:INFO:_master_model_container: 18
2023-08-02 21:10:33,372:INFO:_display_container: 6
2023-08-02 21:10:33,377:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.7,
                                     weights='uniform')
2023-08-02 21:10:33,378:INFO:create_model() successfully completed......................................
2023-08-02 21:10:41,133:INFO:Initializing create_model()
2023-08-02 21:10:41,133:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, estimator=knn, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=0.55, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:10:41,134:INFO:Checking exceptions
2023-08-02 21:10:41,185:INFO:Importing libraries
2023-08-02 21:10:41,186:INFO:Copying training dataset
2023-08-02 21:10:41,204:INFO:Defining folds
2023-08-02 21:10:41,204:INFO:Declaring metric variables
2023-08-02 21:10:41,216:INFO:Importing untrained model
2023-08-02 21:10:41,229:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:10:41,255:INFO:Starting cross validation
2023-08-02 21:10:41,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:10:43,266:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:10:43,357:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:10:43,441:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:11:18,771:INFO:Calculating mean and std
2023-08-02 21:11:18,773:INFO:Creating metrics dataframe
2023-08-02 21:11:18,787:INFO:Finalizing model
2023-08-02 21:11:24,438:INFO:Uploading results into container
2023-08-02 21:11:24,440:INFO:Uploading model into container now
2023-08-02 21:11:24,482:INFO:_master_model_container: 19
2023-08-02 21:11:24,482:INFO:_display_container: 7
2023-08-02 21:11:24,485:INFO:CustomProbabilityThresholdClassifier(algorithm='auto',
                                     classifier=KNeighborsClassifier(algorithm='auto',
                                                                     leaf_size=30,
                                                                     metric='minkowski',
                                                                     metric_params=None,
                                                                     n_jobs=-1,
                                                                     n_neighbors=5,
                                                                     p=2,
                                                                     weights='uniform'),
                                     leaf_size=30, metric='minkowski',
                                     metric_params=None, n_jobs=-1,
                                     n_neighbors=5, p=2,
                                     probability_threshold=0.55,
                                     weights='uniform')
2023-08-02 21:11:24,486:INFO:create_model() successfully completed......................................
2023-08-02 21:11:41,743:INFO:Initializing plot_model()
2023-08-02 21:11:41,743:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024787C1CFD0>, system=True)
2023-08-02 21:11:41,743:INFO:Checking exceptions
2023-08-02 21:11:41,747:INFO:Preloading libraries
2023-08-02 21:11:41,748:INFO:Copying training dataset
2023-08-02 21:11:41,748:INFO:Plot type: confusion_matrix
2023-08-02 21:11:41,910:INFO:Fitting Model
2023-08-02 21:11:41,911:INFO:Scoring test/hold-out set
2023-08-02 21:11:42,715:INFO:Visual Rendered Successfully
2023-08-02 21:11:43,024:INFO:plot_model() successfully completed......................................
2023-08-02 21:12:33,739:INFO:PyCaret ClassificationExperiment
2023-08-02 21:12:33,739:INFO:Logging name: clf-default-name
2023-08-02 21:12:33,739:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-02 21:12:33,739:INFO:version 3.0.4
2023-08-02 21:12:33,739:INFO:Initializing setup()
2023-08-02 21:12:33,739:INFO:self.USI: f320
2023-08-02 21:12:33,739:INFO:self._variable_keys: {'target_param', 'fold_shuffle_param', 'is_multiclass', 'data', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'seed', 'exp_id', 'pipeline', 'fix_imbalance', 'y', 'X', '_available_plots', 'X_train', 'memory', 'n_jobs_param', 'X_test', 'fold_groups_param', 'idx', '_ml_usecase', 'fold_generator', 'logging_param', 'html_param', 'log_plots_param', 'y_train', 'y_test', 'exp_name_log'}
2023-08-02 21:12:33,739:INFO:Checking environment
2023-08-02 21:12:33,739:INFO:python_version: 3.9.13
2023-08-02 21:12:33,740:INFO:python_build: ('tags/v3.9.13:6de2ca5', 'May 17 2022 16:36:42')
2023-08-02 21:12:33,740:INFO:machine: AMD64
2023-08-02 21:12:33,740:INFO:platform: Windows-10-10.0.19045-SP0
2023-08-02 21:12:33,744:INFO:Memory: svmem(total=17055166464, available=7879450624, percent=53.8, used=9175715840, free=7879450624)
2023-08-02 21:12:33,745:INFO:Physical Core: 4
2023-08-02 21:12:33,745:INFO:Logical Core: 8
2023-08-02 21:12:33,745:INFO:Checking libraries
2023-08-02 21:12:33,745:INFO:System:
2023-08-02 21:12:33,745:INFO:    python: 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]
2023-08-02 21:12:33,745:INFO:executable: c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\python.exe
2023-08-02 21:12:33,745:INFO:   machine: Windows-10-10.0.19045-SP0
2023-08-02 21:12:33,745:INFO:PyCaret required dependencies:
2023-08-02 21:12:33,745:INFO:                 pip: 22.0.4
2023-08-02 21:12:33,745:INFO:          setuptools: 58.1.0
2023-08-02 21:12:33,745:INFO:             pycaret: 3.0.4
2023-08-02 21:12:33,746:INFO:             IPython: 8.13.1
2023-08-02 21:12:33,746:INFO:          ipywidgets: 7.8.0
2023-08-02 21:12:33,746:INFO:                tqdm: 4.65.0
2023-08-02 21:12:33,746:INFO:               numpy: 1.23.0
2023-08-02 21:12:33,746:INFO:              pandas: 1.5.3
2023-08-02 21:12:33,746:INFO:              jinja2: 3.1.2
2023-08-02 21:12:33,746:INFO:               scipy: 1.10.1
2023-08-02 21:12:33,746:INFO:              joblib: 1.2.0
2023-08-02 21:12:33,746:INFO:             sklearn: 1.2.2
2023-08-02 21:12:33,746:INFO:                pyod: 1.1.0
2023-08-02 21:12:33,746:INFO:            imblearn: 0.11.0
2023-08-02 21:12:33,746:INFO:   category_encoders: 2.6.1
2023-08-02 21:12:33,746:INFO:            lightgbm: 3.3.5
2023-08-02 21:12:33,746:INFO:               numba: 0.57.1
2023-08-02 21:12:33,747:INFO:            requests: 2.31.0
2023-08-02 21:12:33,747:INFO:          matplotlib: 3.7.1
2023-08-02 21:12:33,747:INFO:          scikitplot: 0.3.7
2023-08-02 21:12:33,747:INFO:         yellowbrick: 1.5
2023-08-02 21:12:33,747:INFO:              plotly: 5.15.0
2023-08-02 21:12:33,747:INFO:    plotly-resampler: Not installed
2023-08-02 21:12:33,747:INFO:             kaleido: 0.2.1
2023-08-02 21:12:33,747:INFO:           schemdraw: 0.15
2023-08-02 21:12:33,747:INFO:         statsmodels: 0.14.0
2023-08-02 21:12:33,748:INFO:              sktime: 0.20.0
2023-08-02 21:12:33,748:INFO:               tbats: 1.1.3
2023-08-02 21:12:33,748:INFO:            pmdarima: 2.0.3
2023-08-02 21:12:33,748:INFO:              psutil: 5.9.5
2023-08-02 21:12:33,748:INFO:          markupsafe: 2.1.3
2023-08-02 21:12:33,748:INFO:             pickle5: Not installed
2023-08-02 21:12:33,748:INFO:         cloudpickle: 2.2.1
2023-08-02 21:12:33,748:INFO:         deprecation: 2.1.0
2023-08-02 21:12:33,748:INFO:              xxhash: 3.2.0
2023-08-02 21:12:33,748:INFO:           wurlitzer: Not installed
2023-08-02 21:12:33,748:INFO:PyCaret optional dependencies:
2023-08-02 21:12:33,749:INFO:                shap: Not installed
2023-08-02 21:12:33,749:INFO:           interpret: Not installed
2023-08-02 21:12:33,749:INFO:                umap: 0.5.3
2023-08-02 21:12:33,749:INFO:    pandas_profiling: 4.3.1
2023-08-02 21:12:33,749:INFO:  explainerdashboard: Not installed
2023-08-02 21:12:33,749:INFO:             autoviz: Not installed
2023-08-02 21:12:33,749:INFO:           fairlearn: Not installed
2023-08-02 21:12:33,749:INFO:          deepchecks: Not installed
2023-08-02 21:12:33,750:INFO:             xgboost: Not installed
2023-08-02 21:12:33,750:INFO:            catboost: Not installed
2023-08-02 21:12:33,750:INFO:              kmodes: Not installed
2023-08-02 21:12:33,750:INFO:             mlxtend: 0.22.0
2023-08-02 21:12:33,750:INFO:       statsforecast: Not installed
2023-08-02 21:12:33,750:INFO:        tune_sklearn: Not installed
2023-08-02 21:12:33,750:INFO:                 ray: Not installed
2023-08-02 21:12:33,750:INFO:            hyperopt: Not installed
2023-08-02 21:12:33,750:INFO:              optuna: 3.2.0
2023-08-02 21:12:33,750:INFO:               skopt: Not installed
2023-08-02 21:12:33,750:INFO:              mlflow: 2.5.0
2023-08-02 21:12:33,750:INFO:              gradio: Not installed
2023-08-02 21:12:33,750:INFO:             fastapi: Not installed
2023-08-02 21:12:33,750:INFO:             uvicorn: Not installed
2023-08-02 21:12:33,751:INFO:              m2cgen: Not installed
2023-08-02 21:12:33,751:INFO:           evidently: Not installed
2023-08-02 21:12:33,751:INFO:               fugue: Not installed
2023-08-02 21:12:33,751:INFO:           streamlit: 1.25.0
2023-08-02 21:12:33,751:INFO:             prophet: Not installed
2023-08-02 21:12:33,751:INFO:None
2023-08-02 21:12:33,751:INFO:Set up data.
2023-08-02 21:12:33,767:INFO:Set up train/test split.
2023-08-02 21:12:33,778:INFO:Set up index.
2023-08-02 21:12:33,778:INFO:Set up folding strategy.
2023-08-02 21:12:33,778:INFO:Assigning column types.
2023-08-02 21:12:33,786:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-02 21:12:33,861:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 21:12:33,863:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 21:12:33,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:33,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:33,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-02 21:12:33,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 21:12:34,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,038:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-02 21:12:34,116:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 21:12:34,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,254:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-02 21:12:34,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,296:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-02 21:12:34,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,608:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:34,611:INFO:Preparing preprocessing pipeline...
2023-08-02 21:12:34,613:INFO:Set up simple imputation.
2023-08-02 21:12:34,620:INFO:Set up encoding of categorical features.
2023-08-02 21:12:34,620:INFO:Set up polynomial features.
2023-08-02 21:12:34,620:INFO:Set up removing multicollinearity.
2023-08-02 21:12:34,620:INFO:Set up feature normalization.
2023-08-02 21:12:40,484:INFO:Finished creating preprocessing pipeline.
2023-08-02 21:12:40,497:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\faisa\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['previous_cancellations',
                                             'booking_changes',
                                             'days_in_waiting_list',
                                             'required_car_parking_spaces',
                                             'total_of_special_requests'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_e...
                                    transformer=PolynomialFeatures(degree=2,
                                                                   include_bias=False,
                                                                   interaction_only=False,
                                                                   order='C'))),
                ('remove_multicollinearity',
                 TransformerWrapper(exclude=[], include=None,
                                    transformer=RemoveMulticollinearity(threshold=0.8))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2023-08-02 21:12:40,498:INFO:Creating final display dataframe.
2023-08-02 21:12:41,512:INFO:Setup _display_container:                     Description             Value
0                    Session id              2020
1                        Target       is_canceled
2                   Target type            Binary
3           Original data shape        (8136, 10)
4        Transformed data shape       (8136, 377)
5   Transformed train set shape       (5695, 377)
6    Transformed test set shape       (2441, 377)
7              Numeric features                 5
8          Categorical features                 4
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15          Polynomial features              True
16            Polynomial degree                 2
17     Remove multicollinearity              True
18  Multicollinearity threshold               0.8
19                    Normalize              True
20             Normalize method            zscore
21               Fold Generator   StratifiedKFold
22                  Fold Number                10
23                     CPU Jobs                -1
24                      Use GPU             False
25               Log Experiment             False
26              Experiment Name  clf-default-name
27                          USI              f320
2023-08-02 21:12:41,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:41,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:41,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:41,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-08-02 21:12:41,888:INFO:setup() successfully completed in 12.12s...............
2023-08-02 21:12:51,604:INFO:Initializing get_config()
2023-08-02 21:12:51,605:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, variable=None)
2023-08-02 21:12:57,513:INFO:Initializing get_config()
2023-08-02 21:12:57,514:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, variable=X_train_transformed)
2023-08-02 21:12:57,759:INFO:Variable: X_train returned as       market_segment_Offline TA/TO  market_segment_Online TA  \
5614                     -0.412171                 -0.973144   
6470                     -0.412171                 -0.973144   
9620                      2.426177                 -0.973144   
852                      -0.412171                  1.027598   
1966                     -0.412171                  1.027598   
...                            ...                       ...   
9238                     -0.412171                 -0.973144   
7745                     -0.412171                 -0.973144   
5901                      2.426177                 -0.973144   
5894                      2.426177                 -0.973144   
2344                     -0.412171                  1.027598   

      market_segment_Aviation  previous_cancellations  \
5614                -0.081959               -0.197595   
6470                -0.081959               -0.197595   
9620                -0.081959               -0.197595   
852                 -0.081959               -0.197595   
1966                -0.081959               -0.197595   
...                       ...                     ...   
9238                -0.081959               -0.197595   
7745                -0.081959               -0.197595   
5901                -0.081959               -0.197595   
5894                -0.081959               -0.197595   
2344                -0.081959               -0.197595   

      deposit_type_Refundable  deposit_type_No Deposit  \
5614                14.488821                -6.417568   
6470                -0.069019                 0.155822   
9620                -0.069019                 0.155822   
852                 -0.069019                 0.155822   
1966                -0.069019                 0.155822   
...                       ...                      ...   
9238                -0.069019                 0.155822   
7745                -0.069019                 0.155822   
5901                -0.069019                 0.155822   
5894                -0.069019                 0.155822   
2344                -0.069019                 0.155822   

      customer_type_Transient-Party  customer_type_Transient  \
5614                       1.715781                -1.442813   
6470                      -0.582825                 0.693090   
9620                       1.715781                -1.442813   
852                       -0.582825                 0.693090   
1966                      -0.582825                 0.693090   
...                             ...                      ...   
9238                      -0.582825                 0.693090   
7745                       1.715781                -1.442813   
5901                      -0.582825                -1.442813   
5894                      -0.582825                 0.693090   
2344                      -0.582825                 0.693090   

      customer_type_Contract  reserved_room_type_A  ...  \
5614               -0.219599              1.105052  ...   
6470               -0.219599             -0.904935  ...   
9620               -0.219599              1.105052  ...   
852                -0.219599             -0.904935  ...   
1966               -0.219599             -0.904935  ...   
...                      ...                   ...  ...   
9238               -0.219599             -0.904935  ...   
7745               -0.219599              1.105052  ...   
5901                4.553750             -0.904935  ...   
5894               -0.219599             -0.904935  ...   
2344               -0.219599             -0.904935  ...   

      reserved_room_type_G reserved_room_type_P  \
5614                                        0.0   
6470                                        0.0   
9620                                        0.0   
852                                         0.0   
1966                                        0.0   
...                                         ...   
9238                                        0.0   
7745                                        0.0   
5901                                        0.0   
5894                                        0.0   
2344                                        0.0   

      reserved_room_type_G required_car_parking_spaces  \
5614                                         -0.120902   
6470                                         -0.120902   
9620                                         -0.120902   
852                                          -0.120902   
1966                                         -0.120902   
...                                                ...   
9238                                         -0.120902   
7745                                         -0.120902   
5901                                         -0.120902   
5894                                         -0.120902   
2344                                         -0.120902   

      reserved_room_type_G total_of_special_requests  \
5614                                       -0.158418   
6470                                       -0.158418   
9620                                       -0.158418   
852                                        -0.158418   
1966                                       -0.158418   
...                                              ...   
9238                                       -0.158418   
7745                                       -0.158418   
5901                                       -0.158418   
5894                                       -0.158418   
2344                                       -0.158418   

      reserved_room_type_L reserved_room_type_P  \
5614                                        0.0   
6470                                        0.0   
9620                                        0.0   
852                                         0.0   
1966                                        0.0   
...                                         ...   
9238                                        0.0   
7745                                        0.0   
5901                                        0.0   
5894                                        0.0   
2344                                        0.0   

      reserved_room_type_L required_car_parking_spaces  \
5614                                               0.0   
6470                                               0.0   
9620                                               0.0   
852                                                0.0   
1966                                               0.0   
...                                                ...   
9238                                               0.0   
7745                                               0.0   
5901                                               0.0   
5894                                               0.0   
2344                                               0.0   

      reserved_room_type_L total_of_special_requests  \
5614                                             0.0   
6470                                             0.0   
9620                                             0.0   
852                                              0.0   
1966                                             0.0   
...                                              ...   
9238                                             0.0   
7745                                             0.0   
5901                                             0.0   
5894                                             0.0   
2344                                             0.0   

      reserved_room_type_P required_car_parking_spaces  \
5614                                               0.0   
6470                                               0.0   
9620                                               0.0   
852                                                0.0   
1966                                               0.0   
...                                                ...   
9238                                               0.0   
7745                                               0.0   
5901                                               0.0   
5894                                               0.0   
2344                                               0.0   

      reserved_room_type_P total_of_special_requests  \
5614                                             0.0   
6470                                             0.0   
9620                                             0.0   
852                                              0.0   
1966                                             0.0   
...                                              ...   
9238                                             0.0   
7745                                             0.0   
5901                                             0.0   
5894                                             0.0   
2344                                             0.0   

      required_car_parking_spaces total_of_special_requests  \
5614                                          -0.302982       
6470                                          -0.302982       
9620                                          -0.302982       
852                                           -0.302982       
1966                                          -0.302982       
...                                                 ...       
9238                                          -0.302982       
7745                                          -0.302982       
5901                                          -0.302982       
5894                                          -0.302982       
2344                                          -0.302982       

      total_of_special_requests^2  
5614                    -0.683345  
6470                     0.826364  
9620                    -0.683345  
852                      2.713500  
1966                    -0.683345  
...                           ...  
9238                    -0.683345  
7745                    -0.683345  
5901                     2.713500  
5894                    -0.683345  
2344                    -0.683345  

[5695 rows x 376 columns]
2023-08-02 21:12:57,760:INFO:get_config() successfully completed......................................
2023-08-02 21:13:37,405:INFO:Initializing compare_models()
2023-08-02 21:13:37,406:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, include=None, fold=None, round=4, cross_validation=True, sort=MCC, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MCC', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-02 21:13:37,406:INFO:Checking exceptions
2023-08-02 21:13:37,420:INFO:Preparing display monitor
2023-08-02 21:13:37,476:INFO:Initializing Logistic Regression
2023-08-02 21:13:37,476:INFO:Total runtime is 0.0 minutes
2023-08-02 21:13:37,485:INFO:SubProcess create_model() called ==================================
2023-08-02 21:13:37,486:INFO:Initializing create_model()
2023-08-02 21:13:37,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:13:37,486:INFO:Checking exceptions
2023-08-02 21:13:37,486:INFO:Importing libraries
2023-08-02 21:13:37,486:INFO:Copying training dataset
2023-08-02 21:13:37,498:INFO:Defining folds
2023-08-02 21:13:37,498:INFO:Declaring metric variables
2023-08-02 21:13:37,506:INFO:Importing untrained model
2023-08-02 21:13:37,518:INFO:Logistic Regression Imported successfully
2023-08-02 21:13:37,538:INFO:Starting cross validation
2023-08-02 21:13:37,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:13:38,860:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:39,301:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:56,710:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:56,744:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:56,763:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:56,780:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:56,814:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:56,937:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:57,175:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:57,531:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:57,925:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:57,971:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:57,979:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:58,024:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:58,106:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:58,278:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:58,462:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:58,793:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,030:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,043:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,082:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,210:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:13:59,305:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,441:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:13:59,669:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:14:00,220:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:00,373:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:00,402:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:00,409:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:00,613:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:00,827:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:01,115:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:14:02,160:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:03,587:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:04,065:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,231:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,354:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,368:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,375:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,692:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:04,798:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:05,521:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:05,831:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:45,513:INFO:Calculating mean and std
2023-08-02 21:14:45,515:INFO:Creating metrics dataframe
2023-08-02 21:14:50,850:INFO:Uploading results into container
2023-08-02 21:14:50,851:INFO:Uploading model into container now
2023-08-02 21:14:50,854:INFO:_master_model_container: 1
2023-08-02 21:14:50,854:INFO:_display_container: 2
2023-08-02 21:14:50,856:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2020, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-02 21:14:50,856:INFO:create_model() successfully completed......................................
2023-08-02 21:14:51,113:INFO:SubProcess create_model() end ==================================
2023-08-02 21:14:51,113:INFO:Creating metrics dataframe
2023-08-02 21:14:51,131:INFO:Initializing K Neighbors Classifier
2023-08-02 21:14:51,131:INFO:Total runtime is 1.227583368619283 minutes
2023-08-02 21:14:51,141:INFO:SubProcess create_model() called ==================================
2023-08-02 21:14:51,141:INFO:Initializing create_model()
2023-08-02 21:14:51,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:14:51,141:INFO:Checking exceptions
2023-08-02 21:14:51,142:INFO:Importing libraries
2023-08-02 21:14:51,142:INFO:Copying training dataset
2023-08-02 21:14:51,158:INFO:Defining folds
2023-08-02 21:14:51,158:INFO:Declaring metric variables
2023-08-02 21:14:51,168:INFO:Importing untrained model
2023-08-02 21:14:51,179:INFO:K Neighbors Classifier Imported successfully
2023-08-02 21:14:51,212:INFO:Starting cross validation
2023-08-02 21:14:51,223:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:14:53,859:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:53,888:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:53,903:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:53,906:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:53,932:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:53,983:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:14:55,100:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:55,228:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:55,264:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:55,295:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:14:55,883:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-02 21:14:56,427:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:15:09,262:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:15:09,466:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-08-02 21:15:31,506:INFO:Calculating mean and std
2023-08-02 21:15:31,508:INFO:Creating metrics dataframe
2023-08-02 21:15:36,587:INFO:Uploading results into container
2023-08-02 21:15:36,589:INFO:Uploading model into container now
2023-08-02 21:15:36,591:INFO:_master_model_container: 2
2023-08-02 21:15:36,592:INFO:_display_container: 2
2023-08-02 21:15:36,593:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-02 21:15:36,594:INFO:create_model() successfully completed......................................
2023-08-02 21:15:36,815:INFO:SubProcess create_model() end ==================================
2023-08-02 21:15:36,816:INFO:Creating metrics dataframe
2023-08-02 21:15:36,838:INFO:Initializing Naive Bayes
2023-08-02 21:15:36,839:INFO:Total runtime is 1.9893756548563637 minutes
2023-08-02 21:15:36,846:INFO:SubProcess create_model() called ==================================
2023-08-02 21:15:36,847:INFO:Initializing create_model()
2023-08-02 21:15:36,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:15:36,848:INFO:Checking exceptions
2023-08-02 21:15:36,848:INFO:Importing libraries
2023-08-02 21:15:36,848:INFO:Copying training dataset
2023-08-02 21:15:36,861:INFO:Defining folds
2023-08-02 21:15:36,862:INFO:Declaring metric variables
2023-08-02 21:15:36,874:INFO:Importing untrained model
2023-08-02 21:15:36,885:INFO:Naive Bayes Imported successfully
2023-08-02 21:15:36,913:INFO:Starting cross validation
2023-08-02 21:15:36,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:15:39,153:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:15:39,206:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,259:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,331:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,358:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,359:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,361:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:39,592:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:40,448:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:15:54,560:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:15:54,567:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:16:21,772:INFO:Calculating mean and std
2023-08-02 21:16:21,779:INFO:Creating metrics dataframe
2023-08-02 21:16:28,197:INFO:Uploading results into container
2023-08-02 21:16:28,199:INFO:Uploading model into container now
2023-08-02 21:16:28,200:INFO:_master_model_container: 3
2023-08-02 21:16:28,200:INFO:_display_container: 2
2023-08-02 21:16:28,201:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-02 21:16:28,201:INFO:create_model() successfully completed......................................
2023-08-02 21:16:28,434:INFO:SubProcess create_model() end ==================================
2023-08-02 21:16:28,435:INFO:Creating metrics dataframe
2023-08-02 21:16:28,469:INFO:Initializing Decision Tree Classifier
2023-08-02 21:16:28,469:INFO:Total runtime is 2.8498686393102006 minutes
2023-08-02 21:16:28,480:INFO:SubProcess create_model() called ==================================
2023-08-02 21:16:28,480:INFO:Initializing create_model()
2023-08-02 21:16:28,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:16:28,481:INFO:Checking exceptions
2023-08-02 21:16:28,482:INFO:Importing libraries
2023-08-02 21:16:28,482:INFO:Copying training dataset
2023-08-02 21:16:28,503:INFO:Defining folds
2023-08-02 21:16:28,503:INFO:Declaring metric variables
2023-08-02 21:16:28,518:INFO:Importing untrained model
2023-08-02 21:16:28,532:INFO:Decision Tree Classifier Imported successfully
2023-08-02 21:16:28,566:INFO:Starting cross validation
2023-08-02 21:16:28,575:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:16:30,848:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-08-02 21:16:31,606:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,638:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,705:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,790:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,809:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,827:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:31,881:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:32,502:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:16:33,013:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:16:33,069:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:16:33,093:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:16:33,148:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:16:33,184:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:16,406:INFO:Calculating mean and std
2023-08-02 21:17:16,408:INFO:Creating metrics dataframe
2023-08-02 21:17:22,278:INFO:Uploading results into container
2023-08-02 21:17:22,281:INFO:Uploading model into container now
2023-08-02 21:17:22,282:INFO:_master_model_container: 4
2023-08-02 21:17:22,283:INFO:_display_container: 2
2023-08-02 21:17:22,283:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2020, splitter='best')
2023-08-02 21:17:22,284:INFO:create_model() successfully completed......................................
2023-08-02 21:17:22,773:INFO:SubProcess create_model() end ==================================
2023-08-02 21:17:22,774:INFO:Creating metrics dataframe
2023-08-02 21:17:22,870:INFO:Initializing SVM - Linear Kernel
2023-08-02 21:17:22,871:INFO:Total runtime is 3.756571066379547 minutes
2023-08-02 21:17:22,916:INFO:SubProcess create_model() called ==================================
2023-08-02 21:17:22,918:INFO:Initializing create_model()
2023-08-02 21:17:22,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:17:22,918:INFO:Checking exceptions
2023-08-02 21:17:22,919:INFO:Importing libraries
2023-08-02 21:17:22,919:INFO:Copying training dataset
2023-08-02 21:17:22,959:INFO:Defining folds
2023-08-02 21:17:22,961:INFO:Declaring metric variables
2023-08-02 21:17:22,989:INFO:Importing untrained model
2023-08-02 21:17:23,018:INFO:SVM - Linear Kernel Imported successfully
2023-08-02 21:17:23,076:INFO:Starting cross validation
2023-08-02 21:17:23,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:17:29,124:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:29,576:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:29,817:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:29,965:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:30,008:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:30,291:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:30,322:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:30,423:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:17:30,583:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:30,634:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,068:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:31,143:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,272:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:31,315:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,669:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:31,720:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,733:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,777:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:31,822:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:31,906:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:32,340:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:17:32,371:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:48,374:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:17:48,593:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-02 21:18:12,141:INFO:Calculating mean and std
2023-08-02 21:18:12,144:INFO:Creating metrics dataframe
2023-08-02 21:18:17,908:INFO:Uploading results into container
2023-08-02 21:18:17,910:INFO:Uploading model into container now
2023-08-02 21:18:17,911:INFO:_master_model_container: 5
2023-08-02 21:18:17,911:INFO:_display_container: 2
2023-08-02 21:18:17,913:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2020, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-02 21:18:17,913:INFO:create_model() successfully completed......................................
2023-08-02 21:18:18,181:INFO:SubProcess create_model() end ==================================
2023-08-02 21:18:18,181:INFO:Creating metrics dataframe
2023-08-02 21:18:18,214:INFO:Initializing Ridge Classifier
2023-08-02 21:18:18,214:INFO:Total runtime is 4.678955948352813 minutes
2023-08-02 21:18:18,223:INFO:SubProcess create_model() called ==================================
2023-08-02 21:18:18,224:INFO:Initializing create_model()
2023-08-02 21:18:18,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:18:18,224:INFO:Checking exceptions
2023-08-02 21:18:18,224:INFO:Importing libraries
2023-08-02 21:18:18,224:INFO:Copying training dataset
2023-08-02 21:18:18,244:INFO:Defining folds
2023-08-02 21:18:18,244:INFO:Declaring metric variables
2023-08-02 21:18:18,255:INFO:Importing untrained model
2023-08-02 21:18:18,271:INFO:Ridge Classifier Imported successfully
2023-08-02 21:18:18,306:INFO:Starting cross validation
2023-08-02 21:18:18,318:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:18:21,066:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,145:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,210:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,244:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,308:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,439:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,491:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:21,649:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:18:22,420:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:18:22,428:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:18:22,454:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,478:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,487:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,499:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,592:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,607:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,923:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:22,990:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:38,681:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:18:38,770:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-02 21:19:02,836:INFO:Calculating mean and std
2023-08-02 21:19:02,838:INFO:Creating metrics dataframe
2023-08-02 21:19:09,464:INFO:Uploading results into container
2023-08-02 21:19:09,468:INFO:Uploading model into container now
2023-08-02 21:19:09,470:INFO:_master_model_container: 6
2023-08-02 21:19:09,471:INFO:_display_container: 2
2023-08-02 21:19:09,473:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2020, solver='auto',
                tol=0.0001)
2023-08-02 21:19:09,473:INFO:create_model() successfully completed......................................
2023-08-02 21:19:09,795:INFO:SubProcess create_model() end ==================================
2023-08-02 21:19:09,795:INFO:Creating metrics dataframe
2023-08-02 21:19:09,829:INFO:Initializing Random Forest Classifier
2023-08-02 21:19:09,829:INFO:Total runtime is 5.539214646816253 minutes
2023-08-02 21:19:09,842:INFO:SubProcess create_model() called ==================================
2023-08-02 21:19:09,843:INFO:Initializing create_model()
2023-08-02 21:19:09,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:19:09,843:INFO:Checking exceptions
2023-08-02 21:19:09,843:INFO:Importing libraries
2023-08-02 21:19:09,843:INFO:Copying training dataset
2023-08-02 21:19:09,863:INFO:Defining folds
2023-08-02 21:19:09,864:INFO:Declaring metric variables
2023-08-02 21:19:09,884:INFO:Importing untrained model
2023-08-02 21:19:09,896:INFO:Random Forest Classifier Imported successfully
2023-08-02 21:19:09,940:INFO:Starting cross validation
2023-08-02 21:19:09,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:19:23,179:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:23,184:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:23,314:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:23,325:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:23,509:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:23,603:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:24,092:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:24,130:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:25,370:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:25,563:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:25,605:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:25,794:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:26,044:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:26,064:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:26,513:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:26,580:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:46,202:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:46,270:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:19:47,443:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:19:47,510:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:20:10,520:INFO:Calculating mean and std
2023-08-02 21:20:10,523:INFO:Creating metrics dataframe
2023-08-02 21:20:16,942:INFO:Uploading results into container
2023-08-02 21:20:16,944:INFO:Uploading model into container now
2023-08-02 21:20:16,946:INFO:_master_model_container: 7
2023-08-02 21:20:16,946:INFO:_display_container: 2
2023-08-02 21:20:16,948:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2020, verbose=0, warm_start=False)
2023-08-02 21:20:16,948:INFO:create_model() successfully completed......................................
2023-08-02 21:20:17,222:INFO:SubProcess create_model() end ==================================
2023-08-02 21:20:17,222:INFO:Creating metrics dataframe
2023-08-02 21:20:17,257:INFO:Initializing Quadratic Discriminant Analysis
2023-08-02 21:20:17,257:INFO:Total runtime is 6.663009289900462 minutes
2023-08-02 21:20:17,268:INFO:SubProcess create_model() called ==================================
2023-08-02 21:20:17,269:INFO:Initializing create_model()
2023-08-02 21:20:17,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:20:17,270:INFO:Checking exceptions
2023-08-02 21:20:17,270:INFO:Importing libraries
2023-08-02 21:20:17,270:INFO:Copying training dataset
2023-08-02 21:20:17,292:INFO:Defining folds
2023-08-02 21:20:17,292:INFO:Declaring metric variables
2023-08-02 21:20:17,305:INFO:Importing untrained model
2023-08-02 21:20:17,317:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-02 21:20:17,340:INFO:Starting cross validation
2023-08-02 21:20:17,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:20:19,771:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:19,840:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:19,848:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:19,910:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:19,930:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:19,987:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:20,028:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:20,048:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:20,980:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,091:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,097:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,142:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,144:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,176:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,233:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:21,247:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:20:33,765:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:33,924:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-02 21:20:51,650:INFO:Calculating mean and std
2023-08-02 21:20:51,652:INFO:Creating metrics dataframe
2023-08-02 21:20:56,669:INFO:Uploading results into container
2023-08-02 21:20:56,670:INFO:Uploading model into container now
2023-08-02 21:20:56,672:INFO:_master_model_container: 8
2023-08-02 21:20:56,672:INFO:_display_container: 2
2023-08-02 21:20:56,673:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-02 21:20:56,673:INFO:create_model() successfully completed......................................
2023-08-02 21:20:56,861:INFO:SubProcess create_model() end ==================================
2023-08-02 21:20:56,862:INFO:Creating metrics dataframe
2023-08-02 21:20:56,882:INFO:Initializing Ada Boost Classifier
2023-08-02 21:20:56,882:INFO:Total runtime is 7.323427311579386 minutes
2023-08-02 21:20:56,889:INFO:SubProcess create_model() called ==================================
2023-08-02 21:20:56,890:INFO:Initializing create_model()
2023-08-02 21:20:56,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:20:56,890:INFO:Checking exceptions
2023-08-02 21:20:56,890:INFO:Importing libraries
2023-08-02 21:20:56,890:INFO:Copying training dataset
2023-08-02 21:20:56,901:INFO:Defining folds
2023-08-02 21:20:56,901:INFO:Declaring metric variables
2023-08-02 21:20:56,910:INFO:Importing untrained model
2023-08-02 21:20:56,918:INFO:Ada Boost Classifier Imported successfully
2023-08-02 21:20:56,935:INFO:Starting cross validation
2023-08-02 21:20:56,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:21:03,708:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:03,838:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:03,856:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:03,859:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:03,911:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:03,942:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:04,050:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:04,056:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:05,108:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:05,121:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:05,192:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:35,825:INFO:Calculating mean and std
2023-08-02 21:21:35,826:INFO:Creating metrics dataframe
2023-08-02 21:21:40,248:INFO:Uploading results into container
2023-08-02 21:21:40,249:INFO:Uploading model into container now
2023-08-02 21:21:40,250:INFO:_master_model_container: 9
2023-08-02 21:21:40,251:INFO:_display_container: 2
2023-08-02 21:21:40,251:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2020)
2023-08-02 21:21:40,252:INFO:create_model() successfully completed......................................
2023-08-02 21:21:40,454:INFO:SubProcess create_model() end ==================================
2023-08-02 21:21:40,454:INFO:Creating metrics dataframe
2023-08-02 21:21:40,476:INFO:Initializing Gradient Boosting Classifier
2023-08-02 21:21:40,477:INFO:Total runtime is 8.050002284844716 minutes
2023-08-02 21:21:40,484:INFO:SubProcess create_model() called ==================================
2023-08-02 21:21:40,485:INFO:Initializing create_model()
2023-08-02 21:21:40,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:21:40,485:INFO:Checking exceptions
2023-08-02 21:21:40,485:INFO:Importing libraries
2023-08-02 21:21:40,485:INFO:Copying training dataset
2023-08-02 21:21:40,499:INFO:Defining folds
2023-08-02 21:21:40,499:INFO:Declaring metric variables
2023-08-02 21:21:40,509:INFO:Importing untrained model
2023-08-02 21:21:40,520:INFO:Gradient Boosting Classifier Imported successfully
2023-08-02 21:21:40,541:INFO:Starting cross validation
2023-08-02 21:21:40,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:21:52,077:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,093:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,157:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,179:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,219:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,284:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,334:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:52,401:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:21:53,485:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:53,500:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:53,558:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:53,655:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:53,769:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:53,875:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:54,124:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:21:54,391:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:22:28,415:INFO:Calculating mean and std
2023-08-02 21:22:28,417:INFO:Creating metrics dataframe
2023-08-02 21:22:33,245:INFO:Uploading results into container
2023-08-02 21:22:33,248:INFO:Uploading model into container now
2023-08-02 21:22:33,249:INFO:_master_model_container: 10
2023-08-02 21:22:33,249:INFO:_display_container: 2
2023-08-02 21:22:33,250:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2020, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-02 21:22:33,250:INFO:create_model() successfully completed......................................
2023-08-02 21:22:33,452:INFO:SubProcess create_model() end ==================================
2023-08-02 21:22:33,452:INFO:Creating metrics dataframe
2023-08-02 21:22:33,478:INFO:Initializing Linear Discriminant Analysis
2023-08-02 21:22:33,478:INFO:Total runtime is 8.933361490567524 minutes
2023-08-02 21:22:33,487:INFO:SubProcess create_model() called ==================================
2023-08-02 21:22:33,487:INFO:Initializing create_model()
2023-08-02 21:22:33,487:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:22:33,487:INFO:Checking exceptions
2023-08-02 21:22:33,487:INFO:Importing libraries
2023-08-02 21:22:33,488:INFO:Copying training dataset
2023-08-02 21:22:33,502:INFO:Defining folds
2023-08-02 21:22:33,503:INFO:Declaring metric variables
2023-08-02 21:22:33,514:INFO:Importing untrained model
2023-08-02 21:22:33,527:INFO:Linear Discriminant Analysis Imported successfully
2023-08-02 21:22:33,547:INFO:Starting cross validation
2023-08-02 21:22:33,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:22:38,637:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:38,717:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:38,751:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:38,891:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:38,925:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:38,995:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:39,041:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:39,292:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:22:40,160:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:08,877:INFO:Calculating mean and std
2023-08-02 21:23:08,879:INFO:Creating metrics dataframe
2023-08-02 21:23:13,656:INFO:Uploading results into container
2023-08-02 21:23:13,657:INFO:Uploading model into container now
2023-08-02 21:23:13,659:INFO:_master_model_container: 11
2023-08-02 21:23:13,659:INFO:_display_container: 2
2023-08-02 21:23:13,660:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-02 21:23:13,660:INFO:create_model() successfully completed......................................
2023-08-02 21:23:13,886:INFO:SubProcess create_model() end ==================================
2023-08-02 21:23:13,886:INFO:Creating metrics dataframe
2023-08-02 21:23:13,918:INFO:Initializing Extra Trees Classifier
2023-08-02 21:23:13,918:INFO:Total runtime is 9.607355149586994 minutes
2023-08-02 21:23:13,928:INFO:SubProcess create_model() called ==================================
2023-08-02 21:23:13,928:INFO:Initializing create_model()
2023-08-02 21:23:13,928:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:23:13,929:INFO:Checking exceptions
2023-08-02 21:23:13,929:INFO:Importing libraries
2023-08-02 21:23:13,930:INFO:Copying training dataset
2023-08-02 21:23:13,949:INFO:Defining folds
2023-08-02 21:23:13,949:INFO:Declaring metric variables
2023-08-02 21:23:13,961:INFO:Importing untrained model
2023-08-02 21:23:13,974:INFO:Extra Trees Classifier Imported successfully
2023-08-02 21:23:13,996:INFO:Starting cross validation
2023-08-02 21:23:14,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:23:26,787:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:26,865:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:26,924:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:26,991:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:27,449:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:27,468:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:27,995:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:28,223:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:28,623:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:28,981:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:29,213:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:29,980:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:30,156:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:30,199:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:30,334:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:30,487:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-08-02 21:23:31,559:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:48,304:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:48,897:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:23:49,741:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:23:50,216:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-08-02 21:24:15,911:INFO:Calculating mean and std
2023-08-02 21:24:15,913:INFO:Creating metrics dataframe
2023-08-02 21:24:20,569:INFO:Uploading results into container
2023-08-02 21:24:20,570:INFO:Uploading model into container now
2023-08-02 21:24:20,571:INFO:_master_model_container: 12
2023-08-02 21:24:20,571:INFO:_display_container: 2
2023-08-02 21:24:20,572:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2020, verbose=0, warm_start=False)
2023-08-02 21:24:20,573:INFO:create_model() successfully completed......................................
2023-08-02 21:24:20,759:INFO:SubProcess create_model() end ==================================
2023-08-02 21:24:20,760:INFO:Creating metrics dataframe
2023-08-02 21:24:20,784:INFO:Initializing Light Gradient Boosting Machine
2023-08-02 21:24:20,784:INFO:Total runtime is 10.721797422568002 minutes
2023-08-02 21:24:20,790:INFO:SubProcess create_model() called ==================================
2023-08-02 21:24:20,791:INFO:Initializing create_model()
2023-08-02 21:24:20,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:24:20,791:INFO:Checking exceptions
2023-08-02 21:24:20,792:INFO:Importing libraries
2023-08-02 21:24:20,792:INFO:Copying training dataset
2023-08-02 21:24:20,805:INFO:Defining folds
2023-08-02 21:24:20,805:INFO:Declaring metric variables
2023-08-02 21:24:20,816:INFO:Importing untrained model
2023-08-02 21:24:20,826:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-02 21:24:20,843:INFO:Starting cross validation
2023-08-02 21:24:20,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:24:23,409:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,413:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,414:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,423:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,459:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,490:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,511:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:23,553:WARNING:C:\Users\faisa\AppData\Roaming\Python\Python39\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-08-02 21:24:54,731:INFO:Calculating mean and std
2023-08-02 21:24:54,733:INFO:Creating metrics dataframe
2023-08-02 21:24:59,127:INFO:Uploading results into container
2023-08-02 21:24:59,129:INFO:Uploading model into container now
2023-08-02 21:24:59,130:INFO:_master_model_container: 13
2023-08-02 21:24:59,130:INFO:_display_container: 2
2023-08-02 21:24:59,131:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2020, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-02 21:24:59,131:INFO:create_model() successfully completed......................................
2023-08-02 21:24:59,301:INFO:SubProcess create_model() end ==================================
2023-08-02 21:24:59,301:INFO:Creating metrics dataframe
2023-08-02 21:24:59,321:INFO:Initializing Dummy Classifier
2023-08-02 21:24:59,321:INFO:Total runtime is 11.364073133468628 minutes
2023-08-02 21:24:59,328:INFO:SubProcess create_model() called ==================================
2023-08-02 21:24:59,329:INFO:Initializing create_model()
2023-08-02 21:24:59,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024761828070>, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:24:59,329:INFO:Checking exceptions
2023-08-02 21:24:59,329:INFO:Importing libraries
2023-08-02 21:24:59,329:INFO:Copying training dataset
2023-08-02 21:24:59,342:INFO:Defining folds
2023-08-02 21:24:59,342:INFO:Declaring metric variables
2023-08-02 21:24:59,350:INFO:Importing untrained model
2023-08-02 21:24:59,359:INFO:Dummy Classifier Imported successfully
2023-08-02 21:24:59,374:INFO:Starting cross validation
2023-08-02 21:24:59,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-02 21:25:01,076:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,103:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,140:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,176:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,190:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,197:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,211:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:01,279:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:13,842:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:13,853:WARNING:c:\Users\faisa\.pyenv\pyenv-win\versions\3.9.13\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-02 21:25:35,498:INFO:Calculating mean and std
2023-08-02 21:25:35,501:INFO:Creating metrics dataframe
2023-08-02 21:25:40,911:INFO:Uploading results into container
2023-08-02 21:25:40,913:INFO:Uploading model into container now
2023-08-02 21:25:40,914:INFO:_master_model_container: 14
2023-08-02 21:25:40,915:INFO:_display_container: 2
2023-08-02 21:25:40,915:INFO:DummyClassifier(constant=None, random_state=2020, strategy='prior')
2023-08-02 21:25:40,916:INFO:create_model() successfully completed......................................
2023-08-02 21:25:41,111:INFO:SubProcess create_model() end ==================================
2023-08-02 21:25:41,111:INFO:Creating metrics dataframe
2023-08-02 21:25:41,163:INFO:Initializing create_model()
2023-08-02 21:25:41,163:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-02 21:25:41,164:INFO:Checking exceptions
2023-08-02 21:25:41,168:INFO:Importing libraries
2023-08-02 21:25:41,168:INFO:Copying training dataset
2023-08-02 21:25:41,185:INFO:Defining folds
2023-08-02 21:25:41,185:INFO:Declaring metric variables
2023-08-02 21:25:41,186:INFO:Importing untrained model
2023-08-02 21:25:41,186:INFO:Declaring custom model
2023-08-02 21:25:41,187:INFO:Linear Discriminant Analysis Imported successfully
2023-08-02 21:25:41,193:INFO:Cross validation set to False
2023-08-02 21:25:41,193:INFO:Fitting Model
2023-08-02 21:25:46,439:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-02 21:25:46,439:INFO:create_model() successfully completed......................................
2023-08-02 21:25:46,711:INFO:_master_model_container: 14
2023-08-02 21:25:46,711:INFO:_display_container: 2
2023-08-02 21:25:46,712:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-02 21:25:46,712:INFO:compare_models() successfully completed......................................
2023-08-02 21:26:02,460:INFO:Initializing evaluate_model()
2023-08-02 21:26:02,461:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-08-02 21:26:02,523:INFO:Initializing plot_model()
2023-08-02 21:26:02,523:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, system=True)
2023-08-02 21:26:02,524:INFO:Checking exceptions
2023-08-02 21:26:02,534:INFO:Preloading libraries
2023-08-02 21:26:02,536:INFO:Copying training dataset
2023-08-02 21:26:02,536:INFO:Plot type: pipeline
2023-08-02 21:26:03,597:INFO:Visual Rendered Successfully
2023-08-02 21:26:03,915:INFO:plot_model() successfully completed......................................
2023-08-02 21:26:17,566:INFO:Initializing plot_model()
2023-08-02 21:26:17,568:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000247880D63A0>, system=True)
2023-08-02 21:26:17,569:INFO:Checking exceptions
2023-08-02 21:26:17,575:INFO:Preloading libraries
2023-08-02 21:26:17,576:INFO:Copying training dataset
2023-08-02 21:26:17,577:INFO:Plot type: confusion_matrix
2023-08-02 21:26:17,877:INFO:Fitting Model
2023-08-02 21:26:17,877:INFO:Scoring test/hold-out set
2023-08-02 21:26:18,085:INFO:Visual Rendered Successfully
2023-08-02 21:26:18,286:INFO:plot_model() successfully completed......................................
